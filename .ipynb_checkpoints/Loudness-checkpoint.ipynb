{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data\n",
    "for this part we extract the wave file as well as the meta data. the data file has two channels that we are going to clean up before we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = wavfile.read('./LDC2002S28.wav')\n",
    "number_of_samples = data.shape[0]\n",
    "meta_data = open(r\"LDC2002S28-txt.txt\")\n",
    "meta_data = pd.read_csv(\"LDC2002S28-txt.txt\", sep=\"A:\", header=None, engine='python')\n",
    "meta_data.columns = [\"sound limits\",\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.average(data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High pass filter\n",
    "used a high pass filter to clean the noise from the dc signal setting the lowest frequeency possible to be 10 hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = butter_highpass_filter(data, 10, fs)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# divide the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_time_limits = meta_data[\"sound limits\"]\n",
    "\n",
    "voice_time_limits = [i.split(\" \")[0:2] for i in voice_time_limits]\n",
    "voice_time_limits = np.array(voice_time_limits)\n",
    "voice_time_limits = voice_time_limits.astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = 0\n",
    "divided_data = []\n",
    "for i in voice_time_limits:\n",
    "    startingpoint = int(i[0]*fs)\n",
    "    endingpoint = int(i[1]*fs)\n",
    "    divided_data.append(data[startingpoint:endingpoint])\n",
    "    data_number +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(divided_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"segmented_voice_data\",divided_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accepting input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input(voice_data):\n",
    "    fs, data = wavfile.read(voice_data)\n",
    "    number_of_samples = data.shape[0]\n",
    "    data = np.average(data, axis = 1)\n",
    "    data = butter_highpass_filter(data, 10, fs)\n",
    "    plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ronak give back ussr volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting the volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "THRESHOLD = 600\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    \"Trim the blank spots at the start and end\"\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    # Trim to the left\n",
    "    snd_data = _trim(snd_data)\n",
    "\n",
    "    # Trim to the right\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
    "    r = array('h', [0 for i in range(int(seconds*RATE))])\n",
    "    r.extend(snd_data)\n",
    "    r.extend([0 for i in range(int(seconds*RATE))])\n",
    "    return r\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end, and pads with 0.5 seconds of \n",
    "    blank sound to make sure VLC et al can play \n",
    "    it without getting chopped off.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 60:\n",
    "            break\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    r = trim(r)\n",
    "    r = add_silence(r, 0.5)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "def reply(user_volume):\n",
    "    speaker_volume = int(osascript.osascript('output volume of (get volume settings)')[1])\n",
    "    print(\"speaker volume is \" + str(speaker_volume))\n",
    "    print(\"user volume is \"+str(user_volume))\n",
    "    if(speaker_volume < user_volume):\n",
    "        new_volume = speaker_volume + (((speaker_volume - user_volume)**2) /100)\n",
    "    else:\n",
    "        new_volume = speaker_volume - (((speaker_volume - user_volume)**2) /100)\n",
    "    print(\"speaker new volume is \"+str(new_volume))\n",
    "    osascript.osascript(\"set volume output volume \"+str(new_volume)) \n",
    "    thing_to_say = 'hello, your volume is at'+str(int(new_volume))\n",
    "    os.system(\"say \"+thing_to_say)\n",
    "def voice_input(voice_data):\n",
    "    fs, data = wavfile.read(voice_data)\n",
    "    plt.plot(data)\n",
    "    number_of_samples = data.shape\n",
    "    plt.plot(data)\n",
    "    print(data)\n",
    "    data = butter_highpass_filter(data, 10, fs)\n",
    "    return data\n",
    "\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    print(b,a,data)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def remove_silence_from(amplitudes, threshold):\n",
    "    silenced = []\n",
    "    for x in amplitudes:\n",
    "        if x >= threshold:\n",
    "            silenced.append(x)\n",
    "    return silenced\n",
    "\n",
    "\n",
    "def get_loudness_stats(data):\n",
    "    divided_data = data\n",
    "\n",
    "    # Average data to step size\n",
    "    avg_step = 600\n",
    "    avg_data = np.mean(divided_data[:(len(divided_data)//avg_step)*avg_step].reshape(-1,avg_step), axis=1)\n",
    "    #apply envelope\n",
    "    hilbert_transformed = np.abs(scipy.signal.hilbert(avg_data))\n",
    "\n",
    "    plt.figure(0)\n",
    "    plt.plot(hilbert_transformed, label = \"envelope\")\n",
    "    plt.plot(avg_data)\n",
    "\n",
    "    #Alternate envelope makes smoother curves\n",
    "    b, a = scipy.signal.ellip(4, 0.01, 120, 0.125)\n",
    "    fgust = scipy.signal.filtfilt(b, a, hilbert_transformed, method=\"gust\")\n",
    "    fpad = scipy.signal.filtfilt(b, a, hilbert_transformed, padlen=50)\n",
    "    plt.figure(2)\n",
    "\n",
    "    plt.plot(avg_data)\n",
    "    plt.plot(fgust, 'b-', linewidth=4, label='gust')\n",
    "#     plt.plot(fpad, 'c-', linewidth=1.5, label='pad')\n",
    "    print(\"gust LOKO HERE\")\n",
    "    top_ten = int(len(fgust)/10)\n",
    "   \n",
    "\n",
    "    #remove silence \n",
    "    avg = np.mean(fgust)\n",
    "    silence_factor = 3\n",
    "    print(\"avg\")\n",
    "    print(avg)\n",
    "    plt.figure(1)\n",
    "    plt.plot(fgust)\n",
    "    silenced = remove_silence_from(fgust, avg)\n",
    "    plt.plot(silenced)\n",
    "\n",
    "    print(\"silenced\")\n",
    "    sil = silenced\n",
    "    top_ten = int(len(sil)/10)\n",
    "    print(len(sil))\n",
    "    print(np.max(sil))\n",
    "    print(np.mean(sil))\n",
    "    print(np.median(sil))\n",
    "    print(\"hety\")\n",
    "    print(np.mean(np.sort(sil)[-2*top_ten:-top_ten]))\n",
    "    \n",
    "    silenced = [4.80431404 * 1.007071904**x for x in sil] #convert to dB\n",
    "    \n",
    "    #return mean and median\n",
    "    mean = np.mean(silenced)\n",
    "    median = np.median(silenced)\n",
    "\n",
    "    print(\"exponential \"+str(mean))\n",
    "    \n",
    "    \n",
    "    silenced = [0.2043767*x - 7.405759 for x in sil] #convert to dB\n",
    "    \n",
    "    #return mean and median\n",
    "    mean = np.mean(silenced)\n",
    "    median = np.median(silenced)\n",
    "    print(\"linear \"+str(mean))\n",
    "    \n",
    "    \n",
    "    silenced = [-161.8752121 + 38.969402 *np.log(abs(x)+1) for x in sil] #convert to dB\n",
    "    #return mean and median\n",
    "    mean = np.mean(silenced)\n",
    "    median = np.median(silenced)\n",
    "    print(\"logirthimic \"+str(mean))\n",
    "    \n",
    "    silenced = [0.14315*(x**1.44146) for x in sil] #convert to dB\n",
    "    #return mean and median\n",
    "    mean = np.mean(silenced)\n",
    "    median = np.median(silenced)\n",
    "    print(\"power regression \"+str(mean))\n",
    "\n",
    "    return mean, median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_loudness2(data):\n",
    "    divided_data = data\n",
    "\n",
    "    # Average data to step size\n",
    "    avg_step = 500\n",
    "    avg_data = np.mean(divided_data[:(len(divided_data)//avg_step)*avg_step].reshape(-1,avg_step), axis=1)\n",
    "    #apply envelope\n",
    "    hilbert_transformed = np.abs(scipy.signal.hilbert(avg_data))\n",
    "\n",
    "    #Alternate envelope makes smoother curves\n",
    "    b, a = scipy.signal.ellip(4, 0.01, 120, 0.125)\n",
    "    fgust = scipy.signal.filtfilt(b, a, hilbert_transformed, method=\"gust\")\n",
    "    plt.figure(0)\n",
    "    plt.plot(avg_data)\n",
    "    plt.plot(fgust)\n",
    "\n",
    "    #remove silence \n",
    "    avg = np.mean(fgust)\n",
    "    silenced = remove_silence_from(fgust, avg)\n",
    "    plt.figure(3)\n",
    "    plt.plot(silenced)\n",
    "    print(\"look here\")\n",
    "    toReturn = 0.3747*np.median(silenced)-25\n",
    "    \n",
    "    return toReturn, toReturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please speak a word into the microphone\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno -9986] Internal PortAudio error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-327-af80859c56e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"please speak a word into the microphone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrecord_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'demo.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done - result written to demo.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoice_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'demo.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-321-39bccd4d4bb2>\u001b[0m in \u001b[0;36mrecord_to_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m\"Records from the microphone and outputs the resulting data to 'path'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0msample_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-321-39bccd4d4bb2>\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     stream = p.open(format=FORMAT, channels=1, rate=RATE,\n\u001b[1;32m     70\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         frames_per_buffer=CHUNK_SIZE)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnum_silent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# calling pa.open returns a stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_latency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLatency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -9986] Internal PortAudio error"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"please speak a word into the microphone\")\n",
    "    record_to_file('demo.wav')\n",
    "    print(\"done - result written to demo.wav\")\n",
    "    data = voice_input('demo.wav')\n",
    "    new_volume = getting_loudness2(data)\n",
    "    reply(new_volume[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.67755152752272"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =10\n",
    "20 * np.log10(x+1)*x**(1/11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
