{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import time\n",
    "import subprocess\n",
    "import pyttsx3\n",
    "import tkinter\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDPASS_FREQ = [300, 3400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data\n",
    "for this part we extract the wave file as well as the meta data. the data file has two channels that we are going to clean up before we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = wavfile.read('../../LDC2002S28.wav')\n",
    "number_of_samples = data.shape[0]\n",
    "meta_data = open(r\"../../LDC2002S28-txt.txt\")\n",
    "meta_data = pd.read_csv(\"../../LDC2002S28-txt.txt\", sep=\"A:\", header=None, engine='python')\n",
    "meta_data.columns = [\"sound limits\",\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.average(data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x131256390>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], btype='band', analog=False, output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfiltfilt(sos, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = butter_bandpass_filter(data, BANDPASS_FREQ[0], BANDPASS_FREQ[1], fs)\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# divide the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_time_limits = meta_data[\"sound limits\"]\n",
    "\n",
    "voice_time_limits = [i.split(\" \")[0:2] for i in voice_time_limits]\n",
    "voice_time_limits = np.array(voice_time_limits)\n",
    "voice_time_limits = voice_time_limits.astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = 0\n",
    "divided_data = []\n",
    "for i in voice_time_limits:\n",
    "    startingpoint = int(i[0]*fs)\n",
    "    endingpoint = int(i[1]*fs)\n",
    "    divided_data.append(data[startingpoint:endingpoint])\n",
    "    data_number +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(divided_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"segmented_voice_data\",divided_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input(voice_data):\n",
    "    fs, data = wavfile.read(voice_data)\n",
    "    number_of_samples = data.shape[0]\n",
    "    data = np.average(data, axis = 1)\n",
    "    data = butter_highpass_filter(data, 10, fs)\n",
    "    plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
