{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.Pitch_vector import get_pitch_stats\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import time\n",
    "from ipynb.fs.full.Pitch_vector import get_lpc_stats\n",
    "from ipynb.fs.full.Pitch_vector import get_spectral_stats\n",
    "import ipynb.fs.full.concat_project2 as features_aron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDPASS_FREQ = [300, 3400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# butter pass filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], btype='band', analog=False, output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfiltfilt(sos, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data\n",
    "for this part we extract the wave file as well as the meta data. the data file has two channels that we are going to clean up before we use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_location):\n",
    "    fs, data = wavfile.read(file_location)\n",
    "    number_of_samples = data.shape[0]\n",
    "    meta_data = open(r\"LDC2002S28-txt.txt\")\n",
    "    meta_data = pd.read_csv(\"LDC2002S28-txt.txt\", sep=\"A:\", header=None, engine='python')\n",
    "    meta_data.columns = [\"sound limits\",\"description\"]\n",
    "    \n",
    "    #dual channel to one channel\n",
    "    data = np.average(data, axis = 1)\n",
    "    #remove noise\n",
    "    data = butter_bandpass_filter(data, BANDPASS_FREQ[0], BANDPASS_FREQ[1], fs)\n",
    "    \n",
    "    # removee extra data pointts\n",
    "    meta_data = meta_data[meta_data.description != ' [MISC]']\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith(' (')]\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith(' Emotion category elation')]\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith('  [MISC]')]\n",
    "\n",
    "    # description and time limits \n",
    "    voice_time_limits = meta_data[\"sound limits\"]\n",
    "    voice_time_limits = [i.split(\" \")[0:2] for i in voice_time_limits]\n",
    "    voice_time_limits = np.array(voice_time_limits)\n",
    "    voice_time_limits = voice_time_limits.astype(np.float)\n",
    "    description = meta_data[\"description\"]\n",
    "    description = [i.split(\",\")[0].strip() for i in description]\n",
    "\n",
    "    #divide the dataa set\n",
    "    divided_data = []\n",
    "    for i in voice_time_limits:\n",
    "        startingpoint = int(i[0]*fs)\n",
    "        endingpoint = int(i[1]*fs)\n",
    "        divided_data.append(data[startingpoint:endingpoint])\n",
    "    np_data = np.asarray(divided_data)\n",
    "    return np_data, description, len(divided_data), fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC algorithm\n",
    "gets the data as the input and then uses the data to find our the first 13 MFC coef for every 25 ms which are then used to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC_algorithm(np_data):\n",
    "        # MFCC function taking the first thirteen coef\n",
    "    MFCC2 = []\n",
    "    for i in np_data:\n",
    "        i = np.asarray(i)\n",
    "        MFCC2.append(python_speech_features.base.mfcc(i, samplerate=fs, \n",
    "                                     winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                     nfilt=26, nfft=552))\n",
    "        \n",
    "    # gather information from the MFCC (feature extraction)\n",
    "    MFCC3 = []\n",
    "    cache = {}\n",
    "    for data_point in MFCC2:\n",
    "        for time_segment in data_point:\n",
    "            if (data_point[0] == time_segment).all():\n",
    "                for i in range(13):\n",
    "                    cache[i] = [time_segment[i]]\n",
    "            else:\n",
    "                for i in range(13):\n",
    "                    cache[i] = np.concatenate((cache[i], [time_segment[i]]))\n",
    "        cached_variables = []\n",
    "        cache_grad = []\n",
    "        for i in range(13):\n",
    "            cache_grad.append(np.gradient(cache[i]))\n",
    "            cached_variables.append([np.mean(cache[i]), np.median(cache[i]), np.var(cache[i]), \n",
    "                               np.min(cache[i]), np.max(cache[i]), \n",
    "                                     np.mean(cache_grad[i]), np.var(cache_grad[i])])\n",
    "        MFCC3.append(np.hstack(np.hstack(cached_variables)))\n",
    "    return MFCC3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emotional extraction\n",
    "given an array of the emotions it converts the array to a number, if an emotion is not there it will print it out and break the loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emotion_extraction(description, number_examples):\n",
    "    nu_emotion = 15\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    for i in description:\n",
    "        X0 = np.zeros((number_examples,1))\n",
    "        if i == 'neutral':\n",
    "            y[0][counter] = 1\n",
    "        elif i == 'disgust':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'panic':\n",
    "             y[2][counter] = 1\n",
    "        elif i == 'anxiety':\n",
    "             y[3][counter] = 1\n",
    "        elif i == 'hot anger':\n",
    "             y[4][counter] = 1\n",
    "        elif i == 'cold anger':\n",
    "             y[5][counter] = 1\n",
    "        elif i == 'despair':\n",
    "             y[6][counter] = 1\n",
    "        elif i == 'sadness':\n",
    "             y[7][counter] = 1\n",
    "        elif i == 'elation':\n",
    "             y[8][counter] = 1\n",
    "        elif i == 'happy':\n",
    "             y[9][counter] = 1\n",
    "        elif i == 'interest':\n",
    "             y[10][counter] = 1\n",
    "        elif i == 'boredom':\n",
    "             y[11][counter] = 1\n",
    "        elif i == 'shame':\n",
    "             y[12][counter] = 1\n",
    "        elif i == 'pride':\n",
    "             y[13][counter] = 1\n",
    "        elif i == 'contempt':\n",
    "             y[14][counter] = 1\n",
    "        else:\n",
    "            print(i)\n",
    "            break\n",
    "        counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_y(description, number_examples):\n",
    "    nu_emotion = 2\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    for i in description:\n",
    "        if i == 'neutral':\n",
    "            y[0][counter] = 1\n",
    "        elif i == 'disgust':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'panic':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'anxiety':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'hot anger':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'cold anger':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'despair':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'sadness':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'elation':\n",
    "             y[0][counter] = 1\n",
    "        elif i == 'happy':\n",
    "             y[0][counter] = 1\n",
    "        elif i == 'interest':\n",
    "             y[0][counter] = 1\n",
    "        elif i == 'boredom':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'shame':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'pride':\n",
    "             y[0][counter] = 1\n",
    "        elif i == 'contempt':\n",
    "             y[1][counter] = 1\n",
    "        else:\n",
    "            print(i)\n",
    "            break\n",
    "        counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network \n",
    "MLP algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f2c18a3a7ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../LDC2002S28.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFCC_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#x1 = get_pitch_stats(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spectral_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_data' is not defined"
     ]
    }
   ],
   "source": [
    "data, description, data_len, fs = extract_data('../../LDC2002S28.wav')\n",
    "x = MFCC_algorithm(data)\n",
    "x1 = get_pitch_stats(data)\n",
    "x2 = get_spectral_stats(data)\n",
    "tic = time.time()\n",
    "x3 = get_lpc_stats(data)\n",
    "toc = time.time()\n",
    "x4 = features_aron.get_rms_stats(data, fs)\n",
    "x5 = features_aron.get_sr_stats(data, fs)\n",
    "x6 = features_aron.get_zero_stats(data, fs)\n",
    "x = np.concatenate((x,x1,x2,x3,x4, x5, x6), axis=1)\n",
    "y = emotion_extraction(description, data_len)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "num_labels = y_train.shape[1]\n",
    "num_features = X_train.shape[1]\n",
    "print(\"x train shape: \" +str(X_train.shape))\n",
    "print(\"y train shape: \" +str(y_train.shape))\n",
    "print(\"x test shape: \" +str(X_test.shape))\n",
    "print(\"y test shape: \" +str(y_test.shape))\n",
    "for i in range(num_labels):\n",
    "    print(\"y_train for emotion \"+str(i)+\": \"+ str(np.sum(y_train[:,i])))\n",
    "for i in range(num_labels):\n",
    "    print(\"y_test for emotion \"+str(i)+\": \"+ str(np.sum(y_test[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnData ():\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTestData ():\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
