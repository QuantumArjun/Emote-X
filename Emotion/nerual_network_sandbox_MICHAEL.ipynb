{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.Pitch_vector import get_pitch_stats\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import time\n",
    "import  ipynb.fs.full.concat_project2 as emotex_lib\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import keras as keras\n",
    "from  conch.analysis.formants import lpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, fs, x_size = emotex_lib.data_extraction_RAVDESS('../../RAVDESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DELETE\", (X,fs,x_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,fs,x_size) = np.load(\"DELETE.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dimensions are \"+str([len(X), len(X[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC DONE\n",
      "dimensions are [1380, 91]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))\n",
    "seed = 20\n",
    "num_labels =15\n",
    "num_features = X_train.shape[1]\n",
    "# build model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=num_features, activation='softmax'))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    model.add(Dense(output_dim = num_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adadelta(), metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "def big_boy_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def complex_layers():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 5,padding='same', input_shape=( 11,13, 1))) #1\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #2\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #3\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #5\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #6\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10)) #7\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    return model\n",
    "def easy_NN():\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = X\n",
    "MFCC2 = []\n",
    "for one_sound in np_data:\n",
    "    one_sound = np.asarray(one_sound)\n",
    "    MFCC2.append(python_speech_features.base.mfcc(one_sound, samplerate=fs, \n",
    "                                 winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                 nfilt=26, nfft=1200).T)\n",
    "MFCC3 = []\n",
    "cached_variables = []\n",
    "for one_point in MFCC2:\n",
    "    cache_grad = (np.gradient(one_point, axis = 1))\n",
    "    cached_variables.append([np.mean(one_point, axis = 1), np.median(one_point, axis = 1),\n",
    "                             np.var(one_point, axis = 1), \n",
    "                       np.min(one_point, axis = 1), np.max(one_point, axis = 1), \n",
    "                             np.mean(cache_grad, axis = 1), np.var(cache_grad, axis = 1)])\n",
    "return cached_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(one_point, axis = 1).shape, np.median(one_point, axis = 1).shape,np.var(one_point, axis = 1).shape, np.min(one_point, axis = 1).shape, np.max(one_point, axis = 1).shape, np.mean(cache_grad, axis = 1).shape, np.var(cache_grad, axis = 1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(please.T, axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MFCC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MFCC2[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.gradient(MFCC2[0], axis = 1)), len(np.gradient(MFCC2[0], axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
