{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.Pitch_vector import get_pitch_stats\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import time\n",
    "import  ipynb.fs.full.concat_project2 as emotex_lib\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import keras as keras\n",
    "from  conch.analysis.formants import lpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, fs, x_size = emotex_lib.data_extraction_RAVDESS('../../RAVDESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DELETE\", (X,fs,x_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,fs,x_size) = np.load(\"DELETE.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dimensions are \"+str([len(X), len(X[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"RAVDESS_X_Y_train_test\", (X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC DONE\n",
      "dimensions are [1380, 91]\n",
      "pitch DONE\n",
      "dimensions are [1380, 8]\n",
      "spectral DONE\n",
      "dimensions are [1380, 8]\n",
      "rms DONE\n",
      "dimensions are [1380, 8]\n",
      "sr DONE\n",
      "dimensions are [1380, 8]\n",
      "zero DONE\n",
      "dimensions are [1380, 8]\n",
      "x train shape: (1104, 131)\n",
      "y train shape: (1104, 8)\n",
      "x test shape: (276, 131)\n",
      "y test shape: (276, 8)\n",
      "y_train for emotion 0: 594.0\n",
      "y_train for emotion 1: 510.0\n",
      "y_train for emotion 2: 0.0\n",
      "y_train for emotion 3: 0.0\n",
      "y_train for emotion 4: 0.0\n",
      "y_train for emotion 5: 0.0\n",
      "y_train for emotion 6: 0.0\n",
      "y_train for emotion 7: 0.0\n",
      "y_test for emotion 0: 142.0\n",
      "y_test for emotion 1: 134.0\n",
      "y_test for emotion 2: 0.0\n",
      "y_test for emotion 3: 0.0\n",
      "y_test for emotion 4: 0.0\n",
      "y_test for emotion 5: 0.0\n",
      "y_test for emotion 6: 0.0\n",
      "y_test for emotion 7: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_extraction_RAVDESS(folder_location, number_examples):\n",
    "    nu_emotion = 8\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    directory = os.fsencode(folder_location)\n",
    "    for file_name in os.listdir(directory):\n",
    "        if  str(file_name) != \"b'.DS_Store'\":\n",
    "            emotion = str(file_name)[2:-1]\n",
    "            i = (emotion.split('-')[3])\n",
    "            if i == '01': # neutral \n",
    "                y[0][counter] = 1\n",
    "            elif i == '02': #calm\n",
    "                 y[1][counter] = 1\n",
    "            elif i == '03': #hahppy \n",
    "                 y[2][counter] = 1\n",
    "            elif i == '04': #sad\n",
    "                 y[3][counter] = 1\n",
    "            elif i == '05': #angry\n",
    "                 y[4][counter] = 1\n",
    "            elif i == '06': #fearful\n",
    "                 y[5][counter] = 1\n",
    "            elif i == '07': #disgust\n",
    "                 y[6][counter] = 1\n",
    "            elif i == '08': #surprised\n",
    "                 y[7][counter] = 1\n",
    "            else:\n",
    "                print(i)\n",
    "                break\n",
    "            counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.51      0.66       594\n",
      "           1       0.90      0.55      0.68       510\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.53      0.67      1104\n",
      "   macro avg       0.23      0.13      0.17      1104\n",
      "weighted avg       0.92      0.53      0.67      1104\n",
      " samples avg       0.53      0.53      0.53      1104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.45      0.56       142\n",
      "           1       0.75      0.46      0.57       134\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.75      0.45      0.56       276\n",
      "   macro avg       0.19      0.11      0.14       276\n",
      "weighted avg       0.75      0.45      0.56       276\n",
      " samples avg       0.45      0.45      0.45       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (15000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))\n",
    "seed = 20\n",
    "num_labels =15\n",
    "num_features = X_train.shape[1]\n",
    "# build model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=num_features, activation='softmax'))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    model.add(Dense(output_dim = num_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adadelta(), metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "def big_boy_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def complex_layers():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 5,padding='same', input_shape=( 11,13, 1))) #1\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #2\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #3\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #5\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #6\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10)) #7\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    return model\n",
    "def easy_NN():\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = X\n",
    "MFCC2 = []\n",
    "for one_sound in np_data:\n",
    "    one_sound = np.asarray(one_sound)\n",
    "    MFCC2.append(python_speech_features.base.mfcc(one_sound, samplerate=fs, \n",
    "                                 winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                 nfilt=26, nfft=1200).T)\n",
    "MFCC3 = []\n",
    "cached_variables = []\n",
    "for one_point in MFCC2:\n",
    "    cache_grad = (np.gradient(one_point, axis = 1))\n",
    "    cached_variables.append([np.mean(one_point, axis = 1), np.median(one_point, axis = 1),\n",
    "                             np.var(one_point, axis = 1), \n",
    "                       np.min(one_point, axis = 1), np.max(one_point, axis = 1), \n",
    "                             np.mean(cache_grad, axis = 1), np.var(cache_grad, axis = 1)])\n",
    "return cached_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(one_point, axis = 1).shape, np.median(one_point, axis = 1).shape,np.var(one_point, axis = 1).shape, np.min(one_point, axis = 1).shape, np.max(one_point, axis = 1).shape, np.mean(cache_grad, axis = 1).shape, np.var(cache_grad, axis = 1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(please.T, axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MFCC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MFCC2[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.gradient(MFCC2[0], axis = 1)), len(np.gradient(MFCC2[0], axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
