{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib qt\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import keras as keras\n",
    "from  conch.analysis.formants import lpc\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import  ipynb.fs.full.concat_project3 as emotex_lib\n",
    "from keras import regularizers\n",
    "import time\n",
    "from keras import backend as K\n",
    "import sherpa\n",
    "import sherpa.algorithms.bayesian_optimization as bayesian_optimization\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = np.load(\"../../splitdata.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_NN(X_train, X_test, y_train, y_test, regularization = 0.0,drop_likely = 0.0,\n",
    "              learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999,\n",
    "             num_iterations = 40, size_batch=X_train.shape[0],\n",
    "             activation = 'tanh'):\n",
    "    target_class = y_train.shape[1]\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=X_train.shape[1], \n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(1024, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(512, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(target_class, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(lr=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=10e-8)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    nn_history = model.fit(X_train, y_train, batch_size=size_batch, epochs=num_iterations, \n",
    "                         validation_data=(X_test, y_test))\n",
    "                          \n",
    "    \n",
    "    \n",
    "    return model, nn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 14:38:03.411849 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 14:38:03.424428 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 14:38:03.426460 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0722 14:38:03.495229 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0722 14:38:03.632057 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0722 14:38:03.638837 140735512335232 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0722 14:38:03.722009 140735512335232 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 4s 452us/step - loss: 2.7249 - acc: 0.0808 - val_loss: 3.6547 - val_acc: 0.2627\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 3.4377 - acc: 0.2867 - val_loss: 2.8256 - val_acc: 0.3605\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 2.7418 - acc: 0.3911 - val_loss: 2.6806 - val_acc: 0.3116\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.4701 - acc: 0.3499 - val_loss: 1.8702 - val_acc: 0.4366\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 423us/step - loss: 1.7988 - acc: 0.4620 - val_loss: 1.8741 - val_acc: 0.4013\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 426us/step - loss: 1.7541 - acc: 0.4497 - val_loss: 1.6412 - val_acc: 0.4574\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: 1.5461 - acc: 0.4876 - val_loss: 1.5664 - val_acc: 0.4620\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 432us/step - loss: 1.4671 - acc: 0.5013 - val_loss: 1.5441 - val_acc: 0.4466\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 447us/step - loss: 1.4210 - acc: 0.4913 - val_loss: 1.4783 - val_acc: 0.4656\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 1.3598 - acc: 0.5100 - val_loss: 1.4188 - val_acc: 0.4846\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: 1.3070 - acc: 0.5264 - val_loss: 1.3943 - val_acc: 0.5000\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.2669 - acc: 0.5475 - val_loss: 1.3825 - val_acc: 0.5000\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 463us/step - loss: 1.2269 - acc: 0.5574 - val_loss: 1.3618 - val_acc: 0.5163\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 451us/step - loss: 1.1828 - acc: 0.5782 - val_loss: 1.3630 - val_acc: 0.5154\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 1.1630 - acc: 0.5842 - val_loss: 1.3515 - val_acc: 0.5217\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 413us/step - loss: 1.1359 - acc: 0.5913 - val_loss: 1.3211 - val_acc: 0.5236\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: 1.0959 - acc: 0.6106 - val_loss: 1.3070 - val_acc: 0.5272\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 403us/step - loss: 1.0703 - acc: 0.6190 - val_loss: 1.2977 - val_acc: 0.5254\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 1.0445 - acc: 0.6216 - val_loss: 1.2854 - val_acc: 0.5190\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: 1.0106 - acc: 0.6395 - val_loss: 1.2855 - val_acc: 0.5245\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 413us/step - loss: 0.9856 - acc: 0.6478 - val_loss: 1.2832 - val_acc: 0.5299\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 406us/step - loss: 0.9616 - acc: 0.6568 - val_loss: 1.2723 - val_acc: 0.5462\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 0.9331 - acc: 0.6703 - val_loss: 1.2629 - val_acc: 0.5444\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 0.9058 - acc: 0.6830 - val_loss: 1.2572 - val_acc: 0.5516\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 0.8792 - acc: 0.6928 - val_loss: 1.2567 - val_acc: 0.5516\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 423us/step - loss: 0.8571 - acc: 0.6986 - val_loss: 1.2498 - val_acc: 0.5589\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 0.8335 - acc: 0.7124 - val_loss: 1.2381 - val_acc: 0.5607\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 0.8071 - acc: 0.7264 - val_loss: 1.2333 - val_acc: 0.5543\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.7815 - acc: 0.7361 - val_loss: 1.2327 - val_acc: 0.5525\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.7589 - acc: 0.7462 - val_loss: 1.2248 - val_acc: 0.5607\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 3s 359us/step - loss: 0.7347 - acc: 0.7583 - val_loss: 1.2207 - val_acc: 0.5607\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 0.7106 - acc: 0.7697 - val_loss: 1.2256 - val_acc: 0.5616\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 0.6873 - acc: 0.7765 - val_loss: 1.2319 - val_acc: 0.5616\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 3s 382us/step - loss: 0.6628 - acc: 0.7871 - val_loss: 1.2391 - val_acc: 0.5589\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 0.6411 - acc: 0.7974 - val_loss: 1.2372 - val_acc: 0.5661\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 0.6186 - acc: 0.8102 - val_loss: 1.2234 - val_acc: 0.5697\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 0.5943 - acc: 0.8218 - val_loss: 1.2228 - val_acc: 0.5734\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 3s 367us/step - loss: 0.5722 - acc: 0.8309 - val_loss: 1.2215 - val_acc: 0.5797\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 0.5497 - acc: 0.8428 - val_loss: 1.2292 - val_acc: 0.5697\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 0.5264 - acc: 0.8517 - val_loss: 1.2361 - val_acc: 0.5734\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 0.5045 - acc: 0.8602 - val_loss: 1.2312 - val_acc: 0.5725\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 3s 358us/step - loss: 0.4823 - acc: 0.8690 - val_loss: 1.2369 - val_acc: 0.5707\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: 0.4611 - acc: 0.8753 - val_loss: 1.2274 - val_acc: 0.5725\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 0.4464 - acc: 0.8835 - val_loss: 1.3034 - val_acc: 0.5670\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 0.4645 - acc: 0.8633 - val_loss: 1.4280 - val_acc: 0.5299\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 3s 366us/step - loss: 0.6115 - acc: 0.8096 - val_loss: 1.4309 - val_acc: 0.5435\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.5061 - acc: 0.8383 - val_loss: 1.2481 - val_acc: 0.5697\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 0.4044 - acc: 0.8970 - val_loss: 1.2993 - val_acc: 0.5543\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 3s 368us/step - loss: 0.4366 - acc: 0.8779 - val_loss: 1.2661 - val_acc: 0.5806\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 3s 360us/step - loss: 0.3716 - acc: 0.9058 - val_loss: 1.3235 - val_acc: 0.5797\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 3s 358us/step - loss: 0.3782 - acc: 0.8979 - val_loss: 1.3284 - val_acc: 0.5788\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.3486 - acc: 0.9172 - val_loss: 1.2773 - val_acc: 0.5779\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 3s 354us/step - loss: 0.3266 - acc: 0.9286 - val_loss: 1.2790 - val_acc: 0.5752\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.3153 - acc: 0.9331 - val_loss: 1.3032 - val_acc: 0.5734\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 0.2853 - acc: 0.9380 - val_loss: 1.3408 - val_acc: 0.5661\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: 0.2808 - acc: 0.9407 - val_loss: 1.3275 - val_acc: 0.5725\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 3s 360us/step - loss: 0.2465 - acc: 0.9531 - val_loss: 1.3083 - val_acc: 0.5670\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 3s 395us/step - loss: 0.2401 - acc: 0.9581 - val_loss: 1.2918 - val_acc: 0.5842\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 0.2164 - acc: 0.9618 - val_loss: 1.3348 - val_acc: 0.5679\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 3s 373us/step - loss: 0.2025 - acc: 0.9643 - val_loss: 1.3620 - val_acc: 0.5679\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 0.1922 - acc: 0.9709 - val_loss: 1.3716 - val_acc: 0.5743\n",
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 0.1752 - acc: 0.9717 - val_loss: 1.3335 - val_acc: 0.5688\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 3s 360us/step - loss: 0.1649 - acc: 0.9788 - val_loss: 1.3723 - val_acc: 0.5670\n",
      "Epoch 64/150\n",
      "8829/8829 [==============================] - 3s 396us/step - loss: 0.1591 - acc: 0.9741 - val_loss: 1.3671 - val_acc: 0.5743\n",
      "Epoch 65/150\n",
      "8829/8829 [==============================] - 3s 358us/step - loss: 0.1745 - acc: 0.9661 - val_loss: 1.5709 - val_acc: 0.5380\n",
      "Epoch 66/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 0.2287 - acc: 0.9361 - val_loss: 1.5468 - val_acc: 0.5471\n",
      "Epoch 67/150\n",
      "8829/8829 [==============================] - 3s 360us/step - loss: 0.2664 - acc: 0.9148 - val_loss: 1.6271 - val_acc: 0.5525\n",
      "Epoch 68/150\n",
      "8829/8829 [==============================] - 3s 369us/step - loss: 0.2359 - acc: 0.9365 - val_loss: 1.4796 - val_acc: 0.5553\n",
      "Epoch 69/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 0.1676 - acc: 0.9568 - val_loss: 1.5217 - val_acc: 0.5480\n",
      "Epoch 70/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 0.2075 - acc: 0.9353 - val_loss: 1.5019 - val_acc: 0.5707\n",
      "Epoch 71/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 0.1880 - acc: 0.9488 - val_loss: 1.7013 - val_acc: 0.5290\n",
      "Epoch 72/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 0.2517 - acc: 0.9143 - val_loss: 1.5474 - val_acc: 0.5589\n",
      "Epoch 73/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 0.1848 - acc: 0.9551 - val_loss: 1.5794 - val_acc: 0.5498\n",
      "Epoch 74/150\n",
      "8829/8829 [==============================] - 3s 357us/step - loss: 0.1829 - acc: 0.9497 - val_loss: 1.5093 - val_acc: 0.5761\n",
      "Epoch 75/150\n",
      "8829/8829 [==============================] - 3s 355us/step - loss: 0.1325 - acc: 0.9743 - val_loss: 1.5295 - val_acc: 0.5634\n",
      "Epoch 76/150\n",
      "8829/8829 [==============================] - 3s 355us/step - loss: 0.1275 - acc: 0.9746 - val_loss: 1.5774 - val_acc: 0.5507\n",
      "Epoch 77/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 0.1261 - acc: 0.9718 - val_loss: 1.5512 - val_acc: 0.5607\n",
      "Epoch 78/150\n",
      "8829/8829 [==============================] - 3s 368us/step - loss: 0.1088 - acc: 0.9820 - val_loss: 1.4982 - val_acc: 0.5725\n",
      "Epoch 79/150\n",
      "8829/8829 [==============================] - 3s 352us/step - loss: 0.0872 - acc: 0.9909 - val_loss: 1.5286 - val_acc: 0.5752\n",
      "Epoch 80/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.0909 - acc: 0.9887 - val_loss: 1.5637 - val_acc: 0.5670\n",
      "Epoch 81/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.0861 - acc: 0.9871 - val_loss: 1.5495 - val_acc: 0.5752\n",
      "Epoch 82/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.0641 - acc: 0.9959 - val_loss: 1.5622 - val_acc: 0.5770\n",
      "Epoch 83/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0645 - acc: 0.9947 - val_loss: 1.5742 - val_acc: 0.5725\n",
      "Epoch 84/150\n",
      "8829/8829 [==============================] - 3s 372us/step - loss: 0.0640 - acc: 0.9938 - val_loss: 1.5716 - val_acc: 0.5670\n",
      "Epoch 85/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 0.0517 - acc: 0.9976 - val_loss: 1.5446 - val_acc: 0.5788\n",
      "Epoch 86/150\n",
      "8829/8829 [==============================] - 3s 372us/step - loss: 0.0427 - acc: 0.9983 - val_loss: 1.5717 - val_acc: 0.5851\n",
      "Epoch 87/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 0.0491 - acc: 0.9960 - val_loss: 1.5666 - val_acc: 0.5779\n",
      "Epoch 88/150\n",
      "8829/8829 [==============================] - 3s 371us/step - loss: 0.0414 - acc: 0.9981 - val_loss: 1.5508 - val_acc: 0.5770\n",
      "Epoch 89/150\n",
      "8829/8829 [==============================] - 3s 347us/step - loss: 0.0337 - acc: 0.9990 - val_loss: 1.5694 - val_acc: 0.5679\n",
      "Epoch 90/150\n",
      "8829/8829 [==============================] - 3s 369us/step - loss: 0.0325 - acc: 0.9991 - val_loss: 1.6043 - val_acc: 0.5670\n",
      "Epoch 91/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 0.0322 - acc: 0.9989 - val_loss: 1.6196 - val_acc: 0.5716\n",
      "Epoch 92/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.0292 - acc: 0.9992 - val_loss: 1.6168 - val_acc: 0.5797\n",
      "Epoch 93/150\n",
      "8829/8829 [==============================] - 3s 370us/step - loss: 0.0244 - acc: 0.9995 - val_loss: 1.6236 - val_acc: 0.5815\n",
      "Epoch 94/150\n",
      "8829/8829 [==============================] - 3s 359us/step - loss: 0.0230 - acc: 0.9995 - val_loss: 1.6205 - val_acc: 0.5888\n",
      "Epoch 95/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 0.0224 - acc: 0.9995 - val_loss: 1.6024 - val_acc: 0.5870\n",
      "Epoch 96/150\n",
      "8829/8829 [==============================] - 3s 348us/step - loss: 0.0204 - acc: 0.9998 - val_loss: 1.5991 - val_acc: 0.5842\n",
      "Epoch 97/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.0187 - acc: 0.9998 - val_loss: 1.6121 - val_acc: 0.5806\n",
      "Epoch 98/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.0171 - acc: 0.9998 - val_loss: 1.6360 - val_acc: 0.5806\n",
      "Epoch 99/150\n",
      "8829/8829 [==============================] - 3s 372us/step - loss: 0.0161 - acc: 0.9998 - val_loss: 1.6608 - val_acc: 0.5815\n",
      "Epoch 100/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 0.0155 - acc: 0.9998 - val_loss: 1.6714 - val_acc: 0.5779\n",
      "Epoch 101/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0141 - acc: 0.9998 - val_loss: 1.6721 - val_acc: 0.5761\n",
      "Epoch 102/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0129 - acc: 0.9998 - val_loss: 1.6722 - val_acc: 0.5806\n",
      "Epoch 103/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0123 - acc: 0.9998 - val_loss: 1.6727 - val_acc: 0.5806\n",
      "Epoch 104/150\n",
      "8829/8829 [==============================] - 3s 347us/step - loss: 0.0117 - acc: 0.9998 - val_loss: 1.6734 - val_acc: 0.5770\n",
      "Epoch 105/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.0111 - acc: 0.9998 - val_loss: 1.6763 - val_acc: 0.5806\n",
      "Epoch 106/150\n",
      "8829/8829 [==============================] - 3s 349us/step - loss: 0.0106 - acc: 0.9998 - val_loss: 1.6803 - val_acc: 0.5788\n",
      "Epoch 107/150\n",
      "8829/8829 [==============================] - 3s 359us/step - loss: 0.0100 - acc: 0.9998 - val_loss: 1.6851 - val_acc: 0.5888\n",
      "Epoch 108/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.0094 - acc: 0.9998 - val_loss: 1.6938 - val_acc: 0.5897\n",
      "Epoch 109/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 0.0089 - acc: 0.9998 - val_loss: 1.7072 - val_acc: 0.5824\n",
      "Epoch 110/150\n",
      "8829/8829 [==============================] - 3s 357us/step - loss: 0.0085 - acc: 0.9998 - val_loss: 1.7219 - val_acc: 0.5806\n",
      "Epoch 111/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 0.0082 - acc: 0.9998 - val_loss: 1.7337 - val_acc: 0.5842\n",
      "Epoch 112/150\n",
      "8829/8829 [==============================] - 3s 367us/step - loss: 0.0078 - acc: 0.9998 - val_loss: 1.7409 - val_acc: 0.5833\n",
      "Epoch 113/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.0075 - acc: 0.9998 - val_loss: 1.7440 - val_acc: 0.5806\n",
      "Epoch 114/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0072 - acc: 0.9998 - val_loss: 1.7441 - val_acc: 0.5779\n",
      "Epoch 115/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0069 - acc: 0.9998 - val_loss: 1.7431 - val_acc: 0.5761\n",
      "Epoch 116/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0066 - acc: 0.9998 - val_loss: 1.7433 - val_acc: 0.5725\n",
      "Epoch 117/150\n",
      "8829/8829 [==============================] - 3s 356us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 1.7461 - val_acc: 0.5770\n",
      "Epoch 118/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 1.7514 - val_acc: 0.5806\n",
      "Epoch 119/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0060 - acc: 0.9998 - val_loss: 1.7583 - val_acc: 0.5779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "8829/8829 [==============================] - 3s 357us/step - loss: 0.0058 - acc: 0.9998 - val_loss: 1.7654 - val_acc: 0.5779\n",
      "Epoch 121/150\n",
      "8829/8829 [==============================] - 3s 346us/step - loss: 0.0056 - acc: 0.9998 - val_loss: 1.7719 - val_acc: 0.5797\n",
      "Epoch 122/150\n",
      "8829/8829 [==============================] - 3s 347us/step - loss: 0.0054 - acc: 0.9998 - val_loss: 1.7768 - val_acc: 0.5806\n",
      "Epoch 123/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 0.0053 - acc: 0.9998 - val_loss: 1.7802 - val_acc: 0.5806\n",
      "Epoch 124/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 1.7824 - val_acc: 0.5833\n",
      "Epoch 125/150\n",
      "8829/8829 [==============================] - 3s 355us/step - loss: 0.0050 - acc: 0.9998 - val_loss: 1.7847 - val_acc: 0.5824\n",
      "Epoch 126/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.0049 - acc: 0.9998 - val_loss: 1.7879 - val_acc: 0.5806\n",
      "Epoch 127/150\n",
      "8829/8829 [==============================] - 3s 370us/step - loss: 0.0048 - acc: 0.9998 - val_loss: 1.7921 - val_acc: 0.5770\n",
      "Epoch 128/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 0.0046 - acc: 0.9998 - val_loss: 1.7968 - val_acc: 0.5725\n",
      "Epoch 129/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 1.8012 - val_acc: 0.5725\n",
      "Epoch 130/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0044 - acc: 0.9998 - val_loss: 1.8048 - val_acc: 0.5734\n",
      "Epoch 131/150\n",
      "8829/8829 [==============================] - 3s 352us/step - loss: 0.0043 - acc: 0.9998 - val_loss: 1.8078 - val_acc: 0.5752\n",
      "Epoch 132/150\n",
      "8829/8829 [==============================] - 3s 356us/step - loss: 0.0042 - acc: 0.9998 - val_loss: 1.8103 - val_acc: 0.5770\n",
      "Epoch 133/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 0.0041 - acc: 0.9998 - val_loss: 1.8126 - val_acc: 0.5743\n",
      "Epoch 134/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 0.0041 - acc: 0.9998 - val_loss: 1.8152 - val_acc: 0.5734\n",
      "Epoch 135/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 0.0040 - acc: 0.9998 - val_loss: 1.8183 - val_acc: 0.5761\n",
      "Epoch 136/150\n",
      "8829/8829 [==============================] - 3s 354us/step - loss: 0.0039 - acc: 0.9998 - val_loss: 1.8219 - val_acc: 0.5770\n",
      "Epoch 137/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 0.0038 - acc: 0.9998 - val_loss: 1.8261 - val_acc: 0.5743\n",
      "Epoch 138/150\n",
      "8829/8829 [==============================] - 3s 355us/step - loss: 0.0037 - acc: 0.9998 - val_loss: 1.8306 - val_acc: 0.5734\n",
      "Epoch 139/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 0.0037 - acc: 0.9998 - val_loss: 1.8353 - val_acc: 0.5725\n",
      "Epoch 140/150\n",
      "8829/8829 [==============================] - 4s 424us/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.8396 - val_acc: 0.5734\n",
      "Epoch 141/150\n",
      "8829/8829 [==============================] - 3s 366us/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.8434 - val_acc: 0.5725\n",
      "Epoch 142/150\n",
      "8829/8829 [==============================] - 3s 359us/step - loss: 0.0035 - acc: 0.9998 - val_loss: 1.8465 - val_acc: 0.5725\n",
      "Epoch 143/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0034 - acc: 0.9998 - val_loss: 1.8490 - val_acc: 0.5725\n",
      "Epoch 144/150\n",
      "8829/8829 [==============================] - 3s 347us/step - loss: 0.0034 - acc: 0.9998 - val_loss: 1.8510 - val_acc: 0.5725\n",
      "Epoch 145/150\n",
      "8829/8829 [==============================] - 3s 350us/step - loss: 0.0033 - acc: 0.9998 - val_loss: 1.8528 - val_acc: 0.5752\n",
      "Epoch 146/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0033 - acc: 0.9998 - val_loss: 1.8545 - val_acc: 0.5743\n",
      "Epoch 147/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0032 - acc: 0.9998 - val_loss: 1.8563 - val_acc: 0.5743\n",
      "Epoch 148/150\n",
      "8829/8829 [==============================] - 3s 353us/step - loss: 0.0032 - acc: 0.9998 - val_loss: 1.8583 - val_acc: 0.5725\n",
      "Epoch 149/150\n",
      "8829/8829 [==============================] - 3s 354us/step - loss: 0.0031 - acc: 0.9999 - val_loss: 1.8605 - val_acc: 0.5716\n",
      "Epoch 150/150\n",
      "8829/8829 [==============================] - 3s 344us/step - loss: 0.0031 - acc: 0.9998 - val_loss: 1.8629 - val_acc: 0.5725\n"
     ]
    }
   ],
   "source": [
    "model = simple_NN(X_train, X_val, y_train, y_val, num_iterations=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_NN(study, trial, X_train, X_test, y_train, y_test, regularization = 0.1,drop_likely = 0.1,\n",
    "              learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999,\n",
    "             num_iterations = 40, size_batch=X_train.shape[0],\n",
    "             activation = 'tanh'):\n",
    "    target_class = y_train.shape[1]\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=X_train.shape[1], \n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(1024, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(512, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(target_class, activation='softmax'))\n",
    "    \n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_acc', mode='max',  patience=10, min_delta=0)\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=10e-8)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    nn_history = model.fit(X_train, y_train, batch_size=size_batch, epochs=num_iterations, \n",
    "                         validation_data=(X_test, y_test),\n",
    "                          callbacks=[es, study.keras_callback(trial, objective_name='val_acc')])\n",
    "    \n",
    "    \n",
    "    return model, nn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"sherpa.app.app\" (lazy loading)\n",
      " * Debug mode: on\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 68s 8ms/step - loss: 84.3720 - acc: 0.1110 - val_loss: 19.4721 - val_acc: 0.1168\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 15.8029 - acc: 0.1176 - val_loss: 11.6498 - val_acc: 0.0870\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 23.0431 - acc: 0.0937 - val_loss: 41.1481 - val_acc: 0.0996\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 35.2431 - acc: 0.0981 - val_loss: 59.6936 - val_acc: 0.1205\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 35.5810 - acc: 0.1125 - val_loss: 20.0673 - val_acc: 0.1087\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 20.9907 - acc: 0.1078 - val_loss: 26.5300 - val_acc: 0.1232\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 44s 5ms/step - loss: 19.2632 - acc: 0.1111 - val_loss: 20.6231 - val_acc: 0.0870\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 21.1779 - acc: 0.1049 - val_loss: 17.8758 - val_acc: 0.0870\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 39s 4ms/step - loss: 21.4567 - acc: 0.1102 - val_loss: 18.2903 - val_acc: 0.0861\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 15.4906 - acc: 0.1370 - val_loss: 14.0121 - val_acc: 0.1286\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 21.9148 - acc: 0.1199 - val_loss: 58.0470 - val_acc: 0.1060\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 39s 4ms/step - loss: 35.7401 - acc: 0.1164 - val_loss: 18.2315 - val_acc: 0.0824\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 39s 4ms/step - loss: 15.8852 - acc: 0.1206 - val_loss: 14.2329 - val_acc: 0.0870\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 19.7082 - acc: 0.1059 - val_loss: 15.6966 - val_acc: 0.1341\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 15.4364 - acc: 0.1219 - val_loss: 13.4077 - val_acc: 0.1024\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 26.7158 - acc: 0.1045 - val_loss: 23.2021 - val_acc: 0.1096\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 32.6852 - acc: 0.1000 - val_loss: 48.3952 - val_acc: 0.0697\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 25.9381 - acc: 0.1006 - val_loss: 22.3806 - val_acc: 0.0879\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 36.1643 - acc: 0.1270 - val_loss: 32.0179 - val_acc: 0.1060\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 31.8776 - acc: 0.1116 - val_loss: 28.8089 - val_acc: 0.1024\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 30.1682 - acc: 0.1303 - val_loss: 28.1516 - val_acc: 0.1051\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 22.1669 - acc: 0.1151 - val_loss: 18.1416 - val_acc: 0.0707\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 20.1909 - acc: 0.1185 - val_loss: 22.2547 - val_acc: 0.0996\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 23.8936 - acc: 0.1254 - val_loss: 27.0202 - val_acc: 0.1196\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 43.3931 - acc: 0.4440 - val_loss: 39.1523 - val_acc: 0.5127\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 35.3589 - acc: 0.5660 - val_loss: 31.6666 - val_acc: 0.5118\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 28.3031 - acc: 0.6065 - val_loss: 25.3399 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 22.5396 - acc: 0.6240 - val_loss: 20.2342 - val_acc: 0.5471\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 17.9269 - acc: 0.6456 - val_loss: 16.1862 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 14.3072 - acc: 0.6594 - val_loss: 13.0614 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 11.5117 - acc: 0.6641 - val_loss: 10.6267 - val_acc: 0.5471\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 9.3635 - acc: 0.6602 - val_loss: 8.7693 - val_acc: 0.5380\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 7.6728 - acc: 0.6692 - val_loss: 7.2986 - val_acc: 0.5281\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 6.4096 - acc: 0.6599 - val_loss: 6.1853 - val_acc: 0.5380\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 5.4200 - acc: 0.6613 - val_loss: 5.3338 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 4.6658 - acc: 0.6620 - val_loss: 4.6543 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 4.0275 - acc: 0.6788 - val_loss: 4.1381 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 3.5572 - acc: 0.6781 - val_loss: 3.7144 - val_acc: 0.5580\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 3.1999 - acc: 0.6727 - val_loss: 3.4365 - val_acc: 0.5371\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 2.8857 - acc: 0.6854 - val_loss: 3.1955 - val_acc: 0.5399\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 2.6668 - acc: 0.6797 - val_loss: 2.9926 - val_acc: 0.5353\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 2.4492 - acc: 0.6873 - val_loss: 2.7711 - val_acc: 0.5480\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 2.2808 - acc: 0.6871 - val_loss: 2.6171 - val_acc: 0.5670\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 2.1467 - acc: 0.6957 - val_loss: 2.5209 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 2.0226 - acc: 0.7040 - val_loss: 2.4616 - val_acc: 0.5498\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 1.9214 - acc: 0.7082 - val_loss: 2.3257 - val_acc: 0.5797\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 1.8325 - acc: 0.7171 - val_loss: 2.3298 - val_acc: 0.5489\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.7745 - acc: 0.7134 - val_loss: 2.3008 - val_acc: 0.5553\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 1.7047 - acc: 0.7236 - val_loss: 2.3383 - val_acc: 0.5272\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.6466 - acc: 0.7320 - val_loss: 2.2341 - val_acc: 0.5525\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 1.5597 - acc: 0.7505 - val_loss: 2.2357 - val_acc: 0.5498\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 1.5625 - acc: 0.7303 - val_loss: 2.2483 - val_acc: 0.5399\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.4937 - acc: 0.7454 - val_loss: 2.1795 - val_acc: 0.5435\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 1.4646 - acc: 0.7490 - val_loss: 2.2091 - val_acc: 0.5453\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 1.4229 - acc: 0.7610 - val_loss: 2.1760 - val_acc: 0.5489\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.3640 - acc: 0.7760 - val_loss: 2.1487 - val_acc: 0.5534\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 118s 13ms/step - loss: 14.5026 - acc: 0.1698 - val_loss: 5.2890 - val_acc: 0.1250\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 121s 14ms/step - loss: 4.3202 - acc: 0.1851 - val_loss: 4.5389 - val_acc: 0.1259\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 118s 13ms/step - loss: 3.8126 - acc: 0.2133 - val_loss: 3.5706 - val_acc: 0.1187\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 107s 12ms/step - loss: 3.1384 - acc: 0.2194 - val_loss: 2.9966 - val_acc: 0.2382\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 122s 14ms/step - loss: 3.1424 - acc: 0.2291 - val_loss: 3.1845 - val_acc: 0.2500\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 118s 13ms/step - loss: 3.2460 - acc: 0.2198 - val_loss: 3.2706 - val_acc: 0.2083\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 124s 14ms/step - loss: 3.4279 - acc: 0.2153 - val_loss: 3.0852 - val_acc: 0.2654\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 132s 15ms/step - loss: 3.2835 - acc: 0.2272 - val_loss: 3.2661 - val_acc: 0.2111\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 127s 14ms/step - loss: 3.3282 - acc: 0.2229 - val_loss: 3.2134 - val_acc: 0.2572\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 123s 14ms/step - loss: 3.2986 - acc: 0.2280 - val_loss: 3.2232 - val_acc: 0.2364\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 125s 14ms/step - loss: 3.2145 - acc: 0.2321 - val_loss: 3.3938 - val_acc: 0.2790\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 131s 15ms/step - loss: 3.2033 - acc: 0.2342 - val_loss: 3.1897 - val_acc: 0.2264\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 114s 13ms/step - loss: 2.9859 - acc: 0.2465 - val_loss: 3.3663 - val_acc: 0.2853\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 127s 14ms/step - loss: 2.8236 - acc: 0.2697 - val_loss: 2.7880 - val_acc: 0.3152\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 128s 15ms/step - loss: 2.8776 - acc: 0.2640 - val_loss: 2.7385 - val_acc: 0.2781\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 130s 15ms/step - loss: 2.8077 - acc: 0.2570 - val_loss: 2.7522 - val_acc: 0.2790\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 133s 15ms/step - loss: 2.5813 - acc: 0.2851 - val_loss: 2.4845 - val_acc: 0.3043\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 193s 22ms/step - loss: 2.5389 - acc: 0.2859 - val_loss: 2.4844 - val_acc: 0.3143\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 150s 17ms/step - loss: 2.5034 - acc: 0.2842 - val_loss: 2.5033 - val_acc: 0.2808\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 125s 14ms/step - loss: 2.4367 - acc: 0.2901 - val_loss: 2.3162 - val_acc: 0.3025\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 116s 13ms/step - loss: 2.3876 - acc: 0.2904 - val_loss: 2.4575 - val_acc: 0.2400\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 121s 14ms/step - loss: 2.3922 - acc: 0.2915 - val_loss: 2.4366 - val_acc: 0.2971\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 130s 15ms/step - loss: 2.3033 - acc: 0.3025 - val_loss: 2.2700 - val_acc: 0.3134\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 111s 13ms/step - loss: 2.3360 - acc: 0.3073 - val_loss: 2.3084 - val_acc: 0.3016\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 123s 14ms/step - loss: 138.5498 - acc: 0.1036 - val_loss: 46.2619 - val_acc: 0.0888\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 118s 13ms/step - loss: 23.0037 - acc: 0.1185 - val_loss: 13.1143 - val_acc: 0.1141\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 117s 13ms/step - loss: 17.8905 - acc: 0.1069 - val_loss: 21.7329 - val_acc: 0.0969\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 114s 13ms/step - loss: 13.6618 - acc: 0.1278 - val_loss: 7.8973 - val_acc: 0.1132\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 122s 14ms/step - loss: 7.8509 - acc: 0.1283 - val_loss: 11.0615 - val_acc: 0.1105\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 125s 14ms/step - loss: 7.6709 - acc: 0.1401 - val_loss: 8.7174 - val_acc: 0.1042\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 120s 14ms/step - loss: 7.1720 - acc: 0.1438 - val_loss: 9.6168 - val_acc: 0.1495\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 124s 14ms/step - loss: 6.8935 - acc: 0.1454 - val_loss: 5.7315 - val_acc: 0.1232\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 123s 14ms/step - loss: 7.4884 - acc: 0.1549 - val_loss: 6.1148 - val_acc: 0.1005\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 115s 13ms/step - loss: 8.2737 - acc: 0.1645 - val_loss: 9.6250 - val_acc: 0.1295\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 126s 14ms/step - loss: 9.0251 - acc: 0.1658 - val_loss: 10.1142 - val_acc: 0.1449\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 125s 14ms/step - loss: 11.5671 - acc: 0.1632 - val_loss: 21.8870 - val_acc: 0.1024\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 116s 13ms/step - loss: 190.1588 - acc: 0.0882 - val_loss: 197.7317 - val_acc: 0.0625\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 112s 13ms/step - loss: 141.8019 - acc: 0.0826 - val_loss: 73.7239 - val_acc: 0.0897\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 110s 13ms/step - loss: 198.2640 - acc: 0.0984 - val_loss: 169.5043 - val_acc: 0.0716\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 121s 14ms/step - loss: 133.8969 - acc: 0.0936 - val_loss: 186.1761 - val_acc: 0.0969\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 99s 11ms/step - loss: 101.0236 - acc: 0.1000 - val_loss: 16.7384 - val_acc: 0.0897\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 37.4523 - acc: 0.3846 - val_loss: 35.8839 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 626us/step - loss: 34.5625 - acc: 0.5355 - val_loss: 33.1298 - val_acc: 0.4973\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 31.7476 - acc: 0.5873 - val_loss: 30.3150 - val_acc: 0.5290\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 595us/step - loss: 28.8737 - acc: 0.6305 - val_loss: 27.5377 - val_acc: 0.5326\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 26.0502 - acc: 0.6610 - val_loss: 24.7792 - val_acc: 0.5643\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 23.3434 - acc: 0.6797 - val_loss: 22.2159 - val_acc: 0.5389\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 20.7904 - acc: 0.7074 - val_loss: 19.7961 - val_acc: 0.5562\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 541us/step - loss: 18.4381 - acc: 0.7190 - val_loss: 17.5976 - val_acc: 0.5634\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 16.2828 - acc: 0.7435 - val_loss: 15.5945 - val_acc: 0.5534\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 14.3432 - acc: 0.7542 - val_loss: 13.8309 - val_acc: 0.5498\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 12.6267 - acc: 0.7650 - val_loss: 12.2425 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 11.1091 - acc: 0.7675 - val_loss: 10.8725 - val_acc: 0.5553\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 9.7831 - acc: 0.7834 - val_loss: 9.6590 - val_acc: 0.5661\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 8.6268 - acc: 0.7910 - val_loss: 8.6569 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 7.6318 - acc: 0.8010 - val_loss: 7.7693 - val_acc: 0.5335\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 6.7904 - acc: 0.8070 - val_loss: 7.0614 - val_acc: 0.5371\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 6.0706 - acc: 0.8097 - val_loss: 6.4042 - val_acc: 0.5399\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 509us/step - loss: 5.4688 - acc: 0.8081 - val_loss: 5.8721 - val_acc: 0.5362\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 4.9591 - acc: 0.8041 - val_loss: 5.4529 - val_acc: 0.5281\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 4.5134 - acc: 0.8121 - val_loss: 5.0704 - val_acc: 0.5254\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 4.1429 - acc: 0.8155 - val_loss: 4.7031 - val_acc: 0.5226\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 3.8397 - acc: 0.8050 - val_loss: 4.4888 - val_acc: 0.4982\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 3.5645 - acc: 0.8088 - val_loss: 4.2659 - val_acc: 0.4955\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 61.6788 - acc: 0.1383 - val_loss: 139.0258 - val_acc: 0.1703\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 183.0967 - acc: 0.1948 - val_loss: 221.1116 - val_acc: 0.1993\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 231.1351 - acc: 0.2083 - val_loss: 233.7186 - val_acc: 0.1984\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 224.5506 - acc: 0.2119 - val_loss: 208.6100 - val_acc: 0.2056\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 192.1165 - acc: 0.1893 - val_loss: 171.1493 - val_acc: 0.1902\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 155.5292 - acc: 0.1864 - val_loss: 138.3972 - val_acc: 0.1739\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 127.3322 - acc: 0.1655 - val_loss: 116.0573 - val_acc: 0.1350\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 107.6689 - acc: 0.1766 - val_loss: 99.9834 - val_acc: 0.1531\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 94.7172 - acc: 0.1675 - val_loss: 90.6696 - val_acc: 0.1159\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 86.3395 - acc: 0.1614 - val_loss: 83.7437 - val_acc: 0.1757\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 81.1660 - acc: 0.1716 - val_loss: 81.3127 - val_acc: 0.1395\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 78.1736 - acc: 0.1538 - val_loss: 77.8621 - val_acc: 0.1558\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 74.5971 - acc: 0.1581 - val_loss: 74.7995 - val_acc: 0.1431\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 70.5535 - acc: 0.1583 - val_loss: 70.3943 - val_acc: 0.0861\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 30.9019 - acc: 0.2093 - val_loss: 4.3430 - val_acc: 0.2011\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.6441 - acc: 0.2089 - val_loss: 3.1638 - val_acc: 0.2636\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.2023 - acc: 0.2176 - val_loss: 3.0162 - val_acc: 0.2192\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.0671 - acc: 0.2444 - val_loss: 3.1297 - val_acc: 0.2373\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.5252 - acc: 0.2176 - val_loss: 3.7174 - val_acc: 0.2147\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.4466 - acc: 0.2180 - val_loss: 3.0844 - val_acc: 0.2509\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 3.4237 - acc: 0.2168 - val_loss: 3.1812 - val_acc: 0.1821\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 3.3589 - acc: 0.2144 - val_loss: 3.3360 - val_acc: 0.2337\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 3.3244 - acc: 0.2408 - val_loss: 3.7533 - val_acc: 0.2563\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 3.6026 - acc: 0.2318 - val_loss: 3.7120 - val_acc: 0.2065\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 3.3622 - acc: 0.2388 - val_loss: 3.2634 - val_acc: 0.2826\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 3.6630 - acc: 0.2240 - val_loss: 3.4268 - val_acc: 0.2563\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 3.3220 - acc: 0.2283 - val_loss: 3.0356 - val_acc: 0.2572\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3830 - acc: 0.2391 - val_loss: 3.3526 - val_acc: 0.2129\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.4262 - acc: 0.2386 - val_loss: 3.2514 - val_acc: 0.2527\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.2974 - acc: 0.2497 - val_loss: 2.9755 - val_acc: 0.2618\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.2785 - acc: 0.2457 - val_loss: 3.4685 - val_acc: 0.3143\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.4092 - acc: 0.2488 - val_loss: 2.9892 - val_acc: 0.2428\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.1625 - acc: 0.2580 - val_loss: 3.3767 - val_acc: 0.2554\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.5457 - acc: 0.2555 - val_loss: 3.2959 - val_acc: 0.2237\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.1271 - acc: 0.2691 - val_loss: 3.2862 - val_acc: 0.2437\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.1076 - acc: 0.2701 - val_loss: 3.5989 - val_acc: 0.1766\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 3.5261 - acc: 0.2685 - val_loss: 2.8914 - val_acc: 0.2917\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.9894 - acc: 0.2864 - val_loss: 3.0644 - val_acc: 0.2111\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.9102 - acc: 0.2855 - val_loss: 2.9324 - val_acc: 0.2953\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.0052 - acc: 0.2943 - val_loss: 3.0779 - val_acc: 0.2971\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9412 - acc: 0.2789 - val_loss: 3.0475 - val_acc: 0.3197\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.9085 - acc: 0.2939 - val_loss: 2.6558 - val_acc: 0.3071\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 3.1928 - acc: 0.2785 - val_loss: 2.6099 - val_acc: 0.3207\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.7455 - acc: 0.3033 - val_loss: 3.3741 - val_acc: 0.2255\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9019 - acc: 0.2835 - val_loss: 2.7501 - val_acc: 0.3089\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 2.6838 - acc: 0.2967 - val_loss: 2.5373 - val_acc: 0.3288\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.5735 - acc: 0.3110 - val_loss: 2.7256 - val_acc: 0.2817\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.6744 - acc: 0.2992 - val_loss: 2.7916 - val_acc: 0.2618\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.6842 - acc: 0.2975 - val_loss: 2.8766 - val_acc: 0.2672\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 2.5861 - acc: 0.3122 - val_loss: 2.4322 - val_acc: 0.3442\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.6722 - acc: 0.3055 - val_loss: 2.8256 - val_acc: 0.3016\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4612 - acc: 0.3170 - val_loss: 2.4002 - val_acc: 0.3351\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.5565 - acc: 0.3123 - val_loss: 2.6806 - val_acc: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4972 - acc: 0.3109 - val_loss: 2.4791 - val_acc: 0.2554\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4669 - acc: 0.3162 - val_loss: 2.6683 - val_acc: 0.3297\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3941 - acc: 0.3248 - val_loss: 2.3183 - val_acc: 0.3243\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4010 - acc: 0.3213 - val_loss: 2.3317 - val_acc: 0.3333\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3809 - acc: 0.3247 - val_loss: 2.3873 - val_acc: 0.3216\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.4560 - acc: 0.3110 - val_loss: 2.9072 - val_acc: 0.3062\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4239 - acc: 0.3108 - val_loss: 2.4551 - val_acc: 0.3025\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 37.4677 - acc: 0.4209 - val_loss: 34.7047 - val_acc: 0.4937\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 32.0676 - acc: 0.5322 - val_loss: 29.5477 - val_acc: 0.5344\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 27.0520 - acc: 0.5659 - val_loss: 24.8328 - val_acc: 0.5308\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 22.6170 - acc: 0.5893 - val_loss: 20.7754 - val_acc: 0.5326\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 18.8641 - acc: 0.6026 - val_loss: 17.3639 - val_acc: 0.5543\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 15.7232 - acc: 0.6175 - val_loss: 14.5391 - val_acc: 0.5389\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.1141 - acc: 0.6323 - val_loss: 12.1965 - val_acc: 0.5498\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 10.9695 - acc: 0.6406 - val_loss: 10.2973 - val_acc: 0.5534\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 9.2552 - acc: 0.6400 - val_loss: 8.7445 - val_acc: 0.5462\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 7.8371 - acc: 0.6516 - val_loss: 7.5236 - val_acc: 0.5435\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 6.7014 - acc: 0.6523 - val_loss: 6.5206 - val_acc: 0.5417\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 5.7663 - acc: 0.6582 - val_loss: 5.7385 - val_acc: 0.5335\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 5.0208 - acc: 0.6647 - val_loss: 5.0192 - val_acc: 0.5471\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.4191 - acc: 0.6668 - val_loss: 4.4549 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.9502 - acc: 0.6629 - val_loss: 4.0991 - val_acc: 0.5498\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.5446 - acc: 0.6677 - val_loss: 3.7715 - val_acc: 0.5462\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.1875 - acc: 0.6789 - val_loss: 3.4057 - val_acc: 0.5725\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.9047 - acc: 0.6922 - val_loss: 3.2023 - val_acc: 0.5507\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.6968 - acc: 0.6885 - val_loss: 2.9903 - val_acc: 0.5489\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.5220 - acc: 0.6892 - val_loss: 2.8718 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.3811 - acc: 0.6951 - val_loss: 2.8034 - val_acc: 0.5317\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2435 - acc: 0.6943 - val_loss: 2.6273 - val_acc: 0.5571\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.1207 - acc: 0.7023 - val_loss: 2.5870 - val_acc: 0.5435\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 2.0539 - acc: 0.7049 - val_loss: 2.5594 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9514 - acc: 0.7133 - val_loss: 2.4570 - val_acc: 0.5408\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8699 - acc: 0.7200 - val_loss: 2.3808 - val_acc: 0.5562\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7795 - acc: 0.7368 - val_loss: 2.3836 - val_acc: 0.5426\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 74.6048 - acc: 0.3925 - val_loss: 70.2219 - val_acc: 0.4891\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 918us/step - loss: 66.4594 - acc: 0.4969 - val_loss: 62.4863 - val_acc: 0.5072\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 59.0031 - acc: 0.5286 - val_loss: 55.3986 - val_acc: 0.5353\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 864us/step - loss: 52.2259 - acc: 0.5518 - val_loss: 48.9952 - val_acc: 0.5389\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 868us/step - loss: 46.1343 - acc: 0.5705 - val_loss: 43.2872 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 854us/step - loss: 40.6917 - acc: 0.5836 - val_loss: 38.1819 - val_acc: 0.5489\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 35.8688 - acc: 0.5953 - val_loss: 33.7115 - val_acc: 0.5353\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 854us/step - loss: 31.5992 - acc: 0.6070 - val_loss: 29.7478 - val_acc: 0.5389\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 873us/step - loss: 27.8339 - acc: 0.6216 - val_loss: 26.2464 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 24.5421 - acc: 0.6259 - val_loss: 23.1532 - val_acc: 0.5498\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 851us/step - loss: 21.6432 - acc: 0.6318 - val_loss: 20.4901 - val_acc: 0.5444\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 851us/step - loss: 19.1146 - acc: 0.6340 - val_loss: 18.1389 - val_acc: 0.5471\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 16.9042 - acc: 0.6415 - val_loss: 16.1044 - val_acc: 0.5308\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 830us/step - loss: 14.9789 - acc: 0.6475 - val_loss: 14.3112 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 889us/step - loss: 13.2961 - acc: 0.6557 - val_loss: 12.7482 - val_acc: 0.5679\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 864us/step - loss: 11.8359 - acc: 0.6583 - val_loss: 11.4113 - val_acc: 0.5725\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 905us/step - loss: 10.5576 - acc: 0.6633 - val_loss: 10.2735 - val_acc: 0.5453\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 9s 970us/step - loss: 9.4444 - acc: 0.6692 - val_loss: 9.1764 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 926us/step - loss: 8.4931 - acc: 0.6660 - val_loss: 8.3369 - val_acc: 0.5679\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 833us/step - loss: 7.6600 - acc: 0.6732 - val_loss: 7.5922 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 834us/step - loss: 6.9381 - acc: 0.6687 - val_loss: 6.8933 - val_acc: 0.5580\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 818us/step - loss: 6.2910 - acc: 0.6829 - val_loss: 6.3715 - val_acc: 0.5308\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 800us/step - loss: 5.7376 - acc: 0.6872 - val_loss: 5.8969 - val_acc: 0.5426\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 5.2709 - acc: 0.6831 - val_loss: 5.4100 - val_acc: 0.5507\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 4.8483 - acc: 0.6924 - val_loss: 5.0320 - val_acc: 0.5489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 4.4690 - acc: 0.6971 - val_loss: 4.6935 - val_acc: 0.5643\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: nan - acc: 0.0703 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 804us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 756us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 779us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 72.8429 - acc: 0.4357 - val_loss: 63.0714 - val_acc: 0.4964\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 955us/step - loss: 55.0599 - acc: 0.5437 - val_loss: 47.0907 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 926us/step - loss: 40.8524 - acc: 0.5713 - val_loss: 34.8852 - val_acc: 0.5399\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 30.1777 - acc: 0.5872 - val_loss: 25.8184 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 22.3384 - acc: 0.5959 - val_loss: 19.2215 - val_acc: 0.5299\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 883us/step - loss: 16.6308 - acc: 0.6018 - val_loss: 14.4483 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 12.4919 - acc: 0.6037 - val_loss: 10.9711 - val_acc: 0.5399\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 853us/step - loss: 9.5242 - acc: 0.6131 - val_loss: 8.5217 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 880us/step - loss: 7.4250 - acc: 0.6175 - val_loss: 6.7963 - val_acc: 0.5335\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 885us/step - loss: 5.9045 - acc: 0.6172 - val_loss: 5.5108 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 4.8248 - acc: 0.6145 - val_loss: 4.6131 - val_acc: 0.5299\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 895us/step - loss: 4.0466 - acc: 0.6181 - val_loss: 3.9780 - val_acc: 0.5226\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 3.4524 - acc: 0.6271 - val_loss: 3.4307 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 907us/step - loss: 3.0236 - acc: 0.6344 - val_loss: 3.0945 - val_acc: 0.5426\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 928us/step - loss: 2.7077 - acc: 0.6346 - val_loss: 2.8963 - val_acc: 0.5263\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 2.4651 - acc: 0.6417 - val_loss: 2.6848 - val_acc: 0.5399\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 2.3045 - acc: 0.6359 - val_loss: 2.4738 - val_acc: 0.5426\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 903us/step - loss: 2.1359 - acc: 0.6471 - val_loss: 2.3665 - val_acc: 0.5326\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 2.0300 - acc: 0.6515 - val_loss: 2.2785 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 804us/step - loss: 1.9038 - acc: 0.6730 - val_loss: 2.2712 - val_acc: 0.5344\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 811us/step - loss: 1.8518 - acc: 0.6634 - val_loss: 2.2324 - val_acc: 0.5236\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 801us/step - loss: 1.7670 - acc: 0.6735 - val_loss: 2.1304 - val_acc: 0.5507\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 1.7118 - acc: 0.6825 - val_loss: 2.1789 - val_acc: 0.5199\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 1.6901 - acc: 0.6705 - val_loss: 2.0750 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 791us/step - loss: 1.6510 - acc: 0.6866 - val_loss: 2.0376 - val_acc: 0.5444\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 1.5589 - acc: 0.6960 - val_loss: 2.1034 - val_acc: 0.5471\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 800us/step - loss: 1.5528 - acc: 0.7000 - val_loss: 2.0062 - val_acc: 0.5471\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 786us/step - loss: 1.4977 - acc: 0.7099 - val_loss: 1.9924 - val_acc: 0.5462\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 791us/step - loss: 1.4853 - acc: 0.7099 - val_loss: 1.9751 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 56.7646 - acc: 0.4221 - val_loss: 52.0180 - val_acc: 0.5018\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 883us/step - loss: 47.8034 - acc: 0.5437 - val_loss: 43.5531 - val_acc: 0.5299\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 933us/step - loss: 39.7943 - acc: 0.5762 - val_loss: 36.1725 - val_acc: 0.5281\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 892us/step - loss: 32.9434 - acc: 0.6036 - val_loss: 29.9761 - val_acc: 0.5362\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 27.2300 - acc: 0.6155 - val_loss: 24.8541 - val_acc: 0.5299\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 932us/step - loss: 22.5110 - acc: 0.6202 - val_loss: 20.5831 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 958us/step - loss: 18.6215 - acc: 0.6327 - val_loss: 17.1009 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 836us/step - loss: 15.4631 - acc: 0.6454 - val_loss: 14.3020 - val_acc: 0.5498\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 12.8867 - acc: 0.6473 - val_loss: 12.0375 - val_acc: 0.5308\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 907us/step - loss: 10.8119 - acc: 0.6526 - val_loss: 10.1759 - val_acc: 0.5344\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 9.1234 - acc: 0.6582 - val_loss: 8.6889 - val_acc: 0.5371\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 878us/step - loss: 7.7737 - acc: 0.6542 - val_loss: 7.4465 - val_acc: 0.5462\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 6.6654 - acc: 0.6656 - val_loss: 6.4810 - val_acc: 0.5408\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 904us/step - loss: 5.7784 - acc: 0.6667 - val_loss: 5.7622 - val_acc: 0.5462\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 919us/step - loss: 5.0492 - acc: 0.6726 - val_loss: 5.0250 - val_acc: 0.5580\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 4.4714 - acc: 0.6643 - val_loss: 4.5428 - val_acc: 0.5426\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 3.9951 - acc: 0.6729 - val_loss: 4.1202 - val_acc: 0.5444\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 9s 981us/step - loss: 3.5984 - acc: 0.6791 - val_loss: 3.8005 - val_acc: 0.5480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 3.2676 - acc: 0.6829 - val_loss: 3.4907 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 921us/step - loss: 3.0281 - acc: 0.6804 - val_loss: 3.2866 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 2.7635 - acc: 0.6987 - val_loss: 3.1056 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 8s 945us/step - loss: 2.5821 - acc: 0.6985 - val_loss: 2.9831 - val_acc: 0.5417\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 886us/step - loss: 2.4402 - acc: 0.6937 - val_loss: 2.7958 - val_acc: 0.5389\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 861us/step - loss: 2.2583 - acc: 0.7198 - val_loss: 2.7107 - val_acc: 0.5625\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 928us/step - loss: 2.2006 - acc: 0.7013 - val_loss: 2.6611 - val_acc: 0.5435\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 954us/step - loss: 2.0825 - acc: 0.7150 - val_loss: 2.5630 - val_acc: 0.5525\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 907us/step - loss: 1.9870 - acc: 0.7232 - val_loss: 2.6357 - val_acc: 0.5353\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 891us/step - loss: 1.9333 - acc: 0.7185 - val_loss: 2.4838 - val_acc: 0.5444\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 1.8258 - acc: 0.7376 - val_loss: 2.4605 - val_acc: 0.5426\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 8s 948us/step - loss: 1.7425 - acc: 0.7490 - val_loss: 2.3761 - val_acc: 0.5534\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 924us/step - loss: 1.6944 - acc: 0.7549 - val_loss: 2.3156 - val_acc: 0.5625\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 1.6604 - acc: 0.7516 - val_loss: 2.3104 - val_acc: 0.5562\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 8s 919us/step - loss: 1.6291 - acc: 0.7547 - val_loss: 2.4404 - val_acc: 0.5399\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 8s 874us/step - loss: 1.5758 - acc: 0.7635 - val_loss: 2.3866 - val_acc: 0.5299\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 53.1712 - acc: 0.4549 - val_loss: 39.0034 - val_acc: 0.4937\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 28.8751 - acc: 0.5295 - val_loss: 20.4946 - val_acc: 0.4964\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 15.1470 - acc: 0.5426 - val_loss: 10.9457 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 8.3444 - acc: 0.5454 - val_loss: 6.4057 - val_acc: 0.5018\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 5.1227 - acc: 0.5412 - val_loss: 4.2483 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.6030 - acc: 0.5462 - val_loss: 3.1911 - val_acc: 0.5091\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.8054 - acc: 0.5486 - val_loss: 2.5863 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.3963 - acc: 0.5386 - val_loss: 2.2869 - val_acc: 0.5154\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.1304 - acc: 0.5518 - val_loss: 2.0975 - val_acc: 0.5217\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9633 - acc: 0.5532 - val_loss: 2.0038 - val_acc: 0.5172\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8370 - acc: 0.5588 - val_loss: 1.9004 - val_acc: 0.5236\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7452 - acc: 0.5681 - val_loss: 1.8172 - val_acc: 0.5435\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6971 - acc: 0.5619 - val_loss: 1.7526 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6301 - acc: 0.5724 - val_loss: 1.7532 - val_acc: 0.5181\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5951 - acc: 0.5774 - val_loss: 1.6861 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5726 - acc: 0.5784 - val_loss: 1.7930 - val_acc: 0.4982\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5589 - acc: 0.5755 - val_loss: 1.7387 - val_acc: 0.5190\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5186 - acc: 0.5878 - val_loss: 1.6027 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4965 - acc: 0.5966 - val_loss: 1.6071 - val_acc: 0.5353\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4950 - acc: 0.5947 - val_loss: 1.6311 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4684 - acc: 0.6029 - val_loss: 1.6640 - val_acc: 0.5344\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4564 - acc: 0.6044 - val_loss: 1.7300 - val_acc: 0.5091\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4620 - acc: 0.6005 - val_loss: 1.6684 - val_acc: 0.5226\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4527 - acc: 0.6047 - val_loss: 1.6310 - val_acc: 0.5353\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4163 - acc: 0.6141 - val_loss: 1.6683 - val_acc: 0.5399\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4339 - acc: 0.6164 - val_loss: 1.6832 - val_acc: 0.5208\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4015 - acc: 0.6234 - val_loss: 1.6975 - val_acc: 0.5281\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4143 - acc: 0.6186 - val_loss: 1.6979 - val_acc: 0.5299\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4041 - acc: 0.6226 - val_loss: 1.6616 - val_acc: 0.5353\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3977 - acc: 0.6279 - val_loss: 1.6815 - val_acc: 0.5507\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3542 - acc: 0.6454 - val_loss: 1.6529 - val_acc: 0.5507\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3583 - acc: 0.6421 - val_loss: 1.6641 - val_acc: 0.5399\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3702 - acc: 0.6444 - val_loss: 1.7017 - val_acc: 0.5281\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3488 - acc: 0.6446 - val_loss: 1.6238 - val_acc: 0.5543\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3377 - acc: 0.6492 - val_loss: 1.7004 - val_acc: 0.5507\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3513 - acc: 0.6505 - val_loss: 1.6623 - val_acc: 0.5462\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3239 - acc: 0.6539 - val_loss: 1.6893 - val_acc: 0.5534\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2945 - acc: 0.6683 - val_loss: 1.7785 - val_acc: 0.5254\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3830 - acc: 0.6403 - val_loss: 1.6976 - val_acc: 0.5426\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3034 - acc: 0.6678 - val_loss: 1.7572 - val_acc: 0.5371\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3312 - acc: 0.6643 - val_loss: 1.7023 - val_acc: 0.5290\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2964 - acc: 0.6740 - val_loss: 1.6543 - val_acc: 0.5426\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2871 - acc: 0.6756 - val_loss: 1.8469 - val_acc: 0.5353\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2774 - acc: 0.6812 - val_loss: 1.6881 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 9s 986us/step - loss: 74.3682 - acc: 0.3472 - val_loss: 71.7214 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 69.8119 - acc: 0.4942 - val_loss: 67.2486 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 65.3565 - acc: 0.5293 - val_loss: 62.8958 - val_acc: 0.5245\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 61.0773 - acc: 0.5557 - val_loss: 58.7701 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 57.0078 - acc: 0.5737 - val_loss: 54.8630 - val_acc: 0.5399\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 53.1695 - acc: 0.5850 - val_loss: 51.1946 - val_acc: 0.5417\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 49.5619 - acc: 0.6040 - val_loss: 47.7303 - val_acc: 0.5562\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 46.1894 - acc: 0.6112 - val_loss: 44.4963 - val_acc: 0.5516\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 43.0302 - acc: 0.6175 - val_loss: 41.4948 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 40.0786 - acc: 0.6292 - val_loss: 38.6677 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 37.3228 - acc: 0.6422 - val_loss: 36.0357 - val_acc: 0.5661\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 34.7569 - acc: 0.6516 - val_loss: 33.5859 - val_acc: 0.5471\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 32.3611 - acc: 0.6606 - val_loss: 31.3176 - val_acc: 0.5571\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 30.1428 - acc: 0.6664 - val_loss: 29.2129 - val_acc: 0.5480\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 28.0813 - acc: 0.6693 - val_loss: 27.2314 - val_acc: 0.5589\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 26.1478 - acc: 0.6800 - val_loss: 25.4028 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 24.3626 - acc: 0.6847 - val_loss: 23.7204 - val_acc: 0.5507\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 22.7047 - acc: 0.6874 - val_loss: 22.1474 - val_acc: 0.5471\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 21.1721 - acc: 0.6938 - val_loss: 20.6830 - val_acc: 0.5652\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 19.7337 - acc: 0.7005 - val_loss: 19.3176 - val_acc: 0.5670\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 18.4149 - acc: 0.7093 - val_loss: 18.0710 - val_acc: 0.5589\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 17.2027 - acc: 0.7046 - val_loss: 16.9578 - val_acc: 0.5507\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 16.0691 - acc: 0.7104 - val_loss: 15.8436 - val_acc: 0.5607\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 15.0282 - acc: 0.7170 - val_loss: 14.8703 - val_acc: 0.5571\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 14.0408 - acc: 0.7334 - val_loss: 13.9654 - val_acc: 0.5661\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 13.1518 - acc: 0.7270 - val_loss: 13.1718 - val_acc: 0.5426\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 12.3470 - acc: 0.7218 - val_loss: 12.3751 - val_acc: 0.5553\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 11.5877 - acc: 0.7312 - val_loss: 11.6373 - val_acc: 0.5562\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 10.8592 - acc: 0.7438 - val_loss: 10.9861 - val_acc: 0.5326\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 10.2256 - acc: 0.7327 - val_loss: 10.3973 - val_acc: 0.5290\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 79.1257 - acc: 0.4278 - val_loss: 67.2790 - val_acc: 0.5199\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 57.5011 - acc: 0.5180 - val_loss: 48.4154 - val_acc: 0.5181\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 41.0402 - acc: 0.5442 - val_loss: 34.3985 - val_acc: 0.5281\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 29.0292 - acc: 0.5599 - val_loss: 24.3055 - val_acc: 0.5371\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 20.5163 - acc: 0.5689 - val_loss: 17.2970 - val_acc: 0.5208\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 14.6137 - acc: 0.5740 - val_loss: 12.4290 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 10.5498 - acc: 0.5860 - val_loss: 9.1042 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 7.7979 - acc: 0.5799 - val_loss: 6.8947 - val_acc: 0.5281\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 5.9614 - acc: 0.5801 - val_loss: 5.3435 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.6984 - acc: 0.5839 - val_loss: 4.3568 - val_acc: 0.5199\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.8559 - acc: 0.5878 - val_loss: 3.7097 - val_acc: 0.5290\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.2594 - acc: 0.5907 - val_loss: 3.1724 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.8321 - acc: 0.6003 - val_loss: 2.8495 - val_acc: 0.5362\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.5492 - acc: 0.6017 - val_loss: 2.6259 - val_acc: 0.5408\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.3267 - acc: 0.6135 - val_loss: 2.4541 - val_acc: 0.5389\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.1714 - acc: 0.6140 - val_loss: 2.3319 - val_acc: 0.5534\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0478 - acc: 0.6190 - val_loss: 2.1934 - val_acc: 0.5480\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9532 - acc: 0.6248 - val_loss: 2.1560 - val_acc: 0.5498\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8788 - acc: 0.6290 - val_loss: 2.0363 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8119 - acc: 0.6287 - val_loss: 2.0983 - val_acc: 0.5299\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7415 - acc: 0.6362 - val_loss: 1.9741 - val_acc: 0.5525\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6954 - acc: 0.6431 - val_loss: 1.9585 - val_acc: 0.5562\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6596 - acc: 0.6569 - val_loss: 2.0039 - val_acc: 0.5335\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6393 - acc: 0.6484 - val_loss: 1.8865 - val_acc: 0.5525\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5859 - acc: 0.6689 - val_loss: 1.9174 - val_acc: 0.5516\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5544 - acc: 0.6642 - val_loss: 1.9393 - val_acc: 0.5335\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5299 - acc: 0.6786 - val_loss: 1.8765 - val_acc: 0.5543\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5058 - acc: 0.6788 - val_loss: 1.8426 - val_acc: 0.5725\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4948 - acc: 0.6816 - val_loss: 1.8603 - val_acc: 0.5670\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4457 - acc: 0.6983 - val_loss: 1.8963 - val_acc: 0.5317\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4408 - acc: 0.6985 - val_loss: 1.9533 - val_acc: 0.5281\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4275 - acc: 0.6946 - val_loss: 1.8098 - val_acc: 0.5770\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3875 - acc: 0.7081 - val_loss: 1.9091 - val_acc: 0.5389\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3724 - acc: 0.7167 - val_loss: 1.9374 - val_acc: 0.5516\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3714 - acc: 0.7117 - val_loss: 1.9812 - val_acc: 0.5426\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3399 - acc: 0.7240 - val_loss: 1.9702 - val_acc: 0.5389\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3334 - acc: 0.7257 - val_loss: 1.9020 - val_acc: 0.5380\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3015 - acc: 0.7328 - val_loss: 1.9163 - val_acc: 0.5408\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2927 - acc: 0.7393 - val_loss: 1.8735 - val_acc: 0.5679\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2951 - acc: 0.7368 - val_loss: 1.9216 - val_acc: 0.5480\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2755 - acc: 0.7411 - val_loss: 1.9480 - val_acc: 0.5399\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2436 - acc: 0.7548 - val_loss: 1.9552 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 78.6890 - acc: 0.4264 - val_loss: 67.1870 - val_acc: 0.5054\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 57.5696 - acc: 0.5161 - val_loss: 48.6452 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 41.3428 - acc: 0.5417 - val_loss: 34.7599 - val_acc: 0.5353\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 29.4319 - acc: 0.5551 - val_loss: 24.7314 - val_acc: 0.5543\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 20.9200 - acc: 0.5722 - val_loss: 17.6624 - val_acc: 0.5272\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 14.9591 - acc: 0.5762 - val_loss: 12.8125 - val_acc: 0.5091\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 10.8683 - acc: 0.5752 - val_loss: 9.3817 - val_acc: 0.5326\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 8.0613 - acc: 0.5787 - val_loss: 7.1343 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.1582 - acc: 0.5788 - val_loss: 5.6359 - val_acc: 0.5236\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.8590 - acc: 0.5892 - val_loss: 4.4927 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.9527 - acc: 0.5920 - val_loss: 3.7786 - val_acc: 0.5371\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3463 - acc: 0.5924 - val_loss: 3.2440 - val_acc: 0.5471\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9228 - acc: 0.5983 - val_loss: 2.9211 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6267 - acc: 0.5945 - val_loss: 2.6789 - val_acc: 0.5326\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 82.5688 - acc: 0.4606 - val_loss: 74.5912 - val_acc: 0.5072\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 834us/step - loss: 67.7001 - acc: 0.5853 - val_loss: 60.8979 - val_acc: 0.5399\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 824us/step - loss: 54.9724 - acc: 0.6251 - val_loss: 49.4124 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 809us/step - loss: 44.4537 - acc: 0.6490 - val_loss: 40.0009 - val_acc: 0.5408\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 35.9177 - acc: 0.6551 - val_loss: 32.3985 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 833us/step - loss: 29.0238 - acc: 0.6709 - val_loss: 26.2942 - val_acc: 0.5254\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 815us/step - loss: 23.5022 - acc: 0.6685 - val_loss: 21.4069 - val_acc: 0.5236\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 19.1000 - acc: 0.6707 - val_loss: 17.5134 - val_acc: 0.5190\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 880us/step - loss: 15.6028 - acc: 0.6670 - val_loss: 14.4213 - val_acc: 0.5272\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 840us/step - loss: 12.8115 - acc: 0.6705 - val_loss: 11.9631 - val_acc: 0.5199\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 856us/step - loss: 10.6125 - acc: 0.6719 - val_loss: 9.9758 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 8.8885 - acc: 0.6650 - val_loss: 8.4500 - val_acc: 0.5498\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 7.5048 - acc: 0.6650 - val_loss: 7.2212 - val_acc: 0.5453\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 879us/step - loss: 6.4129 - acc: 0.6638 - val_loss: 6.2351 - val_acc: 0.5507\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 900us/step - loss: 5.5254 - acc: 0.6694 - val_loss: 5.4556 - val_acc: 0.5417\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 886us/step - loss: 4.8445 - acc: 0.6581 - val_loss: 4.8445 - val_acc: 0.5516\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 4.2527 - acc: 0.6765 - val_loss: 4.3436 - val_acc: 0.5580\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 3.8247 - acc: 0.6670 - val_loss: 3.9731 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 856us/step - loss: 3.4392 - acc: 0.6832 - val_loss: 3.6767 - val_acc: 0.5190\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 881us/step - loss: 3.1339 - acc: 0.6789 - val_loss: 3.3558 - val_acc: 0.5543\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 849us/step - loss: 2.8652 - acc: 0.6955 - val_loss: 3.2024 - val_acc: 0.5127\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 832us/step - loss: 2.6643 - acc: 0.6944 - val_loss: 3.0684 - val_acc: 0.5281\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 2.5147 - acc: 0.6901 - val_loss: 2.8476 - val_acc: 0.5507\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 833us/step - loss: 2.3473 - acc: 0.7035 - val_loss: 2.7478 - val_acc: 0.5435\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 2.1929 - acc: 0.7258 - val_loss: 2.7144 - val_acc: 0.5263\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 842us/step - loss: 2.1131 - acc: 0.7209 - val_loss: 2.5406 - val_acc: 0.5625\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 831us/step - loss: 1.9958 - acc: 0.7329 - val_loss: 2.4880 - val_acc: 0.5562\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 832us/step - loss: 1.9174 - acc: 0.7351 - val_loss: 2.4631 - val_acc: 0.5643\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 837us/step - loss: 1.8210 - acc: 0.7575 - val_loss: 2.5159 - val_acc: 0.5453\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 812us/step - loss: 1.7771 - acc: 0.7542 - val_loss: 2.3609 - val_acc: 0.5725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 838us/step - loss: 1.7441 - acc: 0.7547 - val_loss: 2.3854 - val_acc: 0.5408\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 8s 889us/step - loss: 1.6533 - acc: 0.7734 - val_loss: 2.3987 - val_acc: 0.5254\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 1.6183 - acc: 0.7804 - val_loss: 2.3175 - val_acc: 0.5543\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 845us/step - loss: 1.5620 - acc: 0.7887 - val_loss: 2.3020 - val_acc: 0.5670\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 1.5365 - acc: 0.7916 - val_loss: 2.3100 - val_acc: 0.5580\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 8s 878us/step - loss: 1.5071 - acc: 0.7907 - val_loss: 2.2895 - val_acc: 0.5670\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 7s 808us/step - loss: 1.4687 - acc: 0.8001 - val_loss: 2.3023 - val_acc: 0.5580\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 1.4368 - acc: 0.8077 - val_loss: 2.2252 - val_acc: 0.5661\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 1.3870 - acc: 0.8242 - val_loss: 2.2934 - val_acc: 0.5534\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 7s 844us/step - loss: 1.3522 - acc: 0.8325 - val_loss: 2.2881 - val_acc: 0.5824\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 8s 855us/step - loss: 1.3282 - acc: 0.8344 - val_loss: 2.2204 - val_acc: 0.5725\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 1.2880 - acc: 0.8460 - val_loss: 2.2082 - val_acc: 0.5679\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 8s 880us/step - loss: 1.2480 - acc: 0.8615 - val_loss: 2.3323 - val_acc: 0.5688\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 7s 843us/step - loss: 1.2570 - acc: 0.8461 - val_loss: 2.3021 - val_acc: 0.5806\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 8s 886us/step - loss: 1.2507 - acc: 0.8528 - val_loss: 2.2609 - val_acc: 0.5616\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 7s 846us/step - loss: 1.2344 - acc: 0.8556 - val_loss: 2.3179 - val_acc: 0.5553\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 7s 796us/step - loss: 1.2090 - acc: 0.8599 - val_loss: 2.3586 - val_acc: 0.5743\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 7s 784us/step - loss: 1.1531 - acc: 0.8808 - val_loss: 2.3416 - val_acc: 0.5598\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 7s 791us/step - loss: 1.1402 - acc: 0.8854 - val_loss: 2.3965 - val_acc: 0.5534\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 1.1402 - acc: 0.8736 - val_loss: 2.3997 - val_acc: 0.5553\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 92.9055 - acc: 0.4567 - val_loss: 83.9898 - val_acc: 0.5326\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 874us/step - loss: 76.2513 - acc: 0.5996 - val_loss: 68.5962 - val_acc: 0.5272\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 911us/step - loss: 61.9778 - acc: 0.6336 - val_loss: 55.7129 - val_acc: 0.5399\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 915us/step - loss: 50.2220 - acc: 0.6498 - val_loss: 45.2361 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 945us/step - loss: 40.6691 - acc: 0.6555 - val_loss: 36.6982 - val_acc: 0.5326\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 32.9377 - acc: 0.6645 - val_loss: 29.8213 - val_acc: 0.5254\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 957us/step - loss: 26.7006 - acc: 0.6779 - val_loss: 24.2878 - val_acc: 0.5498\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 921us/step - loss: 21.7394 - acc: 0.6694 - val_loss: 19.8561 - val_acc: 0.5362\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 905us/step - loss: 17.7538 - acc: 0.6796 - val_loss: 16.3314 - val_acc: 0.5498\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 938us/step - loss: 14.6172 - acc: 0.6724 - val_loss: 13.5508 - val_acc: 0.5462\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 925us/step - loss: 12.0998 - acc: 0.6715 - val_loss: 11.3859 - val_acc: 0.5290\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 867us/step - loss: 10.1003 - acc: 0.6626 - val_loss: 9.5643 - val_acc: 0.5344\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 8.5358 - acc: 0.6568 - val_loss: 8.1508 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 7.2627 - acc: 0.6626 - val_loss: 7.0096 - val_acc: 0.5498\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 6.2483 - acc: 0.6591 - val_loss: 6.1189 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 9s 964us/step - loss: 5.4094 - acc: 0.6735 - val_loss: 5.3749 - val_acc: 0.5534\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 889us/step - loss: 4.7669 - acc: 0.6653 - val_loss: 4.8325 - val_acc: 0.5571\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 947us/step - loss: 4.2037 - acc: 0.6837 - val_loss: 4.3075 - val_acc: 0.5580\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 3.7810 - acc: 0.6863 - val_loss: 4.0315 - val_acc: 0.5408\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 931us/step - loss: 3.4186 - acc: 0.6920 - val_loss: 3.6789 - val_acc: 0.5516\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 872us/step - loss: 3.1204 - acc: 0.7005 - val_loss: 3.3972 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 8s 930us/step - loss: 2.8788 - acc: 0.7038 - val_loss: 3.1966 - val_acc: 0.5571\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 894us/step - loss: 2.6789 - acc: 0.7093 - val_loss: 3.0601 - val_acc: 0.5516\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 2.5249 - acc: 0.7119 - val_loss: 2.9263 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 952us/step - loss: 2.3794 - acc: 0.7153 - val_loss: 2.8536 - val_acc: 0.5471\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 2.2235 - acc: 0.7438 - val_loss: 2.7230 - val_acc: 0.5616\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 929us/step - loss: 2.1236 - acc: 0.7437 - val_loss: 2.7104 - val_acc: 0.5507\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 862us/step - loss: 2.0277 - acc: 0.7586 - val_loss: 2.5908 - val_acc: 0.5697\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 903us/step - loss: 1.9291 - acc: 0.7677 - val_loss: 2.5797 - val_acc: 0.5553\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 8s 889us/step - loss: 1.8757 - acc: 0.7698 - val_loss: 2.5918 - val_acc: 0.5408\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 927us/step - loss: 1.8324 - acc: 0.7680 - val_loss: 2.5476 - val_acc: 0.5371\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 8s 900us/step - loss: 1.7617 - acc: 0.7850 - val_loss: 2.5969 - val_acc: 0.5317\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 8s 918us/step - loss: 1.7266 - acc: 0.7819 - val_loss: 2.4665 - val_acc: 0.5543\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 8s 878us/step - loss: 1.6557 - acc: 0.7944 - val_loss: 2.4335 - val_acc: 0.5697\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 8s 927us/step - loss: 1.5896 - acc: 0.8167 - val_loss: 2.4704 - val_acc: 0.5534\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 8s 890us/step - loss: 1.5574 - acc: 0.8148 - val_loss: 2.4331 - val_acc: 0.5634\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 8s 917us/step - loss: 1.5024 - acc: 0.8299 - val_loss: 2.4622 - val_acc: 0.5571\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 8s 879us/step - loss: 1.5092 - acc: 0.8225 - val_loss: 2.4694 - val_acc: 0.5444\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 1.4646 - acc: 0.8303 - val_loss: 2.4766 - val_acc: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 8s 930us/step - loss: 1.4668 - acc: 0.8275 - val_loss: 2.4549 - val_acc: 0.5661\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 1.4125 - acc: 0.8394 - val_loss: 2.4053 - val_acc: 0.5516\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 1.3553 - acc: 0.8630 - val_loss: 2.4223 - val_acc: 0.5661\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 1.3189 - acc: 0.8693 - val_loss: 2.4122 - val_acc: 0.5643\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 8s 892us/step - loss: 1.3193 - acc: 0.8645 - val_loss: 2.3810 - val_acc: 0.5661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 86.6310 - acc: 0.3854 - val_loss: 83.4248 - val_acc: 0.4900\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 81.0035 - acc: 0.5569 - val_loss: 77.9550 - val_acc: 0.5245\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 75.5196 - acc: 0.6096 - val_loss: 72.6521 - val_acc: 0.5471\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 465us/step - loss: 70.2449 - acc: 0.6362 - val_loss: 67.5716 - val_acc: 0.5389\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 65.2475 - acc: 0.6642 - val_loss: 62.7822 - val_acc: 0.5562\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 60.5646 - acc: 0.6813 - val_loss: 58.3263 - val_acc: 0.5507\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 56.1897 - acc: 0.6975 - val_loss: 54.1446 - val_acc: 0.5453\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 471us/step - loss: 52.1129 - acc: 0.7147 - val_loss: 50.2901 - val_acc: 0.5562\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 48.3343 - acc: 0.7197 - val_loss: 46.6640 - val_acc: 0.5435\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 44.8276 - acc: 0.7336 - val_loss: 43.3698 - val_acc: 0.5525\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 41.5873 - acc: 0.7415 - val_loss: 40.2591 - val_acc: 0.5562\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: 38.5841 - acc: 0.7460 - val_loss: 37.4263 - val_acc: 0.5462\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 463us/step - loss: 35.8092 - acc: 0.7565 - val_loss: 34.8001 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 33.2537 - acc: 0.7517 - val_loss: 32.3833 - val_acc: 0.5380\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 30.8915 - acc: 0.7620 - val_loss: 30.1166 - val_acc: 0.5634\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 458us/step - loss: 28.7128 - acc: 0.7671 - val_loss: 28.0955 - val_acc: 0.5344\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 459us/step - loss: 26.7219 - acc: 0.7574 - val_loss: 26.1715 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 24.8660 - acc: 0.7773 - val_loss: 24.4355 - val_acc: 0.5507\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 23.1506 - acc: 0.7876 - val_loss: 22.8247 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 21.5732 - acc: 0.7894 - val_loss: 21.3716 - val_acc: 0.5380\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 20.1270 - acc: 0.7893 - val_loss: 19.9700 - val_acc: 0.5317\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 463us/step - loss: 18.8166 - acc: 0.7688 - val_loss: 18.7234 - val_acc: 0.5317\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 17.5762 - acc: 0.7780 - val_loss: 17.5588 - val_acc: 0.5553\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: 16.4173 - acc: 0.7986 - val_loss: 16.4621 - val_acc: 0.5453\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 458us/step - loss: 15.3793 - acc: 0.7911 - val_loss: 15.4919 - val_acc: 0.5380\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 78.1502 - acc: 0.4550 - val_loss: 63.4434 - val_acc: 0.5027\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 51.6820 - acc: 0.5399 - val_loss: 41.2532 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 33.2365 - acc: 0.5674 - val_loss: 26.4301 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 21.2637 - acc: 0.5752 - val_loss: 17.0417 - val_acc: 0.5091\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 13.7890 - acc: 0.5689 - val_loss: 11.1614 - val_acc: 0.5562\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 9.2127 - acc: 0.5724 - val_loss: 7.6824 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 6.4571 - acc: 0.5718 - val_loss: 5.5508 - val_acc: 0.5308\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.7756 - acc: 0.5688 - val_loss: 4.2833 - val_acc: 0.5326\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.7589 - acc: 0.5754 - val_loss: 3.5235 - val_acc: 0.5082\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.1000 - acc: 0.5758 - val_loss: 3.0408 - val_acc: 0.4864\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.6903 - acc: 0.5805 - val_loss: 2.6677 - val_acc: 0.5136\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.3915 - acc: 0.5851 - val_loss: 2.4487 - val_acc: 0.5498\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.1838 - acc: 0.5986 - val_loss: 2.2447 - val_acc: 0.5498\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0268 - acc: 0.5946 - val_loss: 2.1262 - val_acc: 0.5299\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9088 - acc: 0.6060 - val_loss: 2.0623 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: nan - acc: 0.0694 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 100.4955 - acc: 0.4336 - val_loss: 81.8808 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 67.1215 - acc: 0.5189 - val_loss: 53.8775 - val_acc: 0.5100\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 43.7975 - acc: 0.5472 - val_loss: 34.9981 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 28.3476 - acc: 0.5566 - val_loss: 22.6944 - val_acc: 0.5308\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 18.4394 - acc: 0.5584 - val_loss: 14.9263 - val_acc: 0.5091\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 12.2349 - acc: 0.5633 - val_loss: 10.0734 - val_acc: 0.5281\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 8.3777 - acc: 0.5690 - val_loss: 7.1112 - val_acc: 0.5272\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 6.0061 - acc: 0.5664 - val_loss: 5.2788 - val_acc: 0.5281\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.5403 - acc: 0.5706 - val_loss: 4.0788 - val_acc: 0.5362\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.6226 - acc: 0.5749 - val_loss: 3.3694 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.0388 - acc: 0.5816 - val_loss: 2.9668 - val_acc: 0.5281\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6399 - acc: 0.5898 - val_loss: 2.6592 - val_acc: 0.5480\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4031 - acc: 0.5778 - val_loss: 2.4514 - val_acc: 0.5362\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.2151 - acc: 0.5919 - val_loss: 2.3239 - val_acc: 0.5272\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0576 - acc: 0.5981 - val_loss: 2.2190 - val_acc: 0.5254\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9552 - acc: 0.6054 - val_loss: 2.1170 - val_acc: 0.5335\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8836 - acc: 0.6133 - val_loss: 2.0800 - val_acc: 0.5362\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8144 - acc: 0.6195 - val_loss: 1.9831 - val_acc: 0.5534\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7563 - acc: 0.6195 - val_loss: 1.9873 - val_acc: 0.5353\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6981 - acc: 0.6302 - val_loss: 1.9077 - val_acc: 0.5516\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6608 - acc: 0.6304 - val_loss: 1.8714 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6292 - acc: 0.6359 - val_loss: 1.9636 - val_acc: 0.5118\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5880 - acc: 0.6478 - val_loss: 1.8337 - val_acc: 0.5679\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5723 - acc: 0.6466 - val_loss: 1.9333 - val_acc: 0.5317\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5297 - acc: 0.6593 - val_loss: 1.8294 - val_acc: 0.5399\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5006 - acc: 0.6646 - val_loss: 1.8345 - val_acc: 0.5670\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4870 - acc: 0.6664 - val_loss: 1.8220 - val_acc: 0.5371\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4527 - acc: 0.6729 - val_loss: 1.8902 - val_acc: 0.5389\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4297 - acc: 0.6817 - val_loss: 1.7966 - val_acc: 0.5598\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4292 - acc: 0.6773 - val_loss: 1.8419 - val_acc: 0.5299\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3831 - acc: 0.6905 - val_loss: 1.8261 - val_acc: 0.5399\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3887 - acc: 0.6922 - val_loss: 1.8502 - val_acc: 0.5480\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3638 - acc: 0.6948 - val_loss: 1.8366 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 32.8054 - acc: 0.4515 - val_loss: 30.3243 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 27.9738 - acc: 0.5527 - val_loss: 25.7939 - val_acc: 0.5263\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 23.5853 - acc: 0.5927 - val_loss: 21.7434 - val_acc: 0.5453\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 19.7755 - acc: 0.6181 - val_loss: 18.3448 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 16.5306 - acc: 0.6396 - val_loss: 15.3607 - val_acc: 0.5335\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 13.8145 - acc: 0.6535 - val_loss: 12.8531 - val_acc: 0.5679\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 11.5685 - acc: 0.6666 - val_loss: 10.8704 - val_acc: 0.5471\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 9.7196 - acc: 0.6688 - val_loss: 9.2550 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 8.2229 - acc: 0.6721 - val_loss: 7.8897 - val_acc: 0.5580\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 7.0042 - acc: 0.6788 - val_loss: 6.8414 - val_acc: 0.5670\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 6.0140 - acc: 0.6860 - val_loss: 5.9602 - val_acc: 0.5525\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 5.2165 - acc: 0.6892 - val_loss: 5.2708 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.5851 - acc: 0.6864 - val_loss: 4.7476 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.0675 - acc: 0.6865 - val_loss: 4.2210 - val_acc: 0.5543\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.6329 - acc: 0.6983 - val_loss: 3.8732 - val_acc: 0.5607\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.2868 - acc: 0.6982 - val_loss: 3.6064 - val_acc: 0.5426\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 56.8153 - acc: 0.3782 - val_loss: 54.6649 - val_acc: 0.4846\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 52.9570 - acc: 0.5371 - val_loss: 50.8285 - val_acc: 0.5344\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 49.0442 - acc: 0.5967 - val_loss: 47.0241 - val_acc: 0.5290\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 45.1988 - acc: 0.6340 - val_loss: 43.2987 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 41.5043 - acc: 0.6587 - val_loss: 39.7620 - val_acc: 0.5516\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 38.0243 - acc: 0.6838 - val_loss: 36.4642 - val_acc: 0.5543\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 34.7902 - acc: 0.6995 - val_loss: 33.4098 - val_acc: 0.5534\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 31.8131 - acc: 0.7106 - val_loss: 30.5898 - val_acc: 0.5389\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 29.0842 - acc: 0.7227 - val_loss: 28.0387 - val_acc: 0.5489\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 26.5977 - acc: 0.7327 - val_loss: 25.7027 - val_acc: 0.5471\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 24.3338 - acc: 0.7453 - val_loss: 23.6014 - val_acc: 0.5598\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 22.2824 - acc: 0.7484 - val_loss: 21.6540 - val_acc: 0.5661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 20.4192 - acc: 0.7555 - val_loss: 19.9463 - val_acc: 0.5462\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 18.7443 - acc: 0.7573 - val_loss: 18.3730 - val_acc: 0.5525\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 17.2075 - acc: 0.7715 - val_loss: 16.9420 - val_acc: 0.5534\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 15.8175 - acc: 0.7774 - val_loss: 15.6365 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 14.5617 - acc: 0.7830 - val_loss: 14.4978 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 13.4193 - acc: 0.7915 - val_loss: 13.4149 - val_acc: 0.5516\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 12.3883 - acc: 0.7964 - val_loss: 12.4337 - val_acc: 0.5607\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 11.4409 - acc: 0.8004 - val_loss: 11.5844 - val_acc: 0.5435\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 10.5983 - acc: 0.7987 - val_loss: 10.8046 - val_acc: 0.5408\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 9.8498 - acc: 0.7958 - val_loss: 10.0852 - val_acc: 0.5589\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: nan - acc: 0.0697 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 40.9664 - acc: 0.4443 - val_loss: 37.3683 - val_acc: 0.5109\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 34.0117 - acc: 0.5425 - val_loss: 30.8839 - val_acc: 0.5299\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 27.8567 - acc: 0.5753 - val_loss: 25.2181 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 22.6401 - acc: 0.5976 - val_loss: 20.5566 - val_acc: 0.5335\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 18.3370 - acc: 0.6240 - val_loss: 16.6561 - val_acc: 0.5707\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 14.8469 - acc: 0.6441 - val_loss: 13.6196 - val_acc: 0.5507\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 12.0706 - acc: 0.6440 - val_loss: 11.1676 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.8917 - acc: 0.6390 - val_loss: 9.2393 - val_acc: 0.5399\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 8.1552 - acc: 0.6403 - val_loss: 7.6680 - val_acc: 0.5607\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.8003 - acc: 0.6521 - val_loss: 6.5358 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.7524 - acc: 0.6540 - val_loss: 5.5884 - val_acc: 0.5507\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.9227 - acc: 0.6542 - val_loss: 4.8641 - val_acc: 0.5480\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.2803 - acc: 0.6564 - val_loss: 4.3254 - val_acc: 0.5426\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.7553 - acc: 0.6613 - val_loss: 3.8448 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3450 - acc: 0.6692 - val_loss: 3.5067 - val_acc: 0.5562\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 79.6508 - acc: 0.4267 - val_loss: 72.7061 - val_acc: 0.4991\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 866us/step - loss: 66.7556 - acc: 0.5437 - val_loss: 60.6835 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 55.4699 - acc: 0.5772 - val_loss: 50.3620 - val_acc: 0.5290\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 905us/step - loss: 45.9415 - acc: 0.5951 - val_loss: 41.7402 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 883us/step - loss: 37.9802 - acc: 0.6088 - val_loss: 34.5006 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 904us/step - loss: 31.3553 - acc: 0.6343 - val_loss: 28.5732 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 898us/step - loss: 25.9013 - acc: 0.6412 - val_loss: 23.7125 - val_acc: 0.5254\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 862us/step - loss: 21.4341 - acc: 0.6456 - val_loss: 19.6734 - val_acc: 0.5308\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 17.7927 - acc: 0.6421 - val_loss: 16.4263 - val_acc: 0.5281\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 14.8312 - acc: 0.6517 - val_loss: 13.7701 - val_acc: 0.5371\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 923us/step - loss: 12.4299 - acc: 0.6524 - val_loss: 11.6711 - val_acc: 0.5317\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 817us/step - loss: 10.4772 - acc: 0.6524 - val_loss: 9.9282 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 872us/step - loss: 8.9017 - acc: 0.6599 - val_loss: 8.5110 - val_acc: 0.5181\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 849us/step - loss: 7.6223 - acc: 0.6620 - val_loss: 7.3638 - val_acc: 0.5417\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 859us/step - loss: 6.5998 - acc: 0.6545 - val_loss: 6.4566 - val_acc: 0.5516\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 5.7531 - acc: 0.6636 - val_loss: 5.7335 - val_acc: 0.5263\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 5.0456 - acc: 0.6649 - val_loss: 5.0798 - val_acc: 0.5417\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 867us/step - loss: 4.5045 - acc: 0.6726 - val_loss: 4.5826 - val_acc: 0.5453\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 956us/step - loss: 4.0297 - acc: 0.6761 - val_loss: 4.1941 - val_acc: 0.5299\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 907us/step - loss: 3.6439 - acc: 0.6771 - val_loss: 3.8408 - val_acc: 0.5562\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 844us/step - loss: 3.3456 - acc: 0.6807 - val_loss: 3.5596 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 3.0582 - acc: 0.6912 - val_loss: 3.4514 - val_acc: 0.5408\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 888us/step - loss: 2.8516 - acc: 0.6945 - val_loss: 3.1632 - val_acc: 0.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 885us/step - loss: 2.6682 - acc: 0.6928 - val_loss: 3.0211 - val_acc: 0.5553\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 891us/step - loss: 2.5233 - acc: 0.6982 - val_loss: 2.9112 - val_acc: 0.5362\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 864us/step - loss: 2.3705 - acc: 0.7073 - val_loss: 2.7812 - val_acc: 0.5507\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 915us/step - loss: 2.2487 - acc: 0.7124 - val_loss: 2.8058 - val_acc: 0.5226\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 878us/step - loss: 2.1691 - acc: 0.7125 - val_loss: 2.6476 - val_acc: 0.5471\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 943us/step - loss: 2.0429 - acc: 0.7307 - val_loss: 2.6393 - val_acc: 0.5480\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 845us/step - loss: 1.9599 - acc: 0.7430 - val_loss: 2.5164 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 60.0447 - acc: 0.4576 - val_loss: 53.3306 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 875us/step - loss: 47.5172 - acc: 0.5710 - val_loss: 41.8098 - val_acc: 0.5254\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 855us/step - loss: 36.9391 - acc: 0.6072 - val_loss: 32.4559 - val_acc: 0.5408\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 28.5674 - acc: 0.6163 - val_loss: 25.1701 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 22.0701 - acc: 0.6429 - val_loss: 19.5761 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 17.1275 - acc: 0.6473 - val_loss: 15.3340 - val_acc: 0.5362\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 13.3941 - acc: 0.6541 - val_loss: 12.1418 - val_acc: 0.5163\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 10.5741 - acc: 0.6567 - val_loss: 9.7394 - val_acc: 0.5199\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 842us/step - loss: 8.5142 - acc: 0.6378 - val_loss: 7.9615 - val_acc: 0.5226\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 6.9384 - acc: 0.6408 - val_loss: 6.5244 - val_acc: 0.5489\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 803us/step - loss: 5.7439 - acc: 0.6466 - val_loss: 5.5381 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 839us/step - loss: 4.8682 - acc: 0.6422 - val_loss: 4.7818 - val_acc: 0.5353\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 4.1752 - acc: 0.6497 - val_loss: 4.2120 - val_acc: 0.5308\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 819us/step - loss: 3.6400 - acc: 0.6492 - val_loss: 3.7176 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 3.2422 - acc: 0.6527 - val_loss: 3.4049 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 807us/step - loss: 2.9158 - acc: 0.6637 - val_loss: 3.1444 - val_acc: 0.5254\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 2.6784 - acc: 0.6555 - val_loss: 2.9353 - val_acc: 0.5480\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 799us/step - loss: 2.4720 - acc: 0.6621 - val_loss: 2.7670 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 807us/step - loss: 2.2654 - acc: 0.6801 - val_loss: 2.5702 - val_acc: 0.5543\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 805us/step - loss: 2.1451 - acc: 0.6815 - val_loss: 2.4918 - val_acc: 0.5362\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 2.0028 - acc: 0.6941 - val_loss: 2.4260 - val_acc: 0.5335\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 798us/step - loss: 1.9181 - acc: 0.6943 - val_loss: 2.3294 - val_acc: 0.5471\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 775us/step - loss: 1.8472 - acc: 0.6925 - val_loss: 2.3069 - val_acc: 0.5326\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 819us/step - loss: 1.7607 - acc: 0.7068 - val_loss: 2.2872 - val_acc: 0.5408\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 829us/step - loss: 1.6839 - acc: 0.7141 - val_loss: 2.2127 - val_acc: 0.5553\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 832us/step - loss: 1.6144 - acc: 0.7266 - val_loss: 2.1582 - val_acc: 0.5589\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 1.5716 - acc: 0.7257 - val_loss: 2.1137 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 1.5195 - acc: 0.7393 - val_loss: 2.1914 - val_acc: 0.5371\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 813us/step - loss: 1.4944 - acc: 0.7380 - val_loss: 2.1232 - val_acc: 0.5489\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 841us/step - loss: 1.4566 - acc: 0.7420 - val_loss: 2.1256 - val_acc: 0.5562\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 1.3960 - acc: 0.7610 - val_loss: 2.0966 - val_acc: 0.5607\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 1.3698 - acc: 0.7654 - val_loss: 2.1184 - val_acc: 0.5444\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 1.3243 - acc: 0.7754 - val_loss: 2.1650 - val_acc: 0.5335\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 841us/step - loss: 1.3224 - acc: 0.7722 - val_loss: 2.1228 - val_acc: 0.5553\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 1.3514 - acc: 0.7628 - val_loss: 2.1095 - val_acc: 0.5616\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 814us/step - loss: 1.2742 - acc: 0.7883 - val_loss: 2.1603 - val_acc: 0.5516\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 8s 854us/step - loss: 1.2247 - acc: 0.8028 - val_loss: 2.2516 - val_acc: 0.5353\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 8s 868us/step - loss: 1.2156 - acc: 0.7992 - val_loss: 2.1050 - val_acc: 0.5580\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 1.1617 - acc: 0.8203 - val_loss: 2.1061 - val_acc: 0.5688\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 7s 818us/step - loss: 1.1540 - acc: 0.8180 - val_loss: 2.2409 - val_acc: 0.5199\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 1.1775 - acc: 0.8129 - val_loss: 2.2417 - val_acc: 0.5389\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 7s 816us/step - loss: 1.1209 - acc: 0.8341 - val_loss: 2.2008 - val_acc: 0.5534\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 8s 894us/step - loss: 1.1510 - acc: 0.8208 - val_loss: 2.2308 - val_acc: 0.5553\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 8s 851us/step - loss: 1.1043 - acc: 0.8389 - val_loss: 2.2586 - val_acc: 0.5444\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 8s 863us/step - loss: 1.1010 - acc: 0.8359 - val_loss: 2.2343 - val_acc: 0.5507\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 1.0782 - acc: 0.8422 - val_loss: 2.2612 - val_acc: 0.5507\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 7s 817us/step - loss: 1.0202 - acc: 0.8631 - val_loss: 2.2058 - val_acc: 0.5607\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 8s 864us/step - loss: 1.0079 - acc: 0.8594 - val_loss: 2.2203 - val_acc: 0.5562\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 7s 804us/step - loss: 1.0273 - acc: 0.8536 - val_loss: 2.2186 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0699 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 735us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 735us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 83.8571 - acc: 0.4400 - val_loss: 70.4704 - val_acc: 0.4955\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 59.3291 - acc: 0.5280 - val_loss: 49.1659 - val_acc: 0.5190\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 41.0721 - acc: 0.5479 - val_loss: 33.8658 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 28.1783 - acc: 0.5597 - val_loss: 23.2793 - val_acc: 0.5226\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 19.3426 - acc: 0.5724 - val_loss: 16.0672 - val_acc: 0.5299\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.4305 - acc: 0.5783 - val_loss: 11.3056 - val_acc: 0.5353\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 9.5180 - acc: 0.5748 - val_loss: 8.1671 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.9632 - acc: 0.5846 - val_loss: 6.1102 - val_acc: 0.5091\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.2984 - acc: 0.5747 - val_loss: 4.8354 - val_acc: 0.5154\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.1983 - acc: 0.5813 - val_loss: 3.9200 - val_acc: 0.5326\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.4683 - acc: 0.5867 - val_loss: 3.2776 - val_acc: 0.5580\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9657 - acc: 0.5949 - val_loss: 2.9521 - val_acc: 0.5317\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6391 - acc: 0.5895 - val_loss: 2.6227 - val_acc: 0.5553\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3852 - acc: 0.5964 - val_loss: 2.4855 - val_acc: 0.5444\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.2073 - acc: 0.6019 - val_loss: 2.3352 - val_acc: 0.5353\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0616 - acc: 0.6142 - val_loss: 2.1806 - val_acc: 0.5489\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9470 - acc: 0.6201 - val_loss: 2.1122 - val_acc: 0.5417\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8761 - acc: 0.6202 - val_loss: 2.0686 - val_acc: 0.5290\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8041 - acc: 0.6271 - val_loss: 2.0679 - val_acc: 0.5335\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7399 - acc: 0.6376 - val_loss: 1.9754 - val_acc: 0.5534\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6917 - acc: 0.6402 - val_loss: 1.9487 - val_acc: 0.5281\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 55.2628 - acc: 0.4400 - val_loss: 48.9100 - val_acc: 0.5127\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 43.5030 - acc: 0.5476 - val_loss: 38.1622 - val_acc: 0.5199\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 892us/step - loss: 33.7110 - acc: 0.5807 - val_loss: 29.4849 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 856us/step - loss: 25.9698 - acc: 0.6040 - val_loss: 22.7636 - val_acc: 0.5335\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 20.0005 - acc: 0.6116 - val_loss: 17.6173 - val_acc: 0.5299\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 15.4318 - acc: 0.6354 - val_loss: 13.7143 - val_acc: 0.5335\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 894us/step - loss: 12.0127 - acc: 0.6348 - val_loss: 10.8209 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 899us/step - loss: 9.4793 - acc: 0.6312 - val_loss: 8.6543 - val_acc: 0.5362\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 827us/step - loss: 7.6076 - acc: 0.6251 - val_loss: 7.1023 - val_acc: 0.5281\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 840us/step - loss: 6.1718 - acc: 0.6386 - val_loss: 5.8728 - val_acc: 0.5199\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 5.1312 - acc: 0.6342 - val_loss: 4.9854 - val_acc: 0.5199\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 4.3804 - acc: 0.6244 - val_loss: 4.2628 - val_acc: 0.5380\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 3.7404 - acc: 0.6417 - val_loss: 3.7987 - val_acc: 0.5172\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 844us/step - loss: 3.2961 - acc: 0.6367 - val_loss: 3.4150 - val_acc: 0.5281\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 863us/step - loss: 2.9703 - acc: 0.6306 - val_loss: 3.1668 - val_acc: 0.5109\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 846us/step - loss: 2.6769 - acc: 0.6436 - val_loss: 2.8527 - val_acc: 0.5589\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 2.4459 - acc: 0.6550 - val_loss: 2.6813 - val_acc: 0.5489\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 891us/step - loss: 2.2805 - acc: 0.6585 - val_loss: 2.5775 - val_acc: 0.5326\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 941us/step - loss: 2.1390 - acc: 0.6591 - val_loss: 2.4110 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 836us/step - loss: 2.0131 - acc: 0.6693 - val_loss: 2.3521 - val_acc: 0.5371\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 1.9251 - acc: 0.6748 - val_loss: 2.2182 - val_acc: 0.5661\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 832us/step - loss: 1.8307 - acc: 0.6755 - val_loss: 2.1552 - val_acc: 0.5435\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 1.7568 - acc: 0.6833 - val_loss: 2.1520 - val_acc: 0.5362\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 1.7100 - acc: 0.6878 - val_loss: 2.1091 - val_acc: 0.5589\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 1.6315 - acc: 0.6983 - val_loss: 2.1247 - val_acc: 0.5417\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 1.6044 - acc: 0.7003 - val_loss: 2.1096 - val_acc: 0.5444\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 920us/step - loss: 1.5581 - acc: 0.7086 - val_loss: 2.1058 - val_acc: 0.5353\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 874us/step - loss: 1.5362 - acc: 0.7036 - val_loss: 2.1073 - val_acc: 0.5254\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 1.4744 - acc: 0.7199 - val_loss: 2.0165 - val_acc: 0.5380\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 795us/step - loss: 1.4263 - acc: 0.7251 - val_loss: 1.9983 - val_acc: 0.5471\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 866us/step - loss: 1.3978 - acc: 0.7354 - val_loss: 2.0504 - val_acc: 0.5272\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 92.5899 - acc: 0.4520 - val_loss: 81.2845 - val_acc: 0.4964\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 71.9495 - acc: 0.5648 - val_loss: 62.7092 - val_acc: 0.5389\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 944us/step - loss: 55.1740 - acc: 0.6014 - val_loss: 47.9845 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 843us/step - loss: 42.0628 - acc: 0.6121 - val_loss: 36.5790 - val_acc: 0.5498\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 938us/step - loss: 32.0280 - acc: 0.6197 - val_loss: 27.9509 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 890us/step - loss: 24.4180 - acc: 0.6343 - val_loss: 21.4508 - val_acc: 0.5362\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 892us/step - loss: 18.6924 - acc: 0.6376 - val_loss: 16.5769 - val_acc: 0.5190\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 14.4618 - acc: 0.6257 - val_loss: 12.9432 - val_acc: 0.5317\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 826us/step - loss: 11.2817 - acc: 0.6265 - val_loss: 10.2792 - val_acc: 0.5100\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 873us/step - loss: 8.9411 - acc: 0.6228 - val_loss: 8.2574 - val_acc: 0.5208\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 937us/step - loss: 7.1974 - acc: 0.6219 - val_loss: 6.7245 - val_acc: 0.5263\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 5.8983 - acc: 0.6282 - val_loss: 5.6491 - val_acc: 0.5217\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 4.9241 - acc: 0.6334 - val_loss: 4.7674 - val_acc: 0.5498\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 938us/step - loss: 4.1994 - acc: 0.6352 - val_loss: 4.1874 - val_acc: 0.5100\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 78.0115 - acc: 0.4147 - val_loss: 71.0566 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 65.2133 - acc: 0.5106 - val_loss: 59.1948 - val_acc: 0.5136\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 54.1435 - acc: 0.5488 - val_loss: 49.0789 - val_acc: 0.5190\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 897us/step - loss: 44.7876 - acc: 0.5674 - val_loss: 40.5595 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 36.9650 - acc: 0.5802 - val_loss: 33.5479 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 908us/step - loss: 30.4634 - acc: 0.5953 - val_loss: 27.6391 - val_acc: 0.5498\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 863us/step - loss: 25.1219 - acc: 0.6045 - val_loss: 22.8628 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 840us/step - loss: 20.7287 - acc: 0.6160 - val_loss: 18.9413 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 894us/step - loss: 17.1560 - acc: 0.6216 - val_loss: 15.7762 - val_acc: 0.5444\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 919us/step - loss: 14.2586 - acc: 0.6271 - val_loss: 13.2063 - val_acc: 0.5236\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 858us/step - loss: 11.9048 - acc: 0.6288 - val_loss: 11.1431 - val_acc: 0.5082\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 10.0203 - acc: 0.6226 - val_loss: 9.4003 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 886us/step - loss: 8.4915 - acc: 0.6285 - val_loss: 8.0758 - val_acc: 0.5163\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 844us/step - loss: 7.2292 - acc: 0.6394 - val_loss: 6.9677 - val_acc: 0.5344\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 876us/step - loss: 6.2437 - acc: 0.6334 - val_loss: 6.0548 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 826us/step - loss: 5.4275 - acc: 0.6359 - val_loss: 5.3708 - val_acc: 0.5317\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 934us/step - loss: 4.7614 - acc: 0.6475 - val_loss: 4.7561 - val_acc: 0.5371\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 903us/step - loss: 4.2362 - acc: 0.6538 - val_loss: 4.2831 - val_acc: 0.5543\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 3.7933 - acc: 0.6598 - val_loss: 3.9368 - val_acc: 0.5353\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 3.4466 - acc: 0.6622 - val_loss: 3.6118 - val_acc: 0.5426\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 910us/step - loss: 3.1420 - acc: 0.6702 - val_loss: 3.3196 - val_acc: 0.5543\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 8s 873us/step - loss: 2.8761 - acc: 0.6838 - val_loss: 3.1260 - val_acc: 0.5462\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 2.6931 - acc: 0.6766 - val_loss: 2.9632 - val_acc: 0.5417\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 2.5055 - acc: 0.6881 - val_loss: 2.8794 - val_acc: 0.5290\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 2.3777 - acc: 0.6878 - val_loss: 2.7409 - val_acc: 0.5245\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 2.2442 - acc: 0.6997 - val_loss: 2.6721 - val_acc: 0.5399\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 818us/step - loss: 2.1455 - acc: 0.6999 - val_loss: 2.6237 - val_acc: 0.5362\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 826us/step - loss: 2.0493 - acc: 0.7102 - val_loss: 2.6094 - val_acc: 0.5172\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 1.9955 - acc: 0.7073 - val_loss: 2.4639 - val_acc: 0.5480\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 1.8938 - acc: 0.7219 - val_loss: 2.4357 - val_acc: 0.5471\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 1.8433 - acc: 0.7265 - val_loss: 2.4734 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 66.3011 - acc: 0.3658 - val_loss: 64.2806 - val_acc: 0.4683\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 62.6812 - acc: 0.5272 - val_loss: 60.7243 - val_acc: 0.5136\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 59.0961 - acc: 0.5707 - val_loss: 57.2006 - val_acc: 0.5172\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 55.5242 - acc: 0.6077 - val_loss: 53.7112 - val_acc: 0.5507\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 52.0495 - acc: 0.6365 - val_loss: 50.3338 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 48.7155 - acc: 0.6519 - val_loss: 47.1263 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 45.5416 - acc: 0.6677 - val_loss: 44.0655 - val_acc: 0.5562\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 42.5347 - acc: 0.6811 - val_loss: 41.1817 - val_acc: 0.5525\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 39.7002 - acc: 0.6954 - val_loss: 38.4804 - val_acc: 0.5670\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 471us/step - loss: 37.0519 - acc: 0.7011 - val_loss: 35.9638 - val_acc: 0.5480\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 34.5634 - acc: 0.7125 - val_loss: 33.5734 - val_acc: 0.5697\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 32.2499 - acc: 0.7155 - val_loss: 31.3736 - val_acc: 0.5562\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 476us/step - loss: 30.0889 - acc: 0.7317 - val_loss: 29.3219 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 28.0743 - acc: 0.7379 - val_loss: 27.4423 - val_acc: 0.5444\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 466us/step - loss: 26.2036 - acc: 0.7508 - val_loss: 25.6269 - val_acc: 0.5607\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 24.4592 - acc: 0.7589 - val_loss: 24.0026 - val_acc: 0.5462\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 22.8408 - acc: 0.7683 - val_loss: 22.4767 - val_acc: 0.5598\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 21.3525 - acc: 0.7676 - val_loss: 21.0555 - val_acc: 0.5562\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 19.9634 - acc: 0.7711 - val_loss: 19.7500 - val_acc: 0.5634\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 18.6752 - acc: 0.7766 - val_loss: 18.5086 - val_acc: 0.5643\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 17.4915 - acc: 0.7782 - val_loss: 17.3893 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 86.1943 - acc: 0.4320 - val_loss: 65.5758 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 50.4654 - acc: 0.5155 - val_loss: 37.5245 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 28.6104 - acc: 0.5334 - val_loss: 21.2332 - val_acc: 0.5118\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 16.2612 - acc: 0.5459 - val_loss: 12.3178 - val_acc: 0.5082\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.5907 - acc: 0.5397 - val_loss: 7.6033 - val_acc: 0.5018\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.0639 - acc: 0.5474 - val_loss: 5.0416 - val_acc: 0.5136\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.2162 - acc: 0.5542 - val_loss: 3.7026 - val_acc: 0.4973\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.2303 - acc: 0.5570 - val_loss: 2.9373 - val_acc: 0.5226\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6608 - acc: 0.5563 - val_loss: 2.5812 - val_acc: 0.5263\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3440 - acc: 0.5557 - val_loss: 2.2366 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0921 - acc: 0.5771 - val_loss: 2.1524 - val_acc: 0.5317\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9856 - acc: 0.5635 - val_loss: 2.1203 - val_acc: 0.4909\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8631 - acc: 0.5750 - val_loss: 1.9407 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7738 - acc: 0.5810 - val_loss: 1.8509 - val_acc: 0.5498\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7208 - acc: 0.5842 - val_loss: 1.8397 - val_acc: 0.5254\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6821 - acc: 0.5900 - val_loss: 1.8340 - val_acc: 0.5254\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6096 - acc: 0.5990 - val_loss: 1.7304 - val_acc: 0.5480\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5907 - acc: 0.5998 - val_loss: 1.7501 - val_acc: 0.5299\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5727 - acc: 0.6051 - val_loss: 1.7435 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5321 - acc: 0.6131 - val_loss: 1.7354 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5381 - acc: 0.6106 - val_loss: 1.7003 - val_acc: 0.5534\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5028 - acc: 0.6186 - val_loss: 1.6684 - val_acc: 0.5444\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4767 - acc: 0.6217 - val_loss: 1.6787 - val_acc: 0.5498\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4566 - acc: 0.6295 - val_loss: 1.7295 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4468 - acc: 0.6295 - val_loss: 1.7463 - val_acc: 0.5308\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4424 - acc: 0.6331 - val_loss: 1.7125 - val_acc: 0.5326\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4422 - acc: 0.6347 - val_loss: 1.6649 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4192 - acc: 0.6370 - val_loss: 1.7333 - val_acc: 0.5335\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4113 - acc: 0.6412 - val_loss: 1.6479 - val_acc: 0.5525\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3965 - acc: 0.6504 - val_loss: 1.7326 - val_acc: 0.5371\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3692 - acc: 0.6525 - val_loss: 1.6953 - val_acc: 0.5362\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 83.2117 - acc: 0.3760 - val_loss: 79.3257 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 76.3656 - acc: 0.5257 - val_loss: 72.5141 - val_acc: 0.5217\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 69.6224 - acc: 0.5725 - val_loss: 65.9987 - val_acc: 0.5426\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 63.2470 - acc: 0.5975 - val_loss: 59.9399 - val_acc: 0.5462\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 466us/step - loss: 57.3305 - acc: 0.6203 - val_loss: 54.3503 - val_acc: 0.5317\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 51.9133 - acc: 0.6373 - val_loss: 49.2175 - val_acc: 0.5571\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 470us/step - loss: 46.9661 - acc: 0.6540 - val_loss: 44.5641 - val_acc: 0.5589\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 42.4798 - acc: 0.6590 - val_loss: 40.3542 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 38.4216 - acc: 0.6685 - val_loss: 36.5646 - val_acc: 0.5380\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 34.7499 - acc: 0.6800 - val_loss: 33.1115 - val_acc: 0.5462\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 31.4547 - acc: 0.6744 - val_loss: 30.0311 - val_acc: 0.5471\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 28.4842 - acc: 0.6826 - val_loss: 27.2465 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 25.8067 - acc: 0.7012 - val_loss: 24.7959 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 23.3965 - acc: 0.7093 - val_loss: 22.5314 - val_acc: 0.5371\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 21.2489 - acc: 0.7028 - val_loss: 20.5093 - val_acc: 0.5571\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 19.3050 - acc: 0.7149 - val_loss: 18.7597 - val_acc: 0.5299\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 17.5802 - acc: 0.7148 - val_loss: 17.1182 - val_acc: 0.5353\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 16.0110 - acc: 0.7209 - val_loss: 15.6416 - val_acc: 0.5571\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 105.1896 - acc: 0.4051 - val_loss: 96.7574 - val_acc: 0.4955\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 900us/step - loss: 89.6655 - acc: 0.5097 - val_loss: 82.2724 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 888us/step - loss: 76.0405 - acc: 0.5439 - val_loss: 69.6759 - val_acc: 0.5389\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 922us/step - loss: 64.2861 - acc: 0.5619 - val_loss: 58.8468 - val_acc: 0.5435\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 943us/step - loss: 54.2065 - acc: 0.5804 - val_loss: 49.6143 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 829us/step - loss: 45.6194 - acc: 0.5979 - val_loss: 41.7883 - val_acc: 0.5417\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 904us/step - loss: 38.3768 - acc: 0.6091 - val_loss: 35.1904 - val_acc: 0.5389\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 32.2860 - acc: 0.6062 - val_loss: 29.6696 - val_acc: 0.5245\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 923us/step - loss: 27.1774 - acc: 0.6124 - val_loss: 25.0444 - val_acc: 0.5371\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 925us/step - loss: 22.9002 - acc: 0.6269 - val_loss: 21.1592 - val_acc: 0.5562\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 933us/step - loss: 19.3345 - acc: 0.6301 - val_loss: 17.9130 - val_acc: 0.5371\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 926us/step - loss: 16.3813 - acc: 0.6326 - val_loss: 15.2679 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 937us/step - loss: 13.9235 - acc: 0.6389 - val_loss: 13.0661 - val_acc: 0.5353\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 11.8870 - acc: 0.6382 - val_loss: 11.2865 - val_acc: 0.5417\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 801us/step - loss: 10.2076 - acc: 0.6420 - val_loss: 9.7347 - val_acc: 0.5299\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 867us/step - loss: 8.8161 - acc: 0.6448 - val_loss: 8.4665 - val_acc: 0.5408\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 880us/step - loss: 7.6687 - acc: 0.6449 - val_loss: 7.4312 - val_acc: 0.5516\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 887us/step - loss: 6.6982 - acc: 0.6572 - val_loss: 6.5541 - val_acc: 0.5534\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 868us/step - loss: 5.8963 - acc: 0.6615 - val_loss: 5.8336 - val_acc: 0.5408\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 5.2631 - acc: 0.6515 - val_loss: 5.2857 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 55.6398 - acc: 0.4572 - val_loss: 47.1609 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 40.0347 - acc: 0.5802 - val_loss: 33.4050 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 28.0833 - acc: 0.6046 - val_loss: 23.4206 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 891us/step - loss: 19.6315 - acc: 0.6290 - val_loss: 16.5408 - val_acc: 0.5082\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 905us/step - loss: 13.8914 - acc: 0.6189 - val_loss: 11.8632 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 864us/step - loss: 10.0052 - acc: 0.6322 - val_loss: 8.7519 - val_acc: 0.5362\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: 7.4450 - acc: 0.6215 - val_loss: 6.7783 - val_acc: 0.5054\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 845us/step - loss: 5.7284 - acc: 0.6185 - val_loss: 5.3456 - val_acc: 0.4810\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 4.5695 - acc: 0.6138 - val_loss: 4.4198 - val_acc: 0.5208\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 3.7906 - acc: 0.6121 - val_loss: 3.6999 - val_acc: 0.5217\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 3.2044 - acc: 0.6148 - val_loss: 3.2461 - val_acc: 0.5263\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 2.8069 - acc: 0.6191 - val_loss: 2.9286 - val_acc: 0.5018\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 871us/step - loss: 2.4871 - acc: 0.6323 - val_loss: 2.6007 - val_acc: 0.5408\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 2.2770 - acc: 0.6368 - val_loss: 2.4868 - val_acc: 0.5118\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 2.0986 - acc: 0.6360 - val_loss: 2.2900 - val_acc: 0.5553\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 879us/step - loss: 1.9603 - acc: 0.6466 - val_loss: 2.2608 - val_acc: 0.5317\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 865us/step - loss: 1.8315 - acc: 0.6567 - val_loss: 2.1364 - val_acc: 0.5290\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 1.7631 - acc: 0.6589 - val_loss: 2.0714 - val_acc: 0.5362\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 1.6601 - acc: 0.6690 - val_loss: 2.0152 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 889us/step - loss: 1.6275 - acc: 0.6696 - val_loss: 1.9316 - val_acc: 0.5444\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 929us/step - loss: 1.5336 - acc: 0.6803 - val_loss: 1.9576 - val_acc: 0.5254\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 8s 872us/step - loss: 1.5221 - acc: 0.6761 - val_loss: 1.9103 - val_acc: 0.5453\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 874us/step - loss: 1.4697 - acc: 0.6929 - val_loss: 1.8818 - val_acc: 0.5471\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 848us/step - loss: 1.4699 - acc: 0.6826 - val_loss: 1.8940 - val_acc: 0.5553\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 899us/step - loss: 1.3812 - acc: 0.7045 - val_loss: 1.8977 - val_acc: 0.5571\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 855us/step - loss: 1.3164 - acc: 0.7225 - val_loss: 1.9502 - val_acc: 0.5435\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 839us/step - loss: 1.3404 - acc: 0.7105 - val_loss: 1.9250 - val_acc: 0.5471\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 939us/step - loss: 1.3241 - acc: 0.7124 - val_loss: 1.8929 - val_acc: 0.5562\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 897us/step - loss: 1.2342 - acc: 0.7463 - val_loss: 1.8310 - val_acc: 0.5679\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 8s 875us/step - loss: 1.2245 - acc: 0.7392 - val_loss: 1.8967 - val_acc: 0.5380\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 1.2312 - acc: 0.7402 - val_loss: 1.8818 - val_acc: 0.5507\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 847us/step - loss: 1.1970 - acc: 0.7481 - val_loss: 1.9144 - val_acc: 0.5389\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 8s 944us/step - loss: 1.1797 - acc: 0.7546 - val_loss: 1.9253 - val_acc: 0.5462\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 8s 881us/step - loss: 1.1676 - acc: 0.7601 - val_loss: 1.9791 - val_acc: 0.5489\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 8s 856us/step - loss: 1.1305 - acc: 0.7728 - val_loss: 1.9546 - val_acc: 0.5426\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 799us/step - loss: 1.1101 - acc: 0.7777 - val_loss: 2.0507 - val_acc: 0.5489\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 8s 853us/step - loss: 1.1378 - acc: 0.7710 - val_loss: 2.0955 - val_acc: 0.5335\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 1.1111 - acc: 0.7848 - val_loss: 2.0123 - val_acc: 0.5444\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 843us/step - loss: 1.0733 - acc: 0.7931 - val_loss: 2.0401 - val_acc: 0.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 36.3507 - acc: 0.4612 - val_loss: 31.7633 - val_acc: 0.4991\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 27.5569 - acc: 0.5534 - val_loss: 23.8231 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 20.4188 - acc: 0.5918 - val_loss: 17.5837 - val_acc: 0.5462\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 15.0294 - acc: 0.6043 - val_loss: 13.0666 - val_acc: 0.5172\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 11.1335 - acc: 0.6192 - val_loss: 9.7961 - val_acc: 0.5453\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 8.3644 - acc: 0.6165 - val_loss: 7.4926 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.4554 - acc: 0.6211 - val_loss: 5.9026 - val_acc: 0.5362\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.1038 - acc: 0.6171 - val_loss: 4.8668 - val_acc: 0.5127\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.1766 - acc: 0.6188 - val_loss: 4.0477 - val_acc: 0.5335\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.5024 - acc: 0.6269 - val_loss: 3.5240 - val_acc: 0.5272\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.0543 - acc: 0.6165 - val_loss: 3.1086 - val_acc: 0.5353\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.7019 - acc: 0.6290 - val_loss: 2.8013 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4309 - acc: 0.6270 - val_loss: 2.5925 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2247 - acc: 0.6340 - val_loss: 2.5234 - val_acc: 0.5127\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0767 - acc: 0.6380 - val_loss: 2.2698 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9499 - acc: 0.6431 - val_loss: 2.1700 - val_acc: 0.5652\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8623 - acc: 0.6450 - val_loss: 2.0852 - val_acc: 0.5344\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7733 - acc: 0.6496 - val_loss: 2.0802 - val_acc: 0.5353\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6903 - acc: 0.6610 - val_loss: 2.0226 - val_acc: 0.5516\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6243 - acc: 0.6666 - val_loss: 2.0572 - val_acc: 0.5389\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5931 - acc: 0.6680 - val_loss: 1.9497 - val_acc: 0.5525\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5355 - acc: 0.6760 - val_loss: 1.8555 - val_acc: 0.5616\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4936 - acc: 0.6839 - val_loss: 1.8727 - val_acc: 0.5516\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4702 - acc: 0.6876 - val_loss: 1.9187 - val_acc: 0.5534\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4274 - acc: 0.6933 - val_loss: 1.8739 - val_acc: 0.5598\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3877 - acc: 0.7017 - val_loss: 1.8355 - val_acc: 0.5679\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3722 - acc: 0.7002 - val_loss: 1.9580 - val_acc: 0.5353\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3412 - acc: 0.7080 - val_loss: 1.9020 - val_acc: 0.5444\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3067 - acc: 0.7206 - val_loss: 1.8586 - val_acc: 0.5507\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2980 - acc: 0.7235 - val_loss: 1.9538 - val_acc: 0.5344\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2904 - acc: 0.7230 - val_loss: 1.9847 - val_acc: 0.5426\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2716 - acc: 0.7249 - val_loss: 1.8745 - val_acc: 0.5543\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2317 - acc: 0.7422 - val_loss: 1.8795 - val_acc: 0.5580\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2083 - acc: 0.7505 - val_loss: 1.9098 - val_acc: 0.5444\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2074 - acc: 0.7449 - val_loss: 1.8931 - val_acc: 0.5580\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.1966 - acc: 0.7479 - val_loss: 1.9176 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 35.0366 - acc: 0.4682 - val_loss: 32.1126 - val_acc: 0.5136\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 29.2342 - acc: 0.5806 - val_loss: 26.7285 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 24.0923 - acc: 0.6303 - val_loss: 22.0007 - val_acc: 0.5543\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 19.7251 - acc: 0.6629 - val_loss: 18.1393 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 16.1343 - acc: 0.6756 - val_loss: 14.9234 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.2158 - acc: 0.6889 - val_loss: 12.3297 - val_acc: 0.5616\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 10.8813 - acc: 0.6945 - val_loss: 10.2917 - val_acc: 0.5426\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.0417 - acc: 0.7009 - val_loss: 8.6280 - val_acc: 0.5625\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 7.5736 - acc: 0.7018 - val_loss: 7.3708 - val_acc: 0.5580\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.4120 - acc: 0.7029 - val_loss: 6.3745 - val_acc: 0.5335\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.5123 - acc: 0.7048 - val_loss: 5.5055 - val_acc: 0.5534\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.7663 - acc: 0.7115 - val_loss: 4.9459 - val_acc: 0.5380\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.2038 - acc: 0.7077 - val_loss: 4.3941 - val_acc: 0.5679\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.7583 - acc: 0.6999 - val_loss: 3.9946 - val_acc: 0.5489\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.3865 - acc: 0.7022 - val_loss: 3.6592 - val_acc: 0.5625\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.0649 - acc: 0.7110 - val_loss: 3.4006 - val_acc: 0.5571\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.8185 - acc: 0.7103 - val_loss: 3.1863 - val_acc: 0.5462\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6150 - acc: 0.7090 - val_loss: 3.0325 - val_acc: 0.5435\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4207 - acc: 0.7261 - val_loss: 2.9037 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2848 - acc: 0.7309 - val_loss: 2.7858 - val_acc: 0.5534\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1511 - acc: 0.7347 - val_loss: 2.7102 - val_acc: 0.5426\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0357 - acc: 0.7355 - val_loss: 2.5983 - val_acc: 0.5543\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9520 - acc: 0.7328 - val_loss: 2.5135 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0726 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 431us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 432us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 425us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 418us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 428us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 434us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 425us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 421us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 62.2317 - acc: 0.3998 - val_loss: 59.7435 - val_acc: 0.5118\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 472us/step - loss: 57.6950 - acc: 0.5765 - val_loss: 55.3213 - val_acc: 0.5100\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 53.1533 - acc: 0.6468 - val_loss: 50.9157 - val_acc: 0.5389\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 443us/step - loss: 48.8026 - acc: 0.6814 - val_loss: 46.7871 - val_acc: 0.5389\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 450us/step - loss: 44.7206 - acc: 0.7160 - val_loss: 42.9097 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 458us/step - loss: 40.9449 - acc: 0.7395 - val_loss: 39.3323 - val_acc: 0.5480\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 37.4720 - acc: 0.7550 - val_loss: 36.0791 - val_acc: 0.5562\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 34.2870 - acc: 0.7779 - val_loss: 33.0754 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 31.3946 - acc: 0.7802 - val_loss: 30.4219 - val_acc: 0.5417\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 28.7804 - acc: 0.7795 - val_loss: 27.9736 - val_acc: 0.5426\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 26.3868 - acc: 0.7974 - val_loss: 25.7313 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 24.2436 - acc: 0.7960 - val_loss: 23.7142 - val_acc: 0.5344\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 22.2881 - acc: 0.8062 - val_loss: 21.8874 - val_acc: 0.5435\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 449us/step - loss: 20.5283 - acc: 0.7996 - val_loss: 20.2124 - val_acc: 0.5525\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 452us/step - loss: 18.9039 - acc: 0.8209 - val_loss: 18.6900 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 449us/step - loss: 17.4304 - acc: 0.8317 - val_loss: 17.3737 - val_acc: 0.5534\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 16.1223 - acc: 0.8148 - val_loss: 16.1613 - val_acc: 0.5127\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: 14.9371 - acc: 0.8104 - val_loss: 15.0258 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 54.4760 - acc: 0.4685 - val_loss: 43.4835 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 34.5662 - acc: 0.5552 - val_loss: 26.9133 - val_acc: 0.5471\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 21.2261 - acc: 0.5767 - val_loss: 16.6602 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 13.1802 - acc: 0.5843 - val_loss: 10.6162 - val_acc: 0.4982\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 8.5334 - acc: 0.5770 - val_loss: 7.0987 - val_acc: 0.5317\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.8950 - acc: 0.5628 - val_loss: 5.0991 - val_acc: 0.5263\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.3482 - acc: 0.5770 - val_loss: 3.9704 - val_acc: 0.5272\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.4424 - acc: 0.5776 - val_loss: 3.2421 - val_acc: 0.5208\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.8649 - acc: 0.5708 - val_loss: 2.8224 - val_acc: 0.5109\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4820 - acc: 0.5834 - val_loss: 2.5280 - val_acc: 0.5181\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2437 - acc: 0.5817 - val_loss: 2.2903 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0494 - acc: 0.5852 - val_loss: 2.1736 - val_acc: 0.5208\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 34.6199 - acc: 0.3879 - val_loss: 32.9440 - val_acc: 0.4837\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 31.6249 - acc: 0.5584 - val_loss: 30.2239 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 453us/step - loss: 28.7521 - acc: 0.6362 - val_loss: 27.4322 - val_acc: 0.5543\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 446us/step - loss: 25.8805 - acc: 0.6946 - val_loss: 24.6943 - val_acc: 0.5516\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 23.1556 - acc: 0.7362 - val_loss: 22.1759 - val_acc: 0.5598\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 453us/step - loss: 20.6479 - acc: 0.7670 - val_loss: 19.8713 - val_acc: 0.5480\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 18.4071 - acc: 0.7760 - val_loss: 17.7611 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 463us/step - loss: 16.4021 - acc: 0.7973 - val_loss: 16.0289 - val_acc: 0.5326\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 457us/step - loss: 14.6370 - acc: 0.8114 - val_loss: 14.3798 - val_acc: 0.5652\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 13.1037 - acc: 0.8131 - val_loss: 12.9962 - val_acc: 0.5399\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 438us/step - loss: 11.7593 - acc: 0.8241 - val_loss: 11.7576 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 10.5837 - acc: 0.8232 - val_loss: 10.6821 - val_acc: 0.5498\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 9.5677 - acc: 0.8210 - val_loss: 9.7954 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 8.6958 - acc: 0.8169 - val_loss: 8.9691 - val_acc: 0.5308\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 471us/step - loss: 7.8807 - acc: 0.8449 - val_loss: 8.2704 - val_acc: 0.5362\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 443us/step - loss: 7.1465 - acc: 0.8701 - val_loss: 7.6542 - val_acc: 0.5399\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 450us/step - loss: 6.5106 - acc: 0.8791 - val_loss: 7.0599 - val_acc: 0.5371\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 5.9631 - acc: 0.8751 - val_loss: 6.6057 - val_acc: 0.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 5.5171 - acc: 0.8573 - val_loss: 6.1268 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 100.4357 - acc: 0.3389 - val_loss: 96.9539 - val_acc: 0.4565\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 94.4774 - acc: 0.4944 - val_loss: 91.1663 - val_acc: 0.4964\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 88.7567 - acc: 0.5210 - val_loss: 85.6073 - val_acc: 0.5127\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 83.2717 - acc: 0.5513 - val_loss: 80.2888 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 78.0499 - acc: 0.5655 - val_loss: 75.2406 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 73.0925 - acc: 0.5906 - val_loss: 70.4781 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 68.4257 - acc: 0.5951 - val_loss: 65.9921 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: 64.0208 - acc: 0.6083 - val_loss: 61.7605 - val_acc: 0.5453\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 59.8796 - acc: 0.6190 - val_loss: 57.7826 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 56.0019 - acc: 0.6218 - val_loss: 54.0514 - val_acc: 0.5534\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 52.3585 - acc: 0.6257 - val_loss: 50.5710 - val_acc: 0.5444\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 48.9352 - acc: 0.6453 - val_loss: 47.2786 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 45.7374 - acc: 0.6552 - val_loss: 44.2159 - val_acc: 0.5652\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 42.7398 - acc: 0.6627 - val_loss: 41.3642 - val_acc: 0.5480\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 39.9467 - acc: 0.6619 - val_loss: 38.6955 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 37.3186 - acc: 0.6794 - val_loss: 36.1733 - val_acc: 0.5625\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 34.8698 - acc: 0.6767 - val_loss: 33.8413 - val_acc: 0.5534\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 32.5964 - acc: 0.6813 - val_loss: 31.6624 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 30.4599 - acc: 0.6866 - val_loss: 29.6220 - val_acc: 0.5562\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 28.4850 - acc: 0.6888 - val_loss: 27.7565 - val_acc: 0.5462\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 26.6431 - acc: 0.6878 - val_loss: 25.9912 - val_acc: 0.5534\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 24.9042 - acc: 0.7044 - val_loss: 24.3537 - val_acc: 0.5543\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 23.3070 - acc: 0.7060 - val_loss: 22.8525 - val_acc: 0.5480\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 21.8337 - acc: 0.7045 - val_loss: 21.4113 - val_acc: 0.5435\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 20.4403 - acc: 0.7155 - val_loss: 20.1232 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: nan - acc: 0.0706 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 740us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 43.2957 - acc: 0.3835 - val_loss: 41.5357 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 440us/step - loss: 40.0935 - acc: 0.5782 - val_loss: 38.4416 - val_acc: 0.5263\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 36.8278 - acc: 0.6500 - val_loss: 35.2528 - val_acc: 0.5453\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 33.5826 - acc: 0.7038 - val_loss: 32.1729 - val_acc: 0.5480\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 466us/step - loss: 30.4838 - acc: 0.7448 - val_loss: 29.2328 - val_acc: 0.5707\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 458us/step - loss: 27.6016 - acc: 0.7678 - val_loss: 26.5235 - val_acc: 0.5716\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: 24.9677 - acc: 0.7798 - val_loss: 24.1027 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 448us/step - loss: 22.5908 - acc: 0.7947 - val_loss: 21.9271 - val_acc: 0.5417\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 453us/step - loss: 20.4590 - acc: 0.8067 - val_loss: 20.0127 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 18.6010 - acc: 0.7926 - val_loss: 18.2254 - val_acc: 0.5263\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 16.8971 - acc: 0.8097 - val_loss: 16.7016 - val_acc: 0.5417\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 15.3827 - acc: 0.8249 - val_loss: 15.3245 - val_acc: 0.5399\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 14.0461 - acc: 0.8270 - val_loss: 14.0533 - val_acc: 0.5435\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 441us/step - loss: 12.8388 - acc: 0.8378 - val_loss: 12.9773 - val_acc: 0.5417\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 11.7584 - acc: 0.8496 - val_loss: 11.9433 - val_acc: 0.5507\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 451us/step - loss: 10.7832 - acc: 0.8563 - val_loss: 11.0904 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 70.7204 - acc: 0.4572 - val_loss: 60.0172 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 932us/step - loss: 51.2158 - acc: 0.5957 - val_loss: 42.8405 - val_acc: 0.5335\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 955us/step - loss: 36.2759 - acc: 0.6115 - val_loss: 30.3769 - val_acc: 0.5082\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 25.5929 - acc: 0.6256 - val_loss: 21.5433 - val_acc: 0.5362\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 921us/step - loss: 18.1567 - acc: 0.6256 - val_loss: 15.4498 - val_acc: 0.5353\n",
      "Epoch 6/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 8s 927us/step - loss: 13.0790 - acc: 0.6245 - val_loss: 11.3618 - val_acc: 0.5163\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 930us/step - loss: 9.6100 - acc: 0.6198 - val_loss: 8.5456 - val_acc: 0.5036\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 956us/step - loss: 7.2776 - acc: 0.6173 - val_loss: 6.6821 - val_acc: 0.5063\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 9s 971us/step - loss: 5.6670 - acc: 0.6186 - val_loss: 5.2776 - val_acc: 0.5408\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 934us/step - loss: 4.5727 - acc: 0.6129 - val_loss: 4.4188 - val_acc: 0.5091\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 921us/step - loss: 3.7990 - acc: 0.6126 - val_loss: 3.7282 - val_acc: 0.5172\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 9s 982us/step - loss: 3.2583 - acc: 0.6162 - val_loss: 3.3134 - val_acc: 0.5018\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 925us/step - loss: 2.8261 - acc: 0.6301 - val_loss: 2.9615 - val_acc: 0.5254\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 932us/step - loss: 2.5503 - acc: 0.6249 - val_loss: 2.7273 - val_acc: 0.5245\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 917us/step - loss: 2.3053 - acc: 0.6364 - val_loss: 2.5012 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 9s 973us/step - loss: 2.1251 - acc: 0.6456 - val_loss: 2.3909 - val_acc: 0.5217\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 948us/step - loss: 1.9757 - acc: 0.6513 - val_loss: 2.2830 - val_acc: 0.5245\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 950us/step - loss: 1.8511 - acc: 0.6628 - val_loss: 2.2015 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 1.7812 - acc: 0.6651 - val_loss: 2.0847 - val_acc: 0.5399\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 940us/step - loss: 1.7019 - acc: 0.6713 - val_loss: 2.1095 - val_acc: 0.5308\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 924us/step - loss: 1.6302 - acc: 0.6824 - val_loss: 2.0006 - val_acc: 0.5562\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 9s 973us/step - loss: 1.5541 - acc: 0.6961 - val_loss: 1.9930 - val_acc: 0.5335\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 945us/step - loss: 1.5237 - acc: 0.6937 - val_loss: 2.0712 - val_acc: 0.5154\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 942us/step - loss: 1.4544 - acc: 0.7147 - val_loss: 2.0370 - val_acc: 0.5254\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 956us/step - loss: 1.4022 - acc: 0.7236 - val_loss: 1.9215 - val_acc: 0.5534\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 893us/step - loss: 1.3565 - acc: 0.7341 - val_loss: 1.8975 - val_acc: 0.5598\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 9s 966us/step - loss: 1.3167 - acc: 0.7441 - val_loss: 1.8909 - val_acc: 0.5525\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 916us/step - loss: 1.3469 - acc: 0.7326 - val_loss: 2.0069 - val_acc: 0.5272\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 920us/step - loss: 1.2951 - acc: 0.7471 - val_loss: 1.9930 - val_acc: 0.5353\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 9s 993us/step - loss: 1.2459 - acc: 0.7552 - val_loss: 1.9201 - val_acc: 0.5607\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 9s 971us/step - loss: 1.2409 - acc: 0.7578 - val_loss: 1.9358 - val_acc: 0.5598\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 8s 900us/step - loss: 1.1813 - acc: 0.7815 - val_loss: 1.9971 - val_acc: 0.5362\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 9s 989us/step - loss: 1.2022 - acc: 0.7736 - val_loss: 2.0159 - val_acc: 0.5480\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 8s 942us/step - loss: 1.1493 - acc: 0.7865 - val_loss: 1.9735 - val_acc: 0.5525\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 8s 916us/step - loss: 1.1511 - acc: 0.7846 - val_loss: 2.0243 - val_acc: 0.5444\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 8s 936us/step - loss: 1.1250 - acc: 0.7971 - val_loss: 2.0016 - val_acc: 0.5697\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 9s 969us/step - loss: 1.0792 - acc: 0.8122 - val_loss: 2.0969 - val_acc: 0.5399\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 8s 959us/step - loss: 1.0644 - acc: 0.8165 - val_loss: 2.0567 - val_acc: 0.5245\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 8s 916us/step - loss: 1.0855 - acc: 0.8077 - val_loss: 1.9870 - val_acc: 0.5516\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 1.0492 - acc: 0.8142 - val_loss: 2.0833 - val_acc: 0.5480\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 8s 945us/step - loss: 1.0394 - acc: 0.8226 - val_loss: 2.0669 - val_acc: 0.5362\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 8s 950us/step - loss: 0.9969 - acc: 0.8391 - val_loss: 2.0314 - val_acc: 0.5543\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 9s 974us/step - loss: 0.9496 - acc: 0.8543 - val_loss: 2.1613 - val_acc: 0.5317\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 8s 942us/step - loss: 0.9875 - acc: 0.8353 - val_loss: 2.2217 - val_acc: 0.5335\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 8s 934us/step - loss: 0.9673 - acc: 0.8441 - val_loss: 2.2365 - val_acc: 0.5290\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 9s 966us/step - loss: 0.9627 - acc: 0.8495 - val_loss: 2.1527 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 41.6570 - acc: 0.4367 - val_loss: 38.4746 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 948us/step - loss: 35.6707 - acc: 0.5421 - val_loss: 32.8617 - val_acc: 0.5290\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 835us/step - loss: 30.3020 - acc: 0.5773 - val_loss: 27.9246 - val_acc: 0.5245\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 9s 968us/step - loss: 25.6179 - acc: 0.6070 - val_loss: 23.6142 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 21.6058 - acc: 0.6348 - val_loss: 19.9887 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 918us/step - loss: 18.2313 - acc: 0.6367 - val_loss: 16.9026 - val_acc: 0.5661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 905us/step - loss: 15.3759 - acc: 0.6523 - val_loss: 14.3839 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 13.0179 - acc: 0.6625 - val_loss: 12.2382 - val_acc: 0.5453\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 862us/step - loss: 11.0613 - acc: 0.6646 - val_loss: 10.5241 - val_acc: 0.5507\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 860us/step - loss: 9.4600 - acc: 0.6709 - val_loss: 9.0363 - val_acc: 0.5543\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 896us/step - loss: 8.1042 - acc: 0.6798 - val_loss: 7.8710 - val_acc: 0.5525\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 7.0024 - acc: 0.6869 - val_loss: 6.8465 - val_acc: 0.5643\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 855us/step - loss: 6.1119 - acc: 0.6813 - val_loss: 6.0704 - val_acc: 0.5471\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 5.3655 - acc: 0.6886 - val_loss: 5.4271 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 913us/step - loss: 4.7497 - acc: 0.6952 - val_loss: 4.8599 - val_acc: 0.5371\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 956us/step - loss: 4.2425 - acc: 0.6950 - val_loss: 4.3817 - val_acc: 0.5670\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 813us/step - loss: 3.8242 - acc: 0.6985 - val_loss: 4.0784 - val_acc: 0.5444\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 918us/step - loss: 3.4845 - acc: 0.6959 - val_loss: 3.7793 - val_acc: 0.5435\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 8s 900us/step - loss: 3.1831 - acc: 0.7008 - val_loss: 3.4863 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 2.9491 - acc: 0.6975 - val_loss: 3.3430 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 865us/step - loss: 2.7243 - acc: 0.7141 - val_loss: 3.1144 - val_acc: 0.5562\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 818us/step - loss: 2.5698 - acc: 0.7091 - val_loss: 2.9676 - val_acc: 0.5562\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 855us/step - loss: 2.3899 - acc: 0.7222 - val_loss: 2.7951 - val_acc: 0.5580\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 846us/step - loss: 2.2633 - acc: 0.7211 - val_loss: 2.7006 - val_acc: 0.5697\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 8s 899us/step - loss: 2.1675 - acc: 0.7147 - val_loss: 2.6726 - val_acc: 0.5643\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 878us/step - loss: 2.0527 - acc: 0.7325 - val_loss: 2.6263 - val_acc: 0.5353\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 1.9726 - acc: 0.7349 - val_loss: 2.5346 - val_acc: 0.5507\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 8s 882us/step - loss: 1.8617 - acc: 0.7520 - val_loss: 2.3868 - val_acc: 0.5707\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 8s 875us/step - loss: 1.8033 - acc: 0.7456 - val_loss: 2.4714 - val_acc: 0.5489\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 8s 870us/step - loss: 1.7689 - acc: 0.7462 - val_loss: 2.4168 - val_acc: 0.5571\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 8s 862us/step - loss: 1.6966 - acc: 0.7526 - val_loss: 2.4735 - val_acc: 0.5371\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 8s 858us/step - loss: 1.6498 - acc: 0.7547 - val_loss: 2.3304 - val_acc: 0.5707\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 8s 863us/step - loss: 1.5916 - acc: 0.7668 - val_loss: 2.3282 - val_acc: 0.5426\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 833us/step - loss: 1.5725 - acc: 0.7643 - val_loss: 2.2484 - val_acc: 0.5525\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 8s 903us/step - loss: 1.5037 - acc: 0.7854 - val_loss: 2.3295 - val_acc: 0.5426\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 8s 875us/step - loss: 1.4851 - acc: 0.7779 - val_loss: 2.2873 - val_acc: 0.5634\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 1.4272 - acc: 0.7917 - val_loss: 2.2586 - val_acc: 0.5688\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 1.4186 - acc: 0.7830 - val_loss: 2.3883 - val_acc: 0.5326\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 8s 850us/step - loss: 1.3886 - acc: 0.7940 - val_loss: 2.2174 - val_acc: 0.5697\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 8s 911us/step - loss: 1.3598 - acc: 0.7926 - val_loss: 2.3872 - val_acc: 0.5317\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 8s 908us/step - loss: 1.3552 - acc: 0.7959 - val_loss: 2.3369 - val_acc: 0.5399\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 7s 812us/step - loss: 1.3055 - acc: 0.8067 - val_loss: 2.3447 - val_acc: 0.5598\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0710 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 414us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 439us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 419us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 436us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 424us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 430us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 419us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 73.2135 - acc: 0.4529 - val_loss: 49.9499 - val_acc: 0.4801\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 34.7854 - acc: 0.5274 - val_loss: 22.9776 - val_acc: 0.4909\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 16.1086 - acc: 0.5351 - val_loss: 11.0561 - val_acc: 0.5127\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 8.1209 - acc: 0.5284 - val_loss: 6.0288 - val_acc: 0.5100\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.7979 - acc: 0.5313 - val_loss: 3.9407 - val_acc: 0.4973\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3464 - acc: 0.5314 - val_loss: 2.9249 - val_acc: 0.5254\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6195 - acc: 0.5479 - val_loss: 2.4794 - val_acc: 0.5190\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2571 - acc: 0.5432 - val_loss: 2.2119 - val_acc: 0.5199\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0137 - acc: 0.5527 - val_loss: 2.0601 - val_acc: 0.5036\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8707 - acc: 0.5535 - val_loss: 1.9295 - val_acc: 0.5027\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7638 - acc: 0.5613 - val_loss: 1.7933 - val_acc: 0.5226\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6628 - acc: 0.5687 - val_loss: 1.7514 - val_acc: 0.5226\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6237 - acc: 0.5721 - val_loss: 1.7657 - val_acc: 0.5254\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5918 - acc: 0.5772 - val_loss: 1.6594 - val_acc: 0.5308\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5433 - acc: 0.5819 - val_loss: 1.6603 - val_acc: 0.5317\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5117 - acc: 0.5853 - val_loss: 1.7127 - val_acc: 0.5217\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4743 - acc: 0.6014 - val_loss: 1.5838 - val_acc: 0.5489\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4882 - acc: 0.5933 - val_loss: 1.6736 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4827 - acc: 0.5911 - val_loss: 1.6239 - val_acc: 0.5417\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4526 - acc: 0.6034 - val_loss: 1.6131 - val_acc: 0.5344\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4303 - acc: 0.6058 - val_loss: 1.5944 - val_acc: 0.5335\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4166 - acc: 0.6097 - val_loss: 1.6117 - val_acc: 0.5389\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4250 - acc: 0.6078 - val_loss: 1.5998 - val_acc: 0.5516\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4046 - acc: 0.6223 - val_loss: 1.6220 - val_acc: 0.5453\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3966 - acc: 0.6205 - val_loss: 1.6406 - val_acc: 0.5226\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3887 - acc: 0.6269 - val_loss: 1.6490 - val_acc: 0.5154\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3628 - acc: 0.6323 - val_loss: 1.6470 - val_acc: 0.5562\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3896 - acc: 0.6276 - val_loss: 1.6432 - val_acc: 0.5362\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3917 - acc: 0.6229 - val_loss: 1.5956 - val_acc: 0.5580\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3268 - acc: 0.6464 - val_loss: 1.6102 - val_acc: 0.5362\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3670 - acc: 0.6345 - val_loss: 1.6545 - val_acc: 0.5534\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3352 - acc: 0.6471 - val_loss: 1.6919 - val_acc: 0.5326\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3064 - acc: 0.6549 - val_loss: 1.6622 - val_acc: 0.5326\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3210 - acc: 0.6534 - val_loss: 1.6499 - val_acc: 0.5389\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3182 - acc: 0.6559 - val_loss: 1.7896 - val_acc: 0.5190\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3342 - acc: 0.6535 - val_loss: 1.6900 - val_acc: 0.5371\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2900 - acc: 0.6636 - val_loss: 1.6086 - val_acc: 0.5471\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2957 - acc: 0.6564 - val_loss: 1.7097 - val_acc: 0.5408\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.2935 - acc: 0.6677 - val_loss: 1.7796 - val_acc: 0.5344\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: nan - acc: 0.0698 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 32.7587 - acc: 0.3910 - val_loss: 31.4957 - val_acc: 0.5045\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 30.5540 - acc: 0.5661 - val_loss: 29.5770 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 28.4564 - acc: 0.6444 - val_loss: 27.5533 - val_acc: 0.5498\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 26.3677 - acc: 0.6944 - val_loss: 25.5821 - val_acc: 0.5571\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 24.3471 - acc: 0.7312 - val_loss: 23.6951 - val_acc: 0.5616\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 22.4208 - acc: 0.7740 - val_loss: 21.8822 - val_acc: 0.5661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 20.6278 - acc: 0.7973 - val_loss: 20.2233 - val_acc: 0.5625\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 18.9554 - acc: 0.8180 - val_loss: 18.6856 - val_acc: 0.5679\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 17.4418 - acc: 0.8235 - val_loss: 17.2709 - val_acc: 0.5553\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 16.0672 - acc: 0.8283 - val_loss: 15.9860 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 14.7843 - acc: 0.8520 - val_loss: 14.8377 - val_acc: 0.5707\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 13.6512 - acc: 0.8537 - val_loss: 13.8566 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 12.6301 - acc: 0.8536 - val_loss: 12.8723 - val_acc: 0.5462\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 11.6821 - acc: 0.8728 - val_loss: 11.9863 - val_acc: 0.5516\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 10.8184 - acc: 0.8807 - val_loss: 11.2436 - val_acc: 0.5507\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 10.0716 - acc: 0.8707 - val_loss: 10.5554 - val_acc: 0.5326\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 9.3572 - acc: 0.8846 - val_loss: 9.8019 - val_acc: 0.5571\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 8.7162 - acc: 0.8949 - val_loss: 9.3605 - val_acc: 0.5417\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 8.1410 - acc: 0.8907 - val_loss: 8.7807 - val_acc: 0.5344\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 7.5824 - acc: 0.9071 - val_loss: 8.2635 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 7.1115 - acc: 0.9004 - val_loss: 7.8255 - val_acc: 0.5371\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 28.4855 - acc: 0.3783 - val_loss: 27.2933 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 26.4079 - acc: 0.5389 - val_loss: 25.4554 - val_acc: 0.5245\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 24.4622 - acc: 0.6003 - val_loss: 23.5616 - val_acc: 0.5353\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 22.4475 - acc: 0.6524 - val_loss: 21.6204 - val_acc: 0.5489\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 20.4566 - acc: 0.6952 - val_loss: 19.7400 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 18.5479 - acc: 0.7284 - val_loss: 17.9331 - val_acc: 0.5534\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 16.7538 - acc: 0.7543 - val_loss: 16.2685 - val_acc: 0.5670\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 15.1018 - acc: 0.7772 - val_loss: 14.7609 - val_acc: 0.5670\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 13.6119 - acc: 0.7884 - val_loss: 13.4001 - val_acc: 0.5553\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 12.2673 - acc: 0.8029 - val_loss: 12.2139 - val_acc: 0.5525\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 11.0854 - acc: 0.8089 - val_loss: 11.1111 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 10.0268 - acc: 0.8199 - val_loss: 10.1437 - val_acc: 0.5725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 9.1108 - acc: 0.8230 - val_loss: 9.3470 - val_acc: 0.5444\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 8.3075 - acc: 0.8208 - val_loss: 8.6266 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 7.5679 - acc: 0.8443 - val_loss: 7.9471 - val_acc: 0.5598\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 6.9180 - acc: 0.8557 - val_loss: 7.3506 - val_acc: 0.5625\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 6.3408 - acc: 0.8618 - val_loss: 6.8797 - val_acc: 0.5389\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 5.8291 - acc: 0.8704 - val_loss: 6.4397 - val_acc: 0.5534\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 5.3806 - acc: 0.8718 - val_loss: 6.0343 - val_acc: 0.5226\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 5.0011 - acc: 0.8631 - val_loss: 5.6346 - val_acc: 0.5453\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 4.6548 - acc: 0.8600 - val_loss: 5.3304 - val_acc: 0.5534\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 4.3415 - acc: 0.8596 - val_loss: 5.0635 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 61.4944 - acc: 0.4555 - val_loss: 48.6362 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 38.4949 - acc: 0.5344 - val_loss: 29.7213 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 23.2669 - acc: 0.5553 - val_loss: 17.9582 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 14.0910 - acc: 0.5651 - val_loss: 11.0065 - val_acc: 0.5562\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 8.8416 - acc: 0.5671 - val_loss: 7.1657 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.9186 - acc: 0.5578 - val_loss: 5.0815 - val_acc: 0.5082\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.2745 - acc: 0.5563 - val_loss: 3.7936 - val_acc: 0.5254\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3132 - acc: 0.5621 - val_loss: 3.1505 - val_acc: 0.5181\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.7535 - acc: 0.5628 - val_loss: 2.7141 - val_acc: 0.4982\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4112 - acc: 0.5702 - val_loss: 2.3646 - val_acc: 0.5353\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1555 - acc: 0.5806 - val_loss: 2.2445 - val_acc: 0.5136\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9914 - acc: 0.5825 - val_loss: 2.1295 - val_acc: 0.5127\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8857 - acc: 0.5877 - val_loss: 2.0062 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7988 - acc: 0.5804 - val_loss: 1.8926 - val_acc: 0.5299\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 50.5370 - acc: 0.4676 - val_loss: 44.2694 - val_acc: 0.5091\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 38.5108 - acc: 0.5758 - val_loss: 33.3932 - val_acc: 0.5236\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 28.7106 - acc: 0.6121 - val_loss: 24.8644 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 21.2417 - acc: 0.6342 - val_loss: 18.4314 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 15.7632 - acc: 0.6303 - val_loss: 13.8704 - val_acc: 0.5263\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 11.8246 - acc: 0.6355 - val_loss: 10.5228 - val_acc: 0.5299\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.0129 - acc: 0.6425 - val_loss: 8.1912 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 7.0588 - acc: 0.6250 - val_loss: 6.4951 - val_acc: 0.5462\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.6318 - acc: 0.6318 - val_loss: 5.3700 - val_acc: 0.5435\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.6385 - acc: 0.6311 - val_loss: 4.5522 - val_acc: 0.5344\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.9293 - acc: 0.6215 - val_loss: 3.8284 - val_acc: 0.5453\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.3787 - acc: 0.6297 - val_loss: 3.4232 - val_acc: 0.5245\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9908 - acc: 0.6326 - val_loss: 3.1073 - val_acc: 0.5236\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6940 - acc: 0.6346 - val_loss: 2.7978 - val_acc: 0.5371\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4491 - acc: 0.6365 - val_loss: 2.6707 - val_acc: 0.5190\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2600 - acc: 0.6519 - val_loss: 2.4476 - val_acc: 0.5598\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1152 - acc: 0.6569 - val_loss: 2.3738 - val_acc: 0.5362\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9986 - acc: 0.6515 - val_loss: 2.2619 - val_acc: 0.5444\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8897 - acc: 0.6654 - val_loss: 2.1705 - val_acc: 0.5525\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7983 - acc: 0.6694 - val_loss: 2.1546 - val_acc: 0.5245\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7250 - acc: 0.6756 - val_loss: 2.0849 - val_acc: 0.5408\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6557 - acc: 0.6825 - val_loss: 2.1142 - val_acc: 0.5408\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5964 - acc: 0.6935 - val_loss: 2.0788 - val_acc: 0.5417\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5390 - acc: 0.7055 - val_loss: 2.0381 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4916 - acc: 0.7127 - val_loss: 2.0800 - val_acc: 0.5308\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4670 - acc: 0.7141 - val_loss: 2.0105 - val_acc: 0.5371\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 101.2917 - acc: 0.4515 - val_loss: 69.1216 - val_acc: 0.4846\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 48.3246 - acc: 0.5262 - val_loss: 31.8827 - val_acc: 0.5190\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 22.2408 - acc: 0.5317 - val_loss: 14.9516 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 10.7608 - acc: 0.5332 - val_loss: 7.7684 - val_acc: 0.4882\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 5.9295 - acc: 0.5281 - val_loss: 4.6687 - val_acc: 0.5054\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.8413 - acc: 0.5404 - val_loss: 3.3831 - val_acc: 0.4828\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.8973 - acc: 0.5340 - val_loss: 2.6905 - val_acc: 0.4946\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3883 - acc: 0.5429 - val_loss: 2.2680 - val_acc: 0.5109\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0964 - acc: 0.5505 - val_loss: 2.0753 - val_acc: 0.5371\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9184 - acc: 0.5578 - val_loss: 1.9600 - val_acc: 0.5290\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7868 - acc: 0.5652 - val_loss: 1.9269 - val_acc: 0.5018\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7150 - acc: 0.5655 - val_loss: 1.8352 - val_acc: 0.5236\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6555 - acc: 0.5695 - val_loss: 1.7349 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5949 - acc: 0.5799 - val_loss: 1.6875 - val_acc: 0.5498\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5610 - acc: 0.5856 - val_loss: 1.7131 - val_acc: 0.5335\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5327 - acc: 0.5834 - val_loss: 1.6566 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5070 - acc: 0.5934 - val_loss: 1.6954 - val_acc: 0.5163\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4922 - acc: 0.5973 - val_loss: 1.6957 - val_acc: 0.5236\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4670 - acc: 0.6004 - val_loss: 1.6443 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4477 - acc: 0.6100 - val_loss: 1.6242 - val_acc: 0.5272\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4301 - acc: 0.6090 - val_loss: 1.6196 - val_acc: 0.5371\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4234 - acc: 0.6141 - val_loss: 1.6382 - val_acc: 0.5263\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4297 - acc: 0.6164 - val_loss: 1.6461 - val_acc: 0.5380\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3925 - acc: 0.6202 - val_loss: 1.6548 - val_acc: 0.5281\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 65.6096 - acc: 0.4384 - val_loss: 44.0916 - val_acc: 0.5082\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 30.4939 - acc: 0.5025 - val_loss: 19.8499 - val_acc: 0.4928\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.8016 - acc: 0.5225 - val_loss: 9.3765 - val_acc: 0.4937\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.8628 - acc: 0.5218 - val_loss: 5.1900 - val_acc: 0.4574\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.1047 - acc: 0.5199 - val_loss: 3.4363 - val_acc: 0.5000\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.9451 - acc: 0.5186 - val_loss: 2.6237 - val_acc: 0.5181\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4207 - acc: 0.5204 - val_loss: 2.3124 - val_acc: 0.5018\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1206 - acc: 0.5366 - val_loss: 2.0116 - val_acc: 0.5362\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9470 - acc: 0.5346 - val_loss: 1.9770 - val_acc: 0.5136\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8381 - acc: 0.5338 - val_loss: 1.8761 - val_acc: 0.4918\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7808 - acc: 0.5358 - val_loss: 1.8461 - val_acc: 0.5245\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 1.7191 - acc: 0.5435 - val_loss: 1.7804 - val_acc: 0.5145\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6508 - acc: 0.5546 - val_loss: 1.7827 - val_acc: 0.5136\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6432 - acc: 0.5485 - val_loss: 1.7358 - val_acc: 0.5072\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5934 - acc: 0.5656 - val_loss: 1.6734 - val_acc: 0.5254\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5903 - acc: 0.5643 - val_loss: 1.8118 - val_acc: 0.4891\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5822 - acc: 0.5644 - val_loss: 1.7309 - val_acc: 0.5127\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 1.5794 - acc: 0.5651 - val_loss: 1.7292 - val_acc: 0.5118\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 41.9811 - acc: 0.4440 - val_loss: 35.1301 - val_acc: 0.4946\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 29.2932 - acc: 0.5232 - val_loss: 24.0127 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 19.8067 - acc: 0.5563 - val_loss: 16.3170 - val_acc: 0.4873\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.3089 - acc: 0.5699 - val_loss: 11.0494 - val_acc: 0.5217\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.1109 - acc: 0.5741 - val_loss: 7.6952 - val_acc: 0.5190\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.4357 - acc: 0.5798 - val_loss: 5.6269 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.7752 - acc: 0.5783 - val_loss: 4.3024 - val_acc: 0.5154\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.7251 - acc: 0.5762 - val_loss: 3.5003 - val_acc: 0.5190\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.0598 - acc: 0.5860 - val_loss: 3.0245 - val_acc: 0.5100\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.6326 - acc: 0.5799 - val_loss: 2.6416 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.3480 - acc: 0.5829 - val_loss: 2.4090 - val_acc: 0.5254\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1417 - acc: 0.5933 - val_loss: 2.2474 - val_acc: 0.5254\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9949 - acc: 0.5875 - val_loss: 2.0858 - val_acc: 0.5607\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8769 - acc: 0.6010 - val_loss: 2.0029 - val_acc: 0.5399\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8078 - acc: 0.5957 - val_loss: 1.9280 - val_acc: 0.5344\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7277 - acc: 0.6010 - val_loss: 1.9283 - val_acc: 0.5272\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6768 - acc: 0.6023 - val_loss: 1.9054 - val_acc: 0.5190\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6302 - acc: 0.6068 - val_loss: 1.7962 - val_acc: 0.5435\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5863 - acc: 0.6166 - val_loss: 1.7907 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5526 - acc: 0.6229 - val_loss: 1.7316 - val_acc: 0.5716\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5310 - acc: 0.6244 - val_loss: 1.7494 - val_acc: 0.5480\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5035 - acc: 0.6258 - val_loss: 1.7965 - val_acc: 0.5480\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4661 - acc: 0.6334 - val_loss: 1.7866 - val_acc: 0.5389\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4883 - acc: 0.6257 - val_loss: 1.7416 - val_acc: 0.5380\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4422 - acc: 0.6450 - val_loss: 1.8330 - val_acc: 0.5281\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4370 - acc: 0.6404 - val_loss: 1.7802 - val_acc: 0.5389\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4119 - acc: 0.6413 - val_loss: 1.7625 - val_acc: 0.5471\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4078 - acc: 0.6548 - val_loss: 1.7653 - val_acc: 0.5380\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3787 - acc: 0.6567 - val_loss: 1.7354 - val_acc: 0.5417\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.3809 - acc: 0.6591 - val_loss: 1.7736 - val_acc: 0.5399\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 22.0477 - acc: 0.3784 - val_loss: 20.8879 - val_acc: 0.4710\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 20.0068 - acc: 0.5576 - val_loss: 19.2353 - val_acc: 0.5163\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 448us/step - loss: 18.2042 - acc: 0.6472 - val_loss: 17.5282 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 16.4191 - acc: 0.7027 - val_loss: 15.8655 - val_acc: 0.5589\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 440us/step - loss: 14.7510 - acc: 0.7381 - val_loss: 14.3834 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 13.2152 - acc: 0.7734 - val_loss: 12.9910 - val_acc: 0.5688\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 11.8432 - acc: 0.7964 - val_loss: 11.7471 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 10.6260 - acc: 0.8077 - val_loss: 10.6944 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 9.5433 - acc: 0.8275 - val_loss: 9.7134 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 8.5906 - acc: 0.8360 - val_loss: 8.8559 - val_acc: 0.5516\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 7.7552 - acc: 0.8421 - val_loss: 8.0823 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 7.0281 - acc: 0.8497 - val_loss: 7.4588 - val_acc: 0.5380\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 6.3789 - acc: 0.8549 - val_loss: 6.9058 - val_acc: 0.5571\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 5.7947 - acc: 0.8673 - val_loss: 6.3690 - val_acc: 0.5399\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 5.2725 - acc: 0.8875 - val_loss: 5.8766 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 4.8237 - acc: 0.8902 - val_loss: 5.5559 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0703 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 795us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 762us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: nan - acc: 0.0721 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 432us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 459us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 419us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 414us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 413us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 402us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 426us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 411us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 26.4613 - acc: 0.3795 - val_loss: 24.7320 - val_acc: 0.4783\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 23.4730 - acc: 0.5527 - val_loss: 22.0553 - val_acc: 0.5217\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 20.6465 - acc: 0.6333 - val_loss: 19.3722 - val_acc: 0.5426\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 17.9367 - acc: 0.6855 - val_loss: 16.8639 - val_acc: 0.5670\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 15.5035 - acc: 0.7165 - val_loss: 14.7007 - val_acc: 0.5417\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 13.3788 - acc: 0.7403 - val_loss: 12.8183 - val_acc: 0.5562\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 11.5882 - acc: 0.7378 - val_loss: 11.2286 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 10.0633 - acc: 0.7513 - val_loss: 9.9224 - val_acc: 0.5163\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 8.7802 - acc: 0.7629 - val_loss: 8.8130 - val_acc: 0.5317\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 7.6837 - acc: 0.7887 - val_loss: 7.7839 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 6.8150 - acc: 0.7674 - val_loss: 7.0706 - val_acc: 0.5181\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 6.0613 - acc: 0.7730 - val_loss: 6.3035 - val_acc: 0.5525\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 5.3626 - acc: 0.8070 - val_loss: 5.7813 - val_acc: 0.5489\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 4.8368 - acc: 0.8012 - val_loss: 5.2969 - val_acc: 0.5362\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 44.1564 - acc: 0.3994 - val_loss: 42.6772 - val_acc: 0.4964\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 41.4662 - acc: 0.5770 - val_loss: 40.2265 - val_acc: 0.5254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 38.8764 - acc: 0.6474 - val_loss: 37.7311 - val_acc: 0.5444\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 36.3193 - acc: 0.7049 - val_loss: 35.2953 - val_acc: 0.5562\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 33.8809 - acc: 0.7292 - val_loss: 32.9653 - val_acc: 0.5589\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 31.5664 - acc: 0.7552 - val_loss: 30.7872 - val_acc: 0.5616\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 29.3990 - acc: 0.7730 - val_loss: 28.7593 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 27.3672 - acc: 0.7933 - val_loss: 26.8201 - val_acc: 0.5553\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 25.4742 - acc: 0.8150 - val_loss: 25.0597 - val_acc: 0.5543\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 23.7332 - acc: 0.8173 - val_loss: 23.4754 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 22.1350 - acc: 0.8251 - val_loss: 21.9255 - val_acc: 0.5453\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 20.6472 - acc: 0.8379 - val_loss: 20.5222 - val_acc: 0.5598\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 19.2680 - acc: 0.8512 - val_loss: 19.2416 - val_acc: 0.5743\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 18.0193 - acc: 0.8381 - val_loss: 18.0834 - val_acc: 0.5525\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 16.8399 - acc: 0.8616 - val_loss: 16.9517 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 15.7762 - acc: 0.8596 - val_loss: 16.0295 - val_acc: 0.5453\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 14.8097 - acc: 0.8502 - val_loss: 15.1102 - val_acc: 0.5534\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 13.8888 - acc: 0.8625 - val_loss: 14.2170 - val_acc: 0.5480\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 13.0231 - acc: 0.8848 - val_loss: 13.4042 - val_acc: 0.5743\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 12.2303 - acc: 0.8932 - val_loss: 12.6425 - val_acc: 0.5625\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 11.5051 - acc: 0.8957 - val_loss: 12.0051 - val_acc: 0.5489\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 10.8533 - acc: 0.8842 - val_loss: 11.3234 - val_acc: 0.5580\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 10.2034 - acc: 0.9029 - val_loss: 10.7679 - val_acc: 0.5589\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 9.6471 - acc: 0.8929 - val_loss: 10.2912 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 9.1369 - acc: 0.8828 - val_loss: 9.7723 - val_acc: 0.5371\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 8.6291 - acc: 0.8957 - val_loss: 9.2709 - val_acc: 0.5534\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 8.1461 - acc: 0.9131 - val_loss: 8.7736 - val_acc: 0.5752\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 7.7104 - acc: 0.9154 - val_loss: 8.4905 - val_acc: 0.5553\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 475us/step - loss: 7.3503 - acc: 0.8957 - val_loss: 8.0720 - val_acc: 0.5571\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 6.9723 - acc: 0.9042 - val_loss: 7.7834 - val_acc: 0.5471\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 6.6301 - acc: 0.8994 - val_loss: 7.3658 - val_acc: 0.5580\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 6.2977 - acc: 0.9157 - val_loss: 7.1039 - val_acc: 0.5616\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 6.0174 - acc: 0.9008 - val_loss: 6.8028 - val_acc: 0.5516\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 5.7492 - acc: 0.9001 - val_loss: 6.5541 - val_acc: 0.5752\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 5.4732 - acc: 0.9113 - val_loss: 6.3183 - val_acc: 0.5534\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 5.2489 - acc: 0.9057 - val_loss: 6.1118 - val_acc: 0.5625\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 5.0064 - acc: 0.9124 - val_loss: 5.8753 - val_acc: 0.5607\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 4.7923 - acc: 0.9178 - val_loss: 5.7185 - val_acc: 0.5607\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 4.6071 - acc: 0.9083 - val_loss: 5.5494 - val_acc: 0.5498\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 4.4134 - acc: 0.9146 - val_loss: 5.3137 - val_acc: 0.5734\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 4.2613 - acc: 0.9066 - val_loss: 5.2109 - val_acc: 0.5625\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 4.1001 - acc: 0.9083 - val_loss: 5.0653 - val_acc: 0.5679\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 3.9108 - acc: 0.9264 - val_loss: 4.9360 - val_acc: 0.5534\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 3.7745 - acc: 0.9200 - val_loss: 4.8326 - val_acc: 0.5824\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 3.6431 - acc: 0.9203 - val_loss: 4.5994 - val_acc: 0.5725\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 3.5248 - acc: 0.9141 - val_loss: 4.5875 - val_acc: 0.5562\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 3.4399 - acc: 0.8993 - val_loss: 4.4636 - val_acc: 0.5661\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 3.2942 - acc: 0.9199 - val_loss: 4.3327 - val_acc: 0.5616\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 3.1665 - acc: 0.9307 - val_loss: 4.3280 - val_acc: 0.5553\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 3.0837 - acc: 0.9212 - val_loss: 4.3034 - val_acc: 0.5498\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 2.9970 - acc: 0.9152 - val_loss: 4.1234 - val_acc: 0.5634\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.9051 - acc: 0.9182 - val_loss: 4.0900 - val_acc: 0.5661\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 2.8068 - acc: 0.9247 - val_loss: 3.9581 - val_acc: 0.5625\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 2.7169 - acc: 0.9327 - val_loss: 3.9330 - val_acc: 0.5643\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 16s 2ms/step - loss: 20.9145 - acc: 0.3654 - val_loss: 19.4401 - val_acc: 0.4746\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 443us/step - loss: 18.4172 - acc: 0.5438 - val_loss: 17.3306 - val_acc: 0.5082\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 459us/step - loss: 16.1425 - acc: 0.6156 - val_loss: 15.2059 - val_acc: 0.5344\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: 13.9506 - acc: 0.6653 - val_loss: 13.1534 - val_acc: 0.5263\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 11.9836 - acc: 0.7011 - val_loss: 11.4110 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 10.3237 - acc: 0.7097 - val_loss: 9.9916 - val_acc: 0.5399\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 8.9017 - acc: 0.7337 - val_loss: 8.7411 - val_acc: 0.5272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 7.7100 - acc: 0.7530 - val_loss: 7.7833 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 6.7307 - acc: 0.7625 - val_loss: 6.8731 - val_acc: 0.5335\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 5.9408 - acc: 0.7546 - val_loss: 6.1236 - val_acc: 0.5308\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 441us/step - loss: 5.2439 - acc: 0.7685 - val_loss: 5.5148 - val_acc: 0.5589\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 457us/step - loss: 4.6623 - acc: 0.7794 - val_loss: 5.0567 - val_acc: 0.5408\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 4.1533 - acc: 0.8021 - val_loss: 4.5955 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 464us/step - loss: 3.7258 - acc: 0.8146 - val_loss: 4.3157 - val_acc: 0.5272\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 449us/step - loss: 3.4050 - acc: 0.8054 - val_loss: 3.9974 - val_acc: 0.5371\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 3.1537 - acc: 0.7905 - val_loss: 3.7971 - val_acc: 0.5272\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: 2.9236 - acc: 0.7933 - val_loss: 3.6208 - val_acc: 0.5154\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 2.7178 - acc: 0.7922 - val_loss: 3.4253 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 2.5182 - acc: 0.8072 - val_loss: 3.2638 - val_acc: 0.5226\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 2.3478 - acc: 0.8120 - val_loss: 3.1515 - val_acc: 0.5426\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 448us/step - loss: 2.2096 - acc: 0.8184 - val_loss: 3.0184 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 113.4113 - acc: 0.3332 - val_loss: 108.0487 - val_acc: 0.4665\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 104.2984 - acc: 0.4755 - val_loss: 99.2260 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 95.6722 - acc: 0.5054 - val_loss: 90.8970 - val_acc: 0.5317\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 87.5668 - acc: 0.5327 - val_loss: 83.1887 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 80.0615 - acc: 0.5467 - val_loss: 76.0197 - val_acc: 0.5417\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 73.1242 - acc: 0.5532 - val_loss: 69.4419 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 66.7373 - acc: 0.5646 - val_loss: 63.3731 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 60.8673 - acc: 0.5851 - val_loss: 57.7989 - val_acc: 0.5489\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 55.4951 - acc: 0.5903 - val_loss: 52.7209 - val_acc: 0.5444\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 50.5783 - acc: 0.5995 - val_loss: 48.0863 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 46.0864 - acc: 0.6074 - val_loss: 43.8478 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 41.9852 - acc: 0.6131 - val_loss: 39.9498 - val_acc: 0.5607\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 38.2545 - acc: 0.6189 - val_loss: 36.4487 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 34.8531 - acc: 0.6218 - val_loss: 33.2267 - val_acc: 0.5435\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 31.7495 - acc: 0.6350 - val_loss: 30.3246 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 28.9369 - acc: 0.6459 - val_loss: 27.6761 - val_acc: 0.5498\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 26.3850 - acc: 0.6417 - val_loss: 25.2752 - val_acc: 0.5480\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 24.0500 - acc: 0.6536 - val_loss: 23.1183 - val_acc: 0.5353\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 21.9565 - acc: 0.6567 - val_loss: 21.1718 - val_acc: 0.5380\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 20.0388 - acc: 0.6658 - val_loss: 19.3610 - val_acc: 0.5489\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 18.3145 - acc: 0.6632 - val_loss: 17.7621 - val_acc: 0.5471\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 16.7532 - acc: 0.6712 - val_loss: 16.3116 - val_acc: 0.5534\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 133.2502 - acc: 0.3765 - val_loss: 126.6686 - val_acc: 0.4819\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 121.8894 - acc: 0.5208 - val_loss: 115.5988 - val_acc: 0.5272\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 111.0591 - acc: 0.5576 - val_loss: 105.2098 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 100.9228 - acc: 0.5812 - val_loss: 95.5306 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 91.5866 - acc: 0.5961 - val_loss: 86.6678 - val_acc: 0.5571\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 83.0203 - acc: 0.6060 - val_loss: 78.5703 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 75.2053 - acc: 0.6261 - val_loss: 71.1872 - val_acc: 0.5571\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 68.0919 - acc: 0.6318 - val_loss: 64.4791 - val_acc: 0.5371\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 61.6248 - acc: 0.6370 - val_loss: 58.3865 - val_acc: 0.5426\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 55.7586 - acc: 0.6479 - val_loss: 52.8648 - val_acc: 0.5507\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 50.4462 - acc: 0.6533 - val_loss: 47.8897 - val_acc: 0.5507\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 45.6244 - acc: 0.6664 - val_loss: 43.3571 - val_acc: 0.5643\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 41.2741 - acc: 0.6710 - val_loss: 39.2627 - val_acc: 0.5498\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 37.3365 - acc: 0.6791 - val_loss: 35.5997 - val_acc: 0.5299\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 33.7880 - acc: 0.6829 - val_loss: 32.2941 - val_acc: 0.5299\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 30.5947 - acc: 0.6762 - val_loss: 29.2773 - val_acc: 0.5408\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 27.7064 - acc: 0.6855 - val_loss: 26.6026 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 25.1329 - acc: 0.6803 - val_loss: 24.2129 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 22.7890 - acc: 0.6915 - val_loss: 22.0049 - val_acc: 0.5444\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 20.6793 - acc: 0.6977 - val_loss: 20.0567 - val_acc: 0.5444\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 542us/step - loss: 18.7863 - acc: 0.6994 - val_loss: 18.3045 - val_acc: 0.5371\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 17.0949 - acc: 0.6987 - val_loss: 16.6955 - val_acc: 0.5534\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 17s 2ms/step - loss: 166.6521 - acc: 0.3056 - val_loss: 160.0543 - val_acc: 0.4393\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 155.4612 - acc: 0.4581 - val_loss: 149.2027 - val_acc: 0.4819\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 144.8257 - acc: 0.4982 - val_loss: 138.8822 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 134.7341 - acc: 0.5078 - val_loss: 129.1817 - val_acc: 0.5118\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 125.2613 - acc: 0.5223 - val_loss: 120.0599 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 116.3760 - acc: 0.5371 - val_loss: 111.5388 - val_acc: 0.5308\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 108.0700 - acc: 0.5491 - val_loss: 103.5557 - val_acc: 0.5326\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 100.3062 - acc: 0.5667 - val_loss: 96.0975 - val_acc: 0.5435\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 93.0593 - acc: 0.5667 - val_loss: 89.1693 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 86.2964 - acc: 0.5892 - val_loss: 82.6816 - val_acc: 0.5471\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 80.0078 - acc: 0.5937 - val_loss: 76.6707 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 74.1502 - acc: 0.5959 - val_loss: 71.0696 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 68.6913 - acc: 0.6073 - val_loss: 65.8560 - val_acc: 0.5453\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 63.6233 - acc: 0.6071 - val_loss: 61.0311 - val_acc: 0.5389\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 58.9215 - acc: 0.6175 - val_loss: 56.5411 - val_acc: 0.5308\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 54.5674 - acc: 0.6125 - val_loss: 52.3778 - val_acc: 0.5299\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 50.5031 - acc: 0.6328 - val_loss: 48.5246 - val_acc: 0.5498\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 46.7556 - acc: 0.6323 - val_loss: 44.9697 - val_acc: 0.5299\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 43.2851 - acc: 0.6347 - val_loss: 41.6529 - val_acc: 0.5317\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 40.0631 - acc: 0.6400 - val_loss: 38.5922 - val_acc: 0.5399\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 37.0823 - acc: 0.6396 - val_loss: 35.7877 - val_acc: 0.5208\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 34.3237 - acc: 0.6495 - val_loss: 33.1572 - val_acc: 0.5371\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 31.7800 - acc: 0.6531 - val_loss: 30.7354 - val_acc: 0.5408\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 29.4225 - acc: 0.6578 - val_loss: 28.5338 - val_acc: 0.5217\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 27.2658 - acc: 0.6574 - val_loss: 26.4646 - val_acc: 0.5371\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 25.2631 - acc: 0.6635 - val_loss: 24.5855 - val_acc: 0.5534\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 472us/step - loss: 23.4091 - acc: 0.6713 - val_loss: 22.8657 - val_acc: 0.5453\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 21.7064 - acc: 0.6740 - val_loss: 21.2380 - val_acc: 0.5471\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 20.1357 - acc: 0.6798 - val_loss: 19.7912 - val_acc: 0.5335\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 18.7037 - acc: 0.6796 - val_loss: 18.4003 - val_acc: 0.5417\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 17.3721 - acc: 0.6777 - val_loss: 17.1627 - val_acc: 0.5118\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 16.1337 - acc: 0.6922 - val_loss: 16.0065 - val_acc: 0.5408\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 15.0030 - acc: 0.6917 - val_loss: 14.9651 - val_acc: 0.5281\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 13.9753 - acc: 0.6962 - val_loss: 13.9889 - val_acc: 0.5290\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 13.0369 - acc: 0.6898 - val_loss: 13.1152 - val_acc: 0.5208\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 12.1379 - acc: 0.7079 - val_loss: 12.2592 - val_acc: 0.5172\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 103.3293 - acc: 0.2569 - val_loss: 100.1774 - val_acc: 0.4438\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 98.1126 - acc: 0.4298 - val_loss: 95.1196 - val_acc: 0.4837\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 93.0733 - acc: 0.4653 - val_loss: 90.1799 - val_acc: 0.5027\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 88.2329 - acc: 0.4843 - val_loss: 85.4757 - val_acc: 0.5109\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 83.5751 - acc: 0.5047 - val_loss: 80.9546 - val_acc: 0.5236\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 79.1455 - acc: 0.5210 - val_loss: 76.6610 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 74.9269 - acc: 0.5243 - val_loss: 72.5798 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 70.8935 - acc: 0.5388 - val_loss: 68.6689 - val_acc: 0.5308\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 67.0613 - acc: 0.5540 - val_loss: 64.9635 - val_acc: 0.5362\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 63.4164 - acc: 0.5567 - val_loss: 61.4393 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 59.9664 - acc: 0.5574 - val_loss: 58.0852 - val_acc: 0.5444\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 56.6829 - acc: 0.5698 - val_loss: 54.9210 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 53.5689 - acc: 0.5742 - val_loss: 51.9158 - val_acc: 0.5553\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 50.6161 - acc: 0.5891 - val_loss: 49.0675 - val_acc: 0.5507\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 47.8278 - acc: 0.5884 - val_loss: 46.3785 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 45.1740 - acc: 0.5944 - val_loss: 43.8489 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 42.6719 - acc: 0.5986 - val_loss: 41.4207 - val_acc: 0.5453\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 40.3057 - acc: 0.6032 - val_loss: 39.1324 - val_acc: 0.5516\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 38.0606 - acc: 0.6097 - val_loss: 36.9609 - val_acc: 0.5471\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 35.9475 - acc: 0.6142 - val_loss: 34.9207 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 33.9340 - acc: 0.6215 - val_loss: 33.0175 - val_acc: 0.5516\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 32.0481 - acc: 0.6259 - val_loss: 31.2128 - val_acc: 0.5489\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 30.2696 - acc: 0.6287 - val_loss: 29.4656 - val_acc: 0.5543\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 70.0860 - acc: 0.4553 - val_loss: 58.5637 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 49.3801 - acc: 0.5613 - val_loss: 40.5994 - val_acc: 0.5516\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 912us/step - loss: 34.0049 - acc: 0.5923 - val_loss: 27.9900 - val_acc: 0.5045\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 888us/step - loss: 23.3639 - acc: 0.5971 - val_loss: 19.4082 - val_acc: 0.5199\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 925us/step - loss: 16.2033 - acc: 0.6014 - val_loss: 13.6119 - val_acc: 0.5127\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 904us/step - loss: 11.4143 - acc: 0.6088 - val_loss: 9.8684 - val_acc: 0.5018\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 899us/step - loss: 8.2759 - acc: 0.6023 - val_loss: 7.3122 - val_acc: 0.5190\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 935us/step - loss: 6.2193 - acc: 0.5940 - val_loss: 5.6660 - val_acc: 0.5036\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 862us/step - loss: 4.8428 - acc: 0.5964 - val_loss: 4.5432 - val_acc: 0.4891\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 9s 975us/step - loss: 3.9141 - acc: 0.6043 - val_loss: 3.7835 - val_acc: 0.5091\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 877us/step - loss: 3.2826 - acc: 0.6043 - val_loss: 3.2273 - val_acc: 0.5290\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 938us/step - loss: 2.8397 - acc: 0.6108 - val_loss: 2.9424 - val_acc: 0.5145\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0729 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 447us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 451us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 456us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 433us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 441us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 44.2979 - acc: 0.4369 - val_loss: 33.1571 - val_acc: 0.4810\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 24.8806 - acc: 0.5050 - val_loss: 18.0213 - val_acc: 0.4846\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 13.4289 - acc: 0.5331 - val_loss: 9.8571 - val_acc: 0.5009\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 7.5435 - acc: 0.5258 - val_loss: 5.8341 - val_acc: 0.5027\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.6896 - acc: 0.5302 - val_loss: 3.8994 - val_acc: 0.4900\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.3173 - acc: 0.5324 - val_loss: 3.0234 - val_acc: 0.4764\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.6448 - acc: 0.5440 - val_loss: 2.5089 - val_acc: 0.5091\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.2603 - acc: 0.5492 - val_loss: 2.2577 - val_acc: 0.4846\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0688 - acc: 0.5429 - val_loss: 2.0635 - val_acc: 0.5145\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9358 - acc: 0.5457 - val_loss: 1.9452 - val_acc: 0.5118\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8394 - acc: 0.5524 - val_loss: 1.8992 - val_acc: 0.5190\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7712 - acc: 0.5578 - val_loss: 1.8901 - val_acc: 0.4991\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7639 - acc: 0.5419 - val_loss: 1.8355 - val_acc: 0.5308\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6829 - acc: 0.5518 - val_loss: 1.8224 - val_acc: 0.5290\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6684 - acc: 0.5613 - val_loss: 1.7321 - val_acc: 0.5190\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6166 - acc: 0.5698 - val_loss: 1.7818 - val_acc: 0.5154\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6388 - acc: 0.5695 - val_loss: 1.7645 - val_acc: 0.5181\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6161 - acc: 0.5656 - val_loss: 1.7775 - val_acc: 0.5317\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6147 - acc: 0.5681 - val_loss: 1.7133 - val_acc: 0.5426\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5944 - acc: 0.5732 - val_loss: 1.6907 - val_acc: 0.5199\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5655 - acc: 0.5746 - val_loss: 1.7249 - val_acc: 0.5136\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5768 - acc: 0.5716 - val_loss: 1.7219 - val_acc: 0.5136\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5555 - acc: 0.5791 - val_loss: 1.7065 - val_acc: 0.5217\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5683 - acc: 0.5827 - val_loss: 1.6689 - val_acc: 0.5317\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5506 - acc: 0.5855 - val_loss: 1.7211 - val_acc: 0.5272\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5330 - acc: 0.5909 - val_loss: 1.6977 - val_acc: 0.5281\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5291 - acc: 0.5933 - val_loss: 1.7880 - val_acc: 0.5009\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5464 - acc: 0.5867 - val_loss: 1.6672 - val_acc: 0.5516\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5388 - acc: 0.5925 - val_loss: 1.7695 - val_acc: 0.5199\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5154 - acc: 0.5916 - val_loss: 1.6633 - val_acc: 0.5417\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5111 - acc: 0.5994 - val_loss: 1.6940 - val_acc: 0.5290\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5454 - acc: 0.5935 - val_loss: 1.7121 - val_acc: 0.5290\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5285 - acc: 0.5925 - val_loss: 1.7160 - val_acc: 0.5317\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5090 - acc: 0.5996 - val_loss: 1.7795 - val_acc: 0.5136\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5013 - acc: 0.5995 - val_loss: 1.7345 - val_acc: 0.5299\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4820 - acc: 0.6105 - val_loss: 1.7256 - val_acc: 0.5453\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5082 - acc: 0.6089 - val_loss: 1.7361 - val_acc: 0.5226\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4961 - acc: 0.6086 - val_loss: 1.7931 - val_acc: 0.5190\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 137.0333 - acc: 0.4070 - val_loss: 106.0184 - val_acc: 0.4755\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 83.1967 - acc: 0.4978 - val_loss: 63.3654 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 49.3733 - acc: 0.5199 - val_loss: 37.4224 - val_acc: 0.5118\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 29.1293 - acc: 0.5250 - val_loss: 22.1617 - val_acc: 0.5236\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 17.3494 - acc: 0.5445 - val_loss: 13.4273 - val_acc: 0.5217\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 10.6380 - acc: 0.5518 - val_loss: 8.5100 - val_acc: 0.5127\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 6.8996 - acc: 0.5602 - val_loss: 5.7435 - val_acc: 0.4955\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.8236 - acc: 0.5554 - val_loss: 4.1833 - val_acc: 0.5308\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.6455 - acc: 0.5608 - val_loss: 3.3482 - val_acc: 0.5082\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.9726 - acc: 0.5694 - val_loss: 2.8247 - val_acc: 0.5172\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.5597 - acc: 0.5766 - val_loss: 2.5144 - val_acc: 0.5344\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.3090 - acc: 0.5724 - val_loss: 2.3229 - val_acc: 0.5217\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.1270 - acc: 0.5818 - val_loss: 2.2053 - val_acc: 0.5109\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0209 - acc: 0.5824 - val_loss: 2.0997 - val_acc: 0.5408\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9298 - acc: 0.5850 - val_loss: 2.0687 - val_acc: 0.5254\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8606 - acc: 0.5860 - val_loss: 1.9780 - val_acc: 0.5335\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7963 - acc: 0.5859 - val_loss: 1.9442 - val_acc: 0.5172\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7462 - acc: 0.6031 - val_loss: 1.9028 - val_acc: 0.5245\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7069 - acc: 0.5994 - val_loss: 1.8784 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6709 - acc: 0.6039 - val_loss: 1.8365 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6323 - acc: 0.6121 - val_loss: 1.8094 - val_acc: 0.5380\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6061 - acc: 0.6184 - val_loss: 1.8208 - val_acc: 0.5290\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5898 - acc: 0.6208 - val_loss: 1.8387 - val_acc: 0.5353\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5626 - acc: 0.6233 - val_loss: 1.7303 - val_acc: 0.5534\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5367 - acc: 0.6306 - val_loss: 1.7502 - val_acc: 0.5435\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5277 - acc: 0.6346 - val_loss: 1.7600 - val_acc: 0.5471\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5088 - acc: 0.6363 - val_loss: 1.8867 - val_acc: 0.5426\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4857 - acc: 0.6404 - val_loss: 1.8349 - val_acc: 0.5353\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4801 - acc: 0.6427 - val_loss: 1.7425 - val_acc: 0.5471\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4641 - acc: 0.6505 - val_loss: 1.7519 - val_acc: 0.5571\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4564 - acc: 0.6445 - val_loss: 1.7432 - val_acc: 0.5444\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4427 - acc: 0.6502 - val_loss: 1.8250 - val_acc: 0.5290\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4143 - acc: 0.6617 - val_loss: 1.6903 - val_acc: 0.5408\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4181 - acc: 0.6629 - val_loss: 1.6934 - val_acc: 0.5598\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3984 - acc: 0.6652 - val_loss: 1.7785 - val_acc: 0.5263\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3966 - acc: 0.6626 - val_loss: 1.7613 - val_acc: 0.5362\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3908 - acc: 0.6681 - val_loss: 1.8577 - val_acc: 0.5181\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3875 - acc: 0.6700 - val_loss: 1.7547 - val_acc: 0.5426\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3425 - acc: 0.6877 - val_loss: 1.7314 - val_acc: 0.5462\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3640 - acc: 0.6783 - val_loss: 1.7101 - val_acc: 0.5643\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3427 - acc: 0.6821 - val_loss: 1.7648 - val_acc: 0.5317\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3404 - acc: 0.6889 - val_loss: 1.7331 - val_acc: 0.5634\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3153 - acc: 0.6943 - val_loss: 1.7082 - val_acc: 0.5462\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3074 - acc: 0.7001 - val_loss: 1.8003 - val_acc: 0.5480\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3176 - acc: 0.6985 - val_loss: 1.9063 - val_acc: 0.5100\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3122 - acc: 0.7022 - val_loss: 1.8542 - val_acc: 0.5236\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2832 - acc: 0.7146 - val_loss: 1.7874 - val_acc: 0.5462\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2897 - acc: 0.7070 - val_loss: 1.7470 - val_acc: 0.5643\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2875 - acc: 0.7124 - val_loss: 1.8265 - val_acc: 0.5462\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.2893 - acc: 0.7096 - val_loss: 1.7958 - val_acc: 0.5507\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 132.8932 - acc: 0.4225 - val_loss: 82.9693 - val_acc: 0.5063\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 54.5362 - acc: 0.5023 - val_loss: 33.0887 - val_acc: 0.4710\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 21.7138 - acc: 0.5119 - val_loss: 13.5414 - val_acc: 0.4764\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 9.2959 - acc: 0.5148 - val_loss: 6.4128 - val_acc: 0.4873\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.8095 - acc: 0.5203 - val_loss: 3.7658 - val_acc: 0.5045\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.1473 - acc: 0.5169 - val_loss: 2.7764 - val_acc: 0.4882\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.4402 - acc: 0.5335 - val_loss: 2.3494 - val_acc: 0.4982\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.1409 - acc: 0.5320 - val_loss: 2.1219 - val_acc: 0.4755\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9467 - acc: 0.5348 - val_loss: 1.9395 - val_acc: 0.5154\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8299 - acc: 0.5422 - val_loss: 1.9544 - val_acc: 0.4882\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7583 - acc: 0.5441 - val_loss: 1.8634 - val_acc: 0.5190\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7052 - acc: 0.5409 - val_loss: 1.8275 - val_acc: 0.4683\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6482 - acc: 0.5520 - val_loss: 1.7041 - val_acc: 0.5263\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6221 - acc: 0.5584 - val_loss: 1.6799 - val_acc: 0.5172\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6017 - acc: 0.5570 - val_loss: 1.6902 - val_acc: 0.5199\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5937 - acc: 0.5611 - val_loss: 1.6560 - val_acc: 0.5236\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5736 - acc: 0.5660 - val_loss: 1.7010 - val_acc: 0.5199\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5638 - acc: 0.5631 - val_loss: 1.6601 - val_acc: 0.5371\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5247 - acc: 0.5757 - val_loss: 1.6999 - val_acc: 0.5281\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5489 - acc: 0.5655 - val_loss: 1.6893 - val_acc: 0.5335\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5157 - acc: 0.5878 - val_loss: 1.6936 - val_acc: 0.5109\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5373 - acc: 0.5754 - val_loss: 1.6613 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5030 - acc: 0.5893 - val_loss: 1.7877 - val_acc: 0.5072\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5223 - acc: 0.5802 - val_loss: 1.6951 - val_acc: 0.5408\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5032 - acc: 0.5927 - val_loss: 1.6077 - val_acc: 0.5435\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5077 - acc: 0.5858 - val_loss: 1.6964 - val_acc: 0.5236\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4931 - acc: 0.5876 - val_loss: 1.6127 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5193 - acc: 0.5798 - val_loss: 1.7011 - val_acc: 0.5245\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4913 - acc: 0.5935 - val_loss: 1.6079 - val_acc: 0.5525\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4780 - acc: 0.5951 - val_loss: 1.6498 - val_acc: 0.5208\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4911 - acc: 0.5961 - val_loss: 1.6028 - val_acc: 0.5471\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4725 - acc: 0.6035 - val_loss: 1.5975 - val_acc: 0.5616\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4642 - acc: 0.6132 - val_loss: 1.6470 - val_acc: 0.5308\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4622 - acc: 0.6128 - val_loss: 1.7109 - val_acc: 0.5181\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4431 - acc: 0.6155 - val_loss: 1.7453 - val_acc: 0.5226\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4886 - acc: 0.6080 - val_loss: 1.6728 - val_acc: 0.5335\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4731 - acc: 0.6043 - val_loss: 1.6388 - val_acc: 0.5534\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4583 - acc: 0.6181 - val_loss: 1.7475 - val_acc: 0.5326\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4578 - acc: 0.6157 - val_loss: 1.7011 - val_acc: 0.5534\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4348 - acc: 0.6277 - val_loss: 1.6246 - val_acc: 0.5679\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4328 - acc: 0.6253 - val_loss: 1.6009 - val_acc: 0.5652\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3985 - acc: 0.6367 - val_loss: 1.7010 - val_acc: 0.5199\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4382 - acc: 0.6294 - val_loss: 1.6552 - val_acc: 0.5543\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4339 - acc: 0.6347 - val_loss: 1.7681 - val_acc: 0.5371\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4501 - acc: 0.6258 - val_loss: 1.7557 - val_acc: 0.5326\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4479 - acc: 0.6274 - val_loss: 1.6794 - val_acc: 0.5516\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4651 - acc: 0.6280 - val_loss: 1.7051 - val_acc: 0.5444\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3722 - acc: 0.6568 - val_loss: 1.6550 - val_acc: 0.5389\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3869 - acc: 0.6404 - val_loss: 1.7235 - val_acc: 0.5308\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.3888 - acc: 0.6515 - val_loss: 1.6514 - val_acc: 0.5498\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: nan - acc: 0.0700 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 50.9030 - acc: 0.3818 - val_loss: 49.6573 - val_acc: 0.5000\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 447us/step - loss: 48.6954 - acc: 0.5694 - val_loss: 47.6854 - val_acc: 0.5263\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 438us/step - loss: 46.6278 - acc: 0.6266 - val_loss: 45.6968 - val_acc: 0.5498\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 441us/step - loss: 44.5887 - acc: 0.6732 - val_loss: 43.7464 - val_acc: 0.5335\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 449us/step - loss: 42.5860 - acc: 0.7066 - val_loss: 41.8344 - val_acc: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 40.6568 - acc: 0.7266 - val_loss: 39.9986 - val_acc: 0.5516\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 38.7992 - acc: 0.7518 - val_loss: 38.2223 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 450us/step - loss: 37.0159 - acc: 0.7772 - val_loss: 36.5270 - val_acc: 0.5562\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 453us/step - loss: 35.3175 - acc: 0.7900 - val_loss: 34.9063 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 441us/step - loss: 33.6901 - acc: 0.8103 - val_loss: 33.3363 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 449us/step - loss: 32.1366 - acc: 0.8203 - val_loss: 31.8767 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 452us/step - loss: 30.6698 - acc: 0.8295 - val_loss: 30.4781 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: 29.2655 - acc: 0.8363 - val_loss: 29.1657 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 448us/step - loss: 27.9313 - acc: 0.8556 - val_loss: 27.8959 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 447us/step - loss: 26.6789 - acc: 0.8557 - val_loss: 26.7133 - val_acc: 0.5399\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 438us/step - loss: 25.4829 - acc: 0.8596 - val_loss: 25.5525 - val_acc: 0.5417\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: 24.3575 - acc: 0.8675 - val_loss: 24.4973 - val_acc: 0.5453\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: 23.2900 - acc: 0.8694 - val_loss: 23.4419 - val_acc: 0.5543\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: 22.2580 - acc: 0.8916 - val_loss: 22.4980 - val_acc: 0.5625\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 21.3004 - acc: 0.8941 - val_loss: 21.5640 - val_acc: 0.5543\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 443us/step - loss: 20.3811 - acc: 0.9020 - val_loss: 20.7192 - val_acc: 0.5335\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 445us/step - loss: 19.5151 - acc: 0.9016 - val_loss: 19.9040 - val_acc: 0.5317\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 18.6991 - acc: 0.9087 - val_loss: 19.1311 - val_acc: 0.5399\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 450us/step - loss: 17.9311 - acc: 0.9032 - val_loss: 18.4051 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 445us/step - loss: 17.1881 - acc: 0.9114 - val_loss: 17.6882 - val_acc: 0.5543\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 446us/step - loss: 16.4920 - acc: 0.9148 - val_loss: 17.0673 - val_acc: 0.5335\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 451us/step - loss: 15.8416 - acc: 0.9121 - val_loss: 16.4222 - val_acc: 0.5589\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 453us/step - loss: 15.2161 - acc: 0.9100 - val_loss: 15.8161 - val_acc: 0.5534\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 452us/step - loss: 14.6282 - acc: 0.9147 - val_loss: 15.2778 - val_acc: 0.5580\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 118.8107 - acc: 0.4101 - val_loss: 82.5784 - val_acc: 0.4837\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 17s 2ms/step - loss: 59.1867 - acc: 0.4845 - val_loss: 40.2971 - val_acc: 0.4710\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 28.6808 - acc: 0.5084 - val_loss: 19.5360 - val_acc: 0.5054\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 14.0920 - acc: 0.5263 - val_loss: 9.9757 - val_acc: 0.4955\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 7.4821 - acc: 0.5272 - val_loss: 5.6628 - val_acc: 0.5063\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 4.5369 - acc: 0.5284 - val_loss: 3.7699 - val_acc: 0.5072\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 3.2292 - acc: 0.5302 - val_loss: 2.8658 - val_acc: 0.5154\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.5853 - acc: 0.5379 - val_loss: 2.4528 - val_acc: 0.5100\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.2628 - acc: 0.5390 - val_loss: 2.2878 - val_acc: 0.5036\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 2.0597 - acc: 0.5517 - val_loss: 2.0953 - val_acc: 0.5100\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.9444 - acc: 0.5499 - val_loss: 1.9829 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.8521 - acc: 0.5573 - val_loss: 1.9596 - val_acc: 0.5154\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7747 - acc: 0.5657 - val_loss: 1.8574 - val_acc: 0.5190\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7315 - acc: 0.5690 - val_loss: 1.8329 - val_acc: 0.5172\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.7003 - acc: 0.5662 - val_loss: 1.8184 - val_acc: 0.5063\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6736 - acc: 0.5725 - val_loss: 1.7730 - val_acc: 0.5208\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6485 - acc: 0.5686 - val_loss: 1.7634 - val_acc: 0.5190\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6285 - acc: 0.5697 - val_loss: 1.7443 - val_acc: 0.5281\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.6030 - acc: 0.5782 - val_loss: 1.7045 - val_acc: 0.5199\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5827 - acc: 0.5806 - val_loss: 1.7026 - val_acc: 0.5326\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5865 - acc: 0.5814 - val_loss: 1.6996 - val_acc: 0.5154\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 108.2164 - acc: 0.4049 - val_loss: 88.4945 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 72.9444 - acc: 0.4950 - val_loss: 58.9315 - val_acc: 0.5082\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 48.1983 - acc: 0.5243 - val_loss: 38.7472 - val_acc: 0.5009\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 31.5862 - acc: 0.5364 - val_loss: 25.3797 - val_acc: 0.5208\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 20.7337 - acc: 0.5489 - val_loss: 16.7756 - val_acc: 0.5326\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 13.7803 - acc: 0.5582 - val_loss: 11.3224 - val_acc: 0.5272\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 9.4150 - acc: 0.5536 - val_loss: 7.9128 - val_acc: 0.5072\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 6.6610 - acc: 0.5619 - val_loss: 5.8685 - val_acc: 0.4973\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.9540 - acc: 0.5646 - val_loss: 4.4818 - val_acc: 0.5045\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.8654 - acc: 0.5762 - val_loss: 3.6128 - val_acc: 0.5199\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 3.2113 - acc: 0.5808 - val_loss: 3.0627 - val_acc: 0.5199\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.7699 - acc: 0.5764 - val_loss: 2.7539 - val_acc: 0.5254\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.4813 - acc: 0.5862 - val_loss: 2.4968 - val_acc: 0.5145\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2583 - acc: 0.5968 - val_loss: 2.3508 - val_acc: 0.5163\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.1136 - acc: 0.5989 - val_loss: 2.2169 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.0189 - acc: 0.6017 - val_loss: 2.1668 - val_acc: 0.5371\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9398 - acc: 0.5993 - val_loss: 2.0979 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8709 - acc: 0.6073 - val_loss: 2.0990 - val_acc: 0.5408\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8147 - acc: 0.6061 - val_loss: 1.9877 - val_acc: 0.5480\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7513 - acc: 0.6186 - val_loss: 1.9762 - val_acc: 0.5299\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7087 - acc: 0.6257 - val_loss: 1.8864 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6714 - acc: 0.6278 - val_loss: 1.8812 - val_acc: 0.5480\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6293 - acc: 0.6395 - val_loss: 1.8754 - val_acc: 0.5589\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6231 - acc: 0.6325 - val_loss: 1.9017 - val_acc: 0.5226\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5888 - acc: 0.6454 - val_loss: 1.8623 - val_acc: 0.5553\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5635 - acc: 0.6421 - val_loss: 1.8573 - val_acc: 0.5444\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5404 - acc: 0.6478 - val_loss: 1.8293 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5279 - acc: 0.6523 - val_loss: 1.8446 - val_acc: 0.5462\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5131 - acc: 0.6552 - val_loss: 1.8517 - val_acc: 0.5362\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4822 - acc: 0.6598 - val_loss: 1.8143 - val_acc: 0.5516\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4760 - acc: 0.6596 - val_loss: 1.8306 - val_acc: 0.5489\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4602 - acc: 0.6706 - val_loss: 1.9705 - val_acc: 0.5063\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4434 - acc: 0.6727 - val_loss: 1.7880 - val_acc: 0.5589\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 104.2327 - acc: 0.4345 - val_loss: 55.9438 - val_acc: 0.4801\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 32.8930 - acc: 0.4956 - val_loss: 17.3189 - val_acc: 0.4774\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 10.6749 - acc: 0.5004 - val_loss: 6.4849 - val_acc: 0.4620\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.6171 - acc: 0.5032 - val_loss: 3.4999 - val_acc: 0.4719\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.8661 - acc: 0.5069 - val_loss: 2.4785 - val_acc: 0.5009\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2456 - acc: 0.5142 - val_loss: 2.1626 - val_acc: 0.4801\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9842 - acc: 0.5246 - val_loss: 2.0043 - val_acc: 0.4755\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8523 - acc: 0.5184 - val_loss: 1.8567 - val_acc: 0.4964\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7619 - acc: 0.5292 - val_loss: 1.7480 - val_acc: 0.5163\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7065 - acc: 0.5287 - val_loss: 1.7467 - val_acc: 0.5109\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6632 - acc: 0.5332 - val_loss: 1.7336 - val_acc: 0.5063\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6491 - acc: 0.5402 - val_loss: 1.6760 - val_acc: 0.5299\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6301 - acc: 0.5429 - val_loss: 1.7171 - val_acc: 0.5145\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6190 - acc: 0.5388 - val_loss: 1.7035 - val_acc: 0.5199\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6130 - acc: 0.5405 - val_loss: 1.6707 - val_acc: 0.5172\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5966 - acc: 0.5500 - val_loss: 1.6395 - val_acc: 0.5236\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5968 - acc: 0.5479 - val_loss: 1.6311 - val_acc: 0.5272\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6043 - acc: 0.5458 - val_loss: 1.7699 - val_acc: 0.4928\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5946 - acc: 0.5571 - val_loss: 1.7219 - val_acc: 0.5054\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5936 - acc: 0.5530 - val_loss: 1.6280 - val_acc: 0.5371\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5895 - acc: 0.5539 - val_loss: 1.6537 - val_acc: 0.5272\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5737 - acc: 0.5652 - val_loss: 1.6625 - val_acc: 0.5371\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5964 - acc: 0.5574 - val_loss: 1.7512 - val_acc: 0.5045\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5871 - acc: 0.5651 - val_loss: 1.6933 - val_acc: 0.5181\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5764 - acc: 0.5677 - val_loss: 1.7376 - val_acc: 0.5190\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5570 - acc: 0.5689 - val_loss: 1.7025 - val_acc: 0.5127\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5665 - acc: 0.5671 - val_loss: 1.6968 - val_acc: 0.5263\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5453 - acc: 0.5750 - val_loss: 1.6986 - val_acc: 0.5100\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5442 - acc: 0.5797 - val_loss: 1.6540 - val_acc: 0.5091\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5700 - acc: 0.5670 - val_loss: 1.6808 - val_acc: 0.5389\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5829 - acc: 0.5703 - val_loss: 1.7132 - val_acc: 0.5362\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5596 - acc: 0.5799 - val_loss: 1.6885 - val_acc: 0.5054\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5361 - acc: 0.5826 - val_loss: 1.6719 - val_acc: 0.5389\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5470 - acc: 0.5796 - val_loss: 1.6846 - val_acc: 0.5254\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5466 - acc: 0.5848 - val_loss: 1.7293 - val_acc: 0.5299\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5389 - acc: 0.5890 - val_loss: 1.6706 - val_acc: 0.5471\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5390 - acc: 0.5892 - val_loss: 1.6069 - val_acc: 0.5534\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5424 - acc: 0.5818 - val_loss: 1.6933 - val_acc: 0.5254\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5188 - acc: 0.5937 - val_loss: 1.7807 - val_acc: 0.5245\n",
      "Epoch 40/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5129 - acc: 0.5951 - val_loss: 1.7640 - val_acc: 0.5208\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5150 - acc: 0.5950 - val_loss: 1.6779 - val_acc: 0.5462\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5640 - acc: 0.5799 - val_loss: 1.7800 - val_acc: 0.5091\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5449 - acc: 0.5912 - val_loss: 1.7690 - val_acc: 0.5408\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5237 - acc: 0.5964 - val_loss: 1.6488 - val_acc: 0.5625\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5060 - acc: 0.5990 - val_loss: 1.7337 - val_acc: 0.5308\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5252 - acc: 0.6065 - val_loss: 1.7987 - val_acc: 0.5181\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5015 - acc: 0.6031 - val_loss: 1.7270 - val_acc: 0.5317\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4785 - acc: 0.6116 - val_loss: 1.6813 - val_acc: 0.5353\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.4812 - acc: 0.6164 - val_loss: 1.6436 - val_acc: 0.5453\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5379 - acc: 0.6001 - val_loss: 1.7842 - val_acc: 0.5118\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 18s 2ms/step - loss: 1.5224 - acc: 0.6026 - val_loss: 1.6752 - val_acc: 0.5353\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.5184 - acc: 0.6071 - val_loss: 1.7676 - val_acc: 0.5145\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4910 - acc: 0.6099 - val_loss: 1.6833 - val_acc: 0.5462\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.4801 - acc: 0.6173 - val_loss: 1.7146 - val_acc: 0.5426\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 22.1215 - acc: 0.3690 - val_loss: 20.6979 - val_acc: 0.4665\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 19.6391 - acc: 0.5238 - val_loss: 18.4281 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 17.2926 - acc: 0.5851 - val_loss: 16.2841 - val_acc: 0.5054\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 15.0578 - acc: 0.6348 - val_loss: 14.1764 - val_acc: 0.5435\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 13.0191 - acc: 0.6704 - val_loss: 12.3274 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 11.2552 - acc: 0.6838 - val_loss: 10.7947 - val_acc: 0.5389\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 9.7607 - acc: 0.6951 - val_loss: 9.4564 - val_acc: 0.5498\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 8.5113 - acc: 0.6960 - val_loss: 8.3318 - val_acc: 0.5353\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 7.4415 - acc: 0.7113 - val_loss: 7.3363 - val_acc: 0.5308\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 6.5131 - acc: 0.7378 - val_loss: 6.5753 - val_acc: 0.5480\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 5.7761 - acc: 0.7324 - val_loss: 5.9976 - val_acc: 0.5145\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 5.1191 - acc: 0.7443 - val_loss: 5.4139 - val_acc: 0.5335\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 4.5716 - acc: 0.7565 - val_loss: 4.9681 - val_acc: 0.5236\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 4.1444 - acc: 0.7449 - val_loss: 4.5148 - val_acc: 0.5389\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 3.7597 - acc: 0.7556 - val_loss: 4.1929 - val_acc: 0.5426\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 3.4276 - acc: 0.7624 - val_loss: 3.9516 - val_acc: 0.5217\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 3.1617 - acc: 0.7666 - val_loss: 3.6747 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 137.8382 - acc: 0.4186 - val_loss: 68.9659 - val_acc: 0.4801\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 38.9285 - acc: 0.4844 - val_loss: 19.1209 - val_acc: 0.4855\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 11.3222 - acc: 0.4904 - val_loss: 6.5370 - val_acc: 0.4611\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 4.5102 - acc: 0.4927 - val_loss: 3.3514 - val_acc: 0.4493\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.7640 - acc: 0.4978 - val_loss: 2.4871 - val_acc: 0.4792\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 2.2178 - acc: 0.5011 - val_loss: 2.1251 - val_acc: 0.4728\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.9930 - acc: 0.5073 - val_loss: 1.9259 - val_acc: 0.5127\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8853 - acc: 0.5124 - val_loss: 1.8568 - val_acc: 0.5118\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.8015 - acc: 0.5114 - val_loss: 1.8149 - val_acc: 0.4955\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7649 - acc: 0.5223 - val_loss: 1.8138 - val_acc: 0.4918\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7264 - acc: 0.5276 - val_loss: 1.7177 - val_acc: 0.5036\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7063 - acc: 0.5261 - val_loss: 1.7527 - val_acc: 0.4964\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6883 - acc: 0.5293 - val_loss: 1.7243 - val_acc: 0.5127\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6979 - acc: 0.5262 - val_loss: 1.7924 - val_acc: 0.5000\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.7024 - acc: 0.5261 - val_loss: 1.7202 - val_acc: 0.5109\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6813 - acc: 0.5298 - val_loss: 1.7737 - val_acc: 0.4928\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 1.6754 - acc: 0.5347 - val_loss: 1.7030 - val_acc: 0.4964\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 19.7322 - acc: 0.3250 - val_loss: 17.8495 - val_acc: 0.4139\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 16.6278 - acc: 0.4920 - val_loss: 15.0390 - val_acc: 0.4982\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 13.6917 - acc: 0.5638 - val_loss: 12.2810 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 11.0217 - acc: 0.6080 - val_loss: 9.9771 - val_acc: 0.5489\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 8.8734 - acc: 0.6216 - val_loss: 8.2273 - val_acc: 0.5045\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 7.2542 - acc: 0.6180 - val_loss: 6.7578 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 5.9501 - acc: 0.6508 - val_loss: 5.8007 - val_acc: 0.5054\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 5.0158 - acc: 0.6459 - val_loss: 4.9925 - val_acc: 0.5082\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 4.3452 - acc: 0.6309 - val_loss: 4.3954 - val_acc: 0.5082\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 3.7647 - acc: 0.6505 - val_loss: 3.8383 - val_acc: 0.5299\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 3.2961 - acc: 0.6625 - val_loss: 3.5600 - val_acc: 0.5145\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 2.9786 - acc: 0.6651 - val_loss: 3.2260 - val_acc: 0.5399\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 2.6764 - acc: 0.6799 - val_loss: 3.0489 - val_acc: 0.5254\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.4481 - acc: 0.6919 - val_loss: 2.7874 - val_acc: 0.5344\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 145.2050 - acc: 0.3397 - val_loss: 140.2917 - val_acc: 0.4755\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 136.6507 - acc: 0.5018 - val_loss: 131.8167 - val_acc: 0.5063\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 128.2402 - acc: 0.5447 - val_loss: 123.6348 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 120.1994 - acc: 0.5680 - val_loss: 115.8897 - val_acc: 0.5308\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 112.6037 - acc: 0.5822 - val_loss: 108.5505 - val_acc: 0.5263\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 105.4323 - acc: 0.5970 - val_loss: 101.6408 - val_acc: 0.5308\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 98.6771 - acc: 0.6139 - val_loss: 95.1513 - val_acc: 0.5335\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 92.3401 - acc: 0.6271 - val_loss: 89.0699 - val_acc: 0.5417\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 86.3751 - acc: 0.6357 - val_loss: 83.3260 - val_acc: 0.5353\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 80.7789 - acc: 0.6464 - val_loss: 77.9637 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 75.5486 - acc: 0.6568 - val_loss: 72.9639 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 70.6465 - acc: 0.6620 - val_loss: 68.2377 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 66.0444 - acc: 0.6692 - val_loss: 63.8197 - val_acc: 0.5444\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 61.7272 - acc: 0.6747 - val_loss: 59.6796 - val_acc: 0.5462\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 57.6940 - acc: 0.6755 - val_loss: 55.8096 - val_acc: 0.5525\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 53.9226 - acc: 0.6859 - val_loss: 52.1913 - val_acc: 0.5462\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 50.3805 - acc: 0.6922 - val_loss: 48.8055 - val_acc: 0.5408\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 47.0945 - acc: 0.6920 - val_loss: 45.6621 - val_acc: 0.5471\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 44.0215 - acc: 0.6969 - val_loss: 42.7141 - val_acc: 0.5471\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 41.1528 - acc: 0.6935 - val_loss: 39.9866 - val_acc: 0.5426\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 38.4670 - acc: 0.7047 - val_loss: 37.4126 - val_acc: 0.5589\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 35.9557 - acc: 0.7122 - val_loss: 35.0415 - val_acc: 0.5362\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 33.6353 - acc: 0.7112 - val_loss: 32.8193 - val_acc: 0.5308\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 31.4738 - acc: 0.7111 - val_loss: 30.7403 - val_acc: 0.5371\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 29.4449 - acc: 0.7228 - val_loss: 28.8076 - val_acc: 0.5607\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 27.5582 - acc: 0.7230 - val_loss: 27.0545 - val_acc: 0.5389\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 25.8132 - acc: 0.7191 - val_loss: 25.3587 - val_acc: 0.5462\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 24.1799 - acc: 0.7268 - val_loss: 23.8081 - val_acc: 0.5326\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 22.6542 - acc: 0.7309 - val_loss: 22.3769 - val_acc: 0.5335\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 21.2488 - acc: 0.7275 - val_loss: 21.0100 - val_acc: 0.5462\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 19.9240 - acc: 0.7310 - val_loss: 19.7696 - val_acc: 0.5281\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 18.7078 - acc: 0.7287 - val_loss: 18.5840 - val_acc: 0.5480\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 17.5611 - acc: 0.7392 - val_loss: 17.5057 - val_acc: 0.5290\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 16.4934 - acc: 0.7444 - val_loss: 16.5302 - val_acc: 0.5380\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 15.5079 - acc: 0.7456 - val_loss: 15.5758 - val_acc: 0.5272\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 20.4858 - acc: 0.3339 - val_loss: 18.8190 - val_acc: 0.4357\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 17.6452 - acc: 0.4916 - val_loss: 16.1648 - val_acc: 0.5145\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 14.9919 - acc: 0.5576 - val_loss: 13.6954 - val_acc: 0.5109\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 12.5206 - acc: 0.5901 - val_loss: 11.5568 - val_acc: 0.5226\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 10.4205 - acc: 0.6072 - val_loss: 9.5567 - val_acc: 0.5281\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 471us/step - loss: 8.6412 - acc: 0.6301 - val_loss: 8.0661 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 7.2259 - acc: 0.6384 - val_loss: 6.9024 - val_acc: 0.5272\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 6.1285 - acc: 0.6352 - val_loss: 5.9121 - val_acc: 0.5489\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 5.2473 - acc: 0.6484 - val_loss: 5.1591 - val_acc: 0.5389\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 4.5299 - acc: 0.6583 - val_loss: 4.5571 - val_acc: 0.5435\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 3.9926 - acc: 0.6559 - val_loss: 4.1185 - val_acc: 0.5281\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 3.5493 - acc: 0.6649 - val_loss: 3.7137 - val_acc: 0.5498\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 3.1771 - acc: 0.6706 - val_loss: 3.3503 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 2.8386 - acc: 0.6924 - val_loss: 3.0980 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 2.6040 - acc: 0.6968 - val_loss: 2.9729 - val_acc: 0.5362\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 2.4082 - acc: 0.6953 - val_loss: 2.7817 - val_acc: 0.5553\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 2.2745 - acc: 0.7005 - val_loss: 2.7184 - val_acc: 0.5399\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.1662 - acc: 0.6952 - val_loss: 2.6573 - val_acc: 0.5281\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.0614 - acc: 0.6979 - val_loss: 2.6110 - val_acc: 0.5036\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: 1.9928 - acc: 0.6944 - val_loss: 2.4314 - val_acc: 0.5199\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 1.8876 - acc: 0.7091 - val_loss: 2.3371 - val_acc: 0.5408\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 1.7977 - acc: 0.7236 - val_loss: 2.5373 - val_acc: 0.5236\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.8345 - acc: 0.6959 - val_loss: 2.3714 - val_acc: 0.5236\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: 141.9213 - acc: 0.2890 - val_loss: 137.6512 - val_acc: 0.4420\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 472us/step - loss: 134.6939 - acc: 0.4495 - val_loss: 130.5687 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 127.7004 - acc: 0.4833 - val_loss: 123.7453 - val_acc: 0.5009\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 120.9863 - acc: 0.5044 - val_loss: 117.2463 - val_acc: 0.5190\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 114.5889 - acc: 0.5229 - val_loss: 111.0177 - val_acc: 0.5226\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 510us/step - loss: 108.4780 - acc: 0.5318 - val_loss: 105.0900 - val_acc: 0.5272\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 102.6479 - acc: 0.5493 - val_loss: 99.4500 - val_acc: 0.5254\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 97.1120 - acc: 0.5614 - val_loss: 94.0817 - val_acc: 0.5326\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 91.8527 - acc: 0.5588 - val_loss: 88.9927 - val_acc: 0.5290\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 86.8558 - acc: 0.5693 - val_loss: 84.1510 - val_acc: 0.5462\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 82.1108 - acc: 0.5788 - val_loss: 79.5855 - val_acc: 0.5344\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 77.6212 - acc: 0.5944 - val_loss: 75.2398 - val_acc: 0.5408\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 73.3640 - acc: 0.5930 - val_loss: 71.1260 - val_acc: 0.5444\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 69.3163 - acc: 0.6013 - val_loss: 67.1981 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 65.4742 - acc: 0.6092 - val_loss: 63.4946 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 61.8363 - acc: 0.6195 - val_loss: 59.9730 - val_acc: 0.5525\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 58.4006 - acc: 0.6143 - val_loss: 56.6560 - val_acc: 0.5426\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 55.1345 - acc: 0.6256 - val_loss: 53.5146 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 52.0635 - acc: 0.6276 - val_loss: 50.5539 - val_acc: 0.5435\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 49.1516 - acc: 0.6310 - val_loss: 47.7360 - val_acc: 0.5534\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 46.3901 - acc: 0.6448 - val_loss: 45.0949 - val_acc: 0.5525\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 43.7944 - acc: 0.6405 - val_loss: 42.5915 - val_acc: 0.5553\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 41.3398 - acc: 0.6466 - val_loss: 40.2401 - val_acc: 0.5553\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 39.0202 - acc: 0.6556 - val_loss: 37.9971 - val_acc: 0.5580\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 36.8390 - acc: 0.6560 - val_loss: 35.9041 - val_acc: 0.5571\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 34.7713 - acc: 0.6590 - val_loss: 33.9010 - val_acc: 0.5598\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 32.8292 - acc: 0.6629 - val_loss: 32.0759 - val_acc: 0.5444\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 30.9998 - acc: 0.6658 - val_loss: 30.2796 - val_acc: 0.5598\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 29.2783 - acc: 0.6641 - val_loss: 28.6382 - val_acc: 0.5471\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 27.6486 - acc: 0.6684 - val_loss: 27.0774 - val_acc: 0.5589\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 26.1055 - acc: 0.6797 - val_loss: 25.6070 - val_acc: 0.5471\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 24.6574 - acc: 0.6849 - val_loss: 24.2652 - val_acc: 0.5380\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 23.3014 - acc: 0.6886 - val_loss: 22.9568 - val_acc: 0.5462\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 22.0210 - acc: 0.6849 - val_loss: 21.7370 - val_acc: 0.5308\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 20.8190 - acc: 0.6934 - val_loss: 20.5612 - val_acc: 0.5480\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 19.6939 - acc: 0.6950 - val_loss: 19.4843 - val_acc: 0.5408\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 28.9208 - acc: 0.3199 - val_loss: 25.4985 - val_acc: 0.4112\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 22.9937 - acc: 0.4926 - val_loss: 19.8235 - val_acc: 0.4982\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 17.4975 - acc: 0.5609 - val_loss: 14.8518 - val_acc: 0.5036\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 12.9708 - acc: 0.5857 - val_loss: 11.1128 - val_acc: 0.5100\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 9.6624 - acc: 0.6022 - val_loss: 8.5116 - val_acc: 0.4973\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 475us/step - loss: 7.4247 - acc: 0.5952 - val_loss: 6.6601 - val_acc: 0.5299\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 5.8349 - acc: 0.6113 - val_loss: 5.4194 - val_acc: 0.5163\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 4.7549 - acc: 0.6090 - val_loss: 4.5741 - val_acc: 0.5154\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 4.0400 - acc: 0.6026 - val_loss: 3.9466 - val_acc: 0.5163\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 3.4582 - acc: 0.6182 - val_loss: 3.4671 - val_acc: 0.4991\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 3.0606 - acc: 0.6198 - val_loss: 3.1927 - val_acc: 0.5009\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 2.7513 - acc: 0.6229 - val_loss: 2.9076 - val_acc: 0.5272\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.4943 - acc: 0.6351 - val_loss: 2.7193 - val_acc: 0.5208\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.3176 - acc: 0.6370 - val_loss: 2.5136 - val_acc: 0.5326\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 2.2405 - acc: 0.6101 - val_loss: 2.4918 - val_acc: 0.5109\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 2.0859 - acc: 0.6327 - val_loss: 2.4145 - val_acc: 0.5100\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.9306 - acc: 0.6508 - val_loss: 2.2661 - val_acc: 0.5154\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 1.8527 - acc: 0.6497 - val_loss: 2.2981 - val_acc: 0.4810\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 475us/step - loss: 1.8034 - acc: 0.6482 - val_loss: 2.1751 - val_acc: 0.5154\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 1.7705 - acc: 0.6339 - val_loss: 2.3164 - val_acc: 0.4900\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.7534 - acc: 0.6453 - val_loss: 2.0395 - val_acc: 0.5317\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.6507 - acc: 0.6579 - val_loss: 2.0069 - val_acc: 0.5444\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 1.5964 - acc: 0.6610 - val_loss: 2.0427 - val_acc: 0.5317\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 1.6139 - acc: 0.6465 - val_loss: 2.0211 - val_acc: 0.5308\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 1.5559 - acc: 0.6644 - val_loss: 1.9831 - val_acc: 0.5317\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 1.4553 - acc: 0.6946 - val_loss: 1.8748 - val_acc: 0.5435\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 1.3995 - acc: 0.7025 - val_loss: 2.0273 - val_acc: 0.4937\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 1.4815 - acc: 0.6676 - val_loss: 2.0959 - val_acc: 0.4946\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 1.4988 - acc: 0.6672 - val_loss: 1.9249 - val_acc: 0.5453\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 1.4338 - acc: 0.6895 - val_loss: 1.9053 - val_acc: 0.5399\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: 1.4195 - acc: 0.6830 - val_loss: 2.1240 - val_acc: 0.4565\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 1.4408 - acc: 0.6649 - val_loss: 1.8704 - val_acc: 0.5562\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 1.3804 - acc: 0.6932 - val_loss: 1.9826 - val_acc: 0.5172\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 1.3733 - acc: 0.6905 - val_loss: 1.8549 - val_acc: 0.5444\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 1.3162 - acc: 0.7117 - val_loss: 2.0283 - val_acc: 0.5127\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 1.3242 - acc: 0.7081 - val_loss: 2.0699 - val_acc: 0.4928\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.3430 - acc: 0.6974 - val_loss: 1.9328 - val_acc: 0.5507\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 4s 479us/step - loss: 1.3298 - acc: 0.7123 - val_loss: 2.4639 - val_acc: 0.4520\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.6244 - acc: 0.6169 - val_loss: 1.9799 - val_acc: 0.5344\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.4661 - acc: 0.6864 - val_loss: 1.9943 - val_acc: 0.5362\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.3686 - acc: 0.7146 - val_loss: 2.0415 - val_acc: 0.5226\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.3146 - acc: 0.7245 - val_loss: 1.9881 - val_acc: 0.5254\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 19s 2ms/step - loss: nan - acc: 0.0697 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 440us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 436us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 471us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 463us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 430us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 444us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 26.4368 - acc: 0.3533 - val_loss: 24.1572 - val_acc: 0.4339\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 22.4961 - acc: 0.5080 - val_loss: 20.4171 - val_acc: 0.5254\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 18.7606 - acc: 0.5697 - val_loss: 16.9197 - val_acc: 0.5317\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 15.3859 - acc: 0.5973 - val_loss: 13.8754 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 12.5453 - acc: 0.6182 - val_loss: 11.3923 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 10.2722 - acc: 0.6287 - val_loss: 9.4281 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 8.4589 - acc: 0.6402 - val_loss: 7.8769 - val_acc: 0.5326\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 7.0318 - acc: 0.6534 - val_loss: 6.6868 - val_acc: 0.5317\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 5.9474 - acc: 0.6575 - val_loss: 5.7357 - val_acc: 0.5199\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 5.0782 - acc: 0.6617 - val_loss: 5.0703 - val_acc: 0.5272\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 4.4476 - acc: 0.6455 - val_loss: 4.4789 - val_acc: 0.5389\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 3.8826 - acc: 0.6662 - val_loss: 4.0168 - val_acc: 0.5453\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 470us/step - loss: 3.4568 - acc: 0.6766 - val_loss: 3.6676 - val_acc: 0.5236\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 3.1099 - acc: 0.6851 - val_loss: 3.4133 - val_acc: 0.5263\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 2.8360 - acc: 0.6798 - val_loss: 3.2048 - val_acc: 0.5181\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 2.6093 - acc: 0.6859 - val_loss: 2.9880 - val_acc: 0.5389\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 2.4160 - acc: 0.6899 - val_loss: 2.7981 - val_acc: 0.5335\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 2.2834 - acc: 0.6874 - val_loss: 2.7408 - val_acc: 0.5263\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 2.1862 - acc: 0.6813 - val_loss: 2.7134 - val_acc: 0.5054\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 2.0823 - acc: 0.6894 - val_loss: 2.4773 - val_acc: 0.5335\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 1.9590 - acc: 0.7102 - val_loss: 2.5723 - val_acc: 0.5009\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.8950 - acc: 0.7038 - val_loss: 2.4431 - val_acc: 0.5389\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 2.4416 - acc: 0.4100 - val_loss: 2.1808 - val_acc: 0.4746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0567 - acc: 0.4942 - val_loss: 2.0370 - val_acc: 0.4991\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9705 - acc: 0.5287 - val_loss: 2.0633 - val_acc: 0.4900\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9079 - acc: 0.5481 - val_loss: 1.9947 - val_acc: 0.5136\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8533 - acc: 0.5668 - val_loss: 2.0039 - val_acc: 0.5236\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8095 - acc: 0.5766 - val_loss: 1.9512 - val_acc: 0.5100\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7927 - acc: 0.5783 - val_loss: 1.9677 - val_acc: 0.5208\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7521 - acc: 0.5992 - val_loss: 1.9918 - val_acc: 0.5136\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7546 - acc: 0.6081 - val_loss: 2.0128 - val_acc: 0.5263\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7365 - acc: 0.6107 - val_loss: 1.9954 - val_acc: 0.5290\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7122 - acc: 0.6229 - val_loss: 1.9725 - val_acc: 0.5399\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7130 - acc: 0.6346 - val_loss: 2.0022 - val_acc: 0.5516\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7115 - acc: 0.6367 - val_loss: 2.0105 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7019 - acc: 0.6434 - val_loss: 2.0168 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7105 - acc: 0.6504 - val_loss: 2.0604 - val_acc: 0.5489\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6896 - acc: 0.6661 - val_loss: 2.1111 - val_acc: 0.5417\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7074 - acc: 0.6638 - val_loss: 2.1032 - val_acc: 0.5371\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7189 - acc: 0.6687 - val_loss: 2.1978 - val_acc: 0.5444\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7215 - acc: 0.6758 - val_loss: 2.2195 - val_acc: 0.5435\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7504 - acc: 0.6777 - val_loss: 2.1857 - val_acc: 0.5580\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7724 - acc: 0.6771 - val_loss: 2.2600 - val_acc: 0.5426\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7569 - acc: 0.6875 - val_loss: 2.2554 - val_acc: 0.5480\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7517 - acc: 0.7000 - val_loss: 2.2940 - val_acc: 0.5534\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7579 - acc: 0.7033 - val_loss: 2.4043 - val_acc: 0.5525\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7794 - acc: 0.7068 - val_loss: 2.3977 - val_acc: 0.5516\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7782 - acc: 0.7146 - val_loss: 2.3245 - val_acc: 0.5553\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8052 - acc: 0.7159 - val_loss: 2.4827 - val_acc: 0.5362\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8181 - acc: 0.7183 - val_loss: 2.4819 - val_acc: 0.5435\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8533 - acc: 0.7086 - val_loss: 2.5395 - val_acc: 0.5263\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8461 - acc: 0.7214 - val_loss: 2.5609 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 20s 2ms/step - loss: 26.9305 - acc: 0.3460 - val_loss: 24.3068 - val_acc: 0.4411\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 22.3397 - acc: 0.5100 - val_loss: 19.8992 - val_acc: 0.4810\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 17.8915 - acc: 0.5702 - val_loss: 15.7669 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 14.0531 - acc: 0.5892 - val_loss: 12.4006 - val_acc: 0.5254\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 10.9836 - acc: 0.6258 - val_loss: 9.8753 - val_acc: 0.5217\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 8.7596 - acc: 0.6140 - val_loss: 8.0779 - val_acc: 0.5236\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 7.0745 - acc: 0.6239 - val_loss: 6.6462 - val_acc: 0.5118\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 5.8296 - acc: 0.6388 - val_loss: 5.5499 - val_acc: 0.5263\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 4.9020 - acc: 0.6441 - val_loss: 4.8264 - val_acc: 0.5226\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 4.1678 - acc: 0.6561 - val_loss: 4.1913 - val_acc: 0.5299\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 3.6403 - acc: 0.6560 - val_loss: 3.7396 - val_acc: 0.5290\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 3.2161 - acc: 0.6596 - val_loss: 3.3665 - val_acc: 0.5399\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 2.9117 - acc: 0.6633 - val_loss: 3.2039 - val_acc: 0.5118\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 2.7497 - acc: 0.6318 - val_loss: 2.9661 - val_acc: 0.5272\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 2.4990 - acc: 0.6567 - val_loss: 2.7860 - val_acc: 0.5299\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.2732 - acc: 0.6875 - val_loss: 2.6760 - val_acc: 0.5018\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 2.1344 - acc: 0.6818 - val_loss: 2.5295 - val_acc: 0.5317\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.0255 - acc: 0.6767 - val_loss: 2.5203 - val_acc: 0.4955\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 1.9753 - acc: 0.6660 - val_loss: 2.3769 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 1.9070 - acc: 0.6642 - val_loss: 2.3331 - val_acc: 0.5326\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 1.7658 - acc: 0.6945 - val_loss: 2.2764 - val_acc: 0.5091\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 1.6739 - acc: 0.7103 - val_loss: 2.3461 - val_acc: 0.4873\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: 2.8153 - acc: 0.3889 - val_loss: 2.4562 - val_acc: 0.4493\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3553 - acc: 0.4800 - val_loss: 2.3684 - val_acc: 0.4746\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2615 - acc: 0.4944 - val_loss: 2.2348 - val_acc: 0.5045\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1739 - acc: 0.5134 - val_loss: 2.2544 - val_acc: 0.4882\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1033 - acc: 0.5312 - val_loss: 2.1827 - val_acc: 0.4909\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0307 - acc: 0.5412 - val_loss: 2.1458 - val_acc: 0.5145\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0250 - acc: 0.5398 - val_loss: 2.1579 - val_acc: 0.5100\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9775 - acc: 0.5584 - val_loss: 2.0888 - val_acc: 0.5136\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9600 - acc: 0.5579 - val_loss: 2.0723 - val_acc: 0.5136\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9510 - acc: 0.5651 - val_loss: 2.0924 - val_acc: 0.5000\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9268 - acc: 0.5698 - val_loss: 2.1044 - val_acc: 0.5226\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9158 - acc: 0.5807 - val_loss: 2.1346 - val_acc: 0.5054\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9424 - acc: 0.5783 - val_loss: 2.1899 - val_acc: 0.5226\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9646 - acc: 0.5747 - val_loss: 2.2257 - val_acc: 0.5063\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9923 - acc: 0.5778 - val_loss: 2.2624 - val_acc: 0.4991\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9640 - acc: 0.5943 - val_loss: 2.1191 - val_acc: 0.5607\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9716 - acc: 0.6006 - val_loss: 2.1841 - val_acc: 0.5272\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9984 - acc: 0.5951 - val_loss: 2.2470 - val_acc: 0.5136\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9936 - acc: 0.5899 - val_loss: 2.1760 - val_acc: 0.5344\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0088 - acc: 0.6014 - val_loss: 2.2190 - val_acc: 0.5507\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0049 - acc: 0.6051 - val_loss: 2.2978 - val_acc: 0.5181\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0227 - acc: 0.6018 - val_loss: 2.3029 - val_acc: 0.5389\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0369 - acc: 0.6111 - val_loss: 2.3523 - val_acc: 0.5027\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0430 - acc: 0.6073 - val_loss: 2.2860 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0405 - acc: 0.6130 - val_loss: 2.3809 - val_acc: 0.5118\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0750 - acc: 0.6182 - val_loss: 2.3391 - val_acc: 0.5389\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 27s 3ms/step - loss: nan - acc: 0.0685 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 2.8379 - acc: 0.3901 - val_loss: 2.4873 - val_acc: 0.4438\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3933 - acc: 0.4875 - val_loss: 2.3257 - val_acc: 0.4665\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3027 - acc: 0.5091 - val_loss: 2.3344 - val_acc: 0.4928\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1991 - acc: 0.5309 - val_loss: 2.2194 - val_acc: 0.5190\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1773 - acc: 0.5382 - val_loss: 2.2955 - val_acc: 0.5181\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1284 - acc: 0.5506 - val_loss: 2.2719 - val_acc: 0.5054\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1190 - acc: 0.5576 - val_loss: 2.2603 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0533 - acc: 0.5630 - val_loss: 2.1700 - val_acc: 0.5226\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0571 - acc: 0.5638 - val_loss: 2.2108 - val_acc: 0.5190\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0373 - acc: 0.5755 - val_loss: 2.2047 - val_acc: 0.5281\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9835 - acc: 0.5930 - val_loss: 2.2181 - val_acc: 0.5399\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9654 - acc: 0.6031 - val_loss: 2.1832 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9935 - acc: 0.6000 - val_loss: 2.2291 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9870 - acc: 0.5959 - val_loss: 2.2812 - val_acc: 0.5181\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0050 - acc: 0.5973 - val_loss: 2.2366 - val_acc: 0.5290\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9812 - acc: 0.6145 - val_loss: 2.2702 - val_acc: 0.5181\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9962 - acc: 0.6182 - val_loss: 2.2856 - val_acc: 0.5326\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0109 - acc: 0.6209 - val_loss: 2.2926 - val_acc: 0.5371\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0083 - acc: 0.6210 - val_loss: 2.2974 - val_acc: 0.5299\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9938 - acc: 0.6283 - val_loss: 2.2782 - val_acc: 0.5480\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0077 - acc: 0.6239 - val_loss: 2.3786 - val_acc: 0.5299\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0590 - acc: 0.6293 - val_loss: 2.4218 - val_acc: 0.5308\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0781 - acc: 0.6232 - val_loss: 2.5144 - val_acc: 0.5190\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 3.2760 - acc: 0.3741 - val_loss: 2.8270 - val_acc: 0.4312\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6815 - acc: 0.4608 - val_loss: 2.5909 - val_acc: 0.4547\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5557 - acc: 0.4852 - val_loss: 2.4626 - val_acc: 0.4973\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3950 - acc: 0.4997 - val_loss: 2.3911 - val_acc: 0.4837\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3023 - acc: 0.5091 - val_loss: 2.3003 - val_acc: 0.4900\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2337 - acc: 0.5157 - val_loss: 2.3850 - val_acc: 0.4737\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2086 - acc: 0.5224 - val_loss: 2.2410 - val_acc: 0.5072\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1515 - acc: 0.5274 - val_loss: 2.2163 - val_acc: 0.5245\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1749 - acc: 0.5203 - val_loss: 2.2490 - val_acc: 0.4982\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1380 - acc: 0.5419 - val_loss: 2.3010 - val_acc: 0.4710\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1994 - acc: 0.5310 - val_loss: 2.2654 - val_acc: 0.5263\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2192 - acc: 0.5301 - val_loss: 2.4195 - val_acc: 0.4864\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2294 - acc: 0.5423 - val_loss: 2.4530 - val_acc: 0.4565\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2540 - acc: 0.5355 - val_loss: 2.3030 - val_acc: 0.5208\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2399 - acc: 0.5411 - val_loss: 2.3640 - val_acc: 0.5036\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2227 - acc: 0.5519 - val_loss: 2.4090 - val_acc: 0.5018\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2272 - acc: 0.5520 - val_loss: 2.3034 - val_acc: 0.5317\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2382 - acc: 0.5542 - val_loss: 2.3307 - val_acc: 0.5100\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2514 - acc: 0.5539 - val_loss: 2.4243 - val_acc: 0.4928\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2093 - acc: 0.5601 - val_loss: 2.3363 - val_acc: 0.5091\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2569 - acc: 0.5467 - val_loss: 2.3619 - val_acc: 0.5236\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2691 - acc: 0.5511 - val_loss: 2.4619 - val_acc: 0.5127\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2555 - acc: 0.5596 - val_loss: 2.4033 - val_acc: 0.5109\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2622 - acc: 0.5537 - val_loss: 2.3909 - val_acc: 0.5172\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2562 - acc: 0.5638 - val_loss: 2.4603 - val_acc: 0.5118\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2897 - acc: 0.5621 - val_loss: 2.4838 - val_acc: 0.5172\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2651 - acc: 0.5668 - val_loss: 2.3549 - val_acc: 0.5335\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2431 - acc: 0.5702 - val_loss: 2.4486 - val_acc: 0.5000\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2703 - acc: 0.5646 - val_loss: 2.4036 - val_acc: 0.5435\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3057 - acc: 0.5695 - val_loss: 2.5001 - val_acc: 0.5145\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3526 - acc: 0.5617 - val_loss: 2.4803 - val_acc: 0.5453\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3328 - acc: 0.5724 - val_loss: 2.6374 - val_acc: 0.5154\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3507 - acc: 0.5718 - val_loss: 2.5578 - val_acc: 0.5154\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3270 - acc: 0.5767 - val_loss: 2.4894 - val_acc: 0.5299\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3536 - acc: 0.5677 - val_loss: 2.5379 - val_acc: 0.5172\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3206 - acc: 0.5855 - val_loss: 2.5648 - val_acc: 0.5181\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3374 - acc: 0.5861 - val_loss: 2.6234 - val_acc: 0.5091\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3364 - acc: 0.5770 - val_loss: 2.6047 - val_acc: 0.4909\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3235 - acc: 0.5822 - val_loss: 2.5220 - val_acc: 0.5290\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3284 - acc: 0.5868 - val_loss: 2.5254 - val_acc: 0.5326\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3032 - acc: 0.5882 - val_loss: 2.6266 - val_acc: 0.5100\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 2.4599 - acc: 0.4039 - val_loss: 2.1660 - val_acc: 0.4683\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0640 - acc: 0.5054 - val_loss: 2.0486 - val_acc: 0.4964\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9918 - acc: 0.5253 - val_loss: 2.0294 - val_acc: 0.5082\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9233 - acc: 0.5537 - val_loss: 2.0065 - val_acc: 0.5245\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8624 - acc: 0.5749 - val_loss: 2.0359 - val_acc: 0.5072\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8209 - acc: 0.5808 - val_loss: 1.9825 - val_acc: 0.5335\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7820 - acc: 0.6001 - val_loss: 1.9846 - val_acc: 0.5254\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7266 - acc: 0.6164 - val_loss: 1.9945 - val_acc: 0.5371\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7054 - acc: 0.6254 - val_loss: 2.0242 - val_acc: 0.5226\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6984 - acc: 0.6276 - val_loss: 2.0224 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6537 - acc: 0.6472 - val_loss: 2.1051 - val_acc: 0.5362\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6243 - acc: 0.6629 - val_loss: 2.0645 - val_acc: 0.5254\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6120 - acc: 0.6679 - val_loss: 2.0600 - val_acc: 0.5335\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6004 - acc: 0.6820 - val_loss: 2.1057 - val_acc: 0.5254\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5981 - acc: 0.6800 - val_loss: 2.0792 - val_acc: 0.5417\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5722 - acc: 0.6941 - val_loss: 2.0471 - val_acc: 0.5707\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5404 - acc: 0.7174 - val_loss: 2.1350 - val_acc: 0.5426\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5385 - acc: 0.7140 - val_loss: 2.1409 - val_acc: 0.5507\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5574 - acc: 0.7180 - val_loss: 2.1511 - val_acc: 0.5516\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5687 - acc: 0.7219 - val_loss: 2.1911 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5366 - acc: 0.7420 - val_loss: 2.1841 - val_acc: 0.5571\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5133 - acc: 0.7479 - val_loss: 2.2082 - val_acc: 0.5507\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5299 - acc: 0.7472 - val_loss: 2.3058 - val_acc: 0.5462\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5505 - acc: 0.7505 - val_loss: 2.3214 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5257 - acc: 0.7629 - val_loss: 2.2941 - val_acc: 0.5498\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5376 - acc: 0.7658 - val_loss: 2.3093 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 3.1527 - acc: 0.3859 - val_loss: 2.8009 - val_acc: 0.4393\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6561 - acc: 0.4764 - val_loss: 2.6236 - val_acc: 0.4764\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4773 - acc: 0.5005 - val_loss: 2.4795 - val_acc: 0.5000\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3268 - acc: 0.5165 - val_loss: 2.3697 - val_acc: 0.4928\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2198 - acc: 0.5292 - val_loss: 2.3764 - val_acc: 0.4647\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1238 - acc: 0.5390 - val_loss: 2.1965 - val_acc: 0.4964\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0584 - acc: 0.5491 - val_loss: 2.1586 - val_acc: 0.5072\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9982 - acc: 0.5634 - val_loss: 2.0527 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9481 - acc: 0.5578 - val_loss: 2.0477 - val_acc: 0.5172\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8934 - acc: 0.5750 - val_loss: 2.0352 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8980 - acc: 0.5750 - val_loss: 2.0986 - val_acc: 0.5045\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8773 - acc: 0.5835 - val_loss: 2.1320 - val_acc: 0.5109\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8772 - acc: 0.5870 - val_loss: 2.0479 - val_acc: 0.5281\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8820 - acc: 0.5829 - val_loss: 2.0706 - val_acc: 0.5236\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8559 - acc: 0.5969 - val_loss: 2.1150 - val_acc: 0.5154\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8799 - acc: 0.5892 - val_loss: 2.0645 - val_acc: 0.5217\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8417 - acc: 0.6029 - val_loss: 2.0979 - val_acc: 0.5426\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8387 - acc: 0.5964 - val_loss: 2.0335 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8518 - acc: 0.6039 - val_loss: 2.1338 - val_acc: 0.5489\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8547 - acc: 0.6087 - val_loss: 2.0768 - val_acc: 0.5389\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8449 - acc: 0.6172 - val_loss: 2.1243 - val_acc: 0.5272\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8802 - acc: 0.6109 - val_loss: 2.1580 - val_acc: 0.5136\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8570 - acc: 0.6182 - val_loss: 2.1957 - val_acc: 0.5118\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9094 - acc: 0.6036 - val_loss: 2.1928 - val_acc: 0.5299\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8692 - acc: 0.6231 - val_loss: 2.2490 - val_acc: 0.5263\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8686 - acc: 0.6231 - val_loss: 2.1699 - val_acc: 0.5154\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8855 - acc: 0.6214 - val_loss: 2.1657 - val_acc: 0.5389\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8675 - acc: 0.6377 - val_loss: 2.2630 - val_acc: 0.5199\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9037 - acc: 0.6256 - val_loss: 2.2247 - val_acc: 0.5281\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 41.2856 - acc: 0.3269 - val_loss: 35.5613 - val_acc: 0.4375\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 475us/step - loss: 31.3769 - acc: 0.5021 - val_loss: 26.0760 - val_acc: 0.4882\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 22.4692 - acc: 0.5596 - val_loss: 18.3434 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 15.6765 - acc: 0.5846 - val_loss: 12.9105 - val_acc: 0.5190\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 11.0711 - acc: 0.5929 - val_loss: 9.3706 - val_acc: 0.4973\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 8.0601 - acc: 0.5958 - val_loss: 7.0302 - val_acc: 0.4946\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 6.1232 - acc: 0.5911 - val_loss: 5.5482 - val_acc: 0.5036\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 4.8348 - acc: 0.6010 - val_loss: 4.5158 - val_acc: 0.5190\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 3.9761 - acc: 0.5994 - val_loss: 3.9192 - val_acc: 0.5009\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 3.4135 - acc: 0.5874 - val_loss: 3.4805 - val_acc: 0.4529\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 3.0152 - acc: 0.5868 - val_loss: 3.0505 - val_acc: 0.5100\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 2.7353 - acc: 0.5923 - val_loss: 2.8349 - val_acc: 0.4846\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 2.4600 - acc: 0.6018 - val_loss: 2.6200 - val_acc: 0.5027\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 26s 3ms/step - loss: 109.1369 - acc: 0.4332 - val_loss: 99.6956 - val_acc: 0.5082\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 932us/step - loss: 91.6997 - acc: 0.5406 - val_loss: 83.5094 - val_acc: 0.5308\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 9s 985us/step - loss: 76.5222 - acc: 0.5761 - val_loss: 69.5818 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 9s 1ms/step - loss: 63.5926 - acc: 0.5980 - val_loss: 57.7733 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 9s 982us/step - loss: 52.7081 - acc: 0.6143 - val_loss: 47.9344 - val_acc: 0.5136\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 884us/step - loss: 43.6209 - acc: 0.6276 - val_loss: 39.7103 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 857us/step - loss: 36.0966 - acc: 0.6346 - val_loss: 32.9111 - val_acc: 0.5453\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 29.8800 - acc: 0.6433 - val_loss: 27.3247 - val_acc: 0.5453\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 934us/step - loss: 24.7646 - acc: 0.6464 - val_loss: 22.7213 - val_acc: 0.5444\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 904us/step - loss: 20.5905 - acc: 0.6487 - val_loss: 19.0186 - val_acc: 0.5299\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 17.1773 - acc: 0.6485 - val_loss: 15.9402 - val_acc: 0.5516\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 960us/step - loss: 14.3988 - acc: 0.6536 - val_loss: 13.4501 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 901us/step - loss: 12.1224 - acc: 0.6545 - val_loss: 11.4439 - val_acc: 0.5245\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 888us/step - loss: 10.2812 - acc: 0.6539 - val_loss: 9.8032 - val_acc: 0.5417\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 935us/step - loss: 8.7726 - acc: 0.6602 - val_loss: 8.4130 - val_acc: 0.5353\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 897us/step - loss: 7.5451 - acc: 0.6639 - val_loss: 7.3663 - val_acc: 0.5362\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 917us/step - loss: 6.5715 - acc: 0.6531 - val_loss: 6.4285 - val_acc: 0.5208\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 916us/step - loss: 5.7332 - acc: 0.6661 - val_loss: 5.6907 - val_acc: 0.5444\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 923us/step - loss: 5.0685 - acc: 0.6667 - val_loss: 5.1253 - val_acc: 0.5399\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 4.5397 - acc: 0.6668 - val_loss: 4.6364 - val_acc: 0.5308\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 867us/step - loss: 4.0604 - acc: 0.6846 - val_loss: 4.2381 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 2.8289 - acc: 0.4202 - val_loss: 2.4787 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4237 - acc: 0.5074 - val_loss: 2.4469 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3242 - acc: 0.5365 - val_loss: 2.3650 - val_acc: 0.4937\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2151 - acc: 0.5684 - val_loss: 2.3162 - val_acc: 0.5245\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1272 - acc: 0.5795 - val_loss: 2.2536 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0394 - acc: 0.5993 - val_loss: 2.2069 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9615 - acc: 0.6182 - val_loss: 2.2140 - val_acc: 0.5317\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8989 - acc: 0.6304 - val_loss: 2.1763 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8537 - acc: 0.6420 - val_loss: 2.2177 - val_acc: 0.5263\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8076 - acc: 0.6562 - val_loss: 2.1390 - val_acc: 0.5344\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7369 - acc: 0.6771 - val_loss: 2.1589 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6956 - acc: 0.6880 - val_loss: 2.2114 - val_acc: 0.5290\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6676 - acc: 0.6875 - val_loss: 2.1670 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6427 - acc: 0.7010 - val_loss: 2.1736 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5991 - acc: 0.7175 - val_loss: 2.1381 - val_acc: 0.5534\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5849 - acc: 0.7252 - val_loss: 2.1658 - val_acc: 0.5571\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5573 - acc: 0.7347 - val_loss: 2.1795 - val_acc: 0.5507\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5424 - acc: 0.7388 - val_loss: 2.2317 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 2.5851 - acc: 0.4162 - val_loss: 2.3407 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2084 - acc: 0.5108 - val_loss: 2.2348 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0905 - acc: 0.5483 - val_loss: 2.1592 - val_acc: 0.5208\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 2.0023 - acc: 0.5693 - val_loss: 2.1390 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.9405 - acc: 0.5928 - val_loss: 2.1663 - val_acc: 0.5335\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.8702 - acc: 0.6147 - val_loss: 2.1395 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.7936 - acc: 0.6389 - val_loss: 2.0587 - val_acc: 0.5525\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.7551 - acc: 0.6519 - val_loss: 2.0710 - val_acc: 0.5480\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.6882 - acc: 0.6677 - val_loss: 2.0718 - val_acc: 0.5543\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.6234 - acc: 0.6978 - val_loss: 2.1197 - val_acc: 0.5498\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.5948 - acc: 0.7049 - val_loss: 2.0873 - val_acc: 0.5553\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.5298 - acc: 0.7244 - val_loss: 2.0617 - val_acc: 0.5697\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.4839 - acc: 0.7419 - val_loss: 2.1302 - val_acc: 0.5426\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.4754 - acc: 0.7493 - val_loss: 2.1450 - val_acc: 0.5616\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.4378 - acc: 0.7632 - val_loss: 2.1334 - val_acc: 0.5661\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.3957 - acc: 0.7756 - val_loss: 2.1752 - val_acc: 0.5625\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.3605 - acc: 0.7915 - val_loss: 2.1540 - val_acc: 0.5634\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.3232 - acc: 0.8041 - val_loss: 2.1514 - val_acc: 0.5580\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.2771 - acc: 0.8253 - val_loss: 2.2378 - val_acc: 0.5697\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.2578 - acc: 0.8261 - val_loss: 2.2578 - val_acc: 0.5688\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.2417 - acc: 0.8369 - val_loss: 2.2614 - val_acc: 0.5553\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.2278 - acc: 0.8423 - val_loss: 2.3022 - val_acc: 0.5607\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.2112 - acc: 0.8457 - val_loss: 2.2951 - val_acc: 0.5661\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1865 - acc: 0.8574 - val_loss: 2.2921 - val_acc: 0.5607\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1779 - acc: 0.8583 - val_loss: 2.2897 - val_acc: 0.5616\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1398 - acc: 0.8722 - val_loss: 2.3907 - val_acc: 0.5688\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1407 - acc: 0.8758 - val_loss: 2.3238 - val_acc: 0.5761\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1219 - acc: 0.8862 - val_loss: 2.3662 - val_acc: 0.5670\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1246 - acc: 0.8798 - val_loss: 2.3475 - val_acc: 0.5725\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0998 - acc: 0.8942 - val_loss: 2.3762 - val_acc: 0.5752\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0907 - acc: 0.8950 - val_loss: 2.5193 - val_acc: 0.5562\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.1167 - acc: 0.8865 - val_loss: 2.3636 - val_acc: 0.5779\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0852 - acc: 0.8981 - val_loss: 2.3766 - val_acc: 0.5824\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0701 - acc: 0.9058 - val_loss: 2.4555 - val_acc: 0.5752\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0885 - acc: 0.8949 - val_loss: 2.4068 - val_acc: 0.5562\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0683 - acc: 0.9083 - val_loss: 2.4768 - val_acc: 0.5707\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0763 - acc: 0.9045 - val_loss: 2.5226 - val_acc: 0.5562\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0703 - acc: 0.9097 - val_loss: 2.4984 - val_acc: 0.5716\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0554 - acc: 0.9120 - val_loss: 2.5380 - val_acc: 0.5553\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0532 - acc: 0.9155 - val_loss: 2.5772 - val_acc: 0.5679\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0583 - acc: 0.9120 - val_loss: 2.5815 - val_acc: 0.5652\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0447 - acc: 0.9166 - val_loss: 2.4911 - val_acc: 0.5797\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.0304 - acc: 0.9223 - val_loss: 2.5610 - val_acc: 0.5661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 2.5976 - acc: 0.4288 - val_loss: 2.2826 - val_acc: 0.5045\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1883 - acc: 0.5268 - val_loss: 2.2214 - val_acc: 0.5163\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0471 - acc: 0.5733 - val_loss: 2.2038 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.9297 - acc: 0.6086 - val_loss: 2.1667 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8486 - acc: 0.6310 - val_loss: 2.1412 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.7625 - acc: 0.6568 - val_loss: 2.1434 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6688 - acc: 0.6928 - val_loss: 2.1556 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 1.6039 - acc: 0.7070 - val_loss: 2.1756 - val_acc: 0.5453\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5226 - acc: 0.7325 - val_loss: 2.1160 - val_acc: 0.5516\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4238 - acc: 0.7735 - val_loss: 2.1241 - val_acc: 0.5679\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3577 - acc: 0.7907 - val_loss: 2.1541 - val_acc: 0.5417\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3317 - acc: 0.7983 - val_loss: 2.1261 - val_acc: 0.5462\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2736 - acc: 0.8193 - val_loss: 2.2723 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2102 - acc: 0.8400 - val_loss: 2.1945 - val_acc: 0.5516\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1786 - acc: 0.8540 - val_loss: 2.2980 - val_acc: 0.5408\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1548 - acc: 0.8568 - val_loss: 2.3584 - val_acc: 0.5299\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1052 - acc: 0.8795 - val_loss: 2.3256 - val_acc: 0.5598\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0712 - acc: 0.8855 - val_loss: 2.2843 - val_acc: 0.5652\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0656 - acc: 0.8836 - val_loss: 2.3697 - val_acc: 0.5598\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0537 - acc: 0.8906 - val_loss: 2.4131 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 16.5441 - acc: 0.3579 - val_loss: 15.3862 - val_acc: 0.4230\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 14.6375 - acc: 0.5055 - val_loss: 13.8228 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 13.0693 - acc: 0.5641 - val_loss: 12.3217 - val_acc: 0.5317\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 11.5261 - acc: 0.6072 - val_loss: 10.9711 - val_acc: 0.5236\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 10.1148 - acc: 0.6359 - val_loss: 9.7189 - val_acc: 0.5208\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 8.8710 - acc: 0.6559 - val_loss: 8.6062 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 7.8202 - acc: 0.6645 - val_loss: 7.5969 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 6.8619 - acc: 0.6880 - val_loss: 6.7953 - val_acc: 0.5553\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 6.0640 - acc: 0.7012 - val_loss: 6.0509 - val_acc: 0.5562\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 5.3757 - acc: 0.7177 - val_loss: 5.5163 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 4.8458 - acc: 0.7085 - val_loss: 5.1611 - val_acc: 0.5281\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 4.3887 - acc: 0.7100 - val_loss: 4.6825 - val_acc: 0.5281\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 3.9318 - acc: 0.7304 - val_loss: 4.2435 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 3.5497 - acc: 0.7530 - val_loss: 3.9441 - val_acc: 0.5571\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 3.2569 - acc: 0.7550 - val_loss: 3.7200 - val_acc: 0.5389\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 3.0046 - acc: 0.7560 - val_loss: 3.5233 - val_acc: 0.5335\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 2.8062 - acc: 0.7573 - val_loss: 3.4008 - val_acc: 0.5371\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 2.6193 - acc: 0.7551 - val_loss: 3.1268 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 2.4445 - acc: 0.7652 - val_loss: 2.9990 - val_acc: 0.5616\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 2.2760 - acc: 0.7798 - val_loss: 2.9654 - val_acc: 0.5380\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 2.1468 - acc: 0.7887 - val_loss: 2.8779 - val_acc: 0.5326\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.0445 - acc: 0.7922 - val_loss: 2.9220 - val_acc: 0.5136\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 1.9902 - acc: 0.7799 - val_loss: 2.7822 - val_acc: 0.5263\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 1.8756 - acc: 0.7998 - val_loss: 2.6879 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 1.7720 - acc: 0.8110 - val_loss: 2.5942 - val_acc: 0.5362\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 1.7260 - acc: 0.8035 - val_loss: 2.5293 - val_acc: 0.5553\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.6778 - acc: 0.8028 - val_loss: 2.5715 - val_acc: 0.5462\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 1.6268 - acc: 0.8116 - val_loss: 2.5289 - val_acc: 0.5389\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.5579 - acc: 0.8222 - val_loss: 2.4699 - val_acc: 0.5534\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 3.0048 - acc: 0.4178 - val_loss: 2.6908 - val_acc: 0.4801\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5962 - acc: 0.5240 - val_loss: 2.6022 - val_acc: 0.5136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4621 - acc: 0.5548 - val_loss: 2.5486 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3522 - acc: 0.5852 - val_loss: 2.4629 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2885 - acc: 0.5926 - val_loss: 2.5084 - val_acc: 0.5353\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1616 - acc: 0.6295 - val_loss: 2.4541 - val_acc: 0.5335\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0769 - acc: 0.6480 - val_loss: 2.4175 - val_acc: 0.5426\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0048 - acc: 0.6748 - val_loss: 2.4307 - val_acc: 0.5426\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9259 - acc: 0.6867 - val_loss: 2.3820 - val_acc: 0.5308\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8595 - acc: 0.7062 - val_loss: 2.3431 - val_acc: 0.5643\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7847 - acc: 0.7268 - val_loss: 2.3547 - val_acc: 0.5399\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7251 - acc: 0.7421 - val_loss: 2.3959 - val_acc: 0.5371\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6740 - acc: 0.7467 - val_loss: 2.3548 - val_acc: 0.5589\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6097 - acc: 0.7686 - val_loss: 2.3763 - val_acc: 0.5444\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5496 - acc: 0.7870 - val_loss: 2.3895 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5022 - acc: 0.8024 - val_loss: 2.3627 - val_acc: 0.5589\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4552 - acc: 0.8152 - val_loss: 2.3443 - val_acc: 0.5534\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4086 - acc: 0.8275 - val_loss: 2.3729 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3720 - acc: 0.8411 - val_loss: 2.4056 - val_acc: 0.5417\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3568 - acc: 0.8381 - val_loss: 2.3990 - val_acc: 0.5408\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: nan - acc: 0.0701 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 2.6547 - acc: 0.4178 - val_loss: 2.4040 - val_acc: 0.4683\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2867 - acc: 0.5079 - val_loss: 2.3368 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1365 - acc: 0.5557 - val_loss: 2.2449 - val_acc: 0.5091\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0648 - acc: 0.5713 - val_loss: 2.1577 - val_acc: 0.5362\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9785 - acc: 0.6027 - val_loss: 2.1820 - val_acc: 0.5362\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9255 - acc: 0.6182 - val_loss: 2.1740 - val_acc: 0.5208\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8414 - acc: 0.6420 - val_loss: 2.1468 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7913 - acc: 0.6552 - val_loss: 2.1880 - val_acc: 0.5344\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7436 - acc: 0.6698 - val_loss: 2.1410 - val_acc: 0.5598\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6695 - acc: 0.6955 - val_loss: 2.1685 - val_acc: 0.5507\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6400 - acc: 0.6987 - val_loss: 2.1732 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5908 - acc: 0.7233 - val_loss: 2.1625 - val_acc: 0.5471\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5360 - acc: 0.7330 - val_loss: 2.1822 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4911 - acc: 0.7488 - val_loss: 2.2371 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4443 - acc: 0.7671 - val_loss: 2.2539 - val_acc: 0.5353\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4198 - acc: 0.7739 - val_loss: 2.2190 - val_acc: 0.5453\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3710 - acc: 0.7994 - val_loss: 2.2522 - val_acc: 0.5489\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3613 - acc: 0.8003 - val_loss: 2.2922 - val_acc: 0.5580\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3533 - acc: 0.8051 - val_loss: 2.2207 - val_acc: 0.5616\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3245 - acc: 0.8133 - val_loss: 2.2311 - val_acc: 0.5516\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3012 - acc: 0.8255 - val_loss: 2.3765 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2942 - acc: 0.8342 - val_loss: 2.3487 - val_acc: 0.5679\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2634 - acc: 0.8411 - val_loss: 2.3518 - val_acc: 0.5670\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2562 - acc: 0.8509 - val_loss: 2.4953 - val_acc: 0.5380\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2494 - acc: 0.8508 - val_loss: 2.3823 - val_acc: 0.5553\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2318 - acc: 0.8600 - val_loss: 2.4445 - val_acc: 0.5498\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2397 - acc: 0.8557 - val_loss: 2.4491 - val_acc: 0.5543\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2445 - acc: 0.8590 - val_loss: 2.4657 - val_acc: 0.5489\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2130 - acc: 0.8714 - val_loss: 2.5090 - val_acc: 0.5634\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2142 - acc: 0.8762 - val_loss: 2.6271 - val_acc: 0.5489\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2307 - acc: 0.8710 - val_loss: 2.5475 - val_acc: 0.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2191 - acc: 0.8796 - val_loss: 2.5647 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 3.0965 - acc: 0.4272 - val_loss: 2.7851 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6535 - acc: 0.5220 - val_loss: 2.6525 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5077 - acc: 0.5519 - val_loss: 2.5488 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3304 - acc: 0.5947 - val_loss: 2.4834 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1984 - acc: 0.6197 - val_loss: 2.5010 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0992 - acc: 0.6408 - val_loss: 2.3643 - val_acc: 0.5507\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9884 - acc: 0.6612 - val_loss: 2.3642 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8882 - acc: 0.6795 - val_loss: 2.3957 - val_acc: 0.5299\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8032 - acc: 0.6972 - val_loss: 2.2575 - val_acc: 0.5317\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7003 - acc: 0.7232 - val_loss: 2.3202 - val_acc: 0.5679\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6653 - acc: 0.7227 - val_loss: 2.3150 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5714 - acc: 0.7591 - val_loss: 2.2093 - val_acc: 0.5462\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5183 - acc: 0.7667 - val_loss: 2.3235 - val_acc: 0.5353\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4547 - acc: 0.7838 - val_loss: 2.2275 - val_acc: 0.5498\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3903 - acc: 0.8056 - val_loss: 2.2504 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3677 - acc: 0.8095 - val_loss: 2.3349 - val_acc: 0.5399\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3403 - acc: 0.8203 - val_loss: 2.2816 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3083 - acc: 0.8301 - val_loss: 2.4091 - val_acc: 0.5263\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2850 - acc: 0.8342 - val_loss: 2.3594 - val_acc: 0.5480\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2929 - acc: 0.8371 - val_loss: 2.4131 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 3.3725 - acc: 0.4042 - val_loss: 3.0705 - val_acc: 0.4810\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9571 - acc: 0.5109 - val_loss: 2.9112 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7956 - acc: 0.5439 - val_loss: 2.8157 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6797 - acc: 0.5608 - val_loss: 2.7774 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5595 - acc: 0.5867 - val_loss: 2.5985 - val_acc: 0.5625\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4260 - acc: 0.6029 - val_loss: 2.6460 - val_acc: 0.5317\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3413 - acc: 0.6186 - val_loss: 2.5342 - val_acc: 0.5426\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2222 - acc: 0.6351 - val_loss: 2.5101 - val_acc: 0.5344\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1494 - acc: 0.6415 - val_loss: 2.4407 - val_acc: 0.5543\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0617 - acc: 0.6608 - val_loss: 2.4522 - val_acc: 0.5462\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9841 - acc: 0.6758 - val_loss: 2.4272 - val_acc: 0.5453\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9147 - acc: 0.6864 - val_loss: 2.3810 - val_acc: 0.5290\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8398 - acc: 0.7085 - val_loss: 2.3145 - val_acc: 0.5516\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8040 - acc: 0.7046 - val_loss: 2.3252 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7703 - acc: 0.7127 - val_loss: 2.2642 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 2.3424 - acc: 0.4152 - val_loss: 2.0536 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9687 - acc: 0.5061 - val_loss: 1.9903 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8568 - acc: 0.5414 - val_loss: 1.9353 - val_acc: 0.5172\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7907 - acc: 0.5684 - val_loss: 1.8871 - val_acc: 0.5254\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7130 - acc: 0.5921 - val_loss: 1.9237 - val_acc: 0.5100\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6859 - acc: 0.5984 - val_loss: 1.8408 - val_acc: 0.5335\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5918 - acc: 0.6361 - val_loss: 1.8670 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5698 - acc: 0.6448 - val_loss: 1.9304 - val_acc: 0.5435\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5248 - acc: 0.6647 - val_loss: 1.9034 - val_acc: 0.5516\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4920 - acc: 0.6758 - val_loss: 1.9251 - val_acc: 0.5462\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4435 - acc: 0.6958 - val_loss: 1.9610 - val_acc: 0.5199\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4020 - acc: 0.7106 - val_loss: 1.9420 - val_acc: 0.5399\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3778 - acc: 0.7255 - val_loss: 1.9572 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3329 - acc: 0.7398 - val_loss: 1.9688 - val_acc: 0.5399\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3098 - acc: 0.7456 - val_loss: 1.9990 - val_acc: 0.5553\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2843 - acc: 0.7641 - val_loss: 2.0398 - val_acc: 0.5462\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2849 - acc: 0.7678 - val_loss: 2.0257 - val_acc: 0.5344\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2403 - acc: 0.7828 - val_loss: 2.0026 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2114 - acc: 0.7991 - val_loss: 2.0281 - val_acc: 0.5670\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2051 - acc: 0.8067 - val_loss: 2.1330 - val_acc: 0.5462\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1788 - acc: 0.8150 - val_loss: 2.1326 - val_acc: 0.5553\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1573 - acc: 0.8281 - val_loss: 2.1000 - val_acc: 0.5643\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1431 - acc: 0.8354 - val_loss: 2.1982 - val_acc: 0.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1579 - acc: 0.8291 - val_loss: 2.2127 - val_acc: 0.5380\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1307 - acc: 0.8461 - val_loss: 2.1970 - val_acc: 0.5661\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1068 - acc: 0.8585 - val_loss: 2.2328 - val_acc: 0.5598\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1028 - acc: 0.8626 - val_loss: 2.2384 - val_acc: 0.5553\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1060 - acc: 0.8640 - val_loss: 2.3019 - val_acc: 0.5389\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1160 - acc: 0.8563 - val_loss: 2.3044 - val_acc: 0.5543\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 57.6121 - acc: 0.3943 - val_loss: 54.6539 - val_acc: 0.4846\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 9s 969us/step - loss: 52.1020 - acc: 0.5066 - val_loss: 49.4558 - val_acc: 0.5009\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 8s 891us/step - loss: 47.0329 - acc: 0.5329 - val_loss: 44.6275 - val_acc: 0.5190\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 8s 956us/step - loss: 42.3762 - acc: 0.5493 - val_loss: 40.1753 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 8s 937us/step - loss: 38.1036 - acc: 0.5735 - val_loss: 36.1202 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 8s 931us/step - loss: 34.2292 - acc: 0.5893 - val_loss: 32.4831 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 8s 943us/step - loss: 30.7220 - acc: 0.6035 - val_loss: 29.1817 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 8s 917us/step - loss: 27.5496 - acc: 0.6057 - val_loss: 26.1905 - val_acc: 0.5607\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 8s 919us/step - loss: 24.6966 - acc: 0.6254 - val_loss: 23.5314 - val_acc: 0.5480\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 8s 945us/step - loss: 22.1606 - acc: 0.6287 - val_loss: 21.1679 - val_acc: 0.5399\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 9s 978us/step - loss: 19.8784 - acc: 0.6414 - val_loss: 19.0037 - val_acc: 0.5562\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 17.8507 - acc: 0.6402 - val_loss: 17.1158 - val_acc: 0.5553\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 8s 939us/step - loss: 16.0340 - acc: 0.6549 - val_loss: 15.4376 - val_acc: 0.5516\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 8s 902us/step - loss: 14.4247 - acc: 0.6572 - val_loss: 13.9350 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 8s 950us/step - loss: 13.0011 - acc: 0.6610 - val_loss: 12.5863 - val_acc: 0.5580\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 8s 906us/step - loss: 11.7353 - acc: 0.6675 - val_loss: 11.4358 - val_acc: 0.5607\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 8s 936us/step - loss: 10.6223 - acc: 0.6714 - val_loss: 10.3719 - val_acc: 0.5716\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 8s 914us/step - loss: 9.6258 - acc: 0.6786 - val_loss: 9.4707 - val_acc: 0.5634\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 916us/step - loss: 8.7461 - acc: 0.6798 - val_loss: 8.6620 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 869us/step - loss: 7.9494 - acc: 0.6886 - val_loss: 7.9570 - val_acc: 0.5598\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 8s 900us/step - loss: 7.2788 - acc: 0.6869 - val_loss: 7.3463 - val_acc: 0.5480\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 9s 970us/step - loss: 6.6655 - acc: 0.6938 - val_loss: 6.7399 - val_acc: 0.5534\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 8s 941us/step - loss: 6.1269 - acc: 0.6952 - val_loss: 6.3017 - val_acc: 0.5408\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 8s 930us/step - loss: 5.6435 - acc: 0.7053 - val_loss: 5.8054 - val_acc: 0.5697\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 9s 997us/step - loss: 5.2292 - acc: 0.7033 - val_loss: 5.4648 - val_acc: 0.5589\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 8s 899us/step - loss: 4.8436 - acc: 0.7074 - val_loss: 5.1599 - val_acc: 0.5580\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 8s 915us/step - loss: 4.5134 - acc: 0.7086 - val_loss: 4.8085 - val_acc: 0.5679\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: 3.9104 - acc: 0.4345 - val_loss: 3.6670 - val_acc: 0.4891\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.4380 - acc: 0.5321 - val_loss: 3.4688 - val_acc: 0.5208\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2300 - acc: 0.5665 - val_loss: 3.3558 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0598 - acc: 0.5857 - val_loss: 3.1637 - val_acc: 0.5335\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8386 - acc: 0.6250 - val_loss: 3.0882 - val_acc: 0.5344\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6712 - acc: 0.6412 - val_loss: 2.9359 - val_acc: 0.5245\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5212 - acc: 0.6626 - val_loss: 2.8567 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3536 - acc: 0.6925 - val_loss: 2.7474 - val_acc: 0.5525\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2318 - acc: 0.7035 - val_loss: 2.6853 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1008 - acc: 0.7261 - val_loss: 2.6502 - val_acc: 0.5498\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9880 - acc: 0.7465 - val_loss: 2.5933 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8732 - acc: 0.7640 - val_loss: 2.5249 - val_acc: 0.5471\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7790 - acc: 0.7783 - val_loss: 2.4924 - val_acc: 0.5580\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6791 - acc: 0.7971 - val_loss: 2.4926 - val_acc: 0.5534\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6188 - acc: 0.8036 - val_loss: 2.4923 - val_acc: 0.5453\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5568 - acc: 0.8172 - val_loss: 2.4986 - val_acc: 0.5507\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4995 - acc: 0.8229 - val_loss: 2.4497 - val_acc: 0.5589\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4269 - acc: 0.8422 - val_loss: 2.4801 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3942 - acc: 0.8422 - val_loss: 2.5213 - val_acc: 0.5426\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3546 - acc: 0.8556 - val_loss: 2.5126 - val_acc: 0.5444\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3237 - acc: 0.8607 - val_loss: 2.4720 - val_acc: 0.5498\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2812 - acc: 0.8696 - val_loss: 2.4331 - val_acc: 0.5607\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2533 - acc: 0.8741 - val_loss: 2.5285 - val_acc: 0.5399\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2376 - acc: 0.8759 - val_loss: 2.5173 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2221 - acc: 0.8801 - val_loss: 2.4999 - val_acc: 0.5417\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2077 - acc: 0.8841 - val_loss: 2.5427 - val_acc: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1532 - acc: 0.8983 - val_loss: 2.4699 - val_acc: 0.5543\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1810 - acc: 0.8875 - val_loss: 2.5758 - val_acc: 0.5453\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1456 - acc: 0.8964 - val_loss: 2.5487 - val_acc: 0.5462\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1109 - acc: 0.9046 - val_loss: 2.5493 - val_acc: 0.5589\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1201 - acc: 0.8991 - val_loss: 2.5985 - val_acc: 0.5580\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1149 - acc: 0.9023 - val_loss: 2.5398 - val_acc: 0.5326\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 4.1495 - acc: 0.4298 - val_loss: 3.7226 - val_acc: 0.5109\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5300 - acc: 0.5170 - val_loss: 3.4758 - val_acc: 0.4638\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1879 - acc: 0.5396 - val_loss: 3.0823 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8383 - acc: 0.5676 - val_loss: 2.9039 - val_acc: 0.5226\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5714 - acc: 0.5832 - val_loss: 2.6766 - val_acc: 0.5154\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3662 - acc: 0.5932 - val_loss: 2.5581 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2172 - acc: 0.5960 - val_loss: 2.4168 - val_acc: 0.5181\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0465 - acc: 0.6190 - val_loss: 2.3438 - val_acc: 0.5353\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9304 - acc: 0.6310 - val_loss: 2.2326 - val_acc: 0.5190\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8582 - acc: 0.6337 - val_loss: 2.1548 - val_acc: 0.5371\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7933 - acc: 0.6382 - val_loss: 2.1699 - val_acc: 0.5109\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7452 - acc: 0.6428 - val_loss: 2.0890 - val_acc: 0.5344\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7295 - acc: 0.6475 - val_loss: 2.0596 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6416 - acc: 0.6676 - val_loss: 2.0630 - val_acc: 0.5344\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6157 - acc: 0.6712 - val_loss: 2.0754 - val_acc: 0.5380\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6167 - acc: 0.6724 - val_loss: 2.0763 - val_acc: 0.5598\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6026 - acc: 0.6736 - val_loss: 2.0369 - val_acc: 0.5471\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5729 - acc: 0.6847 - val_loss: 2.1041 - val_acc: 0.5399\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5921 - acc: 0.6852 - val_loss: 2.0711 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5594 - acc: 0.6927 - val_loss: 2.0219 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5243 - acc: 0.7044 - val_loss: 2.1609 - val_acc: 0.5371\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5622 - acc: 0.6950 - val_loss: 2.0510 - val_acc: 0.5516\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5269 - acc: 0.7144 - val_loss: 2.0815 - val_acc: 0.5380\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5664 - acc: 0.6974 - val_loss: 2.1469 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5738 - acc: 0.6969 - val_loss: 2.1448 - val_acc: 0.5462\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5523 - acc: 0.7090 - val_loss: 2.1459 - val_acc: 0.5580\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 3.8932 - acc: 0.4373 - val_loss: 3.5541 - val_acc: 0.4774\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3505 - acc: 0.5302 - val_loss: 3.2590 - val_acc: 0.5236\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0291 - acc: 0.5718 - val_loss: 3.1563 - val_acc: 0.5036\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7809 - acc: 0.6089 - val_loss: 2.9101 - val_acc: 0.5254\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5594 - acc: 0.6174 - val_loss: 2.7785 - val_acc: 0.5172\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3151 - acc: 0.6549 - val_loss: 2.6343 - val_acc: 0.5562\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1433 - acc: 0.6686 - val_loss: 2.5095 - val_acc: 0.5435\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9931 - acc: 0.6925 - val_loss: 2.3924 - val_acc: 0.5471\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8551 - acc: 0.7068 - val_loss: 2.3767 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7313 - acc: 0.7326 - val_loss: 2.3885 - val_acc: 0.5353\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6308 - acc: 0.7488 - val_loss: 2.3359 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5295 - acc: 0.7684 - val_loss: 2.3382 - val_acc: 0.5208\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4377 - acc: 0.7841 - val_loss: 2.3560 - val_acc: 0.5498\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4245 - acc: 0.7777 - val_loss: 2.3099 - val_acc: 0.5290\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3613 - acc: 0.7964 - val_loss: 2.2372 - val_acc: 0.5453\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3234 - acc: 0.8053 - val_loss: 2.3048 - val_acc: 0.5245\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 5.1678 - acc: 0.4318 - val_loss: 4.7819 - val_acc: 0.4547\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.4294 - acc: 0.5335 - val_loss: 4.2379 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.9137 - acc: 0.5627 - val_loss: 3.8166 - val_acc: 0.5245\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.4743 - acc: 0.5808 - val_loss: 3.5259 - val_acc: 0.5027\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0961 - acc: 0.6002 - val_loss: 3.1699 - val_acc: 0.5344\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7565 - acc: 0.6195 - val_loss: 2.8909 - val_acc: 0.5380\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4867 - acc: 0.6421 - val_loss: 2.6514 - val_acc: 0.5453\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2707 - acc: 0.6549 - val_loss: 2.5480 - val_acc: 0.5371\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1049 - acc: 0.6629 - val_loss: 2.4691 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9482 - acc: 0.6808 - val_loss: 2.3689 - val_acc: 0.5290\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8122 - acc: 0.6918 - val_loss: 2.3793 - val_acc: 0.5344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7555 - acc: 0.6861 - val_loss: 2.2292 - val_acc: 0.5480\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6676 - acc: 0.6996 - val_loss: 2.2374 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6052 - acc: 0.7127 - val_loss: 2.1413 - val_acc: 0.5317\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5256 - acc: 0.7281 - val_loss: 2.1583 - val_acc: 0.5480\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4983 - acc: 0.7326 - val_loss: 2.1924 - val_acc: 0.5272\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5114 - acc: 0.7204 - val_loss: 2.2021 - val_acc: 0.5272\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4566 - acc: 0.7413 - val_loss: 2.1350 - val_acc: 0.5408\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4176 - acc: 0.7531 - val_loss: 2.1632 - val_acc: 0.5507\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4114 - acc: 0.7546 - val_loss: 2.2391 - val_acc: 0.5444\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3728 - acc: 0.7709 - val_loss: 2.0914 - val_acc: 0.5462\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3793 - acc: 0.7609 - val_loss: 2.1930 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3507 - acc: 0.7726 - val_loss: 2.2305 - val_acc: 0.5380\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3444 - acc: 0.7743 - val_loss: 2.2060 - val_acc: 0.5290\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3373 - acc: 0.7879 - val_loss: 2.2315 - val_acc: 0.5444\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3236 - acc: 0.7825 - val_loss: 2.2756 - val_acc: 0.5226\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3454 - acc: 0.7865 - val_loss: 2.1794 - val_acc: 0.5489\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3046 - acc: 0.8004 - val_loss: 2.1989 - val_acc: 0.5444\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2962 - acc: 0.7994 - val_loss: 2.1992 - val_acc: 0.5408\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: nan - acc: 0.0689 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 2.9152 - acc: 0.3368 - val_loss: 2.5335 - val_acc: 0.4420\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4935 - acc: 0.4508 - val_loss: 2.4665 - val_acc: 0.4674\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4439 - acc: 0.4567 - val_loss: 2.4259 - val_acc: 0.4466\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3656 - acc: 0.4891 - val_loss: 2.4628 - val_acc: 0.4592\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3406 - acc: 0.5054 - val_loss: 2.4156 - val_acc: 0.4855\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3383 - acc: 0.5108 - val_loss: 2.3974 - val_acc: 0.4846\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3117 - acc: 0.5134 - val_loss: 2.4959 - val_acc: 0.4810\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3371 - acc: 0.5242 - val_loss: 2.4201 - val_acc: 0.4955\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3640 - acc: 0.5373 - val_loss: 2.4846 - val_acc: 0.4991\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3725 - acc: 0.5368 - val_loss: 2.4917 - val_acc: 0.5054\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4063 - acc: 0.5303 - val_loss: 2.4843 - val_acc: 0.5045\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3855 - acc: 0.5432 - val_loss: 2.4777 - val_acc: 0.5263\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3983 - acc: 0.5439 - val_loss: 2.5535 - val_acc: 0.4909\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3861 - acc: 0.5571 - val_loss: 2.5638 - val_acc: 0.5036\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3987 - acc: 0.5530 - val_loss: 2.5256 - val_acc: 0.5181\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4236 - acc: 0.5568 - val_loss: 2.5443 - val_acc: 0.5136\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4487 - acc: 0.5479 - val_loss: 2.6581 - val_acc: 0.4819\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4500 - acc: 0.5602 - val_loss: 2.6025 - val_acc: 0.5009\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4470 - acc: 0.5601 - val_loss: 2.5248 - val_acc: 0.5036\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4607 - acc: 0.5594 - val_loss: 2.6173 - val_acc: 0.5063\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4899 - acc: 0.5636 - val_loss: 2.5972 - val_acc: 0.5226\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4914 - acc: 0.5571 - val_loss: 2.6187 - val_acc: 0.5426\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5262 - acc: 0.5659 - val_loss: 2.6616 - val_acc: 0.5226\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5290 - acc: 0.5676 - val_loss: 2.7190 - val_acc: 0.5091\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5233 - acc: 0.5728 - val_loss: 2.7534 - val_acc: 0.5226\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5475 - acc: 0.5655 - val_loss: 2.7441 - val_acc: 0.5054\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5438 - acc: 0.5691 - val_loss: 2.7767 - val_acc: 0.5036\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5776 - acc: 0.5682 - val_loss: 2.7428 - val_acc: 0.5245\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5692 - acc: 0.5768 - val_loss: 2.7776 - val_acc: 0.5245\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5625 - acc: 0.5833 - val_loss: 2.8682 - val_acc: 0.4918\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6376 - acc: 0.5653 - val_loss: 2.8037 - val_acc: 0.5163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6237 - acc: 0.5740 - val_loss: 2.8014 - val_acc: 0.5236\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 4.6733 - acc: 0.4147 - val_loss: 4.3322 - val_acc: 0.4583\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.0925 - acc: 0.5142 - val_loss: 4.0305 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.7388 - acc: 0.5437 - val_loss: 3.7721 - val_acc: 0.5172\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.4259 - acc: 0.5665 - val_loss: 3.3774 - val_acc: 0.5236\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1446 - acc: 0.5763 - val_loss: 3.1839 - val_acc: 0.5308\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8713 - acc: 0.6038 - val_loss: 2.9962 - val_acc: 0.5281\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6415 - acc: 0.6150 - val_loss: 2.7803 - val_acc: 0.5525\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4441 - acc: 0.6308 - val_loss: 2.6818 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2857 - acc: 0.6374 - val_loss: 2.5574 - val_acc: 0.5426\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1529 - acc: 0.6388 - val_loss: 2.5174 - val_acc: 0.5308\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0241 - acc: 0.6634 - val_loss: 2.3723 - val_acc: 0.5453\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9143 - acc: 0.6806 - val_loss: 2.3064 - val_acc: 0.5607\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8242 - acc: 0.6897 - val_loss: 2.2981 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7877 - acc: 0.6889 - val_loss: 2.2970 - val_acc: 0.5317\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7591 - acc: 0.6891 - val_loss: 2.2451 - val_acc: 0.5353\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7092 - acc: 0.6889 - val_loss: 2.1683 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6644 - acc: 0.7093 - val_loss: 2.2010 - val_acc: 0.5525\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6260 - acc: 0.7172 - val_loss: 2.2147 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6141 - acc: 0.7218 - val_loss: 2.1835 - val_acc: 0.5417\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6186 - acc: 0.7155 - val_loss: 2.1688 - val_acc: 0.5580\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5779 - acc: 0.7253 - val_loss: 2.1972 - val_acc: 0.5453\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5392 - acc: 0.7390 - val_loss: 2.1933 - val_acc: 0.5453\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 4.3315 - acc: 0.4473 - val_loss: 3.9965 - val_acc: 0.5082\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8018 - acc: 0.5571 - val_loss: 3.8281 - val_acc: 0.5254\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.5234 - acc: 0.5917 - val_loss: 3.6183 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2498 - acc: 0.6273 - val_loss: 3.4675 - val_acc: 0.5281\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0109 - acc: 0.6596 - val_loss: 3.4049 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7725 - acc: 0.6949 - val_loss: 3.1306 - val_acc: 0.5525\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5603 - acc: 0.7274 - val_loss: 3.0573 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3634 - acc: 0.7522 - val_loss: 2.9825 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2086 - acc: 0.7719 - val_loss: 2.9193 - val_acc: 0.5462\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0420 - acc: 0.8003 - val_loss: 2.7692 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8895 - acc: 0.8206 - val_loss: 2.7262 - val_acc: 0.5507\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7899 - acc: 0.8247 - val_loss: 2.7112 - val_acc: 0.5507\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6604 - acc: 0.8511 - val_loss: 2.6245 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5673 - acc: 0.8607 - val_loss: 2.5927 - val_acc: 0.5534\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4808 - acc: 0.8712 - val_loss: 2.6006 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4149 - acc: 0.8791 - val_loss: 2.6037 - val_acc: 0.5507\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3270 - acc: 0.8984 - val_loss: 2.5557 - val_acc: 0.5625\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2427 - acc: 0.9117 - val_loss: 2.5009 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2101 - acc: 0.9070 - val_loss: 2.5461 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1816 - acc: 0.9088 - val_loss: 2.5756 - val_acc: 0.5408\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1888 - acc: 0.8995 - val_loss: 2.5823 - val_acc: 0.5453\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1260 - acc: 0.9134 - val_loss: 2.5055 - val_acc: 0.5543\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0683 - acc: 0.9245 - val_loss: 2.5642 - val_acc: 0.5453\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0698 - acc: 0.9157 - val_loss: 2.5569 - val_acc: 0.5389\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0555 - acc: 0.9169 - val_loss: 2.5533 - val_acc: 0.5553\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0524 - acc: 0.9143 - val_loss: 2.5852 - val_acc: 0.5380\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0447 - acc: 0.9126 - val_loss: 2.5055 - val_acc: 0.5580\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 0.9636 - acc: 0.9442 - val_loss: 2.5530 - val_acc: 0.5489\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 5.5066 - acc: 0.4383 - val_loss: 5.1915 - val_acc: 0.4638\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.9249 - acc: 0.5279 - val_loss: 4.7986 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.5124 - acc: 0.5723 - val_loss: 4.5539 - val_acc: 0.5154\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.1544 - acc: 0.5985 - val_loss: 4.2294 - val_acc: 0.5326\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8067 - acc: 0.6250 - val_loss: 3.9461 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.4820 - acc: 0.6476 - val_loss: 3.6864 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1995 - acc: 0.6668 - val_loss: 3.4802 - val_acc: 0.5489\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9522 - acc: 0.6822 - val_loss: 3.3145 - val_acc: 0.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7243 - acc: 0.6948 - val_loss: 3.1094 - val_acc: 0.5353\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5015 - acc: 0.7176 - val_loss: 3.0067 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3366 - acc: 0.7288 - val_loss: 2.9032 - val_acc: 0.5254\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1600 - acc: 0.7492 - val_loss: 2.7631 - val_acc: 0.5353\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0371 - acc: 0.7575 - val_loss: 2.6530 - val_acc: 0.5471\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9020 - acc: 0.7778 - val_loss: 2.6439 - val_acc: 0.5371\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8003 - acc: 0.7881 - val_loss: 2.5345 - val_acc: 0.5489\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 6.0143 - acc: 0.4653 - val_loss: 5.6752 - val_acc: 0.4964\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 5.3211 - acc: 0.5618 - val_loss: 5.2569 - val_acc: 0.5190\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.8333 - acc: 0.6185 - val_loss: 4.8740 - val_acc: 0.5580\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.3782 - acc: 0.6547 - val_loss: 4.4983 - val_acc: 0.5516\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.9650 - acc: 0.6970 - val_loss: 4.2548 - val_acc: 0.5498\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.6006 - acc: 0.7187 - val_loss: 3.9706 - val_acc: 0.5679\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2805 - acc: 0.7512 - val_loss: 3.7740 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9760 - acc: 0.7743 - val_loss: 3.5194 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6940 - acc: 0.8042 - val_loss: 3.3768 - val_acc: 0.5389\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4850 - acc: 0.8139 - val_loss: 3.2226 - val_acc: 0.5426\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2700 - acc: 0.8341 - val_loss: 3.0477 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1077 - acc: 0.8403 - val_loss: 2.9717 - val_acc: 0.5507\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9537 - acc: 0.8551 - val_loss: 2.9405 - val_acc: 0.5453\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8291 - acc: 0.8628 - val_loss: 2.7829 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6693 - acc: 0.8893 - val_loss: 2.7702 - val_acc: 0.5480\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6331 - acc: 0.8704 - val_loss: 2.6045 - val_acc: 0.5525\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 4.5242 - acc: 0.4664 - val_loss: 4.2602 - val_acc: 0.5000\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.9751 - acc: 0.5795 - val_loss: 4.1090 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.6427 - acc: 0.6514 - val_loss: 3.8724 - val_acc: 0.5471\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.3526 - acc: 0.7043 - val_loss: 3.7302 - val_acc: 0.5507\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0957 - acc: 0.7503 - val_loss: 3.5879 - val_acc: 0.5417\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8479 - acc: 0.7916 - val_loss: 3.5087 - val_acc: 0.5426\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6260 - acc: 0.8272 - val_loss: 3.3825 - val_acc: 0.5335\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4095 - acc: 0.8685 - val_loss: 3.2553 - val_acc: 0.5462\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2339 - acc: 0.8917 - val_loss: 3.2635 - val_acc: 0.5353\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0710 - acc: 0.9087 - val_loss: 3.1476 - val_acc: 0.5417\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9265 - acc: 0.9243 - val_loss: 3.1204 - val_acc: 0.5471\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7872 - acc: 0.9394 - val_loss: 2.9102 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6940 - acc: 0.9361 - val_loss: 2.9393 - val_acc: 0.5580\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5734 - acc: 0.9507 - val_loss: 3.0029 - val_acc: 0.5362\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4969 - acc: 0.9477 - val_loss: 2.8590 - val_acc: 0.5371\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4575 - acc: 0.9375 - val_loss: 2.8500 - val_acc: 0.5498\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3732 - acc: 0.9465 - val_loss: 2.8252 - val_acc: 0.5498\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3012 - acc: 0.9531 - val_loss: 2.7533 - val_acc: 0.5471\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2118 - acc: 0.9644 - val_loss: 2.8392 - val_acc: 0.5471\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2318 - acc: 0.9344 - val_loss: 2.7480 - val_acc: 0.5426\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2073 - acc: 0.9317 - val_loss: 2.6893 - val_acc: 0.5389\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1329 - acc: 0.9494 - val_loss: 2.6584 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 4.8836 - acc: 0.4489 - val_loss: 4.6669 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.3982 - acc: 0.5656 - val_loss: 4.4584 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.1390 - acc: 0.6118 - val_loss: 4.2993 - val_acc: 0.5471\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8865 - acc: 0.6599 - val_loss: 4.2096 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.6980 - acc: 0.6847 - val_loss: 4.0690 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.4659 - acc: 0.7281 - val_loss: 3.8922 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2897 - acc: 0.7541 - val_loss: 3.8433 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1123 - acc: 0.7754 - val_loss: 3.6606 - val_acc: 0.5761\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9263 - acc: 0.8092 - val_loss: 3.5930 - val_acc: 0.5580\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7610 - acc: 0.8333 - val_loss: 3.4924 - val_acc: 0.5589\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5896 - acc: 0.8617 - val_loss: 3.4543 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4517 - acc: 0.8822 - val_loss: 3.3613 - val_acc: 0.5634\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3352 - acc: 0.8890 - val_loss: 3.2966 - val_acc: 0.5598\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2246 - acc: 0.8914 - val_loss: 3.2863 - val_acc: 0.5679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1045 - acc: 0.9071 - val_loss: 3.2210 - val_acc: 0.5616\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0043 - acc: 0.9135 - val_loss: 3.1281 - val_acc: 0.5670\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8755 - acc: 0.9380 - val_loss: 3.0805 - val_acc: 0.5562\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7954 - acc: 0.9366 - val_loss: 3.0315 - val_acc: 0.5634\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 3.3419 - acc: 0.4569 - val_loss: 3.1289 - val_acc: 0.4882\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8750 - acc: 0.5505 - val_loss: 2.9243 - val_acc: 0.5299\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6513 - acc: 0.6041 - val_loss: 2.8226 - val_acc: 0.5263\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4654 - acc: 0.6405 - val_loss: 2.7879 - val_acc: 0.5371\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3093 - acc: 0.6710 - val_loss: 2.6825 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1320 - acc: 0.7132 - val_loss: 2.6869 - val_acc: 0.5380\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9716 - acc: 0.7448 - val_loss: 2.5633 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8369 - acc: 0.7757 - val_loss: 2.5494 - val_acc: 0.5353\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6924 - acc: 0.8166 - val_loss: 2.4773 - val_acc: 0.5697\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5861 - acc: 0.8325 - val_loss: 2.5220 - val_acc: 0.5534\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4855 - acc: 0.8519 - val_loss: 2.4928 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3833 - acc: 0.8763 - val_loss: 2.4723 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2966 - acc: 0.8916 - val_loss: 2.5095 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2496 - acc: 0.8901 - val_loss: 2.4278 - val_acc: 0.5625\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1799 - acc: 0.9115 - val_loss: 2.4008 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1129 - acc: 0.9245 - val_loss: 2.5273 - val_acc: 0.5580\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1347 - acc: 0.9008 - val_loss: 2.5260 - val_acc: 0.5543\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0482 - acc: 0.9279 - val_loss: 2.5694 - val_acc: 0.5426\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0558 - acc: 0.9170 - val_loss: 2.5831 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 5.9350 - acc: 0.4678 - val_loss: 5.6346 - val_acc: 0.5263\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 5.3179 - acc: 0.5893 - val_loss: 5.3963 - val_acc: 0.5353\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.9434 - acc: 0.6633 - val_loss: 5.1494 - val_acc: 0.5317\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.6359 - acc: 0.7033 - val_loss: 4.9741 - val_acc: 0.5435\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.3316 - acc: 0.7481 - val_loss: 4.7597 - val_acc: 0.5516\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.0308 - acc: 0.7917 - val_loss: 4.5925 - val_acc: 0.5562\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.7795 - acc: 0.8214 - val_loss: 4.4321 - val_acc: 0.5525\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.5214 - acc: 0.8605 - val_loss: 4.3016 - val_acc: 0.5516\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2940 - acc: 0.8803 - val_loss: 4.1295 - val_acc: 0.5553\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.0801 - acc: 0.8987 - val_loss: 3.9656 - val_acc: 0.5679\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8589 - acc: 0.9332 - val_loss: 3.9245 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7100 - acc: 0.9265 - val_loss: 3.7988 - val_acc: 0.5562\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5452 - acc: 0.9345 - val_loss: 3.6691 - val_acc: 0.5607\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4031 - acc: 0.9430 - val_loss: 3.5657 - val_acc: 0.5543\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2415 - acc: 0.9566 - val_loss: 3.5101 - val_acc: 0.5516\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1046 - acc: 0.9628 - val_loss: 3.3861 - val_acc: 0.5797\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0139 - acc: 0.9541 - val_loss: 3.3302 - val_acc: 0.5525\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9137 - acc: 0.9532 - val_loss: 3.2156 - val_acc: 0.5562\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8216 - acc: 0.9508 - val_loss: 3.2196 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7510 - acc: 0.9485 - val_loss: 3.1592 - val_acc: 0.5607\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6763 - acc: 0.9485 - val_loss: 3.1185 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5920 - acc: 0.9541 - val_loss: 2.9909 - val_acc: 0.5833\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4624 - acc: 0.9781 - val_loss: 2.9158 - val_acc: 0.5634\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3947 - acc: 0.9730 - val_loss: 3.0152 - val_acc: 0.5263\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4044 - acc: 0.9471 - val_loss: 2.9297 - val_acc: 0.5489\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3927 - acc: 0.9368 - val_loss: 3.0054 - val_acc: 0.5462\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3051 - acc: 0.9529 - val_loss: 2.8597 - val_acc: 0.5688\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1954 - acc: 0.9778 - val_loss: 2.7970 - val_acc: 0.5580\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1091 - acc: 0.9858 - val_loss: 2.6753 - val_acc: 0.5716\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0373 - acc: 0.9926 - val_loss: 2.6162 - val_acc: 0.5761\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 0.9833 - acc: 0.9912 - val_loss: 2.6945 - val_acc: 0.5498\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1667 - acc: 0.9076 - val_loss: 2.9370 - val_acc: 0.4918\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: nan - acc: 0.0691 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 238.9971 - acc: 0.1069 - val_loss: 281.0752 - val_acc: 0.0996\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 173.5496 - acc: 0.1209 - val_loss: 101.5208 - val_acc: 0.1241\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 120.7859 - acc: 0.1177 - val_loss: 151.6996 - val_acc: 0.0906\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 151.9795 - acc: 0.1120 - val_loss: 137.1054 - val_acc: 0.0969\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 112.7123 - acc: 0.0955 - val_loss: 94.5705 - val_acc: 0.0951\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 86.9529 - acc: 0.0983 - val_loss: 82.8781 - val_acc: 0.0797\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 78.2458 - acc: 0.0840 - val_loss: 73.3848 - val_acc: 0.0897\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 65.4555 - acc: 0.0942 - val_loss: 59.5222 - val_acc: 0.0897\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 69.1748 - acc: 0.0964 - val_loss: 87.6632 - val_acc: 0.0779\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 92.2190 - acc: 0.0844 - val_loss: 90.3553 - val_acc: 0.0697\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 84.3985 - acc: 0.0855 - val_loss: 79.5313 - val_acc: 0.0779\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 74.7621 - acc: 0.0880 - val_loss: 73.0827 - val_acc: 0.0779\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 4.2944 - acc: 0.2816 - val_loss: 3.3603 - val_acc: 0.3641\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 3.2724 - acc: 0.4376 - val_loss: 3.2204 - val_acc: 0.4601\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 3.0890 - acc: 0.4988 - val_loss: 3.0511 - val_acc: 0.4909\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.8792 - acc: 0.5286 - val_loss: 2.8654 - val_acc: 0.5009\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.6779 - acc: 0.5491 - val_loss: 2.7028 - val_acc: 0.5082\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 2.5165 - acc: 0.5637 - val_loss: 2.5558 - val_acc: 0.5308\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.3820 - acc: 0.5731 - val_loss: 2.4410 - val_acc: 0.5417\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 2.2852 - acc: 0.5739 - val_loss: 2.4322 - val_acc: 0.5380\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.1761 - acc: 0.5916 - val_loss: 2.3093 - val_acc: 0.5326\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 2.0761 - acc: 0.6105 - val_loss: 2.2790 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 2.0502 - acc: 0.6007 - val_loss: 2.2682 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 2.0195 - acc: 0.6100 - val_loss: 2.2609 - val_acc: 0.5308\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.9825 - acc: 0.6169 - val_loss: 2.2830 - val_acc: 0.5426\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.9371 - acc: 0.6234 - val_loss: 2.2602 - val_acc: 0.5317\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.8882 - acc: 0.6365 - val_loss: 2.2647 - val_acc: 0.5498\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 1.8598 - acc: 0.6382 - val_loss: 2.2124 - val_acc: 0.5697\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.8497 - acc: 0.6485 - val_loss: 2.2261 - val_acc: 0.5417\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.8112 - acc: 0.6645 - val_loss: 2.2850 - val_acc: 0.5254\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 1.8082 - acc: 0.6646 - val_loss: 2.1999 - val_acc: 0.5471\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 1.7947 - acc: 0.6642 - val_loss: 2.2321 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.7934 - acc: 0.6727 - val_loss: 2.3100 - val_acc: 0.5290\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.8044 - acc: 0.6697 - val_loss: 2.2768 - val_acc: 0.5399\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.8007 - acc: 0.6938 - val_loss: 2.2952 - val_acc: 0.5408\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.8005 - acc: 0.6897 - val_loss: 2.2376 - val_acc: 0.5743\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.7890 - acc: 0.6934 - val_loss: 2.4506 - val_acc: 0.5353\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.7455 - acc: 0.7147 - val_loss: 2.4002 - val_acc: 0.5426\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.7488 - acc: 0.7150 - val_loss: 2.4210 - val_acc: 0.5408\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.7708 - acc: 0.7088 - val_loss: 2.3686 - val_acc: 0.5326\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.7964 - acc: 0.7025 - val_loss: 2.4321 - val_acc: 0.5272\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.8008 - acc: 0.7110 - val_loss: 2.4300 - val_acc: 0.5417\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 1.7935 - acc: 0.7206 - val_loss: 2.4512 - val_acc: 0.5462\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 1.7987 - acc: 0.7214 - val_loss: 2.4253 - val_acc: 0.5543\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 1.7755 - acc: 0.7329 - val_loss: 2.4669 - val_acc: 0.5534\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.8245 - acc: 0.7276 - val_loss: 2.5143 - val_acc: 0.5516\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 3.7237 - acc: 0.3452 - val_loss: 2.9943 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.8850 - acc: 0.4925 - val_loss: 2.8759 - val_acc: 0.4937\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 2.7268 - acc: 0.5394 - val_loss: 2.7793 - val_acc: 0.5118\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.5685 - acc: 0.5754 - val_loss: 2.6782 - val_acc: 0.5127\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.4223 - acc: 0.6086 - val_loss: 2.6320 - val_acc: 0.5281\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 2.3349 - acc: 0.6068 - val_loss: 2.6043 - val_acc: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 717us/step - loss: 2.2163 - acc: 0.6317 - val_loss: 2.5284 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 2.1481 - acc: 0.6431 - val_loss: 2.5347 - val_acc: 0.5335\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 2.0446 - acc: 0.6685 - val_loss: 2.5058 - val_acc: 0.5399\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 1.9922 - acc: 0.6686 - val_loss: 2.4540 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 1.8998 - acc: 0.6926 - val_loss: 2.4193 - val_acc: 0.5435\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.8070 - acc: 0.7204 - val_loss: 2.4134 - val_acc: 0.5507\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 1.7802 - acc: 0.7181 - val_loss: 2.3735 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 1.6877 - acc: 0.7381 - val_loss: 2.3658 - val_acc: 0.5670\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 1.6484 - acc: 0.7538 - val_loss: 2.3032 - val_acc: 0.5725\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 1.5971 - acc: 0.7670 - val_loss: 2.4160 - val_acc: 0.5389\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 1.5852 - acc: 0.7683 - val_loss: 2.3767 - val_acc: 0.5471\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.5434 - acc: 0.7838 - val_loss: 2.4468 - val_acc: 0.5399\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.5409 - acc: 0.7771 - val_loss: 2.5006 - val_acc: 0.5263\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 1.5484 - acc: 0.7783 - val_loss: 2.4416 - val_acc: 0.5417\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1.5074 - acc: 0.7973 - val_loss: 2.4136 - val_acc: 0.5543\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.4641 - acc: 0.8067 - val_loss: 2.5459 - val_acc: 0.5208\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 1.4425 - acc: 0.8216 - val_loss: 2.4770 - val_acc: 0.5480\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.4237 - acc: 0.8238 - val_loss: 2.4986 - val_acc: 0.5254\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.4014 - acc: 0.8336 - val_loss: 2.4984 - val_acc: 0.5498\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 35s 4ms/step - loss: 4.9714 - acc: 0.4723 - val_loss: 4.6853 - val_acc: 0.5145\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.4018 - acc: 0.6113 - val_loss: 4.6047 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.1002 - acc: 0.6871 - val_loss: 4.4280 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8203 - acc: 0.7420 - val_loss: 4.3204 - val_acc: 0.5281\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.5850 - acc: 0.7928 - val_loss: 4.1553 - val_acc: 0.5362\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.3495 - acc: 0.8360 - val_loss: 4.0412 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1184 - acc: 0.8814 - val_loss: 3.9289 - val_acc: 0.5652\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9355 - acc: 0.9001 - val_loss: 3.8934 - val_acc: 0.5399\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7690 - acc: 0.9216 - val_loss: 3.7705 - val_acc: 0.5525\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5976 - acc: 0.9426 - val_loss: 3.6755 - val_acc: 0.5553\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4455 - acc: 0.9541 - val_loss: 3.5385 - val_acc: 0.5661\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3027 - acc: 0.9665 - val_loss: 3.4653 - val_acc: 0.5408\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1532 - acc: 0.9784 - val_loss: 3.4484 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0559 - acc: 0.9735 - val_loss: 3.4137 - val_acc: 0.5353\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9901 - acc: 0.9610 - val_loss: 3.3671 - val_acc: 0.5516\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9447 - acc: 0.9450 - val_loss: 3.2935 - val_acc: 0.5607\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8181 - acc: 0.9643 - val_loss: 3.1440 - val_acc: 0.5426\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7049 - acc: 0.9752 - val_loss: 3.1493 - val_acc: 0.5435\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6091 - acc: 0.9794 - val_loss: 3.0831 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5281 - acc: 0.9814 - val_loss: 3.0838 - val_acc: 0.5435\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4847 - acc: 0.9704 - val_loss: 3.0411 - val_acc: 0.5571\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 4.8017 - acc: 0.2911 - val_loss: 3.9110 - val_acc: 0.4076\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 3.8896 - acc: 0.4501 - val_loss: 3.8626 - val_acc: 0.4601\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 3.7255 - acc: 0.5008 - val_loss: 3.7330 - val_acc: 0.4701\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 3.4842 - acc: 0.5340 - val_loss: 3.4594 - val_acc: 0.4909\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 3.2042 - acc: 0.5643 - val_loss: 3.2010 - val_acc: 0.5254\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.9299 - acc: 0.5874 - val_loss: 2.9828 - val_acc: 0.5226\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 2.7000 - acc: 0.5961 - val_loss: 2.8339 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 2.5360 - acc: 0.5983 - val_loss: 2.7105 - val_acc: 0.5417\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.3724 - acc: 0.6134 - val_loss: 2.5271 - val_acc: 0.5462\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.2538 - acc: 0.6152 - val_loss: 2.5281 - val_acc: 0.5353\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 2.1528 - acc: 0.6266 - val_loss: 2.4081 - val_acc: 0.5571\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.0696 - acc: 0.6314 - val_loss: 2.3583 - val_acc: 0.5299\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 2.0418 - acc: 0.6275 - val_loss: 2.3250 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.9819 - acc: 0.6424 - val_loss: 2.3577 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.9259 - acc: 0.6495 - val_loss: 2.2909 - val_acc: 0.5399\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 1.9072 - acc: 0.6509 - val_loss: 2.2622 - val_acc: 0.5444\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.8311 - acc: 0.6704 - val_loss: 2.2339 - val_acc: 0.5543\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.7835 - acc: 0.6851 - val_loss: 2.2714 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.7402 - acc: 0.6955 - val_loss: 2.1998 - val_acc: 0.5498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.7196 - acc: 0.6957 - val_loss: 2.2880 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.7186 - acc: 0.6954 - val_loss: 2.2377 - val_acc: 0.5498\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 28s 3ms/step - loss: 4.3169 - acc: 0.3008 - val_loss: 3.3453 - val_acc: 0.4330\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 3.2131 - acc: 0.4611 - val_loss: 3.1122 - val_acc: 0.4801\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 2.9651 - acc: 0.5155 - val_loss: 2.9295 - val_acc: 0.5000\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.7370 - acc: 0.5424 - val_loss: 2.7637 - val_acc: 0.5018\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 2.5809 - acc: 0.5549 - val_loss: 2.6071 - val_acc: 0.5145\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 2.3929 - acc: 0.5759 - val_loss: 2.5320 - val_acc: 0.5245\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 2.2378 - acc: 0.5875 - val_loss: 2.3967 - val_acc: 0.5317\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 2.1290 - acc: 0.5997 - val_loss: 2.3190 - val_acc: 0.5444\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.0343 - acc: 0.6040 - val_loss: 2.3360 - val_acc: 0.5045\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.9841 - acc: 0.6017 - val_loss: 2.2431 - val_acc: 0.5245\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.8909 - acc: 0.6233 - val_loss: 2.2115 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.7841 - acc: 0.6421 - val_loss: 2.0916 - val_acc: 0.5272\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.7456 - acc: 0.6466 - val_loss: 2.1377 - val_acc: 0.5190\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.7124 - acc: 0.6510 - val_loss: 2.0743 - val_acc: 0.5426\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.6615 - acc: 0.6592 - val_loss: 2.1651 - val_acc: 0.5263\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.6283 - acc: 0.6694 - val_loss: 2.1349 - val_acc: 0.5272\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.6393 - acc: 0.6656 - val_loss: 2.1846 - val_acc: 0.5335\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 1.5933 - acc: 0.6817 - val_loss: 2.1740 - val_acc: 0.5335\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 35s 4ms/step - loss: 3.7152 - acc: 0.4315 - val_loss: 3.3979 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2050 - acc: 0.5361 - val_loss: 3.3081 - val_acc: 0.4746\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9977 - acc: 0.5593 - val_loss: 3.0231 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8021 - acc: 0.5818 - val_loss: 2.9185 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5841 - acc: 0.6129 - val_loss: 2.7973 - val_acc: 0.5326\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4230 - acc: 0.6253 - val_loss: 2.6593 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2584 - acc: 0.6513 - val_loss: 2.5805 - val_acc: 0.5435\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1257 - acc: 0.6636 - val_loss: 2.5527 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0018 - acc: 0.6813 - val_loss: 2.4452 - val_acc: 0.5525\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8871 - acc: 0.7077 - val_loss: 2.3147 - val_acc: 0.5525\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7890 - acc: 0.7202 - val_loss: 2.3417 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7012 - acc: 0.7364 - val_loss: 2.4076 - val_acc: 0.5389\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6497 - acc: 0.7386 - val_loss: 2.2614 - val_acc: 0.5353\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5838 - acc: 0.7524 - val_loss: 2.3307 - val_acc: 0.5308\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5218 - acc: 0.7684 - val_loss: 2.3531 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4690 - acc: 0.7815 - val_loss: 2.2674 - val_acc: 0.5697\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4377 - acc: 0.7832 - val_loss: 2.2428 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4191 - acc: 0.7910 - val_loss: 2.2842 - val_acc: 0.5399\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3891 - acc: 0.8017 - val_loss: 2.3184 - val_acc: 0.5507\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3819 - acc: 0.8047 - val_loss: 2.3283 - val_acc: 0.5435\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3540 - acc: 0.8122 - val_loss: 2.3527 - val_acc: 0.5399\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2996 - acc: 0.8319 - val_loss: 2.3967 - val_acc: 0.5426\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3168 - acc: 0.8223 - val_loss: 2.3842 - val_acc: 0.5444\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2898 - acc: 0.8353 - val_loss: 2.3188 - val_acc: 0.5652\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2985 - acc: 0.8324 - val_loss: 2.3786 - val_acc: 0.5471\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2834 - acc: 0.8434 - val_loss: 2.4158 - val_acc: 0.5571\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: nan - acc: 0.0716 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 627us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 615us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 5.1779 - acc: 0.2394 - val_loss: 3.9544 - val_acc: 0.3569\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 3.7937 - acc: 0.3902 - val_loss: 3.5542 - val_acc: 0.4393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 3.3774 - acc: 0.4619 - val_loss: 3.2306 - val_acc: 0.4565\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 3.0641 - acc: 0.4837 - val_loss: 3.0217 - val_acc: 0.4411\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 2.8698 - acc: 0.4887 - val_loss: 2.9068 - val_acc: 0.4529\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 2.6649 - acc: 0.5117 - val_loss: 2.7176 - val_acc: 0.4574\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.5001 - acc: 0.5197 - val_loss: 2.5457 - val_acc: 0.5027\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 2.4038 - acc: 0.5216 - val_loss: 2.5486 - val_acc: 0.4755\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.2880 - acc: 0.5443 - val_loss: 2.3817 - val_acc: 0.5036\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 2.1962 - acc: 0.5491 - val_loss: 2.3868 - val_acc: 0.5045\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 2.1171 - acc: 0.5635 - val_loss: 2.3195 - val_acc: 0.5181\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 2.0867 - acc: 0.5635 - val_loss: 2.4102 - val_acc: 0.4719\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 2.0735 - acc: 0.5667 - val_loss: 2.2040 - val_acc: 0.5254\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.0051 - acc: 0.5928 - val_loss: 2.2335 - val_acc: 0.5063\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.9908 - acc: 0.5879 - val_loss: 2.2477 - val_acc: 0.5335\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.9512 - acc: 0.5966 - val_loss: 2.2088 - val_acc: 0.5190\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 1.9267 - acc: 0.6017 - val_loss: 2.2196 - val_acc: 0.5236\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.9538 - acc: 0.5981 - val_loss: 2.2190 - val_acc: 0.5045\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.9383 - acc: 0.6043 - val_loss: 2.2927 - val_acc: 0.5236\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.9797 - acc: 0.6043 - val_loss: 2.3826 - val_acc: 0.4783\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.9964 - acc: 0.5955 - val_loss: 2.3341 - val_acc: 0.5245\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.9702 - acc: 0.6029 - val_loss: 2.5075 - val_acc: 0.5118\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 2.0105 - acc: 0.6034 - val_loss: 2.2629 - val_acc: 0.5353\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.9429 - acc: 0.6217 - val_loss: 2.2219 - val_acc: 0.5426\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.9140 - acc: 0.6268 - val_loss: 2.3804 - val_acc: 0.5109\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.9494 - acc: 0.6186 - val_loss: 2.2974 - val_acc: 0.5063\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.9302 - acc: 0.6329 - val_loss: 2.2867 - val_acc: 0.5290\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.9085 - acc: 0.6391 - val_loss: 2.3046 - val_acc: 0.5036\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.8798 - acc: 0.6442 - val_loss: 2.3319 - val_acc: 0.5118\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 1.8829 - acc: 0.6353 - val_loss: 2.3004 - val_acc: 0.5380\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.8805 - acc: 0.6425 - val_loss: 2.3013 - val_acc: 0.5226\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.8623 - acc: 0.6542 - val_loss: 2.3100 - val_acc: 0.5199\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.8721 - acc: 0.6482 - val_loss: 2.4240 - val_acc: 0.5109\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.9044 - acc: 0.6473 - val_loss: 2.3225 - val_acc: 0.5154\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 4.0245 - acc: 0.3505 - val_loss: 3.3046 - val_acc: 0.4701\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 3.1659 - acc: 0.5122 - val_loss: 3.1880 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 2.9762 - acc: 0.5539 - val_loss: 3.0458 - val_acc: 0.5091\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.7977 - acc: 0.5779 - val_loss: 3.0509 - val_acc: 0.4909\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.6853 - acc: 0.5994 - val_loss: 2.9859 - val_acc: 0.5145\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 2.5535 - acc: 0.6176 - val_loss: 2.8640 - val_acc: 0.5217\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 2.4335 - acc: 0.6405 - val_loss: 2.8050 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.2885 - acc: 0.6667 - val_loss: 2.7099 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 2.1998 - acc: 0.6815 - val_loss: 2.7281 - val_acc: 0.5399\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 2.1134 - acc: 0.6960 - val_loss: 2.6782 - val_acc: 0.5226\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 2.0261 - acc: 0.7053 - val_loss: 2.6192 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.9155 - acc: 0.7337 - val_loss: 2.5600 - val_acc: 0.5236\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.8346 - acc: 0.7535 - val_loss: 2.4646 - val_acc: 0.5607\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.7486 - acc: 0.7730 - val_loss: 2.4872 - val_acc: 0.5389\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.6850 - acc: 0.7845 - val_loss: 2.5227 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.6758 - acc: 0.7782 - val_loss: 2.5592 - val_acc: 0.5507\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.6086 - acc: 0.7962 - val_loss: 2.4406 - val_acc: 0.5643\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.5715 - acc: 0.8019 - val_loss: 2.5673 - val_acc: 0.5435\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.4795 - acc: 0.8401 - val_loss: 2.5018 - val_acc: 0.5417\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.4254 - acc: 0.8483 - val_loss: 2.5331 - val_acc: 0.5598\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 1.4319 - acc: 0.8343 - val_loss: 2.5800 - val_acc: 0.5353\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.4164 - acc: 0.8353 - val_loss: 2.5071 - val_acc: 0.5389\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.4077 - acc: 0.8413 - val_loss: 2.6359 - val_acc: 0.5281\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.3835 - acc: 0.8489 - val_loss: 2.4383 - val_acc: 0.5589\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.3188 - acc: 0.8704 - val_loss: 2.6354 - val_acc: 0.5353\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.3391 - acc: 0.8597 - val_loss: 2.5654 - val_acc: 0.5634\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.2779 - acc: 0.8807 - val_loss: 2.5015 - val_acc: 0.5571\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 28s 3ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 587us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 3.9255 - acc: 0.3496 - val_loss: 3.1736 - val_acc: 0.4601\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 3.0461 - acc: 0.5076 - val_loss: 3.0549 - val_acc: 0.5036\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 2.8539 - acc: 0.5370 - val_loss: 2.8982 - val_acc: 0.5091\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 2.6785 - acc: 0.5705 - val_loss: 2.8726 - val_acc: 0.5091\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 2.5517 - acc: 0.5929 - val_loss: 2.7491 - val_acc: 0.5091\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 2.4478 - acc: 0.6014 - val_loss: 2.7238 - val_acc: 0.4946\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.3293 - acc: 0.6192 - val_loss: 2.5591 - val_acc: 0.5435\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 2.1805 - acc: 0.6433 - val_loss: 2.5822 - val_acc: 0.5317\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 2.0907 - acc: 0.6607 - val_loss: 2.5862 - val_acc: 0.5181\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 2.0238 - acc: 0.6683 - val_loss: 2.5181 - val_acc: 0.5109\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.9670 - acc: 0.6650 - val_loss: 2.4311 - val_acc: 0.5326\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 1.8885 - acc: 0.6907 - val_loss: 2.4155 - val_acc: 0.5326\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.8111 - acc: 0.7025 - val_loss: 2.3915 - val_acc: 0.5489\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.7508 - acc: 0.7193 - val_loss: 2.3526 - val_acc: 0.5426\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.7274 - acc: 0.7230 - val_loss: 2.2907 - val_acc: 0.5516\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 1.6730 - acc: 0.7355 - val_loss: 2.3897 - val_acc: 0.5335\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.6146 - acc: 0.7510 - val_loss: 2.3675 - val_acc: 0.5380\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 1.5583 - acc: 0.7662 - val_loss: 2.4603 - val_acc: 0.5172\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 1.5991 - acc: 0.7533 - val_loss: 2.3219 - val_acc: 0.5498\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.5775 - acc: 0.7565 - val_loss: 2.3414 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.5343 - acc: 0.7747 - val_loss: 2.4888 - val_acc: 0.5308\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.4877 - acc: 0.7919 - val_loss: 2.4411 - val_acc: 0.5389\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 1.4542 - acc: 0.8039 - val_loss: 2.4452 - val_acc: 0.5371\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.4603 - acc: 0.8042 - val_loss: 2.5442 - val_acc: 0.5163\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 1.4867 - acc: 0.7931 - val_loss: 2.5134 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 4.5682 - acc: 0.3468 - val_loss: 3.9169 - val_acc: 0.4176\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 3.7557 - acc: 0.4922 - val_loss: 3.6952 - val_acc: 0.5036\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 3.5143 - acc: 0.5454 - val_loss: 3.5256 - val_acc: 0.5063\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 3.2563 - acc: 0.5781 - val_loss: 3.3244 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 2.9975 - acc: 0.6035 - val_loss: 3.0719 - val_acc: 0.5399\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 2.7288 - acc: 0.6217 - val_loss: 2.9624 - val_acc: 0.5109\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.5008 - acc: 0.6447 - val_loss: 2.7565 - val_acc: 0.5299\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 2.2984 - acc: 0.6641 - val_loss: 2.6741 - val_acc: 0.5353\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 2.1660 - acc: 0.6669 - val_loss: 2.6062 - val_acc: 0.5380\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 2.0348 - acc: 0.6849 - val_loss: 2.4528 - val_acc: 0.5299\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.9347 - acc: 0.6941 - val_loss: 2.4395 - val_acc: 0.5399\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 1.8064 - acc: 0.7136 - val_loss: 2.3331 - val_acc: 0.5380\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.7071 - acc: 0.7336 - val_loss: 2.3437 - val_acc: 0.5299\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.6498 - acc: 0.7355 - val_loss: 2.3550 - val_acc: 0.5362\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.5841 - acc: 0.7497 - val_loss: 2.2330 - val_acc: 0.5625\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.5183 - acc: 0.7732 - val_loss: 2.3145 - val_acc: 0.5380\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 1.4815 - acc: 0.7744 - val_loss: 2.3724 - val_acc: 0.5281\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.4359 - acc: 0.7833 - val_loss: 2.3355 - val_acc: 0.5371\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.4103 - acc: 0.7913 - val_loss: 2.2836 - val_acc: 0.5598\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.3588 - acc: 0.8080 - val_loss: 2.2999 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.3284 - acc: 0.8195 - val_loss: 2.2924 - val_acc: 0.5389\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.3062 - acc: 0.8197 - val_loss: 2.3793 - val_acc: 0.5399\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.2885 - acc: 0.8308 - val_loss: 2.3805 - val_acc: 0.5435\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.2699 - acc: 0.8349 - val_loss: 2.3618 - val_acc: 0.5453\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.2440 - acc: 0.8473 - val_loss: 2.4558 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: 5.4932 - acc: 0.3433 - val_loss: 4.7049 - val_acc: 0.4692\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 4.4671 - acc: 0.5079 - val_loss: 4.3346 - val_acc: 0.4909\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 4.0450 - acc: 0.5494 - val_loss: 4.0551 - val_acc: 0.4900\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 3.6848 - acc: 0.5770 - val_loss: 3.6726 - val_acc: 0.5172\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 3.3426 - acc: 0.5934 - val_loss: 3.4292 - val_acc: 0.5362\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 3.0500 - acc: 0.6079 - val_loss: 3.1746 - val_acc: 0.5498\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.7710 - acc: 0.6323 - val_loss: 3.0584 - val_acc: 0.5380\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.6000 - acc: 0.6348 - val_loss: 2.9092 - val_acc: 0.5236\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.4171 - acc: 0.6462 - val_loss: 2.7206 - val_acc: 0.5317\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.2423 - acc: 0.6659 - val_loss: 2.6162 - val_acc: 0.5534\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.1210 - acc: 0.6752 - val_loss: 2.6622 - val_acc: 0.5163\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.0450 - acc: 0.6718 - val_loss: 2.5113 - val_acc: 0.5326\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.9549 - acc: 0.6824 - val_loss: 2.5554 - val_acc: 0.5100\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.8683 - acc: 0.7029 - val_loss: 2.4523 - val_acc: 0.5172\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.7998 - acc: 0.7049 - val_loss: 2.4165 - val_acc: 0.5136\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 1.7597 - acc: 0.7036 - val_loss: 2.3928 - val_acc: 0.5254\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.6812 - acc: 0.7283 - val_loss: 2.2550 - val_acc: 0.5571\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.6096 - acc: 0.7424 - val_loss: 2.3977 - val_acc: 0.5127\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.6259 - acc: 0.7330 - val_loss: 2.3079 - val_acc: 0.5471\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.5959 - acc: 0.7344 - val_loss: 2.3094 - val_acc: 0.5308\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.5555 - acc: 0.7482 - val_loss: 2.3063 - val_acc: 0.5389\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.5386 - acc: 0.7592 - val_loss: 2.2385 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.5148 - acc: 0.7669 - val_loss: 2.4683 - val_acc: 0.5091\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.5691 - acc: 0.7462 - val_loss: 2.2941 - val_acc: 0.5389\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.4821 - acc: 0.7825 - val_loss: 2.3075 - val_acc: 0.5543\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.4389 - acc: 0.7910 - val_loss: 2.4593 - val_acc: 0.5217\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.4655 - acc: 0.7821 - val_loss: 2.2657 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 29s 3ms/step - loss: nan - acc: 0.0688 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 619us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 595us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 627us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 590us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 4.8030 - acc: 0.3737 - val_loss: 4.1913 - val_acc: 0.4764\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 3.9652 - acc: 0.5156 - val_loss: 3.9325 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 3.6481 - acc: 0.5690 - val_loss: 3.7111 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 3.3808 - acc: 0.5949 - val_loss: 3.6253 - val_acc: 0.4755\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 3.1781 - acc: 0.6117 - val_loss: 3.3117 - val_acc: 0.5453\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 2.9323 - acc: 0.6411 - val_loss: 3.2413 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 2.7452 - acc: 0.6595 - val_loss: 3.1915 - val_acc: 0.5163\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 2.5874 - acc: 0.6746 - val_loss: 2.9667 - val_acc: 0.5299\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.3921 - acc: 0.6968 - val_loss: 2.8840 - val_acc: 0.5190\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.2345 - acc: 0.7176 - val_loss: 2.7931 - val_acc: 0.5272\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.1062 - acc: 0.7414 - val_loss: 2.7344 - val_acc: 0.5453\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 2.0120 - acc: 0.7439 - val_loss: 2.6511 - val_acc: 0.5371\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 1.8642 - acc: 0.7739 - val_loss: 2.6417 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.7759 - acc: 0.7826 - val_loss: 2.5958 - val_acc: 0.5498\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 1.6613 - acc: 0.8033 - val_loss: 2.5612 - val_acc: 0.5399\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.5769 - acc: 0.8214 - val_loss: 2.5448 - val_acc: 0.5344\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.5809 - acc: 0.8016 - val_loss: 2.5889 - val_acc: 0.5362\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.5264 - acc: 0.8153 - val_loss: 2.4531 - val_acc: 0.5453\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.4492 - acc: 0.8391 - val_loss: 2.5582 - val_acc: 0.5226\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.4912 - acc: 0.8137 - val_loss: 2.4768 - val_acc: 0.5362\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.3845 - acc: 0.8517 - val_loss: 2.4683 - val_acc: 0.5426\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.2954 - acc: 0.8719 - val_loss: 2.4313 - val_acc: 0.5389\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 1.3112 - acc: 0.8608 - val_loss: 2.5132 - val_acc: 0.5408\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.2703 - acc: 0.8660 - val_loss: 2.5331 - val_acc: 0.5380\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 4.1391 - acc: 0.4614 - val_loss: 3.8635 - val_acc: 0.5154\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6628 - acc: 0.5653 - val_loss: 3.7454 - val_acc: 0.5109\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.4293 - acc: 0.6260 - val_loss: 3.6871 - val_acc: 0.5362\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.2296 - acc: 0.6644 - val_loss: 3.5331 - val_acc: 0.5507\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0411 - acc: 0.7048 - val_loss: 3.4666 - val_acc: 0.5335\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8544 - acc: 0.7506 - val_loss: 3.4034 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6989 - acc: 0.7793 - val_loss: 3.3545 - val_acc: 0.5281\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5419 - acc: 0.8123 - val_loss: 3.3143 - val_acc: 0.5417\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3917 - acc: 0.8401 - val_loss: 3.1870 - val_acc: 0.5589\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2668 - acc: 0.8569 - val_loss: 3.1975 - val_acc: 0.5263\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1349 - acc: 0.8816 - val_loss: 3.1664 - val_acc: 0.5362\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0145 - acc: 0.8970 - val_loss: 3.0940 - val_acc: 0.5571\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8901 - acc: 0.9216 - val_loss: 3.0401 - val_acc: 0.5426\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7960 - acc: 0.9269 - val_loss: 2.9507 - val_acc: 0.5589\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7078 - acc: 0.9368 - val_loss: 3.0127 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6570 - acc: 0.9319 - val_loss: 2.9556 - val_acc: 0.5543\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5440 - acc: 0.9530 - val_loss: 2.8775 - val_acc: 0.5716\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4895 - acc: 0.9502 - val_loss: 2.8208 - val_acc: 0.5534\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4269 - acc: 0.9539 - val_loss: 2.8937 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3601 - acc: 0.9581 - val_loss: 2.7801 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3052 - acc: 0.9619 - val_loss: 2.8822 - val_acc: 0.5399\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2711 - acc: 0.9553 - val_loss: 2.8822 - val_acc: 0.5417\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2558 - acc: 0.9467 - val_loss: 2.7772 - val_acc: 0.5516\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2089 - acc: 0.9499 - val_loss: 2.7555 - val_acc: 0.5543\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1562 - acc: 0.9607 - val_loss: 2.7254 - val_acc: 0.5670\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1162 - acc: 0.9621 - val_loss: 2.6857 - val_acc: 0.5598\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0701 - acc: 0.9640 - val_loss: 2.7494 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 4.2222 - acc: 0.2338 - val_loss: 3.5629 - val_acc: 0.2717\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.2874 - acc: 0.2971 - val_loss: 3.0509 - val_acc: 0.2745\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9716 - acc: 0.3089 - val_loss: 2.9573 - val_acc: 0.3071\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 2.8062 - acc: 0.3407 - val_loss: 2.7409 - val_acc: 0.3478\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 2.8749 - acc: 0.3490 - val_loss: 2.9986 - val_acc: 0.3388\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 2.9192 - acc: 0.3842 - val_loss: 2.9133 - val_acc: 0.4212\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.0927 - acc: 0.4021 - val_loss: 3.0874 - val_acc: 0.3995\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.0812 - acc: 0.4219 - val_loss: 3.0933 - val_acc: 0.4457\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.2818 - acc: 0.4204 - val_loss: 3.2976 - val_acc: 0.4284\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.4599 - acc: 0.4227 - val_loss: 3.6087 - val_acc: 0.4158\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.7175 - acc: 0.4299 - val_loss: 3.6793 - val_acc: 0.4475\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.8423 - acc: 0.4330 - val_loss: 4.2003 - val_acc: 0.3931\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9582 - acc: 0.4337 - val_loss: 3.9225 - val_acc: 0.4420\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.0510 - acc: 0.4431 - val_loss: 4.1559 - val_acc: 0.4303\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1636 - acc: 0.4489 - val_loss: 4.1659 - val_acc: 0.4158\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1654 - acc: 0.4380 - val_loss: 4.2267 - val_acc: 0.4321\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1530 - acc: 0.4572 - val_loss: 4.2345 - val_acc: 0.4022\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1275 - acc: 0.4534 - val_loss: 4.2726 - val_acc: 0.4583\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.2668 - acc: 0.4517 - val_loss: 4.3418 - val_acc: 0.4384\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1588 - acc: 0.4638 - val_loss: 4.0788 - val_acc: 0.4447\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.2253 - acc: 0.4617 - val_loss: 4.3927 - val_acc: 0.4185\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.3326 - acc: 0.4548 - val_loss: 4.4830 - val_acc: 0.4493\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.5252 - acc: 0.4583 - val_loss: 4.4524 - val_acc: 0.4348\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.3142 - acc: 0.4691 - val_loss: 4.3665 - val_acc: 0.4475\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1827 - acc: 0.4683 - val_loss: 4.1551 - val_acc: 0.4556\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9183 - acc: 0.4818 - val_loss: 4.1385 - val_acc: 0.4429\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.0012 - acc: 0.4805 - val_loss: 4.1548 - val_acc: 0.4755\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9738 - acc: 0.4911 - val_loss: 4.0900 - val_acc: 0.4647\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9646 - acc: 0.4772 - val_loss: 4.2778 - val_acc: 0.4230\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1218 - acc: 0.4822 - val_loss: 4.1032 - val_acc: 0.4719\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.0314 - acc: 0.4902 - val_loss: 4.1044 - val_acc: 0.4764\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 4.1224 - acc: 0.4918 - val_loss: 4.0104 - val_acc: 0.4891\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9772 - acc: 0.4807 - val_loss: 3.8530 - val_acc: 0.4810\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.8332 - acc: 0.4878 - val_loss: 3.9562 - val_acc: 0.4783\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9037 - acc: 0.4934 - val_loss: 3.9514 - val_acc: 0.4900\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9704 - acc: 0.5010 - val_loss: 4.2882 - val_acc: 0.4683\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9364 - acc: 0.4997 - val_loss: 3.9583 - val_acc: 0.4783\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.8905 - acc: 0.5020 - val_loss: 4.0006 - val_acc: 0.4764\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8269 - acc: 0.4921 - val_loss: 3.8194 - val_acc: 0.4783\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.7590 - acc: 0.5039 - val_loss: 3.8692 - val_acc: 0.4484\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.6967 - acc: 0.5073 - val_loss: 3.7403 - val_acc: 0.4882\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.7494 - acc: 0.5091 - val_loss: 3.7441 - val_acc: 0.5163\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.8054 - acc: 0.4944 - val_loss: 3.9455 - val_acc: 0.4629\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9462 - acc: 0.4924 - val_loss: 4.0404 - val_acc: 0.4891\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9121 - acc: 0.5119 - val_loss: 3.9967 - val_acc: 0.4674\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.8655 - acc: 0.5059 - val_loss: 3.9361 - val_acc: 0.4973\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.8772 - acc: 0.5075 - val_loss: 4.1545 - val_acc: 0.4819\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9660 - acc: 0.5081 - val_loss: 4.1356 - val_acc: 0.4583\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9981 - acc: 0.5074 - val_loss: 4.0899 - val_acc: 0.4846\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9566 - acc: 0.5058 - val_loss: 3.9740 - val_acc: 0.5082\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 3.9084 - acc: 0.5039 - val_loss: 4.0855 - val_acc: 0.4538\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.0018 - acc: 0.5031 - val_loss: 4.0444 - val_acc: 0.4882\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 6.2971 - acc: 0.3551 - val_loss: 5.7132 - val_acc: 0.4493\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 5.4242 - acc: 0.4964 - val_loss: 5.2368 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 4.9352 - acc: 0.5493 - val_loss: 4.8397 - val_acc: 0.4937\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 4.4999 - acc: 0.5659 - val_loss: 4.4822 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 4.1264 - acc: 0.5840 - val_loss: 4.1561 - val_acc: 0.5344\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 3.7610 - acc: 0.6120 - val_loss: 3.8537 - val_acc: 0.5335\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 3.4511 - acc: 0.6246 - val_loss: 3.6291 - val_acc: 0.5172\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 634us/step - loss: 3.1737 - acc: 0.6350 - val_loss: 3.4678 - val_acc: 0.5063\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 2.9389 - acc: 0.6461 - val_loss: 3.2545 - val_acc: 0.5272\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.7253 - acc: 0.6610 - val_loss: 3.0882 - val_acc: 0.5426\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 2.5577 - acc: 0.6660 - val_loss: 2.8740 - val_acc: 0.5525\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.3621 - acc: 0.6940 - val_loss: 2.8079 - val_acc: 0.5344\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 2.2157 - acc: 0.7019 - val_loss: 2.7025 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 2.1413 - acc: 0.6960 - val_loss: 2.5994 - val_acc: 0.5371\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 2.0265 - acc: 0.7057 - val_loss: 2.5751 - val_acc: 0.5417\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.9298 - acc: 0.7193 - val_loss: 2.4501 - val_acc: 0.5543\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.8536 - acc: 0.7277 - val_loss: 2.4502 - val_acc: 0.5471\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 1.8065 - acc: 0.7287 - val_loss: 2.4874 - val_acc: 0.5308\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 1.7571 - acc: 0.7395 - val_loss: 2.4388 - val_acc: 0.5308\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.6706 - acc: 0.7551 - val_loss: 2.3858 - val_acc: 0.5299\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.6613 - acc: 0.7482 - val_loss: 2.4379 - val_acc: 0.5353\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.6539 - acc: 0.7492 - val_loss: 2.5197 - val_acc: 0.5145\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.6217 - acc: 0.7566 - val_loss: 2.3578 - val_acc: 0.5417\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 1.5591 - acc: 0.7743 - val_loss: 2.3375 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 1.5454 - acc: 0.7752 - val_loss: 2.4205 - val_acc: 0.5516\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.5616 - acc: 0.7672 - val_loss: 2.3681 - val_acc: 0.5344\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 7.3108 - acc: 0.3763 - val_loss: 6.5580 - val_acc: 0.4837\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 6.1954 - acc: 0.5341 - val_loss: 5.9642 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 5.4961 - acc: 0.5719 - val_loss: 5.3981 - val_acc: 0.4909\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 4.8581 - acc: 0.6052 - val_loss: 4.8700 - val_acc: 0.5208\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 4.3466 - acc: 0.6044 - val_loss: 4.3377 - val_acc: 0.5199\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 3.8153 - acc: 0.6449 - val_loss: 3.9571 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 3.4034 - acc: 0.6619 - val_loss: 3.7648 - val_acc: 0.4964\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 3.1149 - acc: 0.6609 - val_loss: 3.3756 - val_acc: 0.5308\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 6s 684us/step - loss: 2.8052 - acc: 0.6775 - val_loss: 3.1143 - val_acc: 0.5326\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 2.5254 - acc: 0.7113 - val_loss: 2.9651 - val_acc: 0.5281\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 2.3462 - acc: 0.7022 - val_loss: 2.8851 - val_acc: 0.5417\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 2.1959 - acc: 0.7080 - val_loss: 2.6321 - val_acc: 0.5435\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.0372 - acc: 0.7276 - val_loss: 2.6113 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.9264 - acc: 0.7366 - val_loss: 2.6096 - val_acc: 0.5308\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.8127 - acc: 0.7463 - val_loss: 2.5176 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 1.7558 - acc: 0.7463 - val_loss: 2.4073 - val_acc: 0.5480\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 1.6377 - acc: 0.7686 - val_loss: 2.3899 - val_acc: 0.5226\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.5561 - acc: 0.7798 - val_loss: 2.3974 - val_acc: 0.5362\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.5204 - acc: 0.7807 - val_loss: 2.3888 - val_acc: 0.5217\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 1.4918 - acc: 0.7815 - val_loss: 2.3179 - val_acc: 0.5299\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.4374 - acc: 0.7971 - val_loss: 2.3277 - val_acc: 0.5353\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.4043 - acc: 0.8027 - val_loss: 2.3375 - val_acc: 0.5172\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.3809 - acc: 0.7999 - val_loss: 2.2940 - val_acc: 0.5326\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.3558 - acc: 0.7994 - val_loss: 2.2793 - val_acc: 0.5353\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.3268 - acc: 0.8063 - val_loss: 2.2891 - val_acc: 0.5408\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.2905 - acc: 0.8203 - val_loss: 2.2594 - val_acc: 0.5489\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.3413 - acc: 0.8045 - val_loss: 2.2528 - val_acc: 0.5371\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.2806 - acc: 0.8242 - val_loss: 2.3525 - val_acc: 0.5326\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 1.2723 - acc: 0.8222 - val_loss: 2.3650 - val_acc: 0.5308\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 1.2189 - acc: 0.8431 - val_loss: 2.3262 - val_acc: 0.5371\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.2239 - acc: 0.8326 - val_loss: 2.3202 - val_acc: 0.5489\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.1904 - acc: 0.8497 - val_loss: 2.2935 - val_acc: 0.5507\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.1930 - acc: 0.8441 - val_loss: 2.3597 - val_acc: 0.5236\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.1967 - acc: 0.8395 - val_loss: 2.3555 - val_acc: 0.5389\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.2477 - acc: 0.8197 - val_loss: 2.2923 - val_acc: 0.5408\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.1576 - acc: 0.8622 - val_loss: 2.5096 - val_acc: 0.5326\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 1.1630 - acc: 0.8516 - val_loss: 2.5161 - val_acc: 0.5308\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 1.2099 - acc: 0.8346 - val_loss: 2.4349 - val_acc: 0.5335\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.2040 - acc: 0.8378 - val_loss: 2.3703 - val_acc: 0.5399\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 1.1998 - acc: 0.8504 - val_loss: 2.4495 - val_acc: 0.5344\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.1629 - acc: 0.8581 - val_loss: 2.5024 - val_acc: 0.5145\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.1597 - acc: 0.8596 - val_loss: 2.3920 - val_acc: 0.5553\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.1346 - acc: 0.8692 - val_loss: 2.4451 - val_acc: 0.5272\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.1769 - acc: 0.8515 - val_loss: 2.4154 - val_acc: 0.5435\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.0967 - acc: 0.8793 - val_loss: 2.4447 - val_acc: 0.5399\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.0732 - acc: 0.8808 - val_loss: 2.4299 - val_acc: 0.5344\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1.1149 - acc: 0.8645 - val_loss: 2.4701 - val_acc: 0.5172\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 1.1158 - acc: 0.8688 - val_loss: 2.4686 - val_acc: 0.5534\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.1195 - acc: 0.8659 - val_loss: 2.4876 - val_acc: 0.5498\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 1.1736 - acc: 0.8473 - val_loss: 2.4052 - val_acc: 0.5290\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.1486 - acc: 0.8624 - val_loss: 2.4569 - val_acc: 0.5444\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 1.1277 - acc: 0.8693 - val_loss: 2.4710 - val_acc: 0.5290\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 9.6744 - acc: 0.3595 - val_loss: 8.7488 - val_acc: 0.4547\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 8.0527 - acc: 0.5058 - val_loss: 7.4129 - val_acc: 0.4982\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 6.7503 - acc: 0.5455 - val_loss: 6.3872 - val_acc: 0.4982\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 5.6486 - acc: 0.5656 - val_loss: 5.3376 - val_acc: 0.4982\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 4.7367 - acc: 0.5846 - val_loss: 4.5823 - val_acc: 0.5063\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 4.0564 - acc: 0.5927 - val_loss: 3.9755 - val_acc: 0.5217\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 3.4978 - acc: 0.6101 - val_loss: 3.6247 - val_acc: 0.5163\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 3.0825 - acc: 0.6185 - val_loss: 3.3276 - val_acc: 0.5217\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 2.7973 - acc: 0.6072 - val_loss: 2.9909 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 2.5297 - acc: 0.6237 - val_loss: 2.8664 - val_acc: 0.5027\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.3317 - acc: 0.6336 - val_loss: 2.6288 - val_acc: 0.5145\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.1437 - acc: 0.6437 - val_loss: 2.4796 - val_acc: 0.5263\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 2.0097 - acc: 0.6584 - val_loss: 2.4297 - val_acc: 0.5226\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.9438 - acc: 0.6499 - val_loss: 2.3350 - val_acc: 0.5226\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 1.8661 - acc: 0.6564 - val_loss: 2.3691 - val_acc: 0.5190\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 1.8387 - acc: 0.6502 - val_loss: 2.2771 - val_acc: 0.5217\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 1.7833 - acc: 0.6616 - val_loss: 2.2399 - val_acc: 0.5245\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.7366 - acc: 0.6591 - val_loss: 2.2282 - val_acc: 0.5190\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 1.7309 - acc: 0.6619 - val_loss: 2.2676 - val_acc: 0.5217\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: 8.0134 - acc: 0.3989 - val_loss: 7.3978 - val_acc: 0.4891\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 7.1502 - acc: 0.5194 - val_loss: 6.9425 - val_acc: 0.4973\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 6.5910 - acc: 0.5592 - val_loss: 6.5180 - val_acc: 0.4855\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 6.0714 - acc: 0.5818 - val_loss: 6.0109 - val_acc: 0.5299\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 5.5530 - acc: 0.6037 - val_loss: 5.6438 - val_acc: 0.5254\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 5.1004 - acc: 0.6309 - val_loss: 5.1215 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 4.6620 - acc: 0.6411 - val_loss: 4.7393 - val_acc: 0.5516\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 4.2572 - acc: 0.6710 - val_loss: 4.4841 - val_acc: 0.5480\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 3.9227 - acc: 0.6737 - val_loss: 4.2264 - val_acc: 0.5534\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 3.6054 - acc: 0.6902 - val_loss: 3.9395 - val_acc: 0.5652\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 3.3275 - acc: 0.7115 - val_loss: 3.7689 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 3.1112 - acc: 0.7099 - val_loss: 3.6426 - val_acc: 0.5190\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 2.8892 - acc: 0.7154 - val_loss: 3.3247 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 638us/step - loss: 2.6482 - acc: 0.7467 - val_loss: 3.1643 - val_acc: 0.5453\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 2.4599 - acc: 0.7632 - val_loss: 3.0222 - val_acc: 0.5525\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.3072 - acc: 0.7670 - val_loss: 2.8776 - val_acc: 0.5643\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 2.1825 - acc: 0.7689 - val_loss: 2.8173 - val_acc: 0.5607\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.0782 - acc: 0.7738 - val_loss: 2.7673 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 1.9701 - acc: 0.7857 - val_loss: 2.7884 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.8811 - acc: 0.7870 - val_loss: 2.6248 - val_acc: 0.5507\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 5.8940 - acc: 0.4750 - val_loss: 5.5706 - val_acc: 0.5154\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 5.1972 - acc: 0.6002 - val_loss: 5.3019 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.7317 - acc: 0.6612 - val_loss: 4.9908 - val_acc: 0.5254\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.3142 - acc: 0.7236 - val_loss: 4.6529 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.9329 - acc: 0.7624 - val_loss: 4.4460 - val_acc: 0.5317\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5929 - acc: 0.8004 - val_loss: 4.1934 - val_acc: 0.5498\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2771 - acc: 0.8345 - val_loss: 3.9602 - val_acc: 0.5534\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0105 - acc: 0.8541 - val_loss: 3.7730 - val_acc: 0.5553\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7539 - acc: 0.8761 - val_loss: 3.6242 - val_acc: 0.5435\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5043 - acc: 0.9098 - val_loss: 3.5068 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3162 - acc: 0.9144 - val_loss: 3.3511 - val_acc: 0.5525\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1424 - acc: 0.9246 - val_loss: 3.3496 - val_acc: 0.5263\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0043 - acc: 0.9265 - val_loss: 3.2185 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8608 - acc: 0.9320 - val_loss: 3.0775 - val_acc: 0.5625\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7456 - acc: 0.9327 - val_loss: 3.0493 - val_acc: 0.5426\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6559 - acc: 0.9323 - val_loss: 2.9763 - val_acc: 0.5408\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.5664 - acc: 0.9349 - val_loss: 2.9103 - val_acc: 0.5444\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5114 - acc: 0.9257 - val_loss: 2.8525 - val_acc: 0.5317\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4260 - acc: 0.9341 - val_loss: 2.8661 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3447 - acc: 0.9460 - val_loss: 2.7523 - val_acc: 0.5562\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2632 - acc: 0.9496 - val_loss: 2.7781 - val_acc: 0.5290\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2199 - acc: 0.9484 - val_loss: 2.6877 - val_acc: 0.5335\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.1511 - acc: 0.9548 - val_loss: 2.6716 - val_acc: 0.5380\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.1535 - acc: 0.9336 - val_loss: 2.7969 - val_acc: 0.5199\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 10.3770 - acc: 0.3914 - val_loss: 9.5240 - val_acc: 0.4755\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 636us/step - loss: 8.9350 - acc: 0.5379 - val_loss: 8.4705 - val_acc: 0.5181\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 7.8132 - acc: 0.5937 - val_loss: 7.5424 - val_acc: 0.5091\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 6.8372 - acc: 0.6113 - val_loss: 6.6572 - val_acc: 0.5163\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 5.9440 - acc: 0.6416 - val_loss: 5.8566 - val_acc: 0.5399\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 5.1966 - acc: 0.6525 - val_loss: 5.2438 - val_acc: 0.5389\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 4.5520 - acc: 0.6784 - val_loss: 4.7089 - val_acc: 0.5471\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 4.0421 - acc: 0.6832 - val_loss: 4.2876 - val_acc: 0.5344\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 3.5649 - acc: 0.7077 - val_loss: 3.9685 - val_acc: 0.5299\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 647us/step - loss: 3.2255 - acc: 0.7086 - val_loss: 3.5951 - val_acc: 0.5281\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 2.9020 - acc: 0.7227 - val_loss: 3.3888 - val_acc: 0.5353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 2.6441 - acc: 0.7310 - val_loss: 3.1324 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 2.3952 - acc: 0.7573 - val_loss: 2.9643 - val_acc: 0.5444\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 2.2047 - acc: 0.7669 - val_loss: 2.8279 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 2.0648 - acc: 0.7633 - val_loss: 2.7623 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 1.9605 - acc: 0.7649 - val_loss: 2.6971 - val_acc: 0.5236\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 1.8490 - acc: 0.7719 - val_loss: 2.6162 - val_acc: 0.5371\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.7442 - acc: 0.7857 - val_loss: 2.5458 - val_acc: 0.5408\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 1.7439 - acc: 0.7641 - val_loss: 2.4864 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.6080 - acc: 0.7996 - val_loss: 2.3819 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.5418 - acc: 0.8062 - val_loss: 2.3454 - val_acc: 0.5652\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.4738 - acc: 0.8138 - val_loss: 2.4083 - val_acc: 0.5435\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.4056 - acc: 0.8253 - val_loss: 2.3794 - val_acc: 0.5362\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 1.4392 - acc: 0.8029 - val_loss: 2.3968 - val_acc: 0.5245\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.4199 - acc: 0.8082 - val_loss: 2.3494 - val_acc: 0.5417\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.3712 - acc: 0.8186 - val_loss: 2.3503 - val_acc: 0.5389\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.3435 - acc: 0.8260 - val_loss: 2.2004 - val_acc: 0.5716\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.2798 - acc: 0.8405 - val_loss: 2.3006 - val_acc: 0.5516\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 1.2392 - acc: 0.8507 - val_loss: 2.2794 - val_acc: 0.5598\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 1.2069 - acc: 0.8528 - val_loss: 2.3435 - val_acc: 0.5399\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.2756 - acc: 0.8215 - val_loss: 2.4014 - val_acc: 0.5444\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 1.3027 - acc: 0.8157 - val_loss: 2.2188 - val_acc: 0.5625\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.2018 - acc: 0.8554 - val_loss: 2.2617 - val_acc: 0.5399\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.1681 - acc: 0.8611 - val_loss: 2.4387 - val_acc: 0.5208\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.2126 - acc: 0.8393 - val_loss: 2.4164 - val_acc: 0.5426\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.1637 - acc: 0.8606 - val_loss: 2.3813 - val_acc: 0.5326\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.1972 - acc: 0.8393 - val_loss: 2.4557 - val_acc: 0.5344\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 30s 3ms/step - loss: nan - acc: 0.0707 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 609us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 625us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 590us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 632us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 621us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 11.3333 - acc: 0.3882 - val_loss: 10.3683 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 9.7385 - acc: 0.5238 - val_loss: 9.1687 - val_acc: 0.5054\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 8.4116 - acc: 0.5625 - val_loss: 7.9393 - val_acc: 0.4964\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 7.1714 - acc: 0.6009 - val_loss: 6.9186 - val_acc: 0.5199\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 6.1697 - acc: 0.6055 - val_loss: 5.8947 - val_acc: 0.5353\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 5.3076 - acc: 0.6188 - val_loss: 5.2439 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 4.5754 - acc: 0.6440 - val_loss: 4.6215 - val_acc: 0.5308\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 3.9900 - acc: 0.6536 - val_loss: 4.0940 - val_acc: 0.5317\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 3.5210 - acc: 0.6645 - val_loss: 3.7653 - val_acc: 0.5236\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.1633 - acc: 0.6627 - val_loss: 3.3617 - val_acc: 0.5489\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.8312 - acc: 0.6770 - val_loss: 3.1191 - val_acc: 0.5389\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 2.5580 - acc: 0.6892 - val_loss: 2.9553 - val_acc: 0.5217\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.4072 - acc: 0.6772 - val_loss: 2.7627 - val_acc: 0.5380\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 2.2299 - acc: 0.6922 - val_loss: 2.6775 - val_acc: 0.5245\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.0558 - acc: 0.7114 - val_loss: 2.5762 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.9435 - acc: 0.7115 - val_loss: 2.4159 - val_acc: 0.5426\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.8839 - acc: 0.7099 - val_loss: 2.3449 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.7856 - acc: 0.7163 - val_loss: 2.4718 - val_acc: 0.5172\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 1.7433 - acc: 0.7166 - val_loss: 2.4520 - val_acc: 0.5027\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.7241 - acc: 0.7110 - val_loss: 2.2440 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 1.6256 - acc: 0.7392 - val_loss: 2.2521 - val_acc: 0.5435\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.5663 - acc: 0.7440 - val_loss: 2.2687 - val_acc: 0.5471\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 1.5342 - acc: 0.7454 - val_loss: 2.2975 - val_acc: 0.5344\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.5247 - acc: 0.7402 - val_loss: 2.1874 - val_acc: 0.5525\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.5002 - acc: 0.7522 - val_loss: 2.2587 - val_acc: 0.5118\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.4635 - acc: 0.7551 - val_loss: 2.2238 - val_acc: 0.5399\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.4145 - acc: 0.7658 - val_loss: 2.1754 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: 11.4971 - acc: 0.3855 - val_loss: 10.2304 - val_acc: 0.4547\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 9.2757 - acc: 0.5320 - val_loss: 8.4190 - val_acc: 0.4891\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 7.4731 - acc: 0.5647 - val_loss: 6.8537 - val_acc: 0.5254\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 6.0033 - acc: 0.5900 - val_loss: 5.6283 - val_acc: 0.5190\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 4.9007 - acc: 0.5977 - val_loss: 4.7936 - val_acc: 0.5045\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 4.0802 - acc: 0.6096 - val_loss: 4.1032 - val_acc: 0.5009\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 3.4636 - acc: 0.6129 - val_loss: 3.4274 - val_acc: 0.5317\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 2.9870 - acc: 0.6297 - val_loss: 3.1320 - val_acc: 0.5326\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 2.6577 - acc: 0.6296 - val_loss: 2.9119 - val_acc: 0.5254\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.4315 - acc: 0.6263 - val_loss: 2.7435 - val_acc: 0.5054\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 2.2515 - acc: 0.6303 - val_loss: 2.4770 - val_acc: 0.5317\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 2.0519 - acc: 0.6522 - val_loss: 2.5448 - val_acc: 0.5018\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.9713 - acc: 0.6397 - val_loss: 2.3064 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.8561 - acc: 0.6555 - val_loss: 2.2637 - val_acc: 0.5190\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.7941 - acc: 0.6553 - val_loss: 2.2322 - val_acc: 0.5217\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.7054 - acc: 0.6633 - val_loss: 2.2003 - val_acc: 0.5072\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.6712 - acc: 0.6690 - val_loss: 2.1360 - val_acc: 0.5027\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.5971 - acc: 0.6780 - val_loss: 2.1130 - val_acc: 0.5399\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.5595 - acc: 0.6821 - val_loss: 2.1495 - val_acc: 0.5272\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.5433 - acc: 0.6737 - val_loss: 2.1131 - val_acc: 0.5136\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.5100 - acc: 0.6876 - val_loss: 2.0332 - val_acc: 0.5281\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.4820 - acc: 0.6933 - val_loss: 2.1965 - val_acc: 0.5217\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 1.4915 - acc: 0.6856 - val_loss: 2.0602 - val_acc: 0.5100\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.4376 - acc: 0.7004 - val_loss: 1.9837 - val_acc: 0.5371\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.4188 - acc: 0.7052 - val_loss: 1.9129 - val_acc: 0.5281\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 1.3818 - acc: 0.7082 - val_loss: 2.0532 - val_acc: 0.5308\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.3854 - acc: 0.7097 - val_loss: 2.0088 - val_acc: 0.5245\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.3739 - acc: 0.7095 - val_loss: 2.0525 - val_acc: 0.5281\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: 14.3169 - acc: 0.4005 - val_loss: 13.0608 - val_acc: 0.4692\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 12.0270 - acc: 0.5448 - val_loss: 11.0913 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 10.0279 - acc: 0.5830 - val_loss: 9.2593 - val_acc: 0.5163\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 8.2872 - acc: 0.6113 - val_loss: 7.7375 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 6.8428 - acc: 0.6419 - val_loss: 6.6444 - val_acc: 0.5181\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 5.7275 - acc: 0.6502 - val_loss: 5.6530 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 4.8233 - acc: 0.6711 - val_loss: 4.9104 - val_acc: 0.4973\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 4.1563 - acc: 0.6629 - val_loss: 4.2789 - val_acc: 0.5462\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 3.6089 - acc: 0.6772 - val_loss: 3.7551 - val_acc: 0.5389\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 3.1694 - acc: 0.6861 - val_loss: 3.4783 - val_acc: 0.5399\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.8782 - acc: 0.6704 - val_loss: 3.2150 - val_acc: 0.5199\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.5655 - acc: 0.6975 - val_loss: 2.9757 - val_acc: 0.5217\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 2.3904 - acc: 0.6873 - val_loss: 2.8159 - val_acc: 0.5299\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.2147 - acc: 0.6997 - val_loss: 2.6075 - val_acc: 0.5534\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 2.0546 - acc: 0.7138 - val_loss: 2.5326 - val_acc: 0.5317\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 1.9501 - acc: 0.7078 - val_loss: 2.6025 - val_acc: 0.5100\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 1.8575 - acc: 0.7111 - val_loss: 2.4096 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.7386 - acc: 0.7318 - val_loss: 2.3771 - val_acc: 0.5272\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 1.6889 - acc: 0.7308 - val_loss: 2.2484 - val_acc: 0.5408\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.5858 - acc: 0.7453 - val_loss: 2.3613 - val_acc: 0.5100\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 1.6052 - acc: 0.7233 - val_loss: 2.2622 - val_acc: 0.5471\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 1.5331 - acc: 0.7379 - val_loss: 2.2511 - val_acc: 0.5308\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.5007 - acc: 0.7385 - val_loss: 2.1473 - val_acc: 0.5580\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.3924 - acc: 0.7771 - val_loss: 2.1642 - val_acc: 0.5471\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.3957 - acc: 0.7629 - val_loss: 2.2105 - val_acc: 0.5181\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.3873 - acc: 0.7581 - val_loss: 2.2351 - val_acc: 0.5272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.4022 - acc: 0.7548 - val_loss: 2.1163 - val_acc: 0.5389\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 1.3453 - acc: 0.7725 - val_loss: 2.1627 - val_acc: 0.5462\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 1.2929 - acc: 0.7787 - val_loss: 2.0728 - val_acc: 0.5498\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.3157 - acc: 0.7711 - val_loss: 2.1988 - val_acc: 0.5163\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.3003 - acc: 0.7698 - val_loss: 2.2300 - val_acc: 0.5371\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1.2903 - acc: 0.7769 - val_loss: 2.2098 - val_acc: 0.5399\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 1.2604 - acc: 0.7868 - val_loss: 2.2109 - val_acc: 0.5344\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: 3.8041 - acc: 0.3568 - val_loss: 3.1915 - val_acc: 0.4611\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 2.9938 - acc: 0.5117 - val_loss: 3.0180 - val_acc: 0.5054\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 2.7675 - acc: 0.5596 - val_loss: 2.8524 - val_acc: 0.5054\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 2.6035 - acc: 0.5890 - val_loss: 2.7976 - val_acc: 0.5036\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 2.4525 - acc: 0.6111 - val_loss: 2.6884 - val_acc: 0.5272\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 2.3130 - acc: 0.6276 - val_loss: 2.6736 - val_acc: 0.5263\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.2043 - acc: 0.6483 - val_loss: 2.5573 - val_acc: 0.5290\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.0580 - acc: 0.6772 - val_loss: 2.4686 - val_acc: 0.5553\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 1.9525 - acc: 0.6903 - val_loss: 2.4194 - val_acc: 0.5199\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.8668 - acc: 0.7013 - val_loss: 2.5057 - val_acc: 0.5299\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 1.7385 - acc: 0.7452 - val_loss: 2.4126 - val_acc: 0.5335\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.6820 - acc: 0.7428 - val_loss: 2.4235 - val_acc: 0.5389\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.6020 - acc: 0.7642 - val_loss: 2.3442 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.5443 - acc: 0.7737 - val_loss: 2.4348 - val_acc: 0.5290\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.4933 - acc: 0.7879 - val_loss: 2.3468 - val_acc: 0.5226\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.4196 - acc: 0.8056 - val_loss: 2.3369 - val_acc: 0.5589\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.3610 - acc: 0.8230 - val_loss: 2.4622 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.2843 - acc: 0.8449 - val_loss: 2.4202 - val_acc: 0.5625\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.2414 - acc: 0.8555 - val_loss: 2.4796 - val_acc: 0.5236\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.2663 - acc: 0.8403 - val_loss: 2.4791 - val_acc: 0.5236\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.2194 - acc: 0.8592 - val_loss: 2.4481 - val_acc: 0.5571\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.1642 - acc: 0.8767 - val_loss: 2.5124 - val_acc: 0.5426\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 1.1595 - acc: 0.8716 - val_loss: 2.4742 - val_acc: 0.5480\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.1615 - acc: 0.8721 - val_loss: 2.5581 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 1.1234 - acc: 0.8827 - val_loss: 2.5545 - val_acc: 0.5417\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1.1350 - acc: 0.8758 - val_loss: 2.6407 - val_acc: 0.5226\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.1163 - acc: 0.8880 - val_loss: 2.5735 - val_acc: 0.5272\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.1055 - acc: 0.8897 - val_loss: 2.5354 - val_acc: 0.5408\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 4ms/step - loss: 11.2830 - acc: 0.3948 - val_loss: 10.6540 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 10.2832 - acc: 0.5018 - val_loss: 9.8894 - val_acc: 0.4819\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 9.4245 - acc: 0.5389 - val_loss: 9.1076 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 8.6351 - acc: 0.5719 - val_loss: 8.3595 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 7.8911 - acc: 0.5987 - val_loss: 7.7099 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 7.2331 - acc: 0.5932 - val_loss: 7.0758 - val_acc: 0.5426\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 6.5858 - acc: 0.6250 - val_loss: 6.5865 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 6.0084 - acc: 0.6404 - val_loss: 5.9785 - val_acc: 0.5543\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 5.5010 - acc: 0.6471 - val_loss: 5.5382 - val_acc: 0.5562\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 5.0046 - acc: 0.6672 - val_loss: 5.1555 - val_acc: 0.5471\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 4.5708 - acc: 0.6764 - val_loss: 4.7743 - val_acc: 0.5607\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 4.2214 - acc: 0.6784 - val_loss: 4.4803 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 3.8774 - acc: 0.6910 - val_loss: 4.1687 - val_acc: 0.5489\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 3.5683 - acc: 0.7020 - val_loss: 3.9060 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 3.2934 - acc: 0.7125 - val_loss: 3.6686 - val_acc: 0.5553\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 3.0776 - acc: 0.7150 - val_loss: 3.5300 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 2.8412 - acc: 0.7292 - val_loss: 3.2957 - val_acc: 0.5507\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 2.6513 - acc: 0.7405 - val_loss: 3.1469 - val_acc: 0.5652\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 2.4907 - acc: 0.7490 - val_loss: 3.0254 - val_acc: 0.5534\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 2.3458 - acc: 0.7501 - val_loss: 2.9539 - val_acc: 0.5462\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.2237 - acc: 0.7530 - val_loss: 2.8030 - val_acc: 0.5480\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 2.1526 - acc: 0.7450 - val_loss: 2.7413 - val_acc: 0.5553\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.0303 - acc: 0.7646 - val_loss: 2.6887 - val_acc: 0.5553\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.9404 - acc: 0.7691 - val_loss: 2.6876 - val_acc: 0.5435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 1.8548 - acc: 0.7777 - val_loss: 2.6249 - val_acc: 0.5399\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.7834 - acc: 0.7797 - val_loss: 2.4635 - val_acc: 0.5625\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 1.7060 - acc: 0.7872 - val_loss: 2.4267 - val_acc: 0.5543\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 1.6546 - acc: 0.7932 - val_loss: 2.5117 - val_acc: 0.5417\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 6.1149 - acc: 0.4762 - val_loss: 5.8700 - val_acc: 0.5063\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 5.4896 - acc: 0.6200 - val_loss: 5.6421 - val_acc: 0.5344\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 5.1570 - acc: 0.6940 - val_loss: 5.4270 - val_acc: 0.5516\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.8591 - acc: 0.7554 - val_loss: 5.2608 - val_acc: 0.5607\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.5772 - acc: 0.8109 - val_loss: 5.1551 - val_acc: 0.5697\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.3085 - acc: 0.8558 - val_loss: 4.9907 - val_acc: 0.5589\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.0669 - acc: 0.8942 - val_loss: 4.8507 - val_acc: 0.5716\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8570 - acc: 0.9131 - val_loss: 4.7500 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6435 - acc: 0.9390 - val_loss: 4.5571 - val_acc: 0.5788\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4479 - acc: 0.9536 - val_loss: 4.4335 - val_acc: 0.5634\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2567 - acc: 0.9664 - val_loss: 4.3332 - val_acc: 0.5734\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0807 - acc: 0.9768 - val_loss: 4.2637 - val_acc: 0.5824\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9131 - acc: 0.9846 - val_loss: 4.0671 - val_acc: 0.5752\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7962 - acc: 0.9727 - val_loss: 4.0625 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6773 - acc: 0.9730 - val_loss: 3.9156 - val_acc: 0.5634\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5503 - acc: 0.9723 - val_loss: 3.8543 - val_acc: 0.5634\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4142 - acc: 0.9790 - val_loss: 3.7224 - val_acc: 0.5643\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2735 - acc: 0.9870 - val_loss: 3.6942 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1824 - acc: 0.9814 - val_loss: 3.5503 - val_acc: 0.5697\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0544 - acc: 0.9877 - val_loss: 3.4923 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.9985 - acc: 0.9716 - val_loss: 3.5034 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9974 - acc: 0.9400 - val_loss: 3.3516 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 17.4036 - acc: 0.3885 - val_loss: 16.3701 - val_acc: 0.4611\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 15.4080 - acc: 0.5106 - val_loss: 14.5187 - val_acc: 0.4964\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 13.6083 - acc: 0.5505 - val_loss: 12.8281 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 11.9723 - acc: 0.5693 - val_loss: 11.3364 - val_acc: 0.5326\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 10.4615 - acc: 0.6011 - val_loss: 9.9507 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 9.1752 - acc: 0.6124 - val_loss: 8.8259 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 8.0277 - acc: 0.6313 - val_loss: 7.7190 - val_acc: 0.5571\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 7.0288 - acc: 0.6480 - val_loss: 6.8685 - val_acc: 0.5516\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 6.2119 - acc: 0.6539 - val_loss: 6.1494 - val_acc: 0.5344\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 5.4675 - acc: 0.6681 - val_loss: 5.5221 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 4.8452 - acc: 0.6779 - val_loss: 4.9838 - val_acc: 0.5389\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 4.3487 - acc: 0.6739 - val_loss: 4.5240 - val_acc: 0.5335\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 3.8943 - acc: 0.6876 - val_loss: 4.1392 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 3.5254 - acc: 0.6922 - val_loss: 3.7983 - val_acc: 0.5607\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 3.1935 - acc: 0.7105 - val_loss: 3.5411 - val_acc: 0.5498\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 2.9418 - acc: 0.7026 - val_loss: 3.2896 - val_acc: 0.5435\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 2.7204 - acc: 0.7108 - val_loss: 3.2218 - val_acc: 0.5290\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 2.5553 - acc: 0.7098 - val_loss: 2.9610 - val_acc: 0.5707\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 2.3606 - acc: 0.7249 - val_loss: 2.8693 - val_acc: 0.5435\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 2.2332 - acc: 0.7221 - val_loss: 2.7047 - val_acc: 0.5489\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.1186 - acc: 0.7269 - val_loss: 2.6183 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.9848 - acc: 0.7406 - val_loss: 2.6442 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.9394 - acc: 0.7279 - val_loss: 2.5680 - val_acc: 0.5281\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.8770 - acc: 0.7312 - val_loss: 2.4686 - val_acc: 0.5462\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.8256 - acc: 0.7343 - val_loss: 2.3823 - val_acc: 0.5435\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.6908 - acc: 0.7623 - val_loss: 2.3442 - val_acc: 0.5317\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 1.6791 - acc: 0.7467 - val_loss: 2.4131 - val_acc: 0.5507\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.6547 - acc: 0.7446 - val_loss: 2.3067 - val_acc: 0.5598\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 14.4469 - acc: 0.3812 - val_loss: 13.8165 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 13.3988 - acc: 0.4937 - val_loss: 12.9776 - val_acc: 0.5199\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 643us/step - loss: 12.5562 - acc: 0.5309 - val_loss: 12.1572 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 11.7801 - acc: 0.5502 - val_loss: 11.4790 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 11.0204 - acc: 0.5687 - val_loss: 10.7835 - val_acc: 0.5417\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 10.2872 - acc: 0.5969 - val_loss: 10.0880 - val_acc: 0.5634\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 9.6152 - acc: 0.6077 - val_loss: 9.4890 - val_acc: 0.5534\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 8.9802 - acc: 0.6183 - val_loss: 8.9295 - val_acc: 0.5389\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 8.3818 - acc: 0.6378 - val_loss: 8.3473 - val_acc: 0.5580\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 7.8118 - acc: 0.6515 - val_loss: 7.8128 - val_acc: 0.5598\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 7.2763 - acc: 0.6585 - val_loss: 7.3409 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 6.7931 - acc: 0.6663 - val_loss: 6.8744 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 6.3455 - acc: 0.6739 - val_loss: 6.5455 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 5.9377 - acc: 0.6868 - val_loss: 6.1426 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 5.5341 - acc: 0.6985 - val_loss: 5.7480 - val_acc: 0.5607\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 5.1557 - acc: 0.7133 - val_loss: 5.4525 - val_acc: 0.5643\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 4.8432 - acc: 0.7144 - val_loss: 5.1664 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 4.5446 - acc: 0.7165 - val_loss: 4.8883 - val_acc: 0.5688\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 4.2724 - acc: 0.7192 - val_loss: 4.6698 - val_acc: 0.5525\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 4.0151 - acc: 0.7353 - val_loss: 4.4455 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.7776 - acc: 0.7370 - val_loss: 4.2144 - val_acc: 0.5761\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 3.5358 - acc: 0.7612 - val_loss: 4.0953 - val_acc: 0.5471\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 3.3563 - acc: 0.7533 - val_loss: 3.8710 - val_acc: 0.5652\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 3.1766 - acc: 0.7610 - val_loss: 3.6790 - val_acc: 0.5688\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 3.0187 - acc: 0.7557 - val_loss: 3.6376 - val_acc: 0.5389\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 2.8500 - acc: 0.7789 - val_loss: 3.5034 - val_acc: 0.5534\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.7064 - acc: 0.7734 - val_loss: 3.3309 - val_acc: 0.5652\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.5811 - acc: 0.7843 - val_loss: 3.2624 - val_acc: 0.5634\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 2.4507 - acc: 0.7958 - val_loss: 3.1745 - val_acc: 0.5543\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 2.3451 - acc: 0.7937 - val_loss: 3.0761 - val_acc: 0.5598\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 2.2625 - acc: 0.7935 - val_loss: 2.9878 - val_acc: 0.5734\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 17.0213 - acc: 0.4211 - val_loss: 16.1386 - val_acc: 0.5018\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 15.4858 - acc: 0.5331 - val_loss: 14.8689 - val_acc: 0.5217\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 638us/step - loss: 14.1591 - acc: 0.5829 - val_loss: 13.6815 - val_acc: 0.5226\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 12.9136 - acc: 0.6074 - val_loss: 12.4841 - val_acc: 0.5534\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 11.7220 - acc: 0.6439 - val_loss: 11.4614 - val_acc: 0.5417\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 10.6660 - acc: 0.6525 - val_loss: 10.5074 - val_acc: 0.5353\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 9.6597 - acc: 0.6771 - val_loss: 9.5553 - val_acc: 0.5516\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 8.7821 - acc: 0.6882 - val_loss: 8.7523 - val_acc: 0.5489\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 7.9913 - acc: 0.6943 - val_loss: 8.0297 - val_acc: 0.5616\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 7.2508 - acc: 0.7171 - val_loss: 7.3397 - val_acc: 0.5643\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 6.6034 - acc: 0.7292 - val_loss: 6.8171 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 6.0316 - acc: 0.7421 - val_loss: 6.3127 - val_acc: 0.5453\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 5.5304 - acc: 0.7438 - val_loss: 5.8681 - val_acc: 0.5462\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 5.0550 - acc: 0.7580 - val_loss: 5.5001 - val_acc: 0.5380\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 4.6444 - acc: 0.7655 - val_loss: 5.0540 - val_acc: 0.5634\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 4.2928 - acc: 0.7696 - val_loss: 4.7739 - val_acc: 0.5453\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 3.9603 - acc: 0.7782 - val_loss: 4.4495 - val_acc: 0.5525\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 3.6619 - acc: 0.7899 - val_loss: 4.2067 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 3.3966 - acc: 0.8021 - val_loss: 3.9999 - val_acc: 0.5607\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 3.1839 - acc: 0.7947 - val_loss: 3.7949 - val_acc: 0.5589\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 21.8189 - acc: 0.3998 - val_loss: 20.7303 - val_acc: 0.4928\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 19.8417 - acc: 0.4987 - val_loss: 18.9459 - val_acc: 0.5217\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 647us/step - loss: 18.0811 - acc: 0.5370 - val_loss: 17.2352 - val_acc: 0.5308\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 16.4373 - acc: 0.5599 - val_loss: 15.6647 - val_acc: 0.5326\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 14.8751 - acc: 0.5729 - val_loss: 14.2066 - val_acc: 0.5625\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 13.4755 - acc: 0.5861 - val_loss: 12.8920 - val_acc: 0.5471\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 12.1673 - acc: 0.6090 - val_loss: 11.7026 - val_acc: 0.5616\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 11.0143 - acc: 0.6115 - val_loss: 10.6423 - val_acc: 0.5471\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 9.9399 - acc: 0.6325 - val_loss: 9.6919 - val_acc: 0.5371\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 8.9921 - acc: 0.6369 - val_loss: 8.8041 - val_acc: 0.5417\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 8.1357 - acc: 0.6456 - val_loss: 7.9649 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 7.3741 - acc: 0.6569 - val_loss: 7.2996 - val_acc: 0.5453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 6.6927 - acc: 0.6675 - val_loss: 6.6981 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 6.0924 - acc: 0.6659 - val_loss: 6.1025 - val_acc: 0.5661\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 5.5395 - acc: 0.6861 - val_loss: 5.6788 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 5.0776 - acc: 0.6852 - val_loss: 5.2305 - val_acc: 0.5598\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 4.6860 - acc: 0.6791 - val_loss: 4.9076 - val_acc: 0.5543\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 4.2827 - acc: 0.6975 - val_loss: 4.5435 - val_acc: 0.5580\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 3.9827 - acc: 0.6937 - val_loss: 4.2143 - val_acc: 0.5761\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 3.6835 - acc: 0.7021 - val_loss: 3.9558 - val_acc: 0.5752\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 3.4211 - acc: 0.7148 - val_loss: 3.7919 - val_acc: 0.5607\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.1708 - acc: 0.7238 - val_loss: 3.5566 - val_acc: 0.5589\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.9800 - acc: 0.7189 - val_loss: 3.4009 - val_acc: 0.5507\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 2.8056 - acc: 0.7248 - val_loss: 3.2372 - val_acc: 0.5589\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.6443 - acc: 0.7296 - val_loss: 3.1385 - val_acc: 0.5317\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 2.5356 - acc: 0.7179 - val_loss: 3.0059 - val_acc: 0.5498\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.3789 - acc: 0.7382 - val_loss: 3.0061 - val_acc: 0.5371\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 2.2616 - acc: 0.7480 - val_loss: 2.7964 - val_acc: 0.5707\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 2.1538 - acc: 0.7506 - val_loss: 2.7132 - val_acc: 0.5553\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 17.7397 - acc: 0.3925 - val_loss: 17.1028 - val_acc: 0.5054\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 609us/step - loss: 16.6751 - acc: 0.5033 - val_loss: 16.2310 - val_acc: 0.5236\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 15.8191 - acc: 0.5346 - val_loss: 15.4149 - val_acc: 0.5534\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 15.0059 - acc: 0.5584 - val_loss: 14.6939 - val_acc: 0.5417\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 14.2305 - acc: 0.5851 - val_loss: 13.9479 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 13.4624 - acc: 0.5996 - val_loss: 13.2521 - val_acc: 0.5507\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 643us/step - loss: 12.7445 - acc: 0.6134 - val_loss: 12.5505 - val_acc: 0.5589\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 12.0526 - acc: 0.6210 - val_loss: 11.9400 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: 11.3953 - acc: 0.6414 - val_loss: 11.3242 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 620us/step - loss: 10.7809 - acc: 0.6466 - val_loss: 10.7189 - val_acc: 0.5598\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 10.1870 - acc: 0.6620 - val_loss: 10.2245 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 9.6106 - acc: 0.6774 - val_loss: 9.6963 - val_acc: 0.5752\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: 9.0913 - acc: 0.6839 - val_loss: 9.2029 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 615us/step - loss: 8.5832 - acc: 0.6962 - val_loss: 8.7632 - val_acc: 0.5707\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 8.1143 - acc: 0.7122 - val_loss: 8.2793 - val_acc: 0.5770\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 7.6794 - acc: 0.7070 - val_loss: 7.9230 - val_acc: 0.5589\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 7.2881 - acc: 0.7094 - val_loss: 7.5210 - val_acc: 0.5589\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 6.8728 - acc: 0.7269 - val_loss: 7.1918 - val_acc: 0.5562\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 6.5011 - acc: 0.7378 - val_loss: 6.8112 - val_acc: 0.5770\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 6.1568 - acc: 0.7467 - val_loss: 6.5347 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 641us/step - loss: 5.8345 - acc: 0.7509 - val_loss: 6.2245 - val_acc: 0.5734\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 647us/step - loss: 5.5425 - acc: 0.7590 - val_loss: 6.0167 - val_acc: 0.5707\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 5.2601 - acc: 0.7563 - val_loss: 5.7150 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 5.0004 - acc: 0.7635 - val_loss: 5.4898 - val_acc: 0.5688\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 4.7539 - acc: 0.7748 - val_loss: 5.3031 - val_acc: 0.5652\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 31s 3ms/step - loss: nan - acc: 0.0699 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 587us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 13.8308 - acc: 0.4174 - val_loss: 12.9900 - val_acc: 0.5027\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 12.5056 - acc: 0.5326 - val_loss: 12.0270 - val_acc: 0.5091\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 11.4062 - acc: 0.5731 - val_loss: 10.9687 - val_acc: 0.5371\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 10.3381 - acc: 0.6091 - val_loss: 10.0339 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 9.3976 - acc: 0.6265 - val_loss: 9.2046 - val_acc: 0.5299\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 8.4889 - acc: 0.6499 - val_loss: 8.3952 - val_acc: 0.5562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 7.6857 - acc: 0.6772 - val_loss: 7.6086 - val_acc: 0.5580\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 6.9667 - acc: 0.6925 - val_loss: 7.0382 - val_acc: 0.5389\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 6.3255 - acc: 0.6976 - val_loss: 6.4329 - val_acc: 0.5543\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 5.7368 - acc: 0.7156 - val_loss: 5.9484 - val_acc: 0.5670\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 5.2413 - acc: 0.7189 - val_loss: 5.5143 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 4.7703 - acc: 0.7312 - val_loss: 5.0993 - val_acc: 0.5353\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 650us/step - loss: 4.3435 - acc: 0.7538 - val_loss: 4.8013 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 3.9966 - acc: 0.7611 - val_loss: 4.4314 - val_acc: 0.5580\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.7034 - acc: 0.7574 - val_loss: 4.1863 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 3.4152 - acc: 0.7608 - val_loss: 3.9890 - val_acc: 0.5290\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 3.1808 - acc: 0.7702 - val_loss: 3.7725 - val_acc: 0.5399\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 2.9332 - acc: 0.7900 - val_loss: 3.6058 - val_acc: 0.5453\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 2.7480 - acc: 0.7944 - val_loss: 3.4761 - val_acc: 0.5408\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 2.5906 - acc: 0.7985 - val_loss: 3.2446 - val_acc: 0.5571\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 24.7700 - acc: 0.3921 - val_loss: 22.7497 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 21.1279 - acc: 0.5025 - val_loss: 19.3643 - val_acc: 0.5009\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 17.8441 - acc: 0.5311 - val_loss: 16.3118 - val_acc: 0.5145\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 14.9407 - acc: 0.5629 - val_loss: 13.6535 - val_acc: 0.5236\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 12.4769 - acc: 0.5645 - val_loss: 11.5143 - val_acc: 0.5236\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 10.4154 - acc: 0.5872 - val_loss: 9.6035 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 8.6794 - acc: 0.6158 - val_loss: 8.0884 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 7.2923 - acc: 0.6183 - val_loss: 6.9533 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 6.1968 - acc: 0.6219 - val_loss: 5.9502 - val_acc: 0.5136\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 5.3029 - acc: 0.6220 - val_loss: 5.1261 - val_acc: 0.5326\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 4.5491 - acc: 0.6397 - val_loss: 4.5388 - val_acc: 0.5489\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 3.9774 - acc: 0.6419 - val_loss: 4.0129 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 3.5284 - acc: 0.6432 - val_loss: 3.6549 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 3.1690 - acc: 0.6496 - val_loss: 3.3433 - val_acc: 0.5353\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 2.8715 - acc: 0.6479 - val_loss: 3.1550 - val_acc: 0.5036\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 2.6343 - acc: 0.6432 - val_loss: 2.8688 - val_acc: 0.5426\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 2.4202 - acc: 0.6654 - val_loss: 2.8356 - val_acc: 0.5217\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 2.2907 - acc: 0.6573 - val_loss: 2.6163 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 2.1541 - acc: 0.6677 - val_loss: 2.4617 - val_acc: 0.5462\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 2.0360 - acc: 0.6687 - val_loss: 2.5883 - val_acc: 0.4928\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.9512 - acc: 0.6743 - val_loss: 2.2976 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 21.6712 - acc: 0.3742 - val_loss: 18.8955 - val_acc: 0.4511\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 16.6973 - acc: 0.5038 - val_loss: 14.2336 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 12.3726 - acc: 0.5406 - val_loss: 10.5513 - val_acc: 0.4918\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 9.1342 - acc: 0.5537 - val_loss: 7.8807 - val_acc: 0.5063\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 6.7737 - acc: 0.5729 - val_loss: 5.9479 - val_acc: 0.5163\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 5.2160 - acc: 0.5668 - val_loss: 4.7689 - val_acc: 0.5172\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 4.1663 - acc: 0.5693 - val_loss: 3.9360 - val_acc: 0.5036\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 3.4682 - acc: 0.5670 - val_loss: 3.4570 - val_acc: 0.5027\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 2.9647 - acc: 0.5790 - val_loss: 3.0258 - val_acc: 0.4801\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 2.5828 - acc: 0.5874 - val_loss: 2.7749 - val_acc: 0.4946\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 2.3488 - acc: 0.5920 - val_loss: 2.5366 - val_acc: 0.4918\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 2.1801 - acc: 0.5909 - val_loss: 2.4006 - val_acc: 0.5063\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 2.0669 - acc: 0.5979 - val_loss: 2.2724 - val_acc: 0.5145\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.9990 - acc: 0.5895 - val_loss: 2.2610 - val_acc: 0.5027\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.9050 - acc: 0.5963 - val_loss: 2.0640 - val_acc: 0.5190\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.8265 - acc: 0.5989 - val_loss: 2.0577 - val_acc: 0.5136\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 1.7704 - acc: 0.6100 - val_loss: 2.0519 - val_acc: 0.5127\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 1.7324 - acc: 0.6125 - val_loss: 2.3092 - val_acc: 0.4348\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 1.7410 - acc: 0.6117 - val_loss: 2.0113 - val_acc: 0.5272\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 1.6699 - acc: 0.6224 - val_loss: 2.1296 - val_acc: 0.4810\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.6773 - acc: 0.6185 - val_loss: 1.9862 - val_acc: 0.5263\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.6768 - acc: 0.6098 - val_loss: 1.9670 - val_acc: 0.5082\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.6556 - acc: 0.6169 - val_loss: 1.9100 - val_acc: 0.5399\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 1.5860 - acc: 0.6308 - val_loss: 1.9886 - val_acc: 0.5136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 1.5831 - acc: 0.6339 - val_loss: 2.1126 - val_acc: 0.5027\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.6430 - acc: 0.6162 - val_loss: 2.0586 - val_acc: 0.4891\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.5866 - acc: 0.6381 - val_loss: 1.8922 - val_acc: 0.5272\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 1.5247 - acc: 0.6458 - val_loss: 2.1492 - val_acc: 0.4855\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.6186 - acc: 0.6207 - val_loss: 1.9677 - val_acc: 0.5245\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.5907 - acc: 0.6337 - val_loss: 1.9668 - val_acc: 0.5236\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.5717 - acc: 0.6396 - val_loss: 2.0582 - val_acc: 0.5145\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.5621 - acc: 0.6318 - val_loss: 2.0324 - val_acc: 0.4973\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 1.5491 - acc: 0.6353 - val_loss: 1.9026 - val_acc: 0.5299\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 32s 4ms/step - loss: 24.0244 - acc: 0.3986 - val_loss: 20.8081 - val_acc: 0.4819\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 18.1442 - acc: 0.5317 - val_loss: 15.3734 - val_acc: 0.4764\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 13.1504 - acc: 0.5665 - val_loss: 11.1650 - val_acc: 0.4991\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 9.5230 - acc: 0.5825 - val_loss: 8.3134 - val_acc: 0.5000\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 7.0536 - acc: 0.5877 - val_loss: 6.3029 - val_acc: 0.5018\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 5.4093 - acc: 0.5930 - val_loss: 4.9956 - val_acc: 0.5127\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 4.2822 - acc: 0.6013 - val_loss: 4.2009 - val_acc: 0.4828\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 3.5554 - acc: 0.6009 - val_loss: 3.5295 - val_acc: 0.5100\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 3.0146 - acc: 0.6137 - val_loss: 3.0915 - val_acc: 0.5308\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.6629 - acc: 0.6072 - val_loss: 2.8036 - val_acc: 0.5254\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 2.4145 - acc: 0.6087 - val_loss: 2.5838 - val_acc: 0.4964\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 2.2053 - acc: 0.6211 - val_loss: 2.3744 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.0664 - acc: 0.6173 - val_loss: 2.2864 - val_acc: 0.5371\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.9098 - acc: 0.6364 - val_loss: 2.2564 - val_acc: 0.5036\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 1.8605 - acc: 0.6240 - val_loss: 2.1494 - val_acc: 0.5082\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.7853 - acc: 0.6293 - val_loss: 2.0915 - val_acc: 0.5326\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.7048 - acc: 0.6325 - val_loss: 2.0689 - val_acc: 0.5018\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.6795 - acc: 0.6355 - val_loss: 2.0473 - val_acc: 0.5000\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 1.6609 - acc: 0.6237 - val_loss: 1.9352 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 1.5837 - acc: 0.6434 - val_loss: 2.0054 - val_acc: 0.5063\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1.6056 - acc: 0.6217 - val_loss: 1.9953 - val_acc: 0.5254\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 1.5677 - acc: 0.6381 - val_loss: 2.1465 - val_acc: 0.4746\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 34.9262 - acc: 0.3827 - val_loss: 27.5394 - val_acc: 0.4755\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 22.1637 - acc: 0.5165 - val_loss: 16.7368 - val_acc: 0.4674\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 13.2545 - acc: 0.5263 - val_loss: 10.0891 - val_acc: 0.5009\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 8.1768 - acc: 0.5395 - val_loss: 6.6147 - val_acc: 0.4891\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 5.5053 - acc: 0.5380 - val_loss: 4.6686 - val_acc: 0.4928\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 3.9750 - acc: 0.5574 - val_loss: 3.6402 - val_acc: 0.4909\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 3.1670 - acc: 0.5525 - val_loss: 3.3306 - val_acc: 0.4429\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 2.7399 - acc: 0.5450 - val_loss: 2.7729 - val_acc: 0.4746\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.4437 - acc: 0.5383 - val_loss: 2.4674 - val_acc: 0.4918\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 2.2092 - acc: 0.5584 - val_loss: 2.3681 - val_acc: 0.4583\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.0517 - acc: 0.5601 - val_loss: 2.2624 - val_acc: 0.4366\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 1.9805 - acc: 0.5541 - val_loss: 2.2227 - val_acc: 0.4774\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 1.8581 - acc: 0.5652 - val_loss: 2.3254 - val_acc: 0.4493\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 14.5876 - acc: 0.3687 - val_loss: 14.0846 - val_acc: 0.4955\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 13.7748 - acc: 0.4811 - val_loss: 13.5322 - val_acc: 0.4991\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 13.1923 - acc: 0.5182 - val_loss: 12.9488 - val_acc: 0.5236\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 12.6683 - acc: 0.5403 - val_loss: 12.4821 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 12.1475 - acc: 0.5568 - val_loss: 12.0117 - val_acc: 0.5118\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 11.6479 - acc: 0.5714 - val_loss: 11.5177 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 647us/step - loss: 11.1619 - acc: 0.5847 - val_loss: 11.0533 - val_acc: 0.5344\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 10.6836 - acc: 0.5953 - val_loss: 10.6093 - val_acc: 0.5471\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 10.2309 - acc: 0.6152 - val_loss: 10.1733 - val_acc: 0.5562\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 9.8064 - acc: 0.6201 - val_loss: 9.8262 - val_acc: 0.5589\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 9.3751 - acc: 0.6291 - val_loss: 9.4356 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 8.9709 - acc: 0.6414 - val_loss: 8.9925 - val_acc: 0.5534\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 8.5886 - acc: 0.6504 - val_loss: 8.6383 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 8.2153 - acc: 0.6578 - val_loss: 8.3448 - val_acc: 0.5643\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 7.8411 - acc: 0.6704 - val_loss: 8.0078 - val_acc: 0.5589\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 7.5005 - acc: 0.6770 - val_loss: 7.6862 - val_acc: 0.5697\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 7.1899 - acc: 0.6840 - val_loss: 7.4250 - val_acc: 0.5562\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 6.8774 - acc: 0.6906 - val_loss: 7.1573 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 6.5675 - acc: 0.7021 - val_loss: 6.8265 - val_acc: 0.5661\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 6.2808 - acc: 0.7055 - val_loss: 6.5531 - val_acc: 0.5688\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 6.0042 - acc: 0.7205 - val_loss: 6.3508 - val_acc: 0.5580\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 5.7528 - acc: 0.7293 - val_loss: 6.1476 - val_acc: 0.5516\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 5.5082 - acc: 0.7318 - val_loss: 5.8757 - val_acc: 0.5679\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 5.2798 - acc: 0.7334 - val_loss: 5.7667 - val_acc: 0.5598\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.0746 - acc: 0.7339 - val_loss: 5.4848 - val_acc: 0.5507\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 4.8369 - acc: 0.7531 - val_loss: 5.3400 - val_acc: 0.5580\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 13.5221 - acc: 0.4139 - val_loss: 12.9531 - val_acc: 0.4891\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 12.6525 - acc: 0.5190 - val_loss: 12.3793 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 11.9798 - acc: 0.5610 - val_loss: 11.7953 - val_acc: 0.5072\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 11.3603 - acc: 0.5833 - val_loss: 11.2330 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 10.7635 - acc: 0.6143 - val_loss: 10.6922 - val_acc: 0.5362\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 10.1852 - acc: 0.6250 - val_loss: 10.1363 - val_acc: 0.5444\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 9.6426 - acc: 0.6422 - val_loss: 9.6653 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 9.0855 - acc: 0.6794 - val_loss: 9.1613 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 8.5858 - acc: 0.6894 - val_loss: 8.7112 - val_acc: 0.5616\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 8.1178 - acc: 0.7003 - val_loss: 8.2979 - val_acc: 0.5380\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 7.6675 - acc: 0.7168 - val_loss: 7.8915 - val_acc: 0.5571\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 7.2296 - acc: 0.7341 - val_loss: 7.5547 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 6.8472 - acc: 0.7370 - val_loss: 7.1978 - val_acc: 0.5589\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 6.4866 - acc: 0.7446 - val_loss: 6.8081 - val_acc: 0.5697\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 6.1228 - acc: 0.7635 - val_loss: 6.5254 - val_acc: 0.5707\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.7737 - acc: 0.7764 - val_loss: 6.1938 - val_acc: 0.5652\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 5.4674 - acc: 0.7822 - val_loss: 5.9449 - val_acc: 0.5625\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 5.1766 - acc: 0.7928 - val_loss: 5.7363 - val_acc: 0.5598\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 4.9059 - acc: 0.7976 - val_loss: 5.4883 - val_acc: 0.5598\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 4.6476 - acc: 0.8072 - val_loss: 5.2434 - val_acc: 0.5670\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 4.3997 - acc: 0.8198 - val_loss: 5.0974 - val_acc: 0.5562\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 4.1773 - acc: 0.8274 - val_loss: 4.9084 - val_acc: 0.5770\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 3.9815 - acc: 0.8258 - val_loss: 4.7933 - val_acc: 0.5462\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 3.7975 - acc: 0.8319 - val_loss: 4.5094 - val_acc: 0.5607\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 3.5946 - acc: 0.8460 - val_loss: 4.4141 - val_acc: 0.5543\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 3.4078 - acc: 0.8562 - val_loss: 4.3046 - val_acc: 0.5571\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.2442 - acc: 0.8686 - val_loss: 4.1805 - val_acc: 0.5480\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 3.1167 - acc: 0.8555 - val_loss: 4.0793 - val_acc: 0.5534\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 2.9692 - acc: 0.8633 - val_loss: 3.9174 - val_acc: 0.5507\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 2.8290 - acc: 0.8794 - val_loss: 3.8029 - val_acc: 0.5661\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 2.7101 - acc: 0.8828 - val_loss: 3.7301 - val_acc: 0.5516\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 2.5988 - acc: 0.8828 - val_loss: 3.6743 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 2.7272 - acc: 0.4324 - val_loss: 2.4894 - val_acc: 0.4692\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2740 - acc: 0.5417 - val_loss: 2.4109 - val_acc: 0.4964\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1325 - acc: 0.5725 - val_loss: 2.2824 - val_acc: 0.5245\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.9886 - acc: 0.6075 - val_loss: 2.2569 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8630 - acc: 0.6408 - val_loss: 2.2539 - val_acc: 0.5245\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7856 - acc: 0.6591 - val_loss: 2.1327 - val_acc: 0.5471\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6734 - acc: 0.6902 - val_loss: 2.1065 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5739 - acc: 0.7200 - val_loss: 2.1835 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4864 - acc: 0.7422 - val_loss: 2.1802 - val_acc: 0.5299\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4039 - acc: 0.7708 - val_loss: 2.1647 - val_acc: 0.5335\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3389 - acc: 0.7856 - val_loss: 2.2040 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2639 - acc: 0.8096 - val_loss: 2.2238 - val_acc: 0.5362\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2181 - acc: 0.8272 - val_loss: 2.2216 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.1811 - acc: 0.8326 - val_loss: 2.2469 - val_acc: 0.5317\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.1308 - acc: 0.8577 - val_loss: 2.3599 - val_acc: 0.5507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.0742 - acc: 0.8745 - val_loss: 2.2885 - val_acc: 0.5426\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 0.9898 - acc: 0.9043 - val_loss: 2.4018 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 3.8700 - acc: 0.4031 - val_loss: 3.4537 - val_acc: 0.4937\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3180 - acc: 0.5042 - val_loss: 3.2852 - val_acc: 0.4792\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0326 - acc: 0.5246 - val_loss: 3.0288 - val_acc: 0.4882\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7869 - acc: 0.5416 - val_loss: 2.8506 - val_acc: 0.4810\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5840 - acc: 0.5573 - val_loss: 2.6164 - val_acc: 0.5100\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3928 - acc: 0.5628 - val_loss: 2.4631 - val_acc: 0.5362\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3050 - acc: 0.5655 - val_loss: 2.3289 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1354 - acc: 0.5832 - val_loss: 2.3136 - val_acc: 0.5082\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0730 - acc: 0.5853 - val_loss: 2.1798 - val_acc: 0.5399\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9873 - acc: 0.5957 - val_loss: 2.1745 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9366 - acc: 0.6003 - val_loss: 2.2040 - val_acc: 0.5254\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8811 - acc: 0.6089 - val_loss: 2.1782 - val_acc: 0.5199\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8681 - acc: 0.6116 - val_loss: 2.0846 - val_acc: 0.5399\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8401 - acc: 0.6137 - val_loss: 2.1960 - val_acc: 0.5236\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8116 - acc: 0.6203 - val_loss: 2.0695 - val_acc: 0.5462\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8121 - acc: 0.6176 - val_loss: 2.1501 - val_acc: 0.5154\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7854 - acc: 0.6192 - val_loss: 2.1003 - val_acc: 0.5389\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7997 - acc: 0.6313 - val_loss: 2.1802 - val_acc: 0.5091\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7782 - acc: 0.6408 - val_loss: 2.1123 - val_acc: 0.5226\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7797 - acc: 0.6388 - val_loss: 2.1084 - val_acc: 0.5417\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8022 - acc: 0.6292 - val_loss: 2.1411 - val_acc: 0.5498\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7882 - acc: 0.6429 - val_loss: 2.1409 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8236 - acc: 0.6382 - val_loss: 2.1256 - val_acc: 0.5299\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8059 - acc: 0.6445 - val_loss: 2.1980 - val_acc: 0.5308\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7689 - acc: 0.6592 - val_loss: 2.1433 - val_acc: 0.5489\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7904 - acc: 0.6552 - val_loss: 2.2290 - val_acc: 0.5326\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7913 - acc: 0.6476 - val_loss: 2.1695 - val_acc: 0.5290\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8222 - acc: 0.6493 - val_loss: 2.2363 - val_acc: 0.5145\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8377 - acc: 0.6474 - val_loss: 2.2292 - val_acc: 0.5344\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8409 - acc: 0.6530 - val_loss: 2.2225 - val_acc: 0.5498\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7933 - acc: 0.6664 - val_loss: 2.2443 - val_acc: 0.5145\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 14.6556 - acc: 0.3404 - val_loss: 13.3113 - val_acc: 0.4411\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 12.6629 - acc: 0.4950 - val_loss: 11.9227 - val_acc: 0.5063\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 11.1968 - acc: 0.5706 - val_loss: 10.5718 - val_acc: 0.5009\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 9.7503 - acc: 0.6126 - val_loss: 9.2943 - val_acc: 0.5371\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 8.4282 - acc: 0.6511 - val_loss: 8.1359 - val_acc: 0.5172\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 7.3136 - acc: 0.6667 - val_loss: 7.1973 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 6.3509 - acc: 0.6851 - val_loss: 6.3721 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 5.5520 - acc: 0.7008 - val_loss: 5.6615 - val_acc: 0.5245\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 4.8895 - acc: 0.7151 - val_loss: 5.0888 - val_acc: 0.5417\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 4.3833 - acc: 0.7042 - val_loss: 4.7230 - val_acc: 0.5172\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 3.9016 - acc: 0.7286 - val_loss: 4.2227 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 3.4848 - acc: 0.7503 - val_loss: 3.9379 - val_acc: 0.5408\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 3.1757 - acc: 0.7454 - val_loss: 3.7067 - val_acc: 0.5516\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.9454 - acc: 0.7385 - val_loss: 3.5494 - val_acc: 0.5290\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 2.7404 - acc: 0.7311 - val_loss: 3.2207 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 2.5002 - acc: 0.7659 - val_loss: 3.1157 - val_acc: 0.5380\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 2.3041 - acc: 0.7805 - val_loss: 3.0129 - val_acc: 0.5317\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 2.1468 - acc: 0.7877 - val_loss: 2.8907 - val_acc: 0.5389\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 2.0198 - acc: 0.7945 - val_loss: 2.7906 - val_acc: 0.5344\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 510us/step - loss: 1.9318 - acc: 0.7942 - val_loss: 2.7538 - val_acc: 0.5299\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 1.8308 - acc: 0.8022 - val_loss: 2.6135 - val_acc: 0.5516\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.7331 - acc: 0.8136 - val_loss: 2.5488 - val_acc: 0.5326\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 1.6649 - acc: 0.8165 - val_loss: 2.5249 - val_acc: 0.5362\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 1.5999 - acc: 0.8157 - val_loss: 2.4609 - val_acc: 0.5543\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 1.5274 - acc: 0.8290 - val_loss: 2.4863 - val_acc: 0.5435\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 4.0576 - acc: 0.4575 - val_loss: 3.8038 - val_acc: 0.5272\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6336 - acc: 0.5657 - val_loss: 3.7375 - val_acc: 0.5136\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4504 - acc: 0.6194 - val_loss: 3.6327 - val_acc: 0.5344\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2937 - acc: 0.6644 - val_loss: 3.5392 - val_acc: 0.5616\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1336 - acc: 0.7116 - val_loss: 3.5918 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0195 - acc: 0.7366 - val_loss: 3.4639 - val_acc: 0.5534\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8906 - acc: 0.7747 - val_loss: 3.4475 - val_acc: 0.5589\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7674 - acc: 0.7992 - val_loss: 3.4346 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6625 - acc: 0.8276 - val_loss: 3.4266 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5643 - acc: 0.8494 - val_loss: 3.3436 - val_acc: 0.5616\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4594 - acc: 0.8716 - val_loss: 3.3550 - val_acc: 0.5625\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3523 - acc: 0.9004 - val_loss: 3.3508 - val_acc: 0.5670\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2665 - acc: 0.9146 - val_loss: 3.3185 - val_acc: 0.5725\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1928 - acc: 0.9314 - val_loss: 3.2373 - val_acc: 0.5788\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1215 - acc: 0.9344 - val_loss: 3.2375 - val_acc: 0.5679\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0249 - acc: 0.9592 - val_loss: 3.2914 - val_acc: 0.5616\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9531 - acc: 0.9683 - val_loss: 3.1878 - val_acc: 0.5716\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8948 - acc: 0.9689 - val_loss: 3.2432 - val_acc: 0.5634\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8413 - acc: 0.9698 - val_loss: 3.2006 - val_acc: 0.5697\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7927 - acc: 0.9694 - val_loss: 3.1592 - val_acc: 0.5752\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7466 - acc: 0.9713 - val_loss: 3.1075 - val_acc: 0.5788\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6958 - acc: 0.9724 - val_loss: 3.1108 - val_acc: 0.5589\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6528 - acc: 0.9724 - val_loss: 3.1171 - val_acc: 0.5525\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6137 - acc: 0.9719 - val_loss: 3.1129 - val_acc: 0.5688\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5751 - acc: 0.9710 - val_loss: 3.0830 - val_acc: 0.5652\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5114 - acc: 0.9822 - val_loss: 3.0894 - val_acc: 0.5607\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4841 - acc: 0.9739 - val_loss: 3.1182 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4629 - acc: 0.9681 - val_loss: 3.0591 - val_acc: 0.5725\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4175 - acc: 0.9730 - val_loss: 3.0159 - val_acc: 0.5634\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3456 - acc: 0.9883 - val_loss: 3.0036 - val_acc: 0.5471\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.2927 - acc: 0.9911 - val_loss: 2.9192 - val_acc: 0.5589\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 35s 4ms/step - loss: 21.5712 - acc: 0.3645 - val_loss: 16.8679 - val_acc: 0.4864\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 13.3191 - acc: 0.5186 - val_loss: 9.9340 - val_acc: 0.4855\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 7.8331 - acc: 0.5312 - val_loss: 6.0975 - val_acc: 0.4909\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 5.0753 - acc: 0.5365 - val_loss: 4.4654 - val_acc: 0.4375\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 3.8846 - acc: 0.4979 - val_loss: 3.5754 - val_acc: 0.4674\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 3.0349 - acc: 0.5450 - val_loss: 3.1142 - val_acc: 0.4520\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 2.6208 - acc: 0.5361 - val_loss: 2.7048 - val_acc: 0.4393\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 2.3963 - acc: 0.5281 - val_loss: 2.3317 - val_acc: 0.5172\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 2.1204 - acc: 0.5602 - val_loss: 2.1788 - val_acc: 0.4764\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.0137 - acc: 0.5438 - val_loss: 2.3316 - val_acc: 0.4429\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.9604 - acc: 0.5429 - val_loss: 2.1843 - val_acc: 0.5009\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.8781 - acc: 0.5447 - val_loss: 2.0549 - val_acc: 0.4837\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.8330 - acc: 0.5553 - val_loss: 2.2316 - val_acc: 0.4158\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.8771 - acc: 0.5406 - val_loss: 2.0073 - val_acc: 0.5091\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.7833 - acc: 0.5591 - val_loss: 2.1000 - val_acc: 0.4701\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.6929 - acc: 0.5674 - val_loss: 1.9535 - val_acc: 0.4719\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 1.6694 - acc: 0.5657 - val_loss: 1.9581 - val_acc: 0.4801\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.7847 - acc: 0.5398 - val_loss: 2.2019 - val_acc: 0.4312\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 10.2695 - acc: 0.3222 - val_loss: 9.0053 - val_acc: 0.4348\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 8.6624 - acc: 0.4975 - val_loss: 8.3293 - val_acc: 0.4819\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 7.8588 - acc: 0.5563 - val_loss: 7.6167 - val_acc: 0.5154\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 7.0499 - acc: 0.5962 - val_loss: 6.8530 - val_acc: 0.5199\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 6.2468 - acc: 0.6385 - val_loss: 6.1661 - val_acc: 0.5525\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 5.5522 - acc: 0.6664 - val_loss: 5.6802 - val_acc: 0.5254\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 4.9750 - acc: 0.6683 - val_loss: 5.1016 - val_acc: 0.5181\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 4.4691 - acc: 0.6794 - val_loss: 4.7309 - val_acc: 0.5371\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 4.0117 - acc: 0.7005 - val_loss: 4.3946 - val_acc: 0.5281\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 3.6615 - acc: 0.7016 - val_loss: 4.0033 - val_acc: 0.5489\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 507us/step - loss: 3.2653 - acc: 0.7389 - val_loss: 3.8439 - val_acc: 0.5281\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 3.0152 - acc: 0.7334 - val_loss: 3.6039 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 2.7814 - acc: 0.7389 - val_loss: 3.3956 - val_acc: 0.5426\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 2.5475 - acc: 0.7599 - val_loss: 3.0974 - val_acc: 0.5571\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.3108 - acc: 0.7999 - val_loss: 3.0853 - val_acc: 0.5562\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 2.2281 - acc: 0.7727 - val_loss: 2.9951 - val_acc: 0.5362\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 2.1135 - acc: 0.7691 - val_loss: 2.8474 - val_acc: 0.5525\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.9413 - acc: 0.8030 - val_loss: 2.7564 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 1.8095 - acc: 0.8197 - val_loss: 2.7808 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 1.7043 - acc: 0.8299 - val_loss: 2.6803 - val_acc: 0.5353\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 1.6170 - acc: 0.8376 - val_loss: 2.6979 - val_acc: 0.5226\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 1.6706 - acc: 0.7944 - val_loss: 2.6331 - val_acc: 0.5453\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 1.5887 - acc: 0.8125 - val_loss: 2.6062 - val_acc: 0.5326\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.4906 - acc: 0.8364 - val_loss: 2.6079 - val_acc: 0.5254\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: 13.6082 - acc: 0.3802 - val_loss: 13.1294 - val_acc: 0.4891\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 12.9283 - acc: 0.5013 - val_loss: 12.7440 - val_acc: 0.5145\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 12.5348 - acc: 0.5412 - val_loss: 12.3883 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 12.1685 - acc: 0.5665 - val_loss: 12.0742 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 11.8161 - acc: 0.5806 - val_loss: 11.7726 - val_acc: 0.5444\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 11.4698 - acc: 0.6012 - val_loss: 11.4857 - val_acc: 0.5543\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 11.1447 - acc: 0.6194 - val_loss: 11.1849 - val_acc: 0.5525\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 10.8251 - acc: 0.6246 - val_loss: 10.8783 - val_acc: 0.5480\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 10.5052 - acc: 0.6370 - val_loss: 10.6006 - val_acc: 0.5480\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 10.1890 - acc: 0.6618 - val_loss: 10.3215 - val_acc: 0.5607\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 9.9024 - acc: 0.6604 - val_loss: 10.0710 - val_acc: 0.5625\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 9.6083 - acc: 0.6747 - val_loss: 9.7770 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 9.3155 - acc: 0.6914 - val_loss: 9.5260 - val_acc: 0.5716\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: 9.0429 - acc: 0.6937 - val_loss: 9.2797 - val_acc: 0.5734\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 8.7738 - acc: 0.7070 - val_loss: 9.0445 - val_acc: 0.5797\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 8.5088 - acc: 0.7183 - val_loss: 8.8127 - val_acc: 0.5697\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 8.2489 - acc: 0.7270 - val_loss: 8.5545 - val_acc: 0.5888\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 7.9876 - acc: 0.7472 - val_loss: 8.3546 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 7.7642 - acc: 0.7449 - val_loss: 8.1585 - val_acc: 0.5734\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 7.5195 - acc: 0.7571 - val_loss: 7.9488 - val_acc: 0.5725\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 7.2997 - acc: 0.7626 - val_loss: 7.7387 - val_acc: 0.5743\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 7.0760 - acc: 0.7736 - val_loss: 7.5663 - val_acc: 0.5679\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 6.8678 - acc: 0.7799 - val_loss: 7.3585 - val_acc: 0.5707\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 6.6482 - acc: 0.7948 - val_loss: 7.2080 - val_acc: 0.5679\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 6.4673 - acc: 0.7990 - val_loss: 7.0613 - val_acc: 0.5616\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 6.2761 - acc: 0.7939 - val_loss: 6.8923 - val_acc: 0.5634\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 6.0884 - acc: 0.8048 - val_loss: 6.7223 - val_acc: 0.5580\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 33s 4ms/step - loss: 10.0146 - acc: 0.3119 - val_loss: 9.0397 - val_acc: 0.4239\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 8.6432 - acc: 0.5042 - val_loss: 8.3527 - val_acc: 0.4882\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 481us/step - loss: 7.8970 - acc: 0.5676 - val_loss: 7.7002 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 7.1721 - acc: 0.6219 - val_loss: 7.0564 - val_acc: 0.5290\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 6.4856 - acc: 0.6510 - val_loss: 6.4914 - val_acc: 0.5353\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 5.8451 - acc: 0.6800 - val_loss: 5.9761 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 5.3036 - acc: 0.6935 - val_loss: 5.5368 - val_acc: 0.5335\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 4.8173 - acc: 0.7120 - val_loss: 5.0971 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 4.3552 - acc: 0.7403 - val_loss: 4.7769 - val_acc: 0.5217\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 3.9831 - acc: 0.7493 - val_loss: 4.5344 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 3.7589 - acc: 0.7319 - val_loss: 4.1883 - val_acc: 0.5462\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 3.4082 - acc: 0.7539 - val_loss: 3.9493 - val_acc: 0.5308\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 3.0995 - acc: 0.7937 - val_loss: 3.7599 - val_acc: 0.5272\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 2.8489 - acc: 0.8111 - val_loss: 3.5653 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 2.6524 - acc: 0.8127 - val_loss: 3.3696 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.4849 - acc: 0.8173 - val_loss: 3.2523 - val_acc: 0.5661\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 2.3085 - acc: 0.8375 - val_loss: 3.1347 - val_acc: 0.5625\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 2.1573 - acc: 0.8417 - val_loss: 3.0991 - val_acc: 0.5444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 2.0522 - acc: 0.8458 - val_loss: 2.9512 - val_acc: 0.5652\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.9208 - acc: 0.8615 - val_loss: 2.9292 - val_acc: 0.5326\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 1.8294 - acc: 0.8623 - val_loss: 2.9203 - val_acc: 0.5272\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.7989 - acc: 0.8432 - val_loss: 2.9006 - val_acc: 0.5290\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.7321 - acc: 0.8497 - val_loss: 2.7454 - val_acc: 0.5435\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 1.5982 - acc: 0.8837 - val_loss: 2.6615 - val_acc: 0.5516\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.5009 - acc: 0.9043 - val_loss: 2.6851 - val_acc: 0.5707\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 1.4641 - acc: 0.8909 - val_loss: 2.7022 - val_acc: 0.5335\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.4077 - acc: 0.8919 - val_loss: 2.5804 - val_acc: 0.5435\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.3408 - acc: 0.9037 - val_loss: 2.6710 - val_acc: 0.5525\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.3260 - acc: 0.8989 - val_loss: 2.5457 - val_acc: 0.5598\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 1.2781 - acc: 0.9061 - val_loss: 2.5946 - val_acc: 0.5543\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 1.2660 - acc: 0.8933 - val_loss: 2.5537 - val_acc: 0.5562\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 1.2350 - acc: 0.8977 - val_loss: 2.5081 - val_acc: 0.5562\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 1.1607 - acc: 0.9211 - val_loss: 2.5821 - val_acc: 0.5480\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 1.1431 - acc: 0.9196 - val_loss: 2.4843 - val_acc: 0.5534\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 1.1372 - acc: 0.9072 - val_loss: 2.5708 - val_acc: 0.5426\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: 10.3078 - acc: 0.4116 - val_loss: 9.9104 - val_acc: 0.4937\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 9.7244 - acc: 0.5304 - val_loss: 9.6315 - val_acc: 0.5272\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 9.4086 - acc: 0.5763 - val_loss: 9.3876 - val_acc: 0.5399\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 9.1170 - acc: 0.6083 - val_loss: 9.1772 - val_acc: 0.5498\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 8.8609 - acc: 0.6317 - val_loss: 8.9873 - val_acc: 0.5562\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 8.6198 - acc: 0.6566 - val_loss: 8.8055 - val_acc: 0.5562\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 8.3722 - acc: 0.6736 - val_loss: 8.5873 - val_acc: 0.5697\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 640us/step - loss: 8.1405 - acc: 0.6967 - val_loss: 8.4275 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 7.9112 - acc: 0.7141 - val_loss: 8.2297 - val_acc: 0.5589\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 7.7099 - acc: 0.7241 - val_loss: 8.0705 - val_acc: 0.5607\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 7.4936 - acc: 0.7406 - val_loss: 7.8784 - val_acc: 0.5643\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 7.2666 - acc: 0.7611 - val_loss: 7.6906 - val_acc: 0.5770\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 7.0571 - acc: 0.7777 - val_loss: 7.5444 - val_acc: 0.5743\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 6.8602 - acc: 0.7903 - val_loss: 7.4238 - val_acc: 0.5761\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 6.6641 - acc: 0.8098 - val_loss: 7.2386 - val_acc: 0.5734\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 6.4783 - acc: 0.8226 - val_loss: 7.0719 - val_acc: 0.5797\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 6.3145 - acc: 0.8215 - val_loss: 6.9511 - val_acc: 0.5797\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 6.1230 - acc: 0.8409 - val_loss: 6.8043 - val_acc: 0.5652\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 5.9544 - acc: 0.8441 - val_loss: 6.6541 - val_acc: 0.5725\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: 5.7828 - acc: 0.8599 - val_loss: 6.5212 - val_acc: 0.5643\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 5.6258 - acc: 0.8660 - val_loss: 6.3654 - val_acc: 0.5716\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 5.4575 - acc: 0.8777 - val_loss: 6.2962 - val_acc: 0.5679\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 5.2835 - acc: 0.8995 - val_loss: 6.1719 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 5.1631 - acc: 0.8890 - val_loss: 6.0370 - val_acc: 0.5716\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: 5.0074 - acc: 0.9026 - val_loss: 5.9573 - val_acc: 0.5598\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 4.8666 - acc: 0.9115 - val_loss: 5.8593 - val_acc: 0.5697\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: 9.8823 - acc: 0.3712 - val_loss: 9.5312 - val_acc: 0.4846\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 9.4008 - acc: 0.4975 - val_loss: 9.2830 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 625us/step - loss: 9.1856 - acc: 0.5280 - val_loss: 9.1464 - val_acc: 0.5281\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 8.9942 - acc: 0.5517 - val_loss: 8.9937 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 8.8279 - acc: 0.5719 - val_loss: 8.8939 - val_acc: 0.5344\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 8.6850 - acc: 0.5793 - val_loss: 8.7524 - val_acc: 0.5389\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 8.5259 - acc: 0.5942 - val_loss: 8.6472 - val_acc: 0.5426\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 8.3764 - acc: 0.6117 - val_loss: 8.4964 - val_acc: 0.5607\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 8.2220 - acc: 0.6223 - val_loss: 8.3935 - val_acc: 0.5462\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 8.0899 - acc: 0.6362 - val_loss: 8.2731 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 7.9505 - acc: 0.6444 - val_loss: 8.1671 - val_acc: 0.5507\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 7.8216 - acc: 0.6565 - val_loss: 8.0716 - val_acc: 0.5525\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 7.6909 - acc: 0.6603 - val_loss: 7.9597 - val_acc: 0.5562\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 7.5578 - acc: 0.6754 - val_loss: 7.8090 - val_acc: 0.5688\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 638us/step - loss: 7.4249 - acc: 0.6857 - val_loss: 7.7285 - val_acc: 0.5598\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 7.3154 - acc: 0.6821 - val_loss: 7.6240 - val_acc: 0.5652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 7.1684 - acc: 0.7048 - val_loss: 7.5196 - val_acc: 0.5725\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 7.0556 - acc: 0.7108 - val_loss: 7.4112 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 6.9214 - acc: 0.7235 - val_loss: 7.3199 - val_acc: 0.5679\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 6.8146 - acc: 0.7188 - val_loss: 7.2143 - val_acc: 0.5616\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 6.6881 - acc: 0.7350 - val_loss: 7.1005 - val_acc: 0.5779\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 6.5667 - acc: 0.7471 - val_loss: 7.0326 - val_acc: 0.5670\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 6.4613 - acc: 0.7527 - val_loss: 6.9510 - val_acc: 0.5643\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 6.3391 - acc: 0.7623 - val_loss: 6.8530 - val_acc: 0.5670\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 6.2231 - acc: 0.7735 - val_loss: 6.7831 - val_acc: 0.5725\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 6.1333 - acc: 0.7635 - val_loss: 6.6912 - val_acc: 0.5734\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 6.0184 - acc: 0.7786 - val_loss: 6.5875 - val_acc: 0.5679\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.9011 - acc: 0.7919 - val_loss: 6.5014 - val_acc: 0.5797\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 5.8044 - acc: 0.7935 - val_loss: 6.4239 - val_acc: 0.5788\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 5.6953 - acc: 0.8070 - val_loss: 6.3484 - val_acc: 0.5652\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.6031 - acc: 0.8075 - val_loss: 6.2913 - val_acc: 0.5661\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 5.5109 - acc: 0.8080 - val_loss: 6.1766 - val_acc: 0.5824\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 5.4039 - acc: 0.8218 - val_loss: 6.1270 - val_acc: 0.5770\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 5.3096 - acc: 0.8208 - val_loss: 6.0557 - val_acc: 0.5788\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 5.2090 - acc: 0.8378 - val_loss: 5.9771 - val_acc: 0.5679\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 5.1227 - acc: 0.8378 - val_loss: 5.9092 - val_acc: 0.5815\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 5.0242 - acc: 0.8452 - val_loss: 5.8277 - val_acc: 0.5806\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 4.9371 - acc: 0.8495 - val_loss: 5.7915 - val_acc: 0.5643\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 4.8483 - acc: 0.8542 - val_loss: 5.6909 - val_acc: 0.5752\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 4.7696 - acc: 0.8559 - val_loss: 5.6329 - val_acc: 0.5788\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 4.6673 - acc: 0.8729 - val_loss: 5.5816 - val_acc: 0.5707\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 4.5942 - acc: 0.8690 - val_loss: 5.5056 - val_acc: 0.5752\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: nan - acc: 0.0712 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 41s 5ms/step - loss: 4.6413 - acc: 0.4643 - val_loss: 4.3797 - val_acc: 0.5245\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.1564 - acc: 0.6015 - val_loss: 4.3257 - val_acc: 0.5335\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.9473 - acc: 0.6598 - val_loss: 4.1911 - val_acc: 0.5616\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.7684 - acc: 0.7166 - val_loss: 4.1310 - val_acc: 0.5643\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5940 - acc: 0.7677 - val_loss: 4.0903 - val_acc: 0.5607\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4461 - acc: 0.8077 - val_loss: 4.1012 - val_acc: 0.5534\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3194 - acc: 0.8378 - val_loss: 4.0121 - val_acc: 0.5716\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1877 - acc: 0.8763 - val_loss: 3.9715 - val_acc: 0.5652\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0704 - acc: 0.8964 - val_loss: 3.9722 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9509 - acc: 0.9241 - val_loss: 3.9301 - val_acc: 0.5779\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8446 - acc: 0.9443 - val_loss: 3.8139 - val_acc: 0.5707\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7500 - acc: 0.9555 - val_loss: 3.8375 - val_acc: 0.5562\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6609 - acc: 0.9670 - val_loss: 3.7961 - val_acc: 0.5661\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5752 - acc: 0.9725 - val_loss: 3.7526 - val_acc: 0.5652\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4870 - acc: 0.9831 - val_loss: 3.7584 - val_acc: 0.5616\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4172 - acc: 0.9852 - val_loss: 3.7220 - val_acc: 0.5507\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3483 - acc: 0.9873 - val_loss: 3.6300 - val_acc: 0.5770\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2769 - acc: 0.9909 - val_loss: 3.6071 - val_acc: 0.5788\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2068 - acc: 0.9925 - val_loss: 3.5820 - val_acc: 0.5688\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1759 - acc: 0.9795 - val_loss: 3.6281 - val_acc: 0.5679\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1235 - acc: 0.9807 - val_loss: 3.5213 - val_acc: 0.5652\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0583 - acc: 0.9848 - val_loss: 3.5015 - val_acc: 0.5661\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9827 - acc: 0.9911 - val_loss: 3.4580 - val_acc: 0.5634\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9233 - acc: 0.9915 - val_loss: 3.4267 - val_acc: 0.5571\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8581 - acc: 0.9946 - val_loss: 3.3088 - val_acc: 0.5679\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8049 - acc: 0.9933 - val_loss: 3.3625 - val_acc: 0.5571\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7898 - acc: 0.9803 - val_loss: 3.4079 - val_acc: 0.5435\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8390 - acc: 0.9467 - val_loss: 3.3630 - val_acc: 0.5426\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 11.4727 - acc: 0.4037 - val_loss: 11.0764 - val_acc: 0.5036\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 10.9364 - acc: 0.5129 - val_loss: 10.8310 - val_acc: 0.5380\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 10.6573 - acc: 0.5588 - val_loss: 10.6634 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 10.4214 - acc: 0.5824 - val_loss: 10.4626 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 10.1930 - acc: 0.6046 - val_loss: 10.2531 - val_acc: 0.5516\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 9.9885 - acc: 0.6211 - val_loss: 10.0797 - val_acc: 0.5652\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 9.7734 - acc: 0.6422 - val_loss: 9.9353 - val_acc: 0.5525\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 9.5630 - acc: 0.6607 - val_loss: 9.7344 - val_acc: 0.5716\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 9.3666 - acc: 0.6721 - val_loss: 9.6002 - val_acc: 0.5598\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 717us/step - loss: 9.1699 - acc: 0.6883 - val_loss: 9.4070 - val_acc: 0.5688\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 8.9775 - acc: 0.7005 - val_loss: 9.2787 - val_acc: 0.5707\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 8.7907 - acc: 0.7158 - val_loss: 9.0961 - val_acc: 0.5824\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 8.6029 - acc: 0.7338 - val_loss: 8.9740 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 8.4378 - acc: 0.7379 - val_loss: 8.8644 - val_acc: 0.5643\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 8.2569 - acc: 0.7514 - val_loss: 8.6579 - val_acc: 0.5842\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 8.0687 - acc: 0.7704 - val_loss: 8.5118 - val_acc: 0.5851\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 7.9088 - acc: 0.7740 - val_loss: 8.4191 - val_acc: 0.5607\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 7.7369 - acc: 0.7875 - val_loss: 8.2436 - val_acc: 0.5734\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 7.5862 - acc: 0.7923 - val_loss: 8.1126 - val_acc: 0.5779\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 7.4207 - acc: 0.8078 - val_loss: 7.9918 - val_acc: 0.5833\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 7.2622 - acc: 0.8127 - val_loss: 7.9039 - val_acc: 0.5716\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 7.1087 - acc: 0.8277 - val_loss: 7.7377 - val_acc: 0.5716\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 6.9531 - acc: 0.8381 - val_loss: 7.6214 - val_acc: 0.5743\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 6.8168 - acc: 0.8389 - val_loss: 7.5178 - val_acc: 0.5725\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 6.6716 - acc: 0.8533 - val_loss: 7.3485 - val_acc: 0.5824\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 6.5197 - acc: 0.8559 - val_loss: 7.2423 - val_acc: 0.5752\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: 9.4396 - acc: 0.3466 - val_loss: 8.5745 - val_acc: 0.4520\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 8.2096 - acc: 0.5323 - val_loss: 8.0208 - val_acc: 0.5236\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 7.6022 - acc: 0.6054 - val_loss: 7.5349 - val_acc: 0.5308\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 7.0278 - acc: 0.6635 - val_loss: 7.1047 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 6.4679 - acc: 0.7121 - val_loss: 6.6751 - val_acc: 0.5525\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 5.9570 - acc: 0.7448 - val_loss: 6.2609 - val_acc: 0.5471\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 5.4969 - acc: 0.7696 - val_loss: 5.8793 - val_acc: 0.5571\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 5.0635 - acc: 0.8009 - val_loss: 5.5109 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 4.6798 - acc: 0.8140 - val_loss: 5.2593 - val_acc: 0.5607\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 537us/step - loss: 4.3480 - acc: 0.8215 - val_loss: 5.0412 - val_acc: 0.5371\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 4.0302 - acc: 0.8347 - val_loss: 4.7576 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 3.7185 - acc: 0.8632 - val_loss: 4.5546 - val_acc: 0.5643\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 3.4390 - acc: 0.8839 - val_loss: 4.3058 - val_acc: 0.5516\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 3.2102 - acc: 0.8865 - val_loss: 4.1562 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 3.0098 - acc: 0.8835 - val_loss: 4.0445 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 2.8077 - acc: 0.8996 - val_loss: 3.7848 - val_acc: 0.5453\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 2.6187 - acc: 0.9144 - val_loss: 3.7117 - val_acc: 0.5562\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 2.4649 - acc: 0.9130 - val_loss: 3.5728 - val_acc: 0.5507\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 2.3029 - acc: 0.9281 - val_loss: 3.5288 - val_acc: 0.5417\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 2.1779 - acc: 0.9251 - val_loss: 3.3451 - val_acc: 0.5453\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 2.0524 - acc: 0.9334 - val_loss: 3.3371 - val_acc: 0.5489\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 1.9564 - acc: 0.9286 - val_loss: 3.2703 - val_acc: 0.5498\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 34s 4ms/step - loss: 7.6568 - acc: 0.3311 - val_loss: 6.6477 - val_acc: 0.4103\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 6.3492 - acc: 0.4988 - val_loss: 6.1855 - val_acc: 0.5145\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 5.8867 - acc: 0.5707 - val_loss: 5.8745 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 5.4658 - acc: 0.6130 - val_loss: 5.5515 - val_acc: 0.5462\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 506us/step - loss: 5.0682 - acc: 0.6496 - val_loss: 5.2164 - val_acc: 0.5525\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 4.6706 - acc: 0.6894 - val_loss: 4.9308 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 4.3174 - acc: 0.7147 - val_loss: 4.6754 - val_acc: 0.5417\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 3.9832 - acc: 0.7481 - val_loss: 4.4257 - val_acc: 0.5453\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 3.7086 - acc: 0.7557 - val_loss: 4.2479 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 3.4934 - acc: 0.7522 - val_loss: 4.0261 - val_acc: 0.5480\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 3.2160 - acc: 0.7906 - val_loss: 3.8300 - val_acc: 0.5516\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 3.0159 - acc: 0.7965 - val_loss: 3.7524 - val_acc: 0.5453\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 2.8150 - acc: 0.8199 - val_loss: 3.5719 - val_acc: 0.5462\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 2.6092 - acc: 0.8436 - val_loss: 3.4674 - val_acc: 0.5471\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 2.4308 - acc: 0.8609 - val_loss: 3.4060 - val_acc: 0.5272\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 3.5169 - acc: 0.4652 - val_loss: 3.3506 - val_acc: 0.5199\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0674 - acc: 0.6014 - val_loss: 3.2390 - val_acc: 0.5371\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8836 - acc: 0.6636 - val_loss: 3.1961 - val_acc: 0.5616\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7059 - acc: 0.7335 - val_loss: 3.1640 - val_acc: 0.5408\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5759 - acc: 0.7800 - val_loss: 3.1235 - val_acc: 0.5643\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4679 - acc: 0.8163 - val_loss: 3.1400 - val_acc: 0.5707\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3427 - acc: 0.8618 - val_loss: 3.1257 - val_acc: 0.5616\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2385 - acc: 0.8953 - val_loss: 3.0873 - val_acc: 0.5716\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1534 - acc: 0.9197 - val_loss: 3.0698 - val_acc: 0.5743\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0660 - acc: 0.9419 - val_loss: 3.1102 - val_acc: 0.5625\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.9894 - acc: 0.9602 - val_loss: 3.1181 - val_acc: 0.5571\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.9264 - acc: 0.9701 - val_loss: 3.0915 - val_acc: 0.5716\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8656 - acc: 0.9797 - val_loss: 3.1033 - val_acc: 0.5679\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8110 - acc: 0.9852 - val_loss: 3.0571 - val_acc: 0.5906\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7571 - acc: 0.9907 - val_loss: 3.1340 - val_acc: 0.5661\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.7271 - acc: 0.9908 - val_loss: 3.0428 - val_acc: 0.5752\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6984 - acc: 0.9875 - val_loss: 3.1302 - val_acc: 0.5670\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6664 - acc: 0.9882 - val_loss: 3.0762 - val_acc: 0.5707\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6284 - acc: 0.9901 - val_loss: 3.0272 - val_acc: 0.5634\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5794 - acc: 0.9956 - val_loss: 3.0386 - val_acc: 0.5707\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5409 - acc: 0.9956 - val_loss: 2.9865 - val_acc: 0.5833\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5068 - acc: 0.9969 - val_loss: 2.9845 - val_acc: 0.5734\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4765 - acc: 0.9950 - val_loss: 3.0371 - val_acc: 0.5616\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4683 - acc: 0.9891 - val_loss: 3.0997 - val_acc: 0.5734\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 35s 4ms/step - loss: 7.7218 - acc: 0.3536 - val_loss: 6.9909 - val_acc: 0.4565\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 6.7328 - acc: 0.5245 - val_loss: 6.6739 - val_acc: 0.5127\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 6.3385 - acc: 0.5934 - val_loss: 6.4116 - val_acc: 0.5254\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 5.9946 - acc: 0.6461 - val_loss: 6.1365 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 5.6677 - acc: 0.6815 - val_loss: 5.9129 - val_acc: 0.5362\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 5.3625 - acc: 0.7090 - val_loss: 5.6910 - val_acc: 0.5607\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 5.0701 - acc: 0.7377 - val_loss: 5.4977 - val_acc: 0.5498\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 4.8114 - acc: 0.7520 - val_loss: 5.2795 - val_acc: 0.5498\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 4.5585 - acc: 0.7783 - val_loss: 5.0867 - val_acc: 0.5507\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 4.3186 - acc: 0.7926 - val_loss: 4.9101 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 4.0956 - acc: 0.8135 - val_loss: 4.7996 - val_acc: 0.5625\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 3.8613 - acc: 0.8363 - val_loss: 4.6101 - val_acc: 0.5480\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 3.6404 - acc: 0.8625 - val_loss: 4.4552 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 3.4496 - acc: 0.8701 - val_loss: 4.3179 - val_acc: 0.5598\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 3.2626 - acc: 0.8884 - val_loss: 4.1457 - val_acc: 0.5543\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 3.0953 - acc: 0.8973 - val_loss: 4.0694 - val_acc: 0.5580\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 2.9569 - acc: 0.8994 - val_loss: 3.9938 - val_acc: 0.5462\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 478us/step - loss: 2.7831 - acc: 0.9226 - val_loss: 3.8331 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 2.6463 - acc: 0.9263 - val_loss: 3.6881 - val_acc: 0.5616\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.5259 - acc: 0.9296 - val_loss: 3.6267 - val_acc: 0.5625\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 2.4093 - acc: 0.9328 - val_loss: 3.5937 - val_acc: 0.5543\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.2871 - acc: 0.9461 - val_loss: 3.4259 - val_acc: 0.5607\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.1874 - acc: 0.9433 - val_loss: 3.5130 - val_acc: 0.5625\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: 2.0952 - acc: 0.9461 - val_loss: 3.3523 - val_acc: 0.5580\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.9900 - acc: 0.9536 - val_loss: 3.3076 - val_acc: 0.5525\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 1.9088 - acc: 0.9530 - val_loss: 3.2107 - val_acc: 0.5525\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 1.8213 - acc: 0.9595 - val_loss: 3.1456 - val_acc: 0.5688\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 1.7373 - acc: 0.9658 - val_loss: 3.1366 - val_acc: 0.5607\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.6605 - acc: 0.9667 - val_loss: 3.0544 - val_acc: 0.5725\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.6062 - acc: 0.9608 - val_loss: 3.1331 - val_acc: 0.5408\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 1.5580 - acc: 0.9571 - val_loss: 2.9091 - val_acc: 0.5707\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.4926 - acc: 0.9616 - val_loss: 2.9627 - val_acc: 0.5525\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 1.4483 - acc: 0.9583 - val_loss: 3.0143 - val_acc: 0.5534\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 1.4241 - acc: 0.9516 - val_loss: 2.9500 - val_acc: 0.5562\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 1.3691 - acc: 0.9565 - val_loss: 2.9309 - val_acc: 0.5453\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 543us/step - loss: 1.3383 - acc: 0.9515 - val_loss: 2.9289 - val_acc: 0.5399\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 1.3172 - acc: 0.9471 - val_loss: 2.9353 - val_acc: 0.5417\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.2733 - acc: 0.9524 - val_loss: 2.8366 - val_acc: 0.5399\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 1.2332 - acc: 0.9564 - val_loss: 2.8683 - val_acc: 0.5380\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 12.4228 - acc: 0.4258 - val_loss: 12.0061 - val_acc: 0.5072\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 628us/step - loss: 11.7248 - acc: 0.5550 - val_loss: 11.6637 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 11.2945 - acc: 0.6004 - val_loss: 11.3114 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 10.8936 - acc: 0.6373 - val_loss: 10.9412 - val_acc: 0.5553\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 10.5168 - acc: 0.6692 - val_loss: 10.6907 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 10.1623 - acc: 0.6954 - val_loss: 10.3866 - val_acc: 0.5498\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 9.8208 - acc: 0.7072 - val_loss: 10.0485 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 9.4759 - acc: 0.7360 - val_loss: 9.7767 - val_acc: 0.5661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 9.1345 - acc: 0.7619 - val_loss: 9.4852 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 8.8380 - acc: 0.7705 - val_loss: 9.1902 - val_acc: 0.5788\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 8.5154 - acc: 0.7945 - val_loss: 9.0054 - val_acc: 0.5534\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 8.2286 - acc: 0.8106 - val_loss: 8.7176 - val_acc: 0.5806\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 7.9509 - acc: 0.8198 - val_loss: 8.5097 - val_acc: 0.5643\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 7.6706 - acc: 0.8331 - val_loss: 8.2731 - val_acc: 0.5761\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 7.4091 - acc: 0.8480 - val_loss: 8.0419 - val_acc: 0.5833\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 7.1439 - acc: 0.8666 - val_loss: 7.8129 - val_acc: 0.5734\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 6.9031 - acc: 0.8742 - val_loss: 7.6116 - val_acc: 0.5761\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 6.6684 - acc: 0.8824 - val_loss: 7.4093 - val_acc: 0.5797\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 6.4369 - acc: 0.8927 - val_loss: 7.2116 - val_acc: 0.5870\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 6.2096 - acc: 0.9038 - val_loss: 7.0717 - val_acc: 0.5797\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 6.0019 - acc: 0.9076 - val_loss: 6.8653 - val_acc: 0.5743\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 5.7970 - acc: 0.9169 - val_loss: 6.6733 - val_acc: 0.5734\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 5.5930 - acc: 0.9284 - val_loss: 6.4868 - val_acc: 0.5725\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 5.4078 - acc: 0.9314 - val_loss: 6.3724 - val_acc: 0.5707\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 5.2328 - acc: 0.9289 - val_loss: 6.2040 - val_acc: 0.5824\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 5.0594 - acc: 0.9393 - val_loss: 6.1008 - val_acc: 0.5779\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 4.8648 - acc: 0.9516 - val_loss: 5.9417 - val_acc: 0.5734\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 4.7138 - acc: 0.9479 - val_loss: 5.8257 - val_acc: 0.5788\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 4.5631 - acc: 0.9474 - val_loss: 5.6314 - val_acc: 0.5842\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 35s 4ms/step - loss: 7.6587 - acc: 0.3187 - val_loss: 6.8842 - val_acc: 0.4049\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 6.5706 - acc: 0.4852 - val_loss: 6.3910 - val_acc: 0.5018\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 6.1389 - acc: 0.5629 - val_loss: 6.0525 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 5.7388 - acc: 0.5998 - val_loss: 5.7717 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 510us/step - loss: 5.3676 - acc: 0.6291 - val_loss: 5.4639 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 5.0110 - acc: 0.6557 - val_loss: 5.1942 - val_acc: 0.5426\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 4.7002 - acc: 0.6727 - val_loss: 4.9685 - val_acc: 0.5453\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 4.3863 - acc: 0.6980 - val_loss: 4.7235 - val_acc: 0.5516\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 4.0949 - acc: 0.7264 - val_loss: 4.4564 - val_acc: 0.5498\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 3.8421 - acc: 0.7304 - val_loss: 4.3532 - val_acc: 0.5489\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 3.6200 - acc: 0.7443 - val_loss: 4.1208 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 3.3859 - acc: 0.7615 - val_loss: 3.9286 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 3.1894 - acc: 0.7728 - val_loss: 3.8054 - val_acc: 0.5389\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 2.9899 - acc: 0.7936 - val_loss: 3.5784 - val_acc: 0.5670\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 2.8059 - acc: 0.8062 - val_loss: 3.5267 - val_acc: 0.5507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.6414 - acc: 0.8196 - val_loss: 3.4402 - val_acc: 0.5580\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 2.4908 - acc: 0.8352 - val_loss: 3.3304 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 2.3578 - acc: 0.8415 - val_loss: 3.1893 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 2.2258 - acc: 0.8550 - val_loss: 3.1673 - val_acc: 0.5444\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 2.1211 - acc: 0.8574 - val_loss: 3.0816 - val_acc: 0.5562\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 2.0412 - acc: 0.8543 - val_loss: 3.0439 - val_acc: 0.5489\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 1.9408 - acc: 0.8658 - val_loss: 2.9656 - val_acc: 0.5562\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 1.8302 - acc: 0.8867 - val_loss: 2.9099 - val_acc: 0.5435\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 1.7476 - acc: 0.8918 - val_loss: 2.8653 - val_acc: 0.5580\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.6617 - acc: 0.9012 - val_loss: 2.8859 - val_acc: 0.5408\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 1.5920 - acc: 0.9026 - val_loss: 2.8318 - val_acc: 0.5399\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 1.5700 - acc: 0.8906 - val_loss: 2.8331 - val_acc: 0.5399\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 3.8648 - acc: 0.4531 - val_loss: 3.6197 - val_acc: 0.5127\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4644 - acc: 0.5587 - val_loss: 3.5152 - val_acc: 0.5281\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3148 - acc: 0.6012 - val_loss: 3.4737 - val_acc: 0.5326\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1862 - acc: 0.6393 - val_loss: 3.4182 - val_acc: 0.5525\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0737 - acc: 0.6795 - val_loss: 3.4062 - val_acc: 0.5553\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9722 - acc: 0.7069 - val_loss: 3.3584 - val_acc: 0.5716\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8833 - acc: 0.7361 - val_loss: 3.3392 - val_acc: 0.5716\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8146 - acc: 0.7532 - val_loss: 3.3310 - val_acc: 0.5616\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7102 - acc: 0.7942 - val_loss: 3.3051 - val_acc: 0.5842\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6374 - acc: 0.8153 - val_loss: 3.3157 - val_acc: 0.5562\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5527 - acc: 0.8427 - val_loss: 3.3254 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4776 - acc: 0.8631 - val_loss: 3.2890 - val_acc: 0.5870\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4328 - acc: 0.8678 - val_loss: 3.2962 - val_acc: 0.5643\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3599 - acc: 0.8950 - val_loss: 3.2391 - val_acc: 0.5652\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2905 - acc: 0.9123 - val_loss: 3.3150 - val_acc: 0.5661\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2365 - acc: 0.9215 - val_loss: 3.2851 - val_acc: 0.5788\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1878 - acc: 0.9331 - val_loss: 3.2726 - val_acc: 0.5815\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1336 - acc: 0.9425 - val_loss: 3.2836 - val_acc: 0.5589\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0869 - acc: 0.9532 - val_loss: 3.2973 - val_acc: 0.5707\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0465 - acc: 0.9547 - val_loss: 3.2258 - val_acc: 0.5761\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9913 - acc: 0.9698 - val_loss: 3.2351 - val_acc: 0.5734\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9528 - acc: 0.9719 - val_loss: 3.2492 - val_acc: 0.5688\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 10.0900 - acc: 0.3628 - val_loss: 9.7158 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 9.6189 - acc: 0.4919 - val_loss: 9.5107 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 9.4362 - acc: 0.5240 - val_loss: 9.3732 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 9.2792 - acc: 0.5358 - val_loss: 9.2477 - val_acc: 0.5290\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 9.1370 - acc: 0.5523 - val_loss: 9.1381 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 8.9971 - acc: 0.5691 - val_loss: 9.0352 - val_acc: 0.5462\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 8.8928 - acc: 0.5719 - val_loss: 8.9266 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 8.7548 - acc: 0.5972 - val_loss: 8.8301 - val_acc: 0.5634\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 8.6308 - acc: 0.6056 - val_loss: 8.7206 - val_acc: 0.5652\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 8.5021 - acc: 0.6254 - val_loss: 8.6585 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 8.4003 - acc: 0.6207 - val_loss: 8.5328 - val_acc: 0.5598\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 8.2893 - acc: 0.6327 - val_loss: 8.4574 - val_acc: 0.5571\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 8.1815 - acc: 0.6403 - val_loss: 8.3496 - val_acc: 0.5734\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 8.0714 - acc: 0.6475 - val_loss: 8.2609 - val_acc: 0.5697\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 7.9566 - acc: 0.6670 - val_loss: 8.1672 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 7.8384 - acc: 0.6667 - val_loss: 8.0771 - val_acc: 0.5752\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 7.7381 - acc: 0.6711 - val_loss: 7.9855 - val_acc: 0.5779\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 7.6349 - acc: 0.6787 - val_loss: 7.8998 - val_acc: 0.5688\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 7.5311 - acc: 0.6901 - val_loss: 7.8153 - val_acc: 0.5788\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 7.4288 - acc: 0.6946 - val_loss: 7.7579 - val_acc: 0.5725\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 7.3271 - acc: 0.7036 - val_loss: 7.6737 - val_acc: 0.5743\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 7.2403 - acc: 0.7037 - val_loss: 7.5755 - val_acc: 0.5842\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 7.1217 - acc: 0.7226 - val_loss: 7.5310 - val_acc: 0.5697\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 7.0266 - acc: 0.7217 - val_loss: 7.4321 - val_acc: 0.5824\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 6.9298 - acc: 0.7325 - val_loss: 7.3492 - val_acc: 0.5761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 6.8384 - acc: 0.7381 - val_loss: 7.2687 - val_acc: 0.5725\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 6.7493 - acc: 0.7404 - val_loss: 7.2091 - val_acc: 0.5833\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 6.6548 - acc: 0.7514 - val_loss: 7.1264 - val_acc: 0.5870\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 6.5562 - acc: 0.7586 - val_loss: 7.0674 - val_acc: 0.5870\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 6.4674 - acc: 0.7641 - val_loss: 7.0007 - val_acc: 0.5888\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 6.3773 - acc: 0.7715 - val_loss: 6.9695 - val_acc: 0.5743\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 6.2914 - acc: 0.7748 - val_loss: 6.8615 - val_acc: 0.5906\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: 6.2070 - acc: 0.7782 - val_loss: 6.7804 - val_acc: 0.5815\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 6.1110 - acc: 0.7884 - val_loss: 6.7205 - val_acc: 0.5806\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 6.0373 - acc: 0.7887 - val_loss: 6.6513 - val_acc: 0.5797\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 5.9549 - acc: 0.7951 - val_loss: 6.5558 - val_acc: 0.5842\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 5.8595 - acc: 0.8019 - val_loss: 6.5143 - val_acc: 0.5897\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 5.7621 - acc: 0.8164 - val_loss: 6.4306 - val_acc: 0.5960\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 5.6933 - acc: 0.8148 - val_loss: 6.4021 - val_acc: 0.5842\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 5.6099 - acc: 0.8253 - val_loss: 6.3211 - val_acc: 0.6033\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 5.5337 - acc: 0.8315 - val_loss: 6.2818 - val_acc: 0.5797\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 5.4598 - acc: 0.8326 - val_loss: 6.1880 - val_acc: 0.5879\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 5.3865 - acc: 0.8355 - val_loss: 6.1865 - val_acc: 0.5824\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 5.3021 - acc: 0.8487 - val_loss: 6.0977 - val_acc: 0.5915\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 5.2267 - acc: 0.8464 - val_loss: 6.0350 - val_acc: 0.5833\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 5.1513 - acc: 0.8533 - val_loss: 5.9972 - val_acc: 0.5797\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 5.0708 - acc: 0.8625 - val_loss: 5.9375 - val_acc: 0.5815\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 4.9992 - acc: 0.8654 - val_loss: 5.8832 - val_acc: 0.5924\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 4.9489 - acc: 0.8613 - val_loss: 5.8187 - val_acc: 0.5942\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 4.8716 - acc: 0.8662 - val_loss: 5.7890 - val_acc: 0.5779\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 43s 5ms/step - loss: 3.8288 - acc: 0.4736 - val_loss: 3.5921 - val_acc: 0.5127\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3627 - acc: 0.6098 - val_loss: 3.5253 - val_acc: 0.5335\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.1602 - acc: 0.6781 - val_loss: 3.4671 - val_acc: 0.5525\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0046 - acc: 0.7370 - val_loss: 3.4553 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8676 - acc: 0.7947 - val_loss: 3.4772 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7499 - acc: 0.8421 - val_loss: 3.3947 - val_acc: 0.5697\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6533 - acc: 0.8678 - val_loss: 3.4249 - val_acc: 0.5571\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5478 - acc: 0.9084 - val_loss: 3.4021 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4722 - acc: 0.9274 - val_loss: 3.4522 - val_acc: 0.5598\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3860 - acc: 0.9503 - val_loss: 3.4324 - val_acc: 0.5607\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3184 - acc: 0.9672 - val_loss: 3.3619 - val_acc: 0.5770\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2691 - acc: 0.9704 - val_loss: 3.4308 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2091 - acc: 0.9829 - val_loss: 3.4181 - val_acc: 0.5734\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1483 - acc: 0.9912 - val_loss: 3.3611 - val_acc: 0.5815\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.1125 - acc: 0.9929 - val_loss: 3.3606 - val_acc: 0.5761\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0759 - acc: 0.9938 - val_loss: 3.3879 - val_acc: 0.5670\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0357 - acc: 0.9951 - val_loss: 3.3669 - val_acc: 0.5752\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0014 - acc: 0.9968 - val_loss: 3.3689 - val_acc: 0.5788\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9699 - acc: 0.9952 - val_loss: 3.4098 - val_acc: 0.5679\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9577 - acc: 0.9912 - val_loss: 3.3898 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9251 - acc: 0.9932 - val_loss: 3.3721 - val_acc: 0.5634\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9005 - acc: 0.9924 - val_loss: 3.3975 - val_acc: 0.5534\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8544 - acc: 0.9966 - val_loss: 3.3220 - val_acc: 0.5688\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.8102 - acc: 0.9990 - val_loss: 3.2730 - val_acc: 0.5833\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7745 - acc: 0.9997 - val_loss: 3.2501 - val_acc: 0.5797\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7401 - acc: 0.9997 - val_loss: 3.2644 - val_acc: 0.5770\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7101 - acc: 0.9993 - val_loss: 3.2238 - val_acc: 0.5743\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6771 - acc: 0.9997 - val_loss: 3.2270 - val_acc: 0.5707\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6437 - acc: 0.9997 - val_loss: 3.2016 - val_acc: 0.5716\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6140 - acc: 0.9993 - val_loss: 3.2106 - val_acc: 0.5716\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6176 - acc: 0.9898 - val_loss: 3.5823 - val_acc: 0.5317\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9984 - acc: 0.8448 - val_loss: 3.1668 - val_acc: 0.5480\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6843 - acc: 0.9588 - val_loss: 3.0291 - val_acc: 0.5743\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5594 - acc: 0.9956 - val_loss: 2.9382 - val_acc: 0.5951\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.5091 - acc: 0.9995 - val_loss: 2.9529 - val_acc: 0.5842\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4785 - acc: 0.9995 - val_loss: 2.9345 - val_acc: 0.5888\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4506 - acc: 0.9995 - val_loss: 2.9315 - val_acc: 0.5897\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4234 - acc: 0.9997 - val_loss: 2.9042 - val_acc: 0.5770\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3970 - acc: 0.9995 - val_loss: 2.8921 - val_acc: 0.5915\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3684 - acc: 0.9998 - val_loss: 2.8850 - val_acc: 0.5915\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3415 - acc: 0.9997 - val_loss: 2.8826 - val_acc: 0.5861\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.3132 - acc: 0.9998 - val_loss: 2.8371 - val_acc: 0.5951\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.2856 - acc: 0.9997 - val_loss: 2.8118 - val_acc: 0.5942\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.2576 - acc: 0.9995 - val_loss: 2.8119 - val_acc: 0.5870\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 39s 4ms/step - loss: 14.7953 - acc: 0.3539 - val_loss: 14.3621 - val_acc: 0.4746\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 14.1823 - acc: 0.4892 - val_loss: 14.0096 - val_acc: 0.5163\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 13.8376 - acc: 0.5167 - val_loss: 13.7150 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 13.5385 - acc: 0.5323 - val_loss: 13.4503 - val_acc: 0.5362\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 13.2399 - acc: 0.5596 - val_loss: 13.1704 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 12.9654 - acc: 0.5635 - val_loss: 12.9316 - val_acc: 0.5444\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 12.6806 - acc: 0.5782 - val_loss: 12.6489 - val_acc: 0.5543\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 12.4100 - acc: 0.5910 - val_loss: 12.4292 - val_acc: 0.5417\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 12.1452 - acc: 0.6035 - val_loss: 12.1814 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 11.8855 - acc: 0.6095 - val_loss: 11.9585 - val_acc: 0.5625\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 11.6203 - acc: 0.6254 - val_loss: 11.6990 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 11.3700 - acc: 0.6353 - val_loss: 11.4763 - val_acc: 0.5707\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 11.1255 - acc: 0.6406 - val_loss: 11.2392 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 10.8783 - acc: 0.6496 - val_loss: 11.0267 - val_acc: 0.5697\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 10.6550 - acc: 0.6531 - val_loss: 10.8121 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 10.4112 - acc: 0.6668 - val_loss: 10.5770 - val_acc: 0.5670\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 10.1815 - acc: 0.6767 - val_loss: 10.3900 - val_acc: 0.5734\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 9.9535 - acc: 0.6811 - val_loss: 10.1788 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 9.7383 - acc: 0.6875 - val_loss: 9.9884 - val_acc: 0.5761\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 9.5193 - acc: 0.6931 - val_loss: 9.7874 - val_acc: 0.5761\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 9.3104 - acc: 0.6997 - val_loss: 9.6196 - val_acc: 0.5761\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 9.1091 - acc: 0.7117 - val_loss: 9.3970 - val_acc: 0.5752\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 8.9004 - acc: 0.7207 - val_loss: 9.2383 - val_acc: 0.5643\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 8.7024 - acc: 0.7258 - val_loss: 9.0523 - val_acc: 0.5743\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 8.5059 - acc: 0.7292 - val_loss: 8.8914 - val_acc: 0.5688\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 8.3201 - acc: 0.7322 - val_loss: 8.7224 - val_acc: 0.5761\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 8.1324 - acc: 0.7389 - val_loss: 8.5381 - val_acc: 0.5806\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 7.9566 - acc: 0.7457 - val_loss: 8.3743 - val_acc: 0.5806\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 7.7684 - acc: 0.7580 - val_loss: 8.2397 - val_acc: 0.5861\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 717us/step - loss: 7.5897 - acc: 0.7665 - val_loss: 8.0491 - val_acc: 0.5752\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 7.4261 - acc: 0.7708 - val_loss: 7.9706 - val_acc: 0.5879\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 7.2816 - acc: 0.7619 - val_loss: 7.8076 - val_acc: 0.5725\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 7.0962 - acc: 0.7721 - val_loss: 7.6378 - val_acc: 0.5806\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 6.9357 - acc: 0.7820 - val_loss: 7.4908 - val_acc: 0.5761\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 6.7663 - acc: 0.7914 - val_loss: 7.3519 - val_acc: 0.5861\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 6.6299 - acc: 0.7935 - val_loss: 7.2623 - val_acc: 0.5643\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 6.4792 - acc: 0.7988 - val_loss: 7.0752 - val_acc: 0.5815\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 6.3305 - acc: 0.8055 - val_loss: 6.9781 - val_acc: 0.5797\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 6.1939 - acc: 0.8085 - val_loss: 6.8457 - val_acc: 0.5779\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 6.0621 - acc: 0.8123 - val_loss: 6.7020 - val_acc: 0.5870\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 5.9245 - acc: 0.8171 - val_loss: 6.6081 - val_acc: 0.5806\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0706 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: nan - acc: 0.0732 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 423us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 404us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 434us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 424us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 418us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 422us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 414us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 424us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 9.2415 - acc: 0.3370 - val_loss: 8.4924 - val_acc: 0.4692\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 8.2098 - acc: 0.5075 - val_loss: 7.9949 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 7.6839 - acc: 0.5670 - val_loss: 7.6067 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 7.1876 - acc: 0.6141 - val_loss: 7.1585 - val_acc: 0.5245\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 6.7087 - acc: 0.6413 - val_loss: 6.7685 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 537us/step - loss: 6.2525 - acc: 0.6672 - val_loss: 6.3809 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 5.8423 - acc: 0.6861 - val_loss: 6.0368 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 5.4380 - acc: 0.7069 - val_loss: 5.7152 - val_acc: 0.5553\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 5.0583 - acc: 0.7367 - val_loss: 5.4410 - val_acc: 0.5562\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 4.7201 - acc: 0.7469 - val_loss: 5.1741 - val_acc: 0.5435\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 4.4204 - acc: 0.7587 - val_loss: 4.9770 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 538us/step - loss: 4.1450 - acc: 0.7682 - val_loss: 4.6901 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 3.8864 - acc: 0.7800 - val_loss: 4.4640 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 541us/step - loss: 3.6195 - acc: 0.7986 - val_loss: 4.2444 - val_acc: 0.5607\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 3.3713 - acc: 0.8255 - val_loss: 4.1363 - val_acc: 0.5371\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 3.1688 - acc: 0.8257 - val_loss: 3.8995 - val_acc: 0.5525\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 2.9557 - acc: 0.8513 - val_loss: 3.7827 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 2.7949 - acc: 0.8463 - val_loss: 3.6584 - val_acc: 0.5643\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.6591 - acc: 0.8516 - val_loss: 3.6347 - val_acc: 0.5453\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 2.5226 - acc: 0.8564 - val_loss: 3.4566 - val_acc: 0.5498\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 2.3752 - acc: 0.8705 - val_loss: 3.3874 - val_acc: 0.5389\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 533us/step - loss: 2.2575 - acc: 0.8756 - val_loss: 3.3327 - val_acc: 0.5326\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 2.1585 - acc: 0.8786 - val_loss: 3.2144 - val_acc: 0.5507\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 2.0478 - acc: 0.8881 - val_loss: 3.0956 - val_acc: 0.5879\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.9378 - acc: 0.8986 - val_loss: 3.0782 - val_acc: 0.5725\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 1.8448 - acc: 0.9077 - val_loss: 3.0522 - val_acc: 0.5571\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 1.7519 - acc: 0.9120 - val_loss: 2.9212 - val_acc: 0.5707\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 1.6870 - acc: 0.9095 - val_loss: 2.9413 - val_acc: 0.5480\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 1.6510 - acc: 0.9035 - val_loss: 2.9069 - val_acc: 0.5471\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 1.5880 - acc: 0.9080 - val_loss: 2.8132 - val_acc: 0.5389\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 1.5058 - acc: 0.9212 - val_loss: 2.7729 - val_acc: 0.5534\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.4763 - acc: 0.9170 - val_loss: 2.8062 - val_acc: 0.5553\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 1.4165 - acc: 0.9190 - val_loss: 2.8011 - val_acc: 0.5426\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.3684 - acc: 0.9255 - val_loss: 2.7459 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 9.1829 - acc: 0.4208 - val_loss: 8.8509 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 627us/step - loss: 8.6202 - acc: 0.5563 - val_loss: 8.5987 - val_acc: 0.5335\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 8.3432 - acc: 0.6087 - val_loss: 8.4480 - val_acc: 0.5408\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 8.1106 - acc: 0.6458 - val_loss: 8.2953 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 7.8974 - acc: 0.6817 - val_loss: 8.1153 - val_acc: 0.5525\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 7.6952 - acc: 0.7097 - val_loss: 8.0424 - val_acc: 0.5580\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 7.5045 - acc: 0.7384 - val_loss: 7.8755 - val_acc: 0.5408\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 7.3204 - acc: 0.7629 - val_loss: 7.7467 - val_acc: 0.5480\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 7.1461 - acc: 0.7746 - val_loss: 7.6167 - val_acc: 0.5688\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 6.9623 - acc: 0.8070 - val_loss: 7.4980 - val_acc: 0.5652\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 6.7971 - acc: 0.8147 - val_loss: 7.3642 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 6.6244 - acc: 0.8401 - val_loss: 7.2512 - val_acc: 0.5652\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 6.4645 - acc: 0.8511 - val_loss: 7.1793 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 6.3172 - acc: 0.8651 - val_loss: 7.0170 - val_acc: 0.5770\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 6.1498 - acc: 0.8845 - val_loss: 6.9184 - val_acc: 0.5661\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 6.0025 - acc: 0.8979 - val_loss: 6.8141 - val_acc: 0.5589\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 5.8732 - acc: 0.8977 - val_loss: 6.6891 - val_acc: 0.5634\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.7097 - acc: 0.9228 - val_loss: 6.5908 - val_acc: 0.5670\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 5.5885 - acc: 0.9231 - val_loss: 6.4891 - val_acc: 0.5670\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 5.4474 - acc: 0.9351 - val_loss: 6.3674 - val_acc: 0.5770\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 5.3189 - acc: 0.9393 - val_loss: 6.2847 - val_acc: 0.5824\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 5.2021 - acc: 0.9437 - val_loss: 6.2115 - val_acc: 0.5788\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 719us/step - loss: 5.0765 - acc: 0.9514 - val_loss: 6.1684 - val_acc: 0.5525\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 4.9516 - acc: 0.9579 - val_loss: 6.0127 - val_acc: 0.5824\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 4.8382 - acc: 0.9614 - val_loss: 5.9083 - val_acc: 0.5788\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 4.7220 - acc: 0.9675 - val_loss: 5.8130 - val_acc: 0.5833\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 4.6145 - acc: 0.9686 - val_loss: 5.7813 - val_acc: 0.5643\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 693us/step - loss: 4.5143 - acc: 0.9682 - val_loss: 5.6777 - val_acc: 0.5779\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 4.4035 - acc: 0.9717 - val_loss: 5.5817 - val_acc: 0.5752\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 726us/step - loss: 4.3021 - acc: 0.9743 - val_loss: 5.5226 - val_acc: 0.5743\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 4.2022 - acc: 0.9776 - val_loss: 5.4604 - val_acc: 0.5779\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 4.1038 - acc: 0.9785 - val_loss: 5.3440 - val_acc: 0.5752\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 4.0051 - acc: 0.9815 - val_loss: 5.2848 - val_acc: 0.5725\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 3.9082 - acc: 0.9827 - val_loss: 5.2092 - val_acc: 0.5688\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 3.8133 - acc: 0.9857 - val_loss: 5.1611 - val_acc: 0.5734\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 3.7191 - acc: 0.9877 - val_loss: 5.0604 - val_acc: 0.5761\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 44s 5ms/step - loss: 4.3357 - acc: 0.4759 - val_loss: 4.1158 - val_acc: 0.5254\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.8362 - acc: 0.6344 - val_loss: 4.0224 - val_acc: 0.5408\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.6133 - acc: 0.7131 - val_loss: 4.0141 - val_acc: 0.5435\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.4488 - acc: 0.7662 - val_loss: 3.9411 - val_acc: 0.5489\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.3040 - acc: 0.8176 - val_loss: 3.9499 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1703 - acc: 0.8606 - val_loss: 3.9157 - val_acc: 0.5571\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0362 - acc: 0.9043 - val_loss: 3.8571 - val_acc: 0.5707\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9265 - acc: 0.9343 - val_loss: 3.8272 - val_acc: 0.5616\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.8433 - acc: 0.9506 - val_loss: 3.8326 - val_acc: 0.5679\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7502 - acc: 0.9710 - val_loss: 3.8117 - val_acc: 0.5616\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6785 - acc: 0.9772 - val_loss: 3.8171 - val_acc: 0.5688\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6099 - acc: 0.9856 - val_loss: 3.7651 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5468 - acc: 0.9891 - val_loss: 3.7954 - val_acc: 0.5670\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4913 - acc: 0.9940 - val_loss: 3.7453 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4198 - acc: 0.9988 - val_loss: 3.7403 - val_acc: 0.5679\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3716 - acc: 0.9976 - val_loss: 3.7368 - val_acc: 0.5643\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3357 - acc: 0.9961 - val_loss: 3.7224 - val_acc: 0.5661\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2770 - acc: 0.9982 - val_loss: 3.6754 - val_acc: 0.5589\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2353 - acc: 0.9973 - val_loss: 3.7253 - val_acc: 0.5707\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2455 - acc: 0.9815 - val_loss: 3.7461 - val_acc: 0.5353\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.2051 - acc: 0.9837 - val_loss: 3.7108 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1820 - acc: 0.9753 - val_loss: 3.6087 - val_acc: 0.5598\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0934 - acc: 0.9932 - val_loss: 3.5522 - val_acc: 0.5688\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0215 - acc: 0.9986 - val_loss: 3.5389 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 44s 5ms/step - loss: 4.0118 - acc: 0.4643 - val_loss: 3.7992 - val_acc: 0.5172\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5724 - acc: 0.5890 - val_loss: 3.6615 - val_acc: 0.5408\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3834 - acc: 0.6449 - val_loss: 3.6316 - val_acc: 0.5389\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2391 - acc: 0.6876 - val_loss: 3.5944 - val_acc: 0.5525\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0969 - acc: 0.7394 - val_loss: 3.5568 - val_acc: 0.5571\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9712 - acc: 0.7812 - val_loss: 3.5027 - val_acc: 0.5525\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.8597 - acc: 0.8163 - val_loss: 3.5103 - val_acc: 0.5580\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7578 - acc: 0.8449 - val_loss: 3.4507 - val_acc: 0.5725\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.6586 - acc: 0.8711 - val_loss: 3.4225 - val_acc: 0.5716\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5647 - acc: 0.8973 - val_loss: 3.4367 - val_acc: 0.5589\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.4788 - acc: 0.9171 - val_loss: 3.3963 - val_acc: 0.5707\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.3974 - acc: 0.9345 - val_loss: 3.3932 - val_acc: 0.5743\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3141 - acc: 0.9532 - val_loss: 3.3871 - val_acc: 0.5779\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2589 - acc: 0.9561 - val_loss: 3.4050 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1969 - acc: 0.9660 - val_loss: 3.3561 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1353 - acc: 0.9732 - val_loss: 3.3358 - val_acc: 0.5842\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0743 - acc: 0.9822 - val_loss: 3.3522 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0212 - acc: 0.9846 - val_loss: 3.3012 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9651 - acc: 0.9906 - val_loss: 3.3025 - val_acc: 0.5707\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9249 - acc: 0.9904 - val_loss: 3.3137 - val_acc: 0.5842\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8884 - acc: 0.9877 - val_loss: 3.3223 - val_acc: 0.5507\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8502 - acc: 0.9882 - val_loss: 3.2842 - val_acc: 0.5815\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8137 - acc: 0.9855 - val_loss: 3.2256 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.7735 - acc: 0.9874 - val_loss: 3.2531 - val_acc: 0.5670\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7414 - acc: 0.9841 - val_loss: 3.2294 - val_acc: 0.5725\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6825 - acc: 0.9939 - val_loss: 3.1836 - val_acc: 0.5824\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 8.9858 - acc: 0.3456 - val_loss: 8.2329 - val_acc: 0.4583\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 7.8838 - acc: 0.4901 - val_loss: 7.6759 - val_acc: 0.4864\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 7.2391 - acc: 0.5620 - val_loss: 7.0273 - val_acc: 0.5353\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 6.6212 - acc: 0.5943 - val_loss: 6.5281 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 6.0326 - acc: 0.6229 - val_loss: 6.0304 - val_acc: 0.5435\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 5.4931 - acc: 0.6493 - val_loss: 5.5452 - val_acc: 0.5353\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 4.9904 - acc: 0.6715 - val_loss: 5.1531 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 4.5462 - acc: 0.6951 - val_loss: 4.8635 - val_acc: 0.5543\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 4.1589 - acc: 0.6983 - val_loss: 4.5405 - val_acc: 0.5281\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 3.8375 - acc: 0.7043 - val_loss: 4.2050 - val_acc: 0.5498\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 3.5120 - acc: 0.7219 - val_loss: 3.9351 - val_acc: 0.5353\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 3.2343 - acc: 0.7369 - val_loss: 3.7698 - val_acc: 0.5226\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 2.9745 - acc: 0.7571 - val_loss: 3.4466 - val_acc: 0.5734\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.7354 - acc: 0.7770 - val_loss: 3.3433 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 2.5716 - acc: 0.7730 - val_loss: 3.2805 - val_acc: 0.5290\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.4443 - acc: 0.7660 - val_loss: 3.1081 - val_acc: 0.5417\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 2.2891 - acc: 0.7825 - val_loss: 2.9437 - val_acc: 0.5598\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 2.1287 - acc: 0.8020 - val_loss: 2.8683 - val_acc: 0.5444\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 2.0056 - acc: 0.8156 - val_loss: 2.8058 - val_acc: 0.5444\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 1.9120 - acc: 0.8199 - val_loss: 2.7732 - val_acc: 0.5371\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 1.8137 - acc: 0.8261 - val_loss: 2.6559 - val_acc: 0.5589\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 1.7170 - acc: 0.8398 - val_loss: 2.6043 - val_acc: 0.5580\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.6645 - acc: 0.8324 - val_loss: 2.6409 - val_acc: 0.5399\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 9.3930 - acc: 0.3644 - val_loss: 8.6703 - val_acc: 0.4529\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 8.3560 - acc: 0.5354 - val_loss: 8.2217 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 7.8432 - acc: 0.5898 - val_loss: 7.7895 - val_acc: 0.5371\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 7.3674 - acc: 0.6397 - val_loss: 7.4274 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 6.8932 - acc: 0.6786 - val_loss: 7.0597 - val_acc: 0.5480\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 6.4517 - acc: 0.7069 - val_loss: 6.6825 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 6.0499 - acc: 0.7316 - val_loss: 6.4225 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 5.6706 - acc: 0.7480 - val_loss: 6.0622 - val_acc: 0.5525\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 5.3019 - acc: 0.7781 - val_loss: 5.7051 - val_acc: 0.5562\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 4.9626 - acc: 0.7964 - val_loss: 5.5326 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 4.6428 - acc: 0.8125 - val_loss: 5.2215 - val_acc: 0.5607\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 4.3593 - acc: 0.8290 - val_loss: 4.9937 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 4.0526 - acc: 0.8641 - val_loss: 4.7640 - val_acc: 0.5643\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 3.8168 - acc: 0.8643 - val_loss: 4.6101 - val_acc: 0.5507\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 3.6178 - acc: 0.8614 - val_loss: 4.3910 - val_acc: 0.5652\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 3.3862 - acc: 0.8810 - val_loss: 4.2510 - val_acc: 0.5707\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 3.1860 - acc: 0.8968 - val_loss: 4.1130 - val_acc: 0.5562\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 3.0099 - acc: 0.8993 - val_loss: 3.9472 - val_acc: 0.5589\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 2.8563 - acc: 0.9045 - val_loss: 3.8696 - val_acc: 0.5670\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 2.7232 - acc: 0.8985 - val_loss: 3.6900 - val_acc: 0.5697\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 505us/step - loss: 2.5388 - acc: 0.9272 - val_loss: 3.6376 - val_acc: 0.5562\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.3950 - acc: 0.9390 - val_loss: 3.5778 - val_acc: 0.5598\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.2576 - acc: 0.9447 - val_loss: 3.4903 - val_acc: 0.5498\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 2.1626 - acc: 0.9356 - val_loss: 3.3472 - val_acc: 0.5417\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 2.0671 - acc: 0.9410 - val_loss: 3.2358 - val_acc: 0.5643\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 1.9706 - acc: 0.9422 - val_loss: 3.2039 - val_acc: 0.5471\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 8.9147 - acc: 0.3004 - val_loss: 7.6875 - val_acc: 0.4230\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 533us/step - loss: 7.3368 - acc: 0.4741 - val_loss: 7.0327 - val_acc: 0.4873\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 6.6036 - acc: 0.5542 - val_loss: 6.3545 - val_acc: 0.4918\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 5.8853 - acc: 0.5824 - val_loss: 5.7582 - val_acc: 0.5136\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 5.2433 - acc: 0.5978 - val_loss: 5.1593 - val_acc: 0.5245\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 538us/step - loss: 4.6413 - acc: 0.6284 - val_loss: 4.7319 - val_acc: 0.5226\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 4.1579 - acc: 0.6393 - val_loss: 4.2648 - val_acc: 0.5281\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 3.6821 - acc: 0.6746 - val_loss: 3.8954 - val_acc: 0.5317\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 3.3393 - acc: 0.6775 - val_loss: 3.6934 - val_acc: 0.5082\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 3.0080 - acc: 0.6991 - val_loss: 3.3936 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 2.7874 - acc: 0.6926 - val_loss: 3.1556 - val_acc: 0.5272\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 2.5790 - acc: 0.7083 - val_loss: 3.0506 - val_acc: 0.5344\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.4113 - acc: 0.7171 - val_loss: 2.9117 - val_acc: 0.5543\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 2.2155 - acc: 0.7304 - val_loss: 2.8398 - val_acc: 0.5290\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 2.1083 - acc: 0.7293 - val_loss: 2.7820 - val_acc: 0.5326\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 1.9594 - acc: 0.7484 - val_loss: 2.6200 - val_acc: 0.5281\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.8456 - acc: 0.7648 - val_loss: 2.5562 - val_acc: 0.5353\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 1.7685 - acc: 0.7669 - val_loss: 2.5663 - val_acc: 0.5245\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 1.6625 - acc: 0.7873 - val_loss: 2.4819 - val_acc: 0.5489\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 1.6031 - acc: 0.7914 - val_loss: 2.4642 - val_acc: 0.5281\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 510us/step - loss: 1.5703 - acc: 0.7849 - val_loss: 2.4662 - val_acc: 0.5344\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 1.5547 - acc: 0.7815 - val_loss: 2.4084 - val_acc: 0.5236\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.5448 - acc: 0.7717 - val_loss: 2.3814 - val_acc: 0.5399\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 36s 4ms/step - loss: 8.2412 - acc: 0.2680 - val_loss: 6.7160 - val_acc: 0.3904\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 480us/step - loss: 6.5126 - acc: 0.4442 - val_loss: 6.2682 - val_acc: 0.4656\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 5.9707 - acc: 0.5247 - val_loss: 5.7889 - val_acc: 0.5136\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 5.4190 - acc: 0.5582 - val_loss: 5.2674 - val_acc: 0.5145\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 4.8527 - acc: 0.5953 - val_loss: 4.7904 - val_acc: 0.5281\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 4.3621 - acc: 0.6149 - val_loss: 4.4339 - val_acc: 0.5082\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 3.9790 - acc: 0.6179 - val_loss: 4.0312 - val_acc: 0.5362\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 3.5984 - acc: 0.6373 - val_loss: 3.7736 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 473us/step - loss: 3.2753 - acc: 0.6509 - val_loss: 3.5329 - val_acc: 0.5453\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 3.0376 - acc: 0.6462 - val_loss: 3.3919 - val_acc: 0.5172\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 2.7568 - acc: 0.6780 - val_loss: 3.1174 - val_acc: 0.5580\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 477us/step - loss: 2.5407 - acc: 0.6962 - val_loss: 2.9461 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 2.3897 - acc: 0.6929 - val_loss: 2.9620 - val_acc: 0.5190\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.2773 - acc: 0.6965 - val_loss: 2.7757 - val_acc: 0.5362\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 2.0784 - acc: 0.7315 - val_loss: 2.6411 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 1.9139 - acc: 0.7523 - val_loss: 2.6488 - val_acc: 0.5399\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.8618 - acc: 0.7432 - val_loss: 2.5721 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.8679 - acc: 0.7160 - val_loss: 2.5395 - val_acc: 0.5091\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 1.7384 - acc: 0.7475 - val_loss: 2.5011 - val_acc: 0.5344\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.6245 - acc: 0.7709 - val_loss: 2.4128 - val_acc: 0.5489\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 492us/step - loss: 1.5497 - acc: 0.7826 - val_loss: 2.4299 - val_acc: 0.5408\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 17.9155 - acc: 0.3543 - val_loss: 16.8850 - val_acc: 0.4611\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 16.1743 - acc: 0.4832 - val_loss: 15.3187 - val_acc: 0.5109\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 14.6186 - acc: 0.5366 - val_loss: 13.8855 - val_acc: 0.4928\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 13.1180 - acc: 0.5625 - val_loss: 12.4451 - val_acc: 0.5082\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 11.7201 - acc: 0.5848 - val_loss: 11.1615 - val_acc: 0.5281\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 10.4371 - acc: 0.6089 - val_loss: 9.9789 - val_acc: 0.5380\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 9.3161 - acc: 0.6146 - val_loss: 8.9432 - val_acc: 0.5435\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 8.3122 - acc: 0.6249 - val_loss: 8.0380 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 7.4029 - acc: 0.6414 - val_loss: 7.2185 - val_acc: 0.5426\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 6.6193 - acc: 0.6517 - val_loss: 6.5320 - val_acc: 0.5444\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 5.9406 - acc: 0.6769 - val_loss: 5.9607 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 5.3457 - acc: 0.6737 - val_loss: 5.3803 - val_acc: 0.5580\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 4.8285 - acc: 0.6795 - val_loss: 5.0242 - val_acc: 0.5553\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 4.4140 - acc: 0.6800 - val_loss: 4.5907 - val_acc: 0.5543\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 3.9995 - acc: 0.6936 - val_loss: 4.2204 - val_acc: 0.5426\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 533us/step - loss: 3.6604 - acc: 0.7078 - val_loss: 3.9519 - val_acc: 0.5562\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 3.3754 - acc: 0.7099 - val_loss: 3.6917 - val_acc: 0.5471\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 3.1125 - acc: 0.7184 - val_loss: 3.5248 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 2.8984 - acc: 0.7224 - val_loss: 3.3906 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.7317 - acc: 0.7107 - val_loss: 3.1264 - val_acc: 0.5697\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.5478 - acc: 0.7290 - val_loss: 3.0474 - val_acc: 0.5480\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 2.4062 - acc: 0.7371 - val_loss: 2.9685 - val_acc: 0.5426\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 2.3186 - acc: 0.7243 - val_loss: 2.8468 - val_acc: 0.5408\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.1717 - acc: 0.7421 - val_loss: 2.8102 - val_acc: 0.5317\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 2.0786 - acc: 0.7503 - val_loss: 2.6678 - val_acc: 0.5462\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.9651 - acc: 0.7627 - val_loss: 2.5676 - val_acc: 0.5426\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.8956 - acc: 0.7603 - val_loss: 2.5328 - val_acc: 0.5571\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 1.8048 - acc: 0.7790 - val_loss: 2.4925 - val_acc: 0.5426\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 1.7356 - acc: 0.7797 - val_loss: 2.4812 - val_acc: 0.5299\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 1.6975 - acc: 0.7774 - val_loss: 2.4662 - val_acc: 0.5489\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 11.3696 - acc: 0.2272 - val_loss: 9.7118 - val_acc: 0.3406\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 9.2301 - acc: 0.4079 - val_loss: 8.5679 - val_acc: 0.4375\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 489us/step - loss: 7.9596 - acc: 0.4772 - val_loss: 7.2737 - val_acc: 0.4755\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 6.5951 - acc: 0.5150 - val_loss: 5.9886 - val_acc: 0.5072\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 467us/step - loss: 5.4281 - acc: 0.5332 - val_loss: 5.0303 - val_acc: 0.5063\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 470us/step - loss: 4.5095 - acc: 0.5536 - val_loss: 4.3283 - val_acc: 0.4819\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 470us/step - loss: 3.8203 - acc: 0.5736 - val_loss: 3.7157 - val_acc: 0.4891\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 499us/step - loss: 3.3694 - acc: 0.5441 - val_loss: 3.2865 - val_acc: 0.5054\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 2.9526 - acc: 0.5699 - val_loss: 3.0475 - val_acc: 0.4955\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 2.6901 - acc: 0.5763 - val_loss: 2.7525 - val_acc: 0.5136\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 493us/step - loss: 2.4626 - acc: 0.5850 - val_loss: 2.5703 - val_acc: 0.5127\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: 2.2384 - acc: 0.5969 - val_loss: 2.3985 - val_acc: 0.5190\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 2.1253 - acc: 0.5955 - val_loss: 2.2971 - val_acc: 0.5263\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 2.0211 - acc: 0.5890 - val_loss: 2.2826 - val_acc: 0.4855\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 1.9522 - acc: 0.5949 - val_loss: 2.1707 - val_acc: 0.5145\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 1.8482 - acc: 0.6013 - val_loss: 2.0615 - val_acc: 0.5272\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 497us/step - loss: 1.7324 - acc: 0.6241 - val_loss: 1.9701 - val_acc: 0.5263\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 498us/step - loss: 1.6804 - acc: 0.6227 - val_loss: 2.0671 - val_acc: 0.5136\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 1.6658 - acc: 0.6117 - val_loss: 2.0047 - val_acc: 0.4964\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.6082 - acc: 0.6283 - val_loss: 1.9277 - val_acc: 0.5082\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.6352 - acc: 0.6121 - val_loss: 2.0253 - val_acc: 0.4837\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.6140 - acc: 0.6139 - val_loss: 1.9067 - val_acc: 0.5236\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: 1.5376 - acc: 0.6338 - val_loss: 1.9970 - val_acc: 0.5036\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.5052 - acc: 0.6330 - val_loss: 1.8381 - val_acc: 0.5226\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 1.3878 - acc: 0.6628 - val_loss: 1.8836 - val_acc: 0.5181\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 1.4687 - acc: 0.6370 - val_loss: 1.9094 - val_acc: 0.5109\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 8.3528 - acc: 0.3756 - val_loss: 7.9700 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 7.8626 - acc: 0.5149 - val_loss: 7.8149 - val_acc: 0.5145\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 622us/step - loss: 7.6898 - acc: 0.5430 - val_loss: 7.6918 - val_acc: 0.5389\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 7.5454 - acc: 0.5756 - val_loss: 7.5818 - val_acc: 0.5543\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 7.4084 - acc: 0.5966 - val_loss: 7.4884 - val_acc: 0.5543\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 641us/step - loss: 7.2912 - acc: 0.6094 - val_loss: 7.4354 - val_acc: 0.5516\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 7.1797 - acc: 0.6240 - val_loss: 7.3372 - val_acc: 0.5625\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 641us/step - loss: 7.0764 - acc: 0.6385 - val_loss: 7.2552 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 6.9628 - acc: 0.6663 - val_loss: 7.2177 - val_acc: 0.5616\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 6.8662 - acc: 0.6709 - val_loss: 7.1423 - val_acc: 0.5589\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 6.7687 - acc: 0.6842 - val_loss: 7.0565 - val_acc: 0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 6.6666 - acc: 0.6987 - val_loss: 6.9638 - val_acc: 0.5743\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 6.5706 - acc: 0.7083 - val_loss: 6.9231 - val_acc: 0.5688\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 6.4717 - acc: 0.7201 - val_loss: 6.8382 - val_acc: 0.5716\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: 6.3779 - acc: 0.7361 - val_loss: 6.7930 - val_acc: 0.5761\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 6.2829 - acc: 0.7472 - val_loss: 6.7393 - val_acc: 0.5707\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 6.2013 - acc: 0.7580 - val_loss: 6.6794 - val_acc: 0.5734\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 6.1061 - acc: 0.7640 - val_loss: 6.6114 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 628us/step - loss: 6.0247 - acc: 0.7725 - val_loss: 6.5830 - val_acc: 0.5679\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 5.9360 - acc: 0.7812 - val_loss: 6.4826 - val_acc: 0.5779\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 5.8578 - acc: 0.7829 - val_loss: 6.4392 - val_acc: 0.5815\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 5.7756 - acc: 0.8033 - val_loss: 6.3655 - val_acc: 0.5797\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 5.6903 - acc: 0.8124 - val_loss: 6.3134 - val_acc: 0.5661\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 5.6018 - acc: 0.8207 - val_loss: 6.2853 - val_acc: 0.5897\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 5.5234 - acc: 0.8249 - val_loss: 6.2023 - val_acc: 0.5824\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 5.4370 - acc: 0.8359 - val_loss: 6.1256 - val_acc: 0.5707\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 5.3700 - acc: 0.8426 - val_loss: 6.1124 - val_acc: 0.5906\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 5.2871 - acc: 0.8533 - val_loss: 6.0453 - val_acc: 0.5761\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 5.2050 - acc: 0.8622 - val_loss: 6.0078 - val_acc: 0.5861\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 5.1323 - acc: 0.8630 - val_loss: 5.9560 - val_acc: 0.5851\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 5.0662 - acc: 0.8679 - val_loss: 5.9041 - val_acc: 0.5797\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 4.9960 - acc: 0.8772 - val_loss: 5.8538 - val_acc: 0.5815\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 4.9121 - acc: 0.8878 - val_loss: 5.7702 - val_acc: 0.5888\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 640us/step - loss: 4.8467 - acc: 0.8881 - val_loss: 5.7382 - val_acc: 0.5815\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 622us/step - loss: 4.7840 - acc: 0.8942 - val_loss: 5.7183 - val_acc: 0.5824\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 4.7079 - acc: 0.9035 - val_loss: 5.6383 - val_acc: 0.5906\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 4.6412 - acc: 0.9084 - val_loss: 5.6402 - val_acc: 0.5815\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 4.5746 - acc: 0.9144 - val_loss: 5.5661 - val_acc: 0.5833\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 638us/step - loss: 4.5132 - acc: 0.9164 - val_loss: 5.5177 - val_acc: 0.5870\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 4.4496 - acc: 0.9226 - val_loss: 5.4747 - val_acc: 0.5861\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 4.3839 - acc: 0.9229 - val_loss: 5.4145 - val_acc: 0.5915\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 4.3262 - acc: 0.9273 - val_loss: 5.4021 - val_acc: 0.5725\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 4.2663 - acc: 0.9286 - val_loss: 5.3654 - val_acc: 0.5824\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 4.2117 - acc: 0.9308 - val_loss: 5.3506 - val_acc: 0.5815\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 4.1453 - acc: 0.9370 - val_loss: 5.2650 - val_acc: 0.5915\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 4.0892 - acc: 0.9403 - val_loss: 5.2569 - val_acc: 0.5806\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 6s 650us/step - loss: 4.0313 - acc: 0.9443 - val_loss: 5.2090 - val_acc: 0.5888\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 6s 630us/step - loss: 3.9934 - acc: 0.9367 - val_loss: 5.1703 - val_acc: 0.5707\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 6s 651us/step - loss: 3.9231 - acc: 0.9489 - val_loss: 5.1381 - val_acc: 0.5842\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 3.8718 - acc: 0.9520 - val_loss: 5.1029 - val_acc: 0.5842\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 3.8103 - acc: 0.9558 - val_loss: 5.0829 - val_acc: 0.5806\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 6s 640us/step - loss: 3.7619 - acc: 0.9553 - val_loss: 5.0242 - val_acc: 0.5861\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 3.7042 - acc: 0.9593 - val_loss: 5.0191 - val_acc: 0.5770\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 6s 657us/step - loss: 3.6516 - acc: 0.9648 - val_loss: 4.9310 - val_acc: 0.5833\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 3.6031 - acc: 0.9619 - val_loss: 4.8875 - val_acc: 0.5815\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 37s 4ms/step - loss: 8.2075 - acc: 0.2103 - val_loss: 6.5894 - val_acc: 0.3062\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 6.3806 - acc: 0.3818 - val_loss: 6.1270 - val_acc: 0.4330\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 5.8017 - acc: 0.4606 - val_loss: 5.5072 - val_acc: 0.4420\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 461us/step - loss: 5.0977 - acc: 0.5115 - val_loss: 4.8081 - val_acc: 0.4828\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 4.4626 - acc: 0.5254 - val_loss: 4.2615 - val_acc: 0.4837\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 3.8782 - acc: 0.5482 - val_loss: 3.7793 - val_acc: 0.4982\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 3.4055 - acc: 0.5652 - val_loss: 3.3444 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 3.1875 - acc: 0.5288 - val_loss: 3.2339 - val_acc: 0.4882\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 2.8678 - acc: 0.5576 - val_loss: 2.8329 - val_acc: 0.5263\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 2.5650 - acc: 0.5823 - val_loss: 2.6109 - val_acc: 0.5399\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: 2.3608 - acc: 0.5903 - val_loss: 2.4692 - val_acc: 0.5127\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 2.1830 - acc: 0.6003 - val_loss: 2.3770 - val_acc: 0.5226\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 474us/step - loss: 2.1127 - acc: 0.5900 - val_loss: 2.3036 - val_acc: 0.5054\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 2.0345 - acc: 0.5804 - val_loss: 2.2605 - val_acc: 0.5054\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 485us/step - loss: 1.9003 - acc: 0.6070 - val_loss: 2.1815 - val_acc: 0.5100\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 482us/step - loss: 1.7952 - acc: 0.6218 - val_loss: 2.1048 - val_acc: 0.5154\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 486us/step - loss: 1.7694 - acc: 0.6143 - val_loss: 2.1200 - val_acc: 0.5136\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 1.7031 - acc: 0.6267 - val_loss: 2.2340 - val_acc: 0.4991\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: 1.6570 - acc: 0.6359 - val_loss: 1.9917 - val_acc: 0.5154\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 1.5670 - acc: 0.6511 - val_loss: 1.9696 - val_acc: 0.5217\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 44s 5ms/step - loss: 4.6621 - acc: 0.4352 - val_loss: 4.3900 - val_acc: 0.5254\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.2780 - acc: 0.5422 - val_loss: 4.3236 - val_acc: 0.5290\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.1175 - acc: 0.5893 - val_loss: 4.2313 - val_acc: 0.5543\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.9884 - acc: 0.6231 - val_loss: 4.1743 - val_acc: 0.5507\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8816 - acc: 0.6504 - val_loss: 4.1046 - val_acc: 0.5580\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.7839 - acc: 0.6795 - val_loss: 4.0892 - val_acc: 0.5752\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6807 - acc: 0.7020 - val_loss: 4.0576 - val_acc: 0.5697\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5976 - acc: 0.7231 - val_loss: 4.0170 - val_acc: 0.5625\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5215 - acc: 0.7364 - val_loss: 4.0032 - val_acc: 0.5743\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4300 - acc: 0.7662 - val_loss: 3.9516 - val_acc: 0.5716\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3571 - acc: 0.7842 - val_loss: 4.0088 - val_acc: 0.5580\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2774 - acc: 0.8044 - val_loss: 3.9078 - val_acc: 0.5734\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2151 - acc: 0.8172 - val_loss: 3.8849 - val_acc: 0.5752\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1297 - acc: 0.8367 - val_loss: 3.8771 - val_acc: 0.5734\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0609 - acc: 0.8534 - val_loss: 3.8427 - val_acc: 0.5725\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9896 - acc: 0.8690 - val_loss: 3.8146 - val_acc: 0.5788\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9351 - acc: 0.8786 - val_loss: 3.8048 - val_acc: 0.5716\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8647 - acc: 0.8918 - val_loss: 3.7756 - val_acc: 0.5797\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.8030 - acc: 0.9075 - val_loss: 3.7574 - val_acc: 0.5924\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7450 - acc: 0.9162 - val_loss: 3.7442 - val_acc: 0.5716\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6821 - acc: 0.9291 - val_loss: 3.7065 - val_acc: 0.5861\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.6362 - acc: 0.9368 - val_loss: 3.7229 - val_acc: 0.5806\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5727 - acc: 0.9425 - val_loss: 3.7302 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.5341 - acc: 0.9439 - val_loss: 3.6812 - val_acc: 0.5842\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4786 - acc: 0.9556 - val_loss: 3.6830 - val_acc: 0.5743\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.4252 - acc: 0.9606 - val_loss: 3.7036 - val_acc: 0.5688\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3909 - acc: 0.9592 - val_loss: 3.7046 - val_acc: 0.5779\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.3481 - acc: 0.9610 - val_loss: 3.6393 - val_acc: 0.5851\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2957 - acc: 0.9703 - val_loss: 3.6389 - val_acc: 0.5670\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 19.6320 - acc: 0.4088 - val_loss: 16.9720 - val_acc: 0.4900\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 14.7437 - acc: 0.5472 - val_loss: 12.5447 - val_acc: 0.4828\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 10.6994 - acc: 0.5657 - val_loss: 9.1912 - val_acc: 0.5063\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 7.8429 - acc: 0.5789 - val_loss: 6.9272 - val_acc: 0.5127\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 5.9218 - acc: 0.5909 - val_loss: 5.4347 - val_acc: 0.4946\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 4.6632 - acc: 0.5900 - val_loss: 4.5645 - val_acc: 0.4873\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 726us/step - loss: 3.7868 - acc: 0.6096 - val_loss: 3.8527 - val_acc: 0.4918\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 3.2020 - acc: 0.6131 - val_loss: 3.2792 - val_acc: 0.4964\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 2.8236 - acc: 0.6054 - val_loss: 3.0525 - val_acc: 0.5045\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 2.5300 - acc: 0.6070 - val_loss: 2.6952 - val_acc: 0.5217\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 2.2694 - acc: 0.6266 - val_loss: 2.5348 - val_acc: 0.5163\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 2.1145 - acc: 0.6229 - val_loss: 2.4081 - val_acc: 0.4855\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 1.9843 - acc: 0.6296 - val_loss: 2.2533 - val_acc: 0.5308\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 1.8556 - acc: 0.6431 - val_loss: 2.2394 - val_acc: 0.5127\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.7497 - acc: 0.6536 - val_loss: 2.1542 - val_acc: 0.5100\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 1.6672 - acc: 0.6519 - val_loss: 2.1146 - val_acc: 0.5045\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.6547 - acc: 0.6424 - val_loss: 2.0539 - val_acc: 0.5091\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: 1.6001 - acc: 0.6572 - val_loss: 2.0786 - val_acc: 0.5045\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.5535 - acc: 0.6579 - val_loss: 1.9959 - val_acc: 0.5181\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 1.4792 - acc: 0.6753 - val_loss: 1.9842 - val_acc: 0.5226\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 1.4268 - acc: 0.6889 - val_loss: 1.9262 - val_acc: 0.5217\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.3876 - acc: 0.6883 - val_loss: 2.0163 - val_acc: 0.5217\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 1.3777 - acc: 0.6917 - val_loss: 2.0325 - val_acc: 0.5181\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 45s 5ms/step - loss: 4.1952 - acc: 0.4321 - val_loss: 3.9608 - val_acc: 0.5163\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8539 - acc: 0.5311 - val_loss: 3.8617 - val_acc: 0.5281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.7029 - acc: 0.5669 - val_loss: 3.7565 - val_acc: 0.5462\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.5934 - acc: 0.5988 - val_loss: 3.6823 - val_acc: 0.5498\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4921 - acc: 0.6172 - val_loss: 3.6838 - val_acc: 0.5471\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3968 - acc: 0.6449 - val_loss: 3.6614 - val_acc: 0.5598\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3070 - acc: 0.6740 - val_loss: 3.5980 - val_acc: 0.5516\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2270 - acc: 0.6908 - val_loss: 3.5666 - val_acc: 0.5661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1464 - acc: 0.7061 - val_loss: 3.5435 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0760 - acc: 0.7239 - val_loss: 3.5108 - val_acc: 0.5716\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0031 - acc: 0.7410 - val_loss: 3.4526 - val_acc: 0.5734\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9351 - acc: 0.7576 - val_loss: 3.4794 - val_acc: 0.5725\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8568 - acc: 0.7781 - val_loss: 3.4638 - val_acc: 0.5697\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7951 - acc: 0.7941 - val_loss: 3.4231 - val_acc: 0.5815\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7292 - acc: 0.8072 - val_loss: 3.4248 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.6667 - acc: 0.8235 - val_loss: 3.3724 - val_acc: 0.5806\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6004 - acc: 0.8389 - val_loss: 3.3731 - val_acc: 0.5770\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5269 - acc: 0.8556 - val_loss: 3.3583 - val_acc: 0.5761\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4749 - acc: 0.8657 - val_loss: 3.4113 - val_acc: 0.5743\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4228 - acc: 0.8759 - val_loss: 3.3536 - val_acc: 0.5670\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.3733 - acc: 0.8829 - val_loss: 3.3319 - val_acc: 0.5707\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3221 - acc: 0.8940 - val_loss: 3.2788 - val_acc: 0.5824\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2643 - acc: 0.9071 - val_loss: 3.2736 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2154 - acc: 0.9127 - val_loss: 3.2521 - val_acc: 0.5806\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1573 - acc: 0.9237 - val_loss: 3.2941 - val_acc: 0.5806\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.1112 - acc: 0.9319 - val_loss: 3.3094 - val_acc: 0.5670\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0738 - acc: 0.9326 - val_loss: 3.3029 - val_acc: 0.5734\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.0368 - acc: 0.9371 - val_loss: 3.2442 - val_acc: 0.5707\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9775 - acc: 0.9536 - val_loss: 3.2666 - val_acc: 0.5734\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9439 - acc: 0.9520 - val_loss: 3.2337 - val_acc: 0.5707\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9122 - acc: 0.9521 - val_loss: 3.2669 - val_acc: 0.5824\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8776 - acc: 0.9531 - val_loss: 3.1712 - val_acc: 0.5788\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8428 - acc: 0.9572 - val_loss: 3.1859 - val_acc: 0.5625\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8000 - acc: 0.9639 - val_loss: 3.2069 - val_acc: 0.5661\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7636 - acc: 0.9676 - val_loss: 3.1125 - val_acc: 0.5734\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7268 - acc: 0.9684 - val_loss: 3.1642 - val_acc: 0.5779\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.7027 - acc: 0.9665 - val_loss: 3.1854 - val_acc: 0.5851\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6782 - acc: 0.9644 - val_loss: 3.1597 - val_acc: 0.5625\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.6361 - acc: 0.9743 - val_loss: 3.1053 - val_acc: 0.5833\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5987 - acc: 0.9773 - val_loss: 3.0946 - val_acc: 0.5743\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5664 - acc: 0.9795 - val_loss: 3.0900 - val_acc: 0.5770\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.5530 - acc: 0.9716 - val_loss: 3.1291 - val_acc: 0.5688\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5212 - acc: 0.9727 - val_loss: 3.1132 - val_acc: 0.5734\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.4888 - acc: 0.9758 - val_loss: 3.0156 - val_acc: 0.5815\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4721 - acc: 0.9742 - val_loss: 3.0201 - val_acc: 0.5643\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4429 - acc: 0.9741 - val_loss: 3.0004 - val_acc: 0.5806\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4079 - acc: 0.9797 - val_loss: 2.9562 - val_acc: 0.5716\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: nan - acc: 0.0673 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 418us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 411us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 401us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 401us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 33.3120 - acc: 0.3921 - val_loss: 24.9839 - val_acc: 0.4837\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 19.1408 - acc: 0.5258 - val_loss: 13.4777 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 10.4237 - acc: 0.5457 - val_loss: 7.8970 - val_acc: 0.4837\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 6.3577 - acc: 0.5301 - val_loss: 5.2372 - val_acc: 0.4928\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 4.3873 - acc: 0.5394 - val_loss: 4.0378 - val_acc: 0.4420\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 3.3941 - acc: 0.5356 - val_loss: 3.2721 - val_acc: 0.4466\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 2.8187 - acc: 0.5355 - val_loss: 2.8215 - val_acc: 0.4647\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 2.4400 - acc: 0.5524 - val_loss: 2.8272 - val_acc: 0.4275\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 2.2548 - acc: 0.5337 - val_loss: 2.3668 - val_acc: 0.4701\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 2.0692 - acc: 0.5426 - val_loss: 2.0889 - val_acc: 0.4982\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.9237 - acc: 0.5553 - val_loss: 2.0439 - val_acc: 0.4810\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.8179 - acc: 0.5626 - val_loss: 2.4229 - val_acc: 0.3678\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.8525 - acc: 0.5388 - val_loss: 1.9660 - val_acc: 0.4891\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.6831 - acc: 0.5724 - val_loss: 1.9017 - val_acc: 0.4819\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.6336 - acc: 0.5696 - val_loss: 2.0312 - val_acc: 0.4737\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.7034 - acc: 0.5629 - val_loss: 1.8084 - val_acc: 0.5045\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.5598 - acc: 0.5910 - val_loss: 1.7892 - val_acc: 0.4937\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 1.5318 - acc: 0.5884 - val_loss: 1.9239 - val_acc: 0.4855\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.4917 - acc: 0.5942 - val_loss: 1.7523 - val_acc: 0.5100\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.4958 - acc: 0.5874 - val_loss: 2.0111 - val_acc: 0.4484\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.5457 - acc: 0.5722 - val_loss: 1.8791 - val_acc: 0.4937\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.5079 - acc: 0.5941 - val_loss: 1.9377 - val_acc: 0.4529\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.6106 - acc: 0.5674 - val_loss: 2.4579 - val_acc: 0.3777\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.8984 - acc: 0.5172 - val_loss: 2.0423 - val_acc: 0.4982\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 1.6291 - acc: 0.5937 - val_loss: 1.7730 - val_acc: 0.5208\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.4597 - acc: 0.6065 - val_loss: 1.7285 - val_acc: 0.5172\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 1.4082 - acc: 0.6140 - val_loss: 1.8779 - val_acc: 0.4783\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 1.4344 - acc: 0.6043 - val_loss: 1.9378 - val_acc: 0.4873\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 1.4525 - acc: 0.6078 - val_loss: 1.8613 - val_acc: 0.4792\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 1.4676 - acc: 0.6039 - val_loss: 1.9614 - val_acc: 0.4801\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 1.5635 - acc: 0.5785 - val_loss: 1.8796 - val_acc: 0.4873\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 1.5117 - acc: 0.6032 - val_loss: 1.8744 - val_acc: 0.4864\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.4370 - acc: 0.6156 - val_loss: 1.7763 - val_acc: 0.5054\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.5145 - acc: 0.5949 - val_loss: 1.7557 - val_acc: 0.5263\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.4301 - acc: 0.6295 - val_loss: 1.9970 - val_acc: 0.4312\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.4270 - acc: 0.6201 - val_loss: 1.8089 - val_acc: 0.5208\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.3938 - acc: 0.6250 - val_loss: 1.7475 - val_acc: 0.5254\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 1.4213 - acc: 0.6222 - val_loss: 1.8494 - val_acc: 0.5127\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.4402 - acc: 0.6164 - val_loss: 1.9296 - val_acc: 0.4855\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.4398 - acc: 0.6243 - val_loss: 2.1312 - val_acc: 0.4601\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 1.5906 - acc: 0.5911 - val_loss: 1.9059 - val_acc: 0.5045\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.4927 - acc: 0.6241 - val_loss: 1.7854 - val_acc: 0.5226\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.4361 - acc: 0.6254 - val_loss: 1.8751 - val_acc: 0.5199\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.4289 - acc: 0.6292 - val_loss: 2.0351 - val_acc: 0.4819\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: nan - acc: 0.0725 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 7.5650 - acc: 0.2708 - val_loss: 6.3312 - val_acc: 0.4094\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 6.0718 - acc: 0.4400 - val_loss: 5.7752 - val_acc: 0.4683\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 5.5010 - acc: 0.5146 - val_loss: 5.2798 - val_acc: 0.4937\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 4.9025 - acc: 0.5445 - val_loss: 4.7101 - val_acc: 0.5127\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 4.3453 - acc: 0.5655 - val_loss: 4.2070 - val_acc: 0.5236\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 3.8388 - acc: 0.5949 - val_loss: 3.8026 - val_acc: 0.5127\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 3.4377 - acc: 0.5930 - val_loss: 3.5085 - val_acc: 0.5317\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 5s 533us/step - loss: 3.1318 - acc: 0.5950 - val_loss: 3.2668 - val_acc: 0.5027\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 2.8467 - acc: 0.6079 - val_loss: 2.9548 - val_acc: 0.5353\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 514us/step - loss: 2.6016 - acc: 0.6245 - val_loss: 2.8915 - val_acc: 0.5245\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 2.4547 - acc: 0.6269 - val_loss: 2.7471 - val_acc: 0.5163\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 2.3081 - acc: 0.6267 - val_loss: 2.6058 - val_acc: 0.5190\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 504us/step - loss: 2.1293 - acc: 0.6487 - val_loss: 2.5716 - val_acc: 0.5208\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 2.0180 - acc: 0.6622 - val_loss: 2.3918 - val_acc: 0.5435\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.9038 - acc: 0.6752 - val_loss: 2.3609 - val_acc: 0.5399\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.8553 - acc: 0.6729 - val_loss: 2.3285 - val_acc: 0.5389\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 526us/step - loss: 1.7864 - acc: 0.6767 - val_loss: 2.2040 - val_acc: 0.5462\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 1.6958 - acc: 0.7009 - val_loss: 2.2655 - val_acc: 0.5154\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.6344 - acc: 0.7057 - val_loss: 2.1839 - val_acc: 0.5326\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 1.6420 - acc: 0.6968 - val_loss: 2.2203 - val_acc: 0.5353\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 1.6206 - acc: 0.7040 - val_loss: 2.1796 - val_acc: 0.5444\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 1.5889 - acc: 0.7147 - val_loss: 2.1283 - val_acc: 0.5525\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 1.5644 - acc: 0.7155 - val_loss: 2.0939 - val_acc: 0.5426\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 1.4920 - acc: 0.7321 - val_loss: 2.1571 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 1.4482 - acc: 0.7438 - val_loss: 2.1004 - val_acc: 0.5408\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.3799 - acc: 0.7659 - val_loss: 2.1663 - val_acc: 0.5525\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 537us/step - loss: 1.3572 - acc: 0.7713 - val_loss: 2.2370 - val_acc: 0.5199\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: 1.3725 - acc: 0.7597 - val_loss: 2.2003 - val_acc: 0.5254\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.3704 - acc: 0.7665 - val_loss: 2.1777 - val_acc: 0.5362\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 1.4070 - acc: 0.7504 - val_loss: 2.2656 - val_acc: 0.5190\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.4215 - acc: 0.7500 - val_loss: 2.2495 - val_acc: 0.5562\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 1.3408 - acc: 0.7823 - val_loss: 2.1571 - val_acc: 0.5453\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 1.3145 - acc: 0.7882 - val_loss: 2.2247 - val_acc: 0.5326\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 511us/step - loss: 1.2614 - acc: 0.8012 - val_loss: 2.2743 - val_acc: 0.5534\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 523us/step - loss: 1.3303 - acc: 0.7742 - val_loss: 2.3348 - val_acc: 0.5299\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 1.3904 - acc: 0.7698 - val_loss: 2.2855 - val_acc: 0.5371\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: 1.3474 - acc: 0.7798 - val_loss: 2.2400 - val_acc: 0.5453\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 1.3474 - acc: 0.7850 - val_loss: 2.2802 - val_acc: 0.5389\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 1.3215 - acc: 0.7899 - val_loss: 2.2503 - val_acc: 0.5471\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 4s 503us/step - loss: 1.2809 - acc: 0.8045 - val_loss: 2.2761 - val_acc: 0.5435\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 1.3237 - acc: 0.7943 - val_loss: 2.3135 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 4ms/step - loss: 31.4810 - acc: 0.4068 - val_loss: 27.0230 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 597us/step - loss: 23.3342 - acc: 0.5719 - val_loss: 19.5760 - val_acc: 0.4864\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: 16.5638 - acc: 0.6040 - val_loss: 13.9495 - val_acc: 0.4937\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 636us/step - loss: 11.7429 - acc: 0.6191 - val_loss: 9.9718 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 8.5263 - acc: 0.6276 - val_loss: 7.6616 - val_acc: 0.4692\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 6.4311 - acc: 0.6145 - val_loss: 5.8648 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 4.9979 - acc: 0.6195 - val_loss: 4.7425 - val_acc: 0.5045\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 641us/step - loss: 4.1122 - acc: 0.6056 - val_loss: 3.9486 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 639us/step - loss: 3.4144 - acc: 0.6262 - val_loss: 3.4730 - val_acc: 0.5208\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 2.9500 - acc: 0.6237 - val_loss: 3.0919 - val_acc: 0.5145\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 2.6401 - acc: 0.6217 - val_loss: 2.7392 - val_acc: 0.5181\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 2.3678 - acc: 0.6338 - val_loss: 2.6471 - val_acc: 0.4964\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 2.1826 - acc: 0.6339 - val_loss: 2.4343 - val_acc: 0.5145\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 2.0369 - acc: 0.6321 - val_loss: 2.2753 - val_acc: 0.5245\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 50.5718 - acc: 0.3957 - val_loss: 38.1737 - val_acc: 0.4819\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 29.4804 - acc: 0.5399 - val_loss: 20.9725 - val_acc: 0.4801\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 16.1367 - acc: 0.5525 - val_loss: 11.8224 - val_acc: 0.4819\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 9.3354 - acc: 0.5535 - val_loss: 7.3090 - val_acc: 0.4819\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 6.0042 - acc: 0.5497 - val_loss: 5.1790 - val_acc: 0.4538\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 4.3280 - acc: 0.5412 - val_loss: 3.9423 - val_acc: 0.4783\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 3.3534 - acc: 0.5446 - val_loss: 3.1655 - val_acc: 0.4846\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 2.7810 - acc: 0.5424 - val_loss: 2.8380 - val_acc: 0.4638\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.4083 - acc: 0.5618 - val_loss: 2.5540 - val_acc: 0.4438\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 2.1472 - acc: 0.5684 - val_loss: 2.3034 - val_acc: 0.4991\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 1.9845 - acc: 0.5611 - val_loss: 2.3687 - val_acc: 0.3632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.8657 - acc: 0.5695 - val_loss: 1.9681 - val_acc: 0.4982\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 1.7065 - acc: 0.5870 - val_loss: 2.3028 - val_acc: 0.4239\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.7598 - acc: 0.5628 - val_loss: 2.0407 - val_acc: 0.4447\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 1.7425 - acc: 0.5622 - val_loss: 2.0332 - val_acc: 0.4674\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 1.6443 - acc: 0.5826 - val_loss: 1.8932 - val_acc: 0.4755\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 1.5430 - acc: 0.5943 - val_loss: 1.8254 - val_acc: 0.4665\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 1.5041 - acc: 0.6052 - val_loss: 2.0949 - val_acc: 0.4303\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.5915 - acc: 0.5823 - val_loss: 1.7911 - val_acc: 0.5109\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.4766 - acc: 0.6147 - val_loss: 1.9314 - val_acc: 0.4846\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.5117 - acc: 0.5903 - val_loss: 1.9775 - val_acc: 0.4810\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 1.5267 - acc: 0.5977 - val_loss: 1.7922 - val_acc: 0.5036\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 1.4463 - acc: 0.6106 - val_loss: 1.8063 - val_acc: 0.5109\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 1.4173 - acc: 0.6195 - val_loss: 1.7893 - val_acc: 0.5154\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 1.4118 - acc: 0.6143 - val_loss: 1.7228 - val_acc: 0.5091\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 1.4275 - acc: 0.6148 - val_loss: 1.7680 - val_acc: 0.5036\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 1.3891 - acc: 0.6277 - val_loss: 1.7251 - val_acc: 0.5254\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 1.3626 - acc: 0.6360 - val_loss: 1.8554 - val_acc: 0.4964\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 1.4242 - acc: 0.6265 - val_loss: 1.8661 - val_acc: 0.4864\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 1.4214 - acc: 0.6262 - val_loss: 1.7462 - val_acc: 0.5335\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 1.3735 - acc: 0.6359 - val_loss: 1.7275 - val_acc: 0.5399\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.3671 - acc: 0.6411 - val_loss: 1.9646 - val_acc: 0.4837\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 1.4222 - acc: 0.6344 - val_loss: 1.7352 - val_acc: 0.5498\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.3555 - acc: 0.6487 - val_loss: 2.0905 - val_acc: 0.4783\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 3.2174 - acc: 0.3257 - val_loss: 3.5863 - val_acc: 0.2772\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 2.8346 - acc: 0.4978 - val_loss: 2.4905 - val_acc: 0.5000\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.8770 - acc: 0.5977 - val_loss: 2.1557 - val_acc: 0.4909\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 1.5842 - acc: 0.6145 - val_loss: 1.7785 - val_acc: 0.5263\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 1.4821 - acc: 0.6249 - val_loss: 1.9816 - val_acc: 0.4647\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.4583 - acc: 0.6296 - val_loss: 1.8008 - val_acc: 0.5236\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 1.3677 - acc: 0.6488 - val_loss: 1.8143 - val_acc: 0.5190\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 1.5735 - acc: 0.5990 - val_loss: 1.8627 - val_acc: 0.5217\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 1.3760 - acc: 0.6517 - val_loss: 1.8434 - val_acc: 0.4918\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 5.2188 - acc: 0.4660 - val_loss: 4.8590 - val_acc: 0.5063\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.5531 - acc: 0.5597 - val_loss: 4.5158 - val_acc: 0.5145\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 4.0994 - acc: 0.6096 - val_loss: 4.2132 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.6995 - acc: 0.6456 - val_loss: 3.8815 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 3.3244 - acc: 0.6784 - val_loss: 3.6387 - val_acc: 0.5326\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.9934 - acc: 0.7127 - val_loss: 3.3769 - val_acc: 0.5362\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.7109 - acc: 0.7379 - val_loss: 3.2013 - val_acc: 0.5380\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4548 - acc: 0.7675 - val_loss: 3.0173 - val_acc: 0.5562\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.2551 - acc: 0.7744 - val_loss: 2.9290 - val_acc: 0.5480\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 2.0510 - acc: 0.8012 - val_loss: 2.8293 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.9010 - acc: 0.8182 - val_loss: 2.7331 - val_acc: 0.5444\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.7554 - acc: 0.8340 - val_loss: 2.6495 - val_acc: 0.5489\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.6183 - acc: 0.8565 - val_loss: 2.6250 - val_acc: 0.5489\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.5353 - acc: 0.8529 - val_loss: 2.6199 - val_acc: 0.5408\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.4363 - acc: 0.8716 - val_loss: 2.5327 - val_acc: 0.5444\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 1.3782 - acc: 0.8730 - val_loss: 2.5105 - val_acc: 0.5326\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.3193 - acc: 0.8789 - val_loss: 2.4591 - val_acc: 0.5353\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2782 - acc: 0.8780 - val_loss: 2.4778 - val_acc: 0.5562\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.2099 - acc: 0.8966 - val_loss: 2.4561 - val_acc: 0.5444\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.1638 - acc: 0.9004 - val_loss: 2.4073 - val_acc: 0.5571\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.0942 - acc: 0.9162 - val_loss: 2.5155 - val_acc: 0.5326\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.1005 - acc: 0.9024 - val_loss: 2.5232 - val_acc: 0.5516\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.0547 - acc: 0.9141 - val_loss: 2.4812 - val_acc: 0.5489\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.0951 - acc: 0.8929 - val_loss: 2.4189 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.0783 - acc: 0.9009 - val_loss: 2.4299 - val_acc: 0.5607\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 0.9942 - acc: 0.9251 - val_loss: 2.4760 - val_acc: 0.5471\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 0.9653 - acc: 0.9271 - val_loss: 2.5677 - val_acc: 0.5562\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 11s 1ms/step - loss: 0.9730 - acc: 0.9191 - val_loss: 2.5728 - val_acc: 0.5326\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 0.9249 - acc: 0.9326 - val_loss: 2.5426 - val_acc: 0.5408\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 0.9580 - acc: 0.9139 - val_loss: 2.6232 - val_acc: 0.5362\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 0.9875 - acc: 0.9023 - val_loss: 2.5421 - val_acc: 0.5172\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 0.9402 - acc: 0.9251 - val_loss: 2.4943 - val_acc: 0.5507\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 0.8681 - acc: 0.9460 - val_loss: 2.4802 - val_acc: 0.5507\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 0.9081 - acc: 0.9207 - val_loss: 2.5269 - val_acc: 0.5317\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 0.9775 - acc: 0.9008 - val_loss: 2.4813 - val_acc: 0.5281\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 41s 5ms/step - loss: 63.9325 - acc: 0.3816 - val_loss: 34.2882 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 21.0331 - acc: 0.4920 - val_loss: 11.0958 - val_acc: 0.3949\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 631us/step - loss: 7.6626 - acc: 0.4849 - val_loss: 5.2861 - val_acc: 0.4130\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 4.1431 - acc: 0.4892 - val_loss: 3.5443 - val_acc: 0.4167\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 2.8965 - acc: 0.4996 - val_loss: 2.7790 - val_acc: 0.4384\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 2.4383 - acc: 0.4861 - val_loss: 2.4222 - val_acc: 0.4312\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 660us/step - loss: 2.1704 - acc: 0.4885 - val_loss: 2.1498 - val_acc: 0.4620\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 1.9277 - acc: 0.5067 - val_loss: 2.2572 - val_acc: 0.3976\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.9499 - acc: 0.4902 - val_loss: 2.1006 - val_acc: 0.4139\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: 1.8394 - acc: 0.5076 - val_loss: 2.2598 - val_acc: 0.4058\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 1.9023 - acc: 0.4971 - val_loss: 2.4305 - val_acc: 0.3361\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 64.0382 - acc: 0.4258 - val_loss: 53.3664 - val_acc: 0.5072\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: 45.1673 - acc: 0.5796 - val_loss: 36.4316 - val_acc: 0.5190\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 643us/step - loss: 30.4131 - acc: 0.6020 - val_loss: 24.5098 - val_acc: 0.5145\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 20.4061 - acc: 0.6051 - val_loss: 16.6611 - val_acc: 0.4792\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 643us/step - loss: 13.8897 - acc: 0.6052 - val_loss: 11.5829 - val_acc: 0.5127\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 653us/step - loss: 9.7394 - acc: 0.5993 - val_loss: 8.4110 - val_acc: 0.4828\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 7.0865 - acc: 0.5915 - val_loss: 6.3872 - val_acc: 0.4656\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 5.4190 - acc: 0.5868 - val_loss: 4.9698 - val_acc: 0.5172\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 4.2748 - acc: 0.5971 - val_loss: 4.0936 - val_acc: 0.5172\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 3.5071 - acc: 0.5961 - val_loss: 3.5415 - val_acc: 0.4909\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 3.0371 - acc: 0.5879 - val_loss: 3.0759 - val_acc: 0.4873\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 659us/step - loss: 2.6955 - acc: 0.5818 - val_loss: 2.9207 - val_acc: 0.4375\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 40s 5ms/step - loss: 6.9233 - acc: 0.2825 - val_loss: 5.8269 - val_acc: 0.3850\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 5.5693 - acc: 0.4524 - val_loss: 5.3866 - val_acc: 0.4647\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 5.1327 - acc: 0.5063 - val_loss: 4.9547 - val_acc: 0.5027\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 4.6416 - acc: 0.5549 - val_loss: 4.5650 - val_acc: 0.5118\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 4.1805 - acc: 0.5849 - val_loss: 4.2083 - val_acc: 0.5181\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 3.7917 - acc: 0.6032 - val_loss: 3.9001 - val_acc: 0.5082\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 512us/step - loss: 3.4449 - acc: 0.6212 - val_loss: 3.5410 - val_acc: 0.5245\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: 3.1337 - acc: 0.6353 - val_loss: 3.3809 - val_acc: 0.5344\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 2.8994 - acc: 0.6433 - val_loss: 3.1875 - val_acc: 0.5326\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 2.6807 - acc: 0.6511 - val_loss: 3.0345 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.5130 - acc: 0.6523 - val_loss: 2.8577 - val_acc: 0.5308\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: 2.2971 - acc: 0.6851 - val_loss: 2.7460 - val_acc: 0.5371\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 494us/step - loss: 2.1456 - acc: 0.7003 - val_loss: 2.6088 - val_acc: 0.5281\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 2.0016 - acc: 0.7147 - val_loss: 2.5549 - val_acc: 0.5399\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.8478 - acc: 0.7399 - val_loss: 2.5387 - val_acc: 0.5199\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 1.7740 - acc: 0.7413 - val_loss: 2.4426 - val_acc: 0.5462\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.6901 - acc: 0.7503 - val_loss: 2.4230 - val_acc: 0.5317\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 490us/step - loss: 1.5810 - acc: 0.7773 - val_loss: 2.4005 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 496us/step - loss: 1.4907 - acc: 0.7919 - val_loss: 2.6198 - val_acc: 0.4882\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: 1.6018 - acc: 0.7341 - val_loss: 2.3732 - val_acc: 0.5308\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.5152 - acc: 0.7627 - val_loss: 2.3365 - val_acc: 0.5571\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 4s 500us/step - loss: 1.4128 - acc: 0.8002 - val_loss: 2.3326 - val_acc: 0.5462\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 1.3339 - acc: 0.8184 - val_loss: 2.4055 - val_acc: 0.5371\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 502us/step - loss: 1.3319 - acc: 0.8056 - val_loss: 2.2979 - val_acc: 0.5534\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 1.2781 - acc: 0.8209 - val_loss: 2.3510 - val_acc: 0.5335\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 1.2263 - acc: 0.8368 - val_loss: 2.2850 - val_acc: 0.5498\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 1.1878 - acc: 0.8445 - val_loss: 2.3161 - val_acc: 0.5525\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 493us/step - loss: 1.2036 - acc: 0.8304 - val_loss: 2.3800 - val_acc: 0.5308\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 41s 5ms/step - loss: 729.7968 - acc: 0.2449 - val_loss: 681.9423 - val_acc: 0.4004\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 623us/step - loss: 643.9117 - acc: 0.4089 - val_loss: 598.6841 - val_acc: 0.4547\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 621us/step - loss: 563.5438 - acc: 0.4668 - val_loss: 522.0484 - val_acc: 0.4810\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 490.0038 - acc: 0.4917 - val_loss: 452.3591 - val_acc: 0.4900\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 423.4217 - acc: 0.5012 - val_loss: 389.5648 - val_acc: 0.4964\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 664us/step - loss: 363.6630 - acc: 0.5181 - val_loss: 333.4571 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 310.3901 - acc: 0.5313 - val_loss: 283.6682 - val_acc: 0.5281\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 263.3128 - acc: 0.5389 - val_loss: 239.9099 - val_acc: 0.5145\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 222.0496 - acc: 0.5501 - val_loss: 201.7297 - val_acc: 0.5199\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 186.1855 - acc: 0.5468 - val_loss: 168.6887 - val_acc: 0.5136\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 155.2613 - acc: 0.5522 - val_loss: 140.3785 - val_acc: 0.4909\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 128.8383 - acc: 0.5626 - val_loss: 116.3480 - val_acc: 0.5063\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 106.4970 - acc: 0.5714 - val_loss: 96.1692 - val_acc: 0.5018\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: 87.8074 - acc: 0.5750 - val_loss: 79.4099 - val_acc: 0.4828\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 72.3662 - acc: 0.5754 - val_loss: 65.6708 - val_acc: 0.4683\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 683us/step - loss: 59.7827 - acc: 0.5792 - val_loss: 54.5512 - val_acc: 0.4611\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 49.6871 - acc: 0.5836 - val_loss: 45.7053 - val_acc: 0.4393\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 41s 5ms/step - loss: 67.6833 - acc: 0.4083 - val_loss: 51.0479 - val_acc: 0.5100\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 40.1222 - acc: 0.5321 - val_loss: 29.0494 - val_acc: 0.5082\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 22.6094 - acc: 0.5420 - val_loss: 16.5799 - val_acc: 0.4864\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 13.0363 - acc: 0.5451 - val_loss: 10.0128 - val_acc: 0.4819\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 8.0134 - acc: 0.5462 - val_loss: 6.4888 - val_acc: 0.4620\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 5.3359 - acc: 0.5542 - val_loss: 4.7509 - val_acc: 0.4194\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 3.9019 - acc: 0.5542 - val_loss: 3.6444 - val_acc: 0.4909\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 3.1249 - acc: 0.5505 - val_loss: 3.0764 - val_acc: 0.4647\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 2.6716 - acc: 0.5545 - val_loss: 2.7322 - val_acc: 0.4674\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 2.3444 - acc: 0.5548 - val_loss: 2.4319 - val_acc: 0.4647\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 2.1099 - acc: 0.5635 - val_loss: 2.2888 - val_acc: 0.4538\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 1191.5485 - acc: 0.2739 - val_loss: 1094.7702 - val_acc: 0.4013\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 676us/step - loss: 1019.7742 - acc: 0.4502 - val_loss: 932.6191 - val_acc: 0.4475\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 867.1827 - acc: 0.4837 - val_loss: 791.6788 - val_acc: 0.4656\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 735.3425 - acc: 0.5208 - val_loss: 670.6375 - val_acc: 0.4728\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 622.4400 - acc: 0.5284 - val_loss: 567.2375 - val_acc: 0.4964\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 526.1033 - acc: 0.5405 - val_loss: 479.1502 - val_acc: 0.4982\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 444.1652 - acc: 0.5524 - val_loss: 404.3854 - val_acc: 0.5082\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 374.5246 - acc: 0.5570 - val_loss: 340.7418 - val_acc: 0.5000\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 315.3126 - acc: 0.5588 - val_loss: 286.7528 - val_acc: 0.5082\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 265.0799 - acc: 0.5664 - val_loss: 240.9613 - val_acc: 0.5127\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 222.5260 - acc: 0.5653 - val_loss: 202.2347 - val_acc: 0.5018\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 186.5502 - acc: 0.5657 - val_loss: 169.5570 - val_acc: 0.4864\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 156.2166 - acc: 0.5752 - val_loss: 142.0331 - val_acc: 0.4964\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 130.6781 - acc: 0.5732 - val_loss: 118.8996 - val_acc: 0.4973\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 109.2215 - acc: 0.5748 - val_loss: 99.4934 - val_acc: 0.4692\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 91.2473 - acc: 0.5840 - val_loss: 83.2181 - val_acc: 0.4647\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 76.2183 - acc: 0.5779 - val_loss: 69.6148 - val_acc: 0.4783\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 63.6762 - acc: 0.5772 - val_loss: 58.2913 - val_acc: 0.4611\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 53.2170 - acc: 0.5806 - val_loss: 48.8327 - val_acc: 0.4719\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 44.5122 - acc: 0.5836 - val_loss: 40.9745 - val_acc: 0.4638\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 549.0918 - acc: 0.3641 - val_loss: 490.0759 - val_acc: 0.4601\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 687us/step - loss: 445.4878 - acc: 0.5172 - val_loss: 394.4035 - val_acc: 0.4864\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 357.0194 - acc: 0.5449 - val_loss: 314.7974 - val_acc: 0.4991\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 284.2096 - acc: 0.5524 - val_loss: 249.9588 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 225.2768 - acc: 0.5685 - val_loss: 197.8803 - val_acc: 0.5063\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 178.0254 - acc: 0.5765 - val_loss: 156.2445 - val_acc: 0.5163\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 140.3224 - acc: 0.5917 - val_loss: 123.1398 - val_acc: 0.5172\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 110.3755 - acc: 0.5810 - val_loss: 96.9128 - val_acc: 0.5263\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 684us/step - loss: 86.6853 - acc: 0.5834 - val_loss: 76.2584 - val_acc: 0.4846\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 68.0051 - acc: 0.5933 - val_loss: 59.9606 - val_acc: 0.4900\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: 53.3371 - acc: 0.5925 - val_loss: 47.2523 - val_acc: 0.4928\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 41.8629 - acc: 0.5902 - val_loss: 37.2828 - val_acc: 0.4909\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 32.9113 - acc: 0.5923 - val_loss: 29.5423 - val_acc: 0.4629\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 717us/step - loss: 25.9457 - acc: 0.6010 - val_loss: 23.4968 - val_acc: 0.4601\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 672us/step - loss: 20.5574 - acc: 0.5983 - val_loss: 18.7908 - val_acc: 0.4882\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 16.3737 - acc: 0.5980 - val_loss: 15.1424 - val_acc: 0.4719\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 13.1199 - acc: 0.6140 - val_loss: 12.3269 - val_acc: 0.4828\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 10.6133 - acc: 0.6070 - val_loss: 10.1290 - val_acc: 0.4946\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 48s 5ms/step - loss: 3.6441 - acc: 0.4754 - val_loss: 3.4758 - val_acc: 0.5072\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1450 - acc: 0.6211 - val_loss: 3.3532 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.9077 - acc: 0.7006 - val_loss: 3.2852 - val_acc: 0.5471\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7100 - acc: 0.7714 - val_loss: 3.2499 - val_acc: 0.5553\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.5569 - acc: 0.8188 - val_loss: 3.2026 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.4051 - acc: 0.8736 - val_loss: 3.1498 - val_acc: 0.5652\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.2665 - acc: 0.9097 - val_loss: 3.1791 - val_acc: 0.5652\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.1552 - acc: 0.9339 - val_loss: 3.1765 - val_acc: 0.5489\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.0554 - acc: 0.9575 - val_loss: 3.1600 - val_acc: 0.5580\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.9464 - acc: 0.9809 - val_loss: 3.1480 - val_acc: 0.5525\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.8858 - acc: 0.9803 - val_loss: 3.1296 - val_acc: 0.5589\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.8052 - acc: 0.9916 - val_loss: 3.1537 - val_acc: 0.5543\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.7365 - acc: 0.9957 - val_loss: 3.0870 - val_acc: 0.5679\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6812 - acc: 0.9963 - val_loss: 3.0509 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.6355 - acc: 0.9929 - val_loss: 3.0236 - val_acc: 0.5580\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.6356 - acc: 0.9820 - val_loss: 3.1447 - val_acc: 0.5444\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.6434 - acc: 0.9638 - val_loss: 3.1273 - val_acc: 0.5435\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.5805 - acc: 0.9750 - val_loss: 2.9684 - val_acc: 0.5543\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.4802 - acc: 0.9941 - val_loss: 2.9169 - val_acc: 0.5725\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.4015 - acc: 0.9995 - val_loss: 2.8418 - val_acc: 0.5797\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.3473 - acc: 0.9997 - val_loss: 2.8155 - val_acc: 0.5661\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.2988 - acc: 0.9997 - val_loss: 2.7747 - val_acc: 0.5806\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.2505 - acc: 0.9997 - val_loss: 2.7370 - val_acc: 0.5770\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.2029 - acc: 0.9998 - val_loss: 2.6917 - val_acc: 0.5734\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.1565 - acc: 0.9997 - val_loss: 2.6641 - val_acc: 0.5815\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.1106 - acc: 0.9995 - val_loss: 2.6466 - val_acc: 0.5815\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.0650 - acc: 0.9997 - val_loss: 2.5968 - val_acc: 0.5707\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.0192 - acc: 0.9998 - val_loss: 2.5941 - val_acc: 0.5634\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.7544 - acc: 0.7674 - val_loss: 2.7227 - val_acc: 0.4873\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.7158 - acc: 0.7433 - val_loss: 2.4125 - val_acc: 0.5661\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.2472 - acc: 0.9205 - val_loss: 2.4496 - val_acc: 0.5625\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.0733 - acc: 0.9771 - val_loss: 2.4494 - val_acc: 0.5607\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 0.9908 - acc: 0.9938 - val_loss: 2.3782 - val_acc: 0.5743\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.9327 - acc: 0.9993 - val_loss: 2.4078 - val_acc: 0.5716\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 0.8945 - acc: 0.9997 - val_loss: 2.3816 - val_acc: 0.5797\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 805.2314 - acc: 0.2826 - val_loss: 699.9657 - val_acc: 0.4429\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 624.3499 - acc: 0.4212 - val_loss: 539.1159 - val_acc: 0.4774\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 479.1494 - acc: 0.4613 - val_loss: 412.2393 - val_acc: 0.4982\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 365.7566 - acc: 0.4907 - val_loss: 314.0141 - val_acc: 0.5027\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 278.0804 - acc: 0.5088 - val_loss: 238.3651 - val_acc: 0.5045\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 210.6782 - acc: 0.5244 - val_loss: 180.3957 - val_acc: 0.4982\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 159.1197 - acc: 0.5352 - val_loss: 136.2280 - val_acc: 0.4937\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 119.8537 - acc: 0.5509 - val_loss: 102.7190 - val_acc: 0.4665\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 90.1147 - acc: 0.5533 - val_loss: 77.4063 - val_acc: 0.4212\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 67.6759 - acc: 0.5591 - val_loss: 58.3328 - val_acc: 0.4475\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 50.8339 - acc: 0.5638 - val_loss: 44.1176 - val_acc: 0.4049\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 38.2718 - acc: 0.5680 - val_loss: 33.4853 - val_acc: 0.3659\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 28.9272 - acc: 0.5663 - val_loss: 25.5507 - val_acc: 0.4112\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 21.9755 - acc: 0.5739 - val_loss: 19.6839 - val_acc: 0.3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 16.8359 - acc: 0.5767 - val_loss: 15.3118 - val_acc: 0.4203\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 41s 5ms/step - loss: 11.7062 - acc: 0.3577 - val_loss: 11.1586 - val_acc: 0.4384\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: 10.7281 - acc: 0.4770 - val_loss: 10.3237 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 9.9695 - acc: 0.5340 - val_loss: 9.6814 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 9.2555 - acc: 0.5627 - val_loss: 9.0508 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 522us/step - loss: 8.5734 - acc: 0.5805 - val_loss: 8.4530 - val_acc: 0.5254\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 7.9111 - acc: 0.6090 - val_loss: 7.8356 - val_acc: 0.5371\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 7.2963 - acc: 0.6256 - val_loss: 7.2534 - val_acc: 0.5498\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: 6.7124 - acc: 0.6501 - val_loss: 6.7595 - val_acc: 0.5616\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 6.1969 - acc: 0.6581 - val_loss: 6.3518 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 5.7319 - acc: 0.6685 - val_loss: 5.9153 - val_acc: 0.5353\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: 5.2821 - acc: 0.6807 - val_loss: 5.5256 - val_acc: 0.5471\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 509us/step - loss: 4.8960 - acc: 0.6886 - val_loss: 5.1180 - val_acc: 0.5453\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 4.5251 - acc: 0.6965 - val_loss: 4.7945 - val_acc: 0.5507\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 4.1675 - acc: 0.7248 - val_loss: 4.5299 - val_acc: 0.5426\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 3.8981 - acc: 0.7251 - val_loss: 4.3071 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 3.6092 - acc: 0.7326 - val_loss: 4.0617 - val_acc: 0.5471\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 3.3647 - acc: 0.7407 - val_loss: 3.8705 - val_acc: 0.5589\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 3.1692 - acc: 0.7476 - val_loss: 3.6986 - val_acc: 0.5480\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 45s 5ms/step - loss: 373.5983 - acc: 0.3176 - val_loss: 344.9490 - val_acc: 0.4710\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 623us/step - loss: 323.3935 - acc: 0.4531 - val_loss: 298.1246 - val_acc: 0.4837\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 279.2797 - acc: 0.4739 - val_loss: 257.2680 - val_acc: 0.5063\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 240.8390 - acc: 0.5031 - val_loss: 221.6989 - val_acc: 0.5118\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 207.3715 - acc: 0.5174 - val_loss: 190.7679 - val_acc: 0.5281\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 178.3258 - acc: 0.5298 - val_loss: 163.9487 - val_acc: 0.5091\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 153.1508 - acc: 0.5480 - val_loss: 140.7849 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 131.3660 - acc: 0.5587 - val_loss: 120.7150 - val_acc: 0.5335\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 112.5521 - acc: 0.5665 - val_loss: 103.4158 - val_acc: 0.5317\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 692us/step - loss: 96.3229 - acc: 0.5766 - val_loss: 88.5260 - val_acc: 0.5371\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 82.3501 - acc: 0.5816 - val_loss: 75.7574 - val_acc: 0.5100\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 70.3701 - acc: 0.5819 - val_loss: 64.7707 - val_acc: 0.5245\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 60.0844 - acc: 0.5925 - val_loss: 55.4036 - val_acc: 0.5136\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 51.3092 - acc: 0.5881 - val_loss: 47.3984 - val_acc: 0.5190\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 43.7955 - acc: 0.5912 - val_loss: 40.5783 - val_acc: 0.5118\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 37.3976 - acc: 0.5976 - val_loss: 34.7714 - val_acc: 0.4928\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 31.9505 - acc: 0.6072 - val_loss: 29.7883 - val_acc: 0.5145\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 719us/step - loss: 27.3094 - acc: 0.6091 - val_loss: 25.6033 - val_acc: 0.5263\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 23.3936 - acc: 0.6114 - val_loss: 22.0055 - val_acc: 0.5236\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 20.0561 - acc: 0.6181 - val_loss: 18.9747 - val_acc: 0.5417\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 17.2381 - acc: 0.6212 - val_loss: 16.4163 - val_acc: 0.5018\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 14.8484 - acc: 0.6198 - val_loss: 14.2299 - val_acc: 0.5380\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 685us/step - loss: 12.8189 - acc: 0.6340 - val_loss: 12.3938 - val_acc: 0.5163\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 11.1312 - acc: 0.6368 - val_loss: 10.8136 - val_acc: 0.5199\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 9.6973 - acc: 0.6352 - val_loss: 9.5055 - val_acc: 0.5344\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 8.4763 - acc: 0.6377 - val_loss: 8.4013 - val_acc: 0.5308\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 682us/step - loss: 7.4667 - acc: 0.6377 - val_loss: 7.4027 - val_acc: 0.5308\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 689us/step - loss: 6.5877 - acc: 0.6445 - val_loss: 6.6257 - val_acc: 0.5109\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 5.8494 - acc: 0.6502 - val_loss: 5.9230 - val_acc: 0.5534\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 5.2393 - acc: 0.6525 - val_loss: 5.3302 - val_acc: 0.5480\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 4.7317 - acc: 0.6431 - val_loss: 4.8501 - val_acc: 0.5353\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 697us/step - loss: 4.2780 - acc: 0.6491 - val_loss: 4.4375 - val_acc: 0.5353\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 3.8919 - acc: 0.6560 - val_loss: 4.0729 - val_acc: 0.5163\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 3.5643 - acc: 0.6598 - val_loss: 3.7667 - val_acc: 0.5226\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 3.2839 - acc: 0.6705 - val_loss: 3.5095 - val_acc: 0.5453\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 3.0640 - acc: 0.6624 - val_loss: 3.2933 - val_acc: 0.5263\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 6s 699us/step - loss: 2.8670 - acc: 0.6618 - val_loss: 3.0813 - val_acc: 0.5553\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 6s 709us/step - loss: 2.6907 - acc: 0.6659 - val_loss: 2.9333 - val_acc: 0.5399\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 2.5341 - acc: 0.6677 - val_loss: 2.7965 - val_acc: 0.5607\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 2.3962 - acc: 0.6833 - val_loss: 2.6895 - val_acc: 0.5462\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 2.2946 - acc: 0.6791 - val_loss: 2.6026 - val_acc: 0.5453\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 6s 719us/step - loss: 2.1908 - acc: 0.6863 - val_loss: 2.5242 - val_acc: 0.5136\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 2.1092 - acc: 0.6833 - val_loss: 2.4391 - val_acc: 0.5399\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 2.0406 - acc: 0.6868 - val_loss: 2.3780 - val_acc: 0.5353\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: 1.9918 - acc: 0.6831 - val_loss: 2.3055 - val_acc: 0.5498\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: 1.9391 - acc: 0.6796 - val_loss: 2.2336 - val_acc: 0.5553\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 1.8614 - acc: 0.6984 - val_loss: 2.2167 - val_acc: 0.5426\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 1.8207 - acc: 0.7006 - val_loss: 2.1803 - val_acc: 0.5507\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 6s 663us/step - loss: 1.7722 - acc: 0.7080 - val_loss: 2.1519 - val_acc: 0.5580\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: nan - acc: 0.0699 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 527us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 543us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 43s 5ms/step - loss: 401.3617 - acc: 0.2863 - val_loss: 364.5893 - val_acc: 0.4447\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 337.3913 - acc: 0.4152 - val_loss: 305.7832 - val_acc: 0.4801\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 282.6591 - acc: 0.4451 - val_loss: 255.8733 - val_acc: 0.4882\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 669us/step - loss: 236.3295 - acc: 0.4830 - val_loss: 213.7195 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 197.2301 - acc: 0.4993 - val_loss: 178.2262 - val_acc: 0.5118\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 164.3071 - acc: 0.5192 - val_loss: 148.3695 - val_acc: 0.5036\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: 136.6422 - acc: 0.5308 - val_loss: 123.3321 - val_acc: 0.5082\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 113.4443 - acc: 0.5433 - val_loss: 102.3750 - val_acc: 0.5281\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 94.0645 - acc: 0.5515 - val_loss: 84.8989 - val_acc: 0.5326\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: 77.8792 - acc: 0.5630 - val_loss: 70.3844 - val_acc: 0.5063\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 64.4526 - acc: 0.5625 - val_loss: 58.3140 - val_acc: 0.5190\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: 53.2952 - acc: 0.5663 - val_loss: 48.3489 - val_acc: 0.4964\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 44.0645 - acc: 0.5745 - val_loss: 40.1281 - val_acc: 0.5281\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 36.4426 - acc: 0.5819 - val_loss: 33.3293 - val_acc: 0.4937\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 700us/step - loss: 30.1668 - acc: 0.5886 - val_loss: 27.7628 - val_acc: 0.5054\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 25.0180 - acc: 0.5907 - val_loss: 23.1628 - val_acc: 0.4955\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 688us/step - loss: 20.7860 - acc: 0.5947 - val_loss: 19.4101 - val_acc: 0.4801\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 17.3277 - acc: 0.5983 - val_loss: 16.2945 - val_acc: 0.4828\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 14.4889 - acc: 0.6051 - val_loss: 13.7756 - val_acc: 0.4928\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 623.4377 - acc: 0.3860 - val_loss: 515.2786 - val_acc: 0.4710\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 581us/step - loss: 441.5672 - acc: 0.4992 - val_loss: 361.9183 - val_acc: 0.4774\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 309.3265 - acc: 0.5207 - val_loss: 252.8393 - val_acc: 0.4864\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: 215.5673 - acc: 0.5368 - val_loss: 175.8524 - val_acc: 0.4918\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 667us/step - loss: 149.5221 - acc: 0.5520 - val_loss: 121.9168 - val_acc: 0.4583\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 671us/step - loss: 103.2860 - acc: 0.5459 - val_loss: 84.2597 - val_acc: 0.4755\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 644us/step - loss: 71.1543 - acc: 0.5477 - val_loss: 58.2971 - val_acc: 0.4203\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 48.9862 - acc: 0.5498 - val_loss: 40.4862 - val_acc: 0.3995\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 668us/step - loss: 33.8562 - acc: 0.5548 - val_loss: 28.3356 - val_acc: 0.3777\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 23.5791 - acc: 0.5548 - val_loss: 20.0439 - val_acc: 0.4348\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 654us/step - loss: 16.5961 - acc: 0.5539 - val_loss: 14.4719 - val_acc: 0.3551\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 673us/step - loss: 11.8788 - acc: 0.5689 - val_loss: 10.6418 - val_acc: 0.4103\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 675us/step - loss: 8.6955 - acc: 0.5662 - val_loss: 8.1077 - val_acc: 0.3650\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 645us/step - loss: 6.5293 - acc: 0.5688 - val_loss: 6.3674 - val_acc: 0.3478\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 9.1778 - acc: 0.3611 - val_loss: 8.7409 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: 8.4871 - acc: 0.4958 - val_loss: 8.3893 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 8.1281 - acc: 0.5413 - val_loss: 8.0545 - val_acc: 0.5208\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 7.7834 - acc: 0.5690 - val_loss: 7.7960 - val_acc: 0.5299\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 5s 523us/step - loss: 7.4622 - acc: 0.5893 - val_loss: 7.4885 - val_acc: 0.5480\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 533us/step - loss: 7.1432 - acc: 0.6140 - val_loss: 7.2558 - val_acc: 0.5317\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 518us/step - loss: 6.8559 - acc: 0.6267 - val_loss: 6.9388 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 6.5753 - acc: 0.6419 - val_loss: 6.7425 - val_acc: 0.5335\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 6.2986 - acc: 0.6581 - val_loss: 6.5180 - val_acc: 0.5534\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 536us/step - loss: 6.0164 - acc: 0.6783 - val_loss: 6.2362 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 5.7560 - acc: 0.6953 - val_loss: 6.0451 - val_acc: 0.5679\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 537us/step - loss: 5.5053 - acc: 0.7086 - val_loss: 5.7953 - val_acc: 0.5770\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 520us/step - loss: 5.2680 - acc: 0.7174 - val_loss: 5.6535 - val_acc: 0.5625\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 5.0448 - acc: 0.7253 - val_loss: 5.4723 - val_acc: 0.5607\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 531us/step - loss: 4.8287 - acc: 0.7330 - val_loss: 5.2648 - val_acc: 0.5707\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 4.6184 - acc: 0.7515 - val_loss: 5.0681 - val_acc: 0.5752\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 4.4119 - acc: 0.7620 - val_loss: 4.9507 - val_acc: 0.5716\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 4.2224 - acc: 0.7764 - val_loss: 4.8243 - val_acc: 0.5643\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 4.0626 - acc: 0.7751 - val_loss: 4.6385 - val_acc: 0.5616\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 3.8762 - acc: 0.7905 - val_loss: 4.5168 - val_acc: 0.5679\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 530us/step - loss: 3.7204 - acc: 0.8003 - val_loss: 4.3836 - val_acc: 0.5670\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: 3.5685 - acc: 0.8059 - val_loss: 4.3059 - val_acc: 0.5661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 42s 5ms/step - loss: 13.0085 - acc: 0.3627 - val_loss: 12.4957 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 12.1328 - acc: 0.4891 - val_loss: 11.8243 - val_acc: 0.5109\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 11.5165 - acc: 0.5234 - val_loss: 11.2882 - val_acc: 0.5245\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 541us/step - loss: 10.9330 - acc: 0.5528 - val_loss: 10.7434 - val_acc: 0.5154\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 10.3512 - acc: 0.5710 - val_loss: 10.1850 - val_acc: 0.5426\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 9.7892 - acc: 0.5968 - val_loss: 9.6339 - val_acc: 0.5462\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 636us/step - loss: 9.2532 - acc: 0.6106 - val_loss: 9.1913 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 8.7597 - acc: 0.6225 - val_loss: 8.7151 - val_acc: 0.5489\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 8.2783 - acc: 0.6309 - val_loss: 8.2550 - val_acc: 0.5634\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 7.8097 - acc: 0.6487 - val_loss: 7.8812 - val_acc: 0.5389\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 7.3821 - acc: 0.6521 - val_loss: 7.5052 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 6.9556 - acc: 0.6744 - val_loss: 7.0939 - val_acc: 0.5571\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 6.5642 - acc: 0.6840 - val_loss: 6.7607 - val_acc: 0.5697\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 6.2045 - acc: 0.6916 - val_loss: 6.4141 - val_acc: 0.5725\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 5.8456 - acc: 0.7056 - val_loss: 6.1513 - val_acc: 0.5734\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 5.5207 - acc: 0.7215 - val_loss: 5.8214 - val_acc: 0.5679\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 5.2281 - acc: 0.7242 - val_loss: 5.6340 - val_acc: 0.5616\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 551us/step - loss: 4.9632 - acc: 0.7301 - val_loss: 5.3237 - val_acc: 0.5616\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 4.6968 - acc: 0.7333 - val_loss: 5.1494 - val_acc: 0.5525\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 4.4415 - acc: 0.7539 - val_loss: 4.9300 - val_acc: 0.5589\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 4.2169 - acc: 0.7582 - val_loss: 4.7018 - val_acc: 0.5670\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 4.0089 - acc: 0.7591 - val_loss: 4.5059 - val_acc: 0.5697\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 3.8040 - acc: 0.7705 - val_loss: 4.3146 - val_acc: 0.5707\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 3.6126 - acc: 0.7794 - val_loss: 4.2279 - val_acc: 0.5562\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 3.4395 - acc: 0.7830 - val_loss: 4.0954 - val_acc: 0.5734\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 45s 5ms/step - loss: 6.2823 - acc: 0.2401 - val_loss: 4.8641 - val_acc: 0.3315\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 627us/step - loss: 4.6928 - acc: 0.3908 - val_loss: 4.5056 - val_acc: 0.4411\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 615us/step - loss: 4.3296 - acc: 0.4784 - val_loss: 4.1983 - val_acc: 0.4719\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 615us/step - loss: 3.9631 - acc: 0.5190 - val_loss: 3.8669 - val_acc: 0.5027\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 621us/step - loss: 3.5955 - acc: 0.5494 - val_loss: 3.5736 - val_acc: 0.5163\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 3.2877 - acc: 0.5720 - val_loss: 3.2849 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 3.0008 - acc: 0.5859 - val_loss: 3.1636 - val_acc: 0.5072\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 2.7878 - acc: 0.5819 - val_loss: 2.9172 - val_acc: 0.5190\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 593us/step - loss: 2.5725 - acc: 0.6024 - val_loss: 2.7573 - val_acc: 0.5236\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 2.4103 - acc: 0.6176 - val_loss: 2.6438 - val_acc: 0.5236\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 2.2228 - acc: 0.6376 - val_loss: 2.5397 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 542us/step - loss: 2.1115 - acc: 0.6473 - val_loss: 2.4610 - val_acc: 0.5199\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 547us/step - loss: 2.0163 - acc: 0.6436 - val_loss: 2.3173 - val_acc: 0.5353\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 1.9361 - acc: 0.6499 - val_loss: 2.3158 - val_acc: 0.5308\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 1.8305 - acc: 0.6702 - val_loss: 2.2493 - val_acc: 0.5534\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 1.7529 - acc: 0.6817 - val_loss: 2.3209 - val_acc: 0.5435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 1.6734 - acc: 0.7001 - val_loss: 2.2116 - val_acc: 0.5462\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 1.6700 - acc: 0.6911 - val_loss: 2.2649 - val_acc: 0.5136\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.6133 - acc: 0.7035 - val_loss: 2.2060 - val_acc: 0.5353\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 1.5599 - acc: 0.7145 - val_loss: 2.3245 - val_acc: 0.5118\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 1.5998 - acc: 0.7012 - val_loss: 2.3444 - val_acc: 0.5109\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 1.5664 - acc: 0.7129 - val_loss: 2.2527 - val_acc: 0.5335\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 581us/step - loss: 1.4771 - acc: 0.7399 - val_loss: 2.1876 - val_acc: 0.5616\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 1.4115 - acc: 0.7555 - val_loss: 2.2470 - val_acc: 0.5299\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 1.4628 - acc: 0.7469 - val_loss: 2.2480 - val_acc: 0.5335\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 1.4321 - acc: 0.7478 - val_loss: 2.1443 - val_acc: 0.5453\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 1.3079 - acc: 0.7958 - val_loss: 2.3009 - val_acc: 0.5326\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.3133 - acc: 0.7819 - val_loss: 2.2792 - val_acc: 0.5444\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 1.2974 - acc: 0.7887 - val_loss: 2.2365 - val_acc: 0.5281\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 1.2908 - acc: 0.7923 - val_loss: 2.2697 - val_acc: 0.5408\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 1.2918 - acc: 0.7917 - val_loss: 2.2034 - val_acc: 0.5598\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 1.2522 - acc: 0.8103 - val_loss: 2.2748 - val_acc: 0.5408\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 1.2324 - acc: 0.8222 - val_loss: 2.4298 - val_acc: 0.5353\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 43s 5ms/step - loss: 7.4898 - acc: 0.2058 - val_loss: 5.9363 - val_acc: 0.3143\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 5.5435 - acc: 0.3756 - val_loss: 5.2901 - val_acc: 0.4248\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 5.0828 - acc: 0.4626 - val_loss: 4.8279 - val_acc: 0.4692\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 4.5598 - acc: 0.5001 - val_loss: 4.3365 - val_acc: 0.4828\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 4.0642 - acc: 0.5157 - val_loss: 3.8929 - val_acc: 0.4774\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 551us/step - loss: 3.5953 - acc: 0.5371 - val_loss: 3.4672 - val_acc: 0.5208\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 3.2089 - acc: 0.5451 - val_loss: 3.1978 - val_acc: 0.5045\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 2.9173 - acc: 0.5602 - val_loss: 2.9168 - val_acc: 0.5299\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 2.7065 - acc: 0.5590 - val_loss: 2.7696 - val_acc: 0.5118\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 2.5337 - acc: 0.5621 - val_loss: 2.6774 - val_acc: 0.5145\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 2.3652 - acc: 0.5824 - val_loss: 2.4905 - val_acc: 0.5054\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 2.2562 - acc: 0.5855 - val_loss: 2.4602 - val_acc: 0.5009\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 2.1684 - acc: 0.5884 - val_loss: 2.3418 - val_acc: 0.5063\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: 2.0756 - acc: 0.6002 - val_loss: 2.2922 - val_acc: 0.5371\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 2.0175 - acc: 0.6005 - val_loss: 2.3460 - val_acc: 0.4964\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 2.0108 - acc: 0.5846 - val_loss: 2.2489 - val_acc: 0.5109\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 1.9608 - acc: 0.6017 - val_loss: 2.2590 - val_acc: 0.4937\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 1.9086 - acc: 0.6052 - val_loss: 2.1408 - val_acc: 0.5326\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 1.8122 - acc: 0.6376 - val_loss: 2.0951 - val_acc: 0.5353\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 1.7851 - acc: 0.6339 - val_loss: 2.2517 - val_acc: 0.5208\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 1.7940 - acc: 0.6299 - val_loss: 2.1113 - val_acc: 0.5335\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 1.7451 - acc: 0.6475 - val_loss: 2.1000 - val_acc: 0.5507\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 1.6870 - acc: 0.6637 - val_loss: 2.1914 - val_acc: 0.5118\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 1.7349 - acc: 0.6445 - val_loss: 2.2112 - val_acc: 0.5326\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 1.7722 - acc: 0.6294 - val_loss: 2.2111 - val_acc: 0.5163\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 1.7346 - acc: 0.6510 - val_loss: 2.2897 - val_acc: 0.5190\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: 1.6940 - acc: 0.6641 - val_loss: 2.2474 - val_acc: 0.5245\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 1.6713 - acc: 0.6703 - val_loss: 2.2273 - val_acc: 0.5263\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 1.6408 - acc: 0.6766 - val_loss: 2.1555 - val_acc: 0.5127\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 547us/step - loss: 1.6523 - acc: 0.6720 - val_loss: 2.2347 - val_acc: 0.5036\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 1.6544 - acc: 0.6676 - val_loss: 2.3064 - val_acc: 0.5109\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 541us/step - loss: 1.6834 - acc: 0.6690 - val_loss: 2.2353 - val_acc: 0.5118\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 44s 5ms/step - loss: 10.1205 - acc: 0.4310 - val_loss: 9.7274 - val_acc: 0.5000\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 9.4037 - acc: 0.5771 - val_loss: 9.3879 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 8.9954 - acc: 0.6331 - val_loss: 9.1082 - val_acc: 0.5353\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: 8.6467 - acc: 0.6823 - val_loss: 8.8750 - val_acc: 0.5380\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 8.3073 - acc: 0.7129 - val_loss: 8.6205 - val_acc: 0.5380\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 7.9714 - acc: 0.7464 - val_loss: 8.3778 - val_acc: 0.5489\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 7.6593 - acc: 0.7708 - val_loss: 8.0812 - val_acc: 0.5716\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 726us/step - loss: 7.3534 - acc: 0.8012 - val_loss: 7.8410 - val_acc: 0.5534\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 7.0715 - acc: 0.8232 - val_loss: 7.6254 - val_acc: 0.5598\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 6.7883 - acc: 0.8398 - val_loss: 7.4154 - val_acc: 0.5589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 6.5151 - acc: 0.8630 - val_loss: 7.1765 - val_acc: 0.5688\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 6.2490 - acc: 0.8808 - val_loss: 7.0126 - val_acc: 0.5607\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 6.0113 - acc: 0.8965 - val_loss: 6.7870 - val_acc: 0.5643\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 5.7704 - acc: 0.9090 - val_loss: 6.6132 - val_acc: 0.5770\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 5.5434 - acc: 0.9174 - val_loss: 6.4390 - val_acc: 0.5761\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 5.3306 - acc: 0.9250 - val_loss: 6.2901 - val_acc: 0.5634\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 5.1245 - acc: 0.9352 - val_loss: 6.0976 - val_acc: 0.5734\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 4.9229 - acc: 0.9487 - val_loss: 5.9905 - val_acc: 0.5462\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 757us/step - loss: 4.7372 - acc: 0.9542 - val_loss: 5.8342 - val_acc: 0.5525\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 4.5587 - acc: 0.9564 - val_loss: 5.6190 - val_acc: 0.5788\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 756us/step - loss: 4.3758 - acc: 0.9614 - val_loss: 5.5030 - val_acc: 0.5643\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 4.2144 - acc: 0.9612 - val_loss: 5.4140 - val_acc: 0.5571\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: 4.0591 - acc: 0.9640 - val_loss: 5.2414 - val_acc: 0.5716\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: 3.8943 - acc: 0.9732 - val_loss: 5.2123 - val_acc: 0.5580\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 3.7716 - acc: 0.9610 - val_loss: 4.9905 - val_acc: 0.5761\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 3.6110 - acc: 0.9763 - val_loss: 4.8617 - val_acc: 0.5562\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 740us/step - loss: 3.4675 - acc: 0.9800 - val_loss: 4.7587 - val_acc: 0.5788\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 3.3278 - acc: 0.9844 - val_loss: 4.6854 - val_acc: 0.5743\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 735us/step - loss: 3.2355 - acc: 0.9730 - val_loss: 4.5775 - val_acc: 0.5716\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: 3.0986 - acc: 0.9800 - val_loss: 4.4905 - val_acc: 0.5543\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 51s 6ms/step - loss: 4.6689 - acc: 0.3893 - val_loss: 4.3481 - val_acc: 0.4918\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.3139 - acc: 0.4935 - val_loss: 4.2741 - val_acc: 0.5027\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.1865 - acc: 0.5237 - val_loss: 4.1693 - val_acc: 0.5263\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.0800 - acc: 0.5457 - val_loss: 4.1349 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.0163 - acc: 0.5536 - val_loss: 4.0711 - val_acc: 0.5453\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.9402 - acc: 0.5805 - val_loss: 4.0266 - val_acc: 0.5435\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8837 - acc: 0.5877 - val_loss: 3.9960 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8121 - acc: 0.6056 - val_loss: 3.9441 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.7521 - acc: 0.6192 - val_loss: 3.9137 - val_acc: 0.5616\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6934 - acc: 0.6280 - val_loss: 3.9394 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6458 - acc: 0.6380 - val_loss: 3.8453 - val_acc: 0.5634\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5968 - acc: 0.6459 - val_loss: 3.8584 - val_acc: 0.5670\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5463 - acc: 0.6579 - val_loss: 3.7904 - val_acc: 0.5679\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4799 - acc: 0.6777 - val_loss: 3.7797 - val_acc: 0.5707\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4318 - acc: 0.6803 - val_loss: 3.7650 - val_acc: 0.5734\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3850 - acc: 0.6886 - val_loss: 3.7231 - val_acc: 0.5770\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3431 - acc: 0.7048 - val_loss: 3.7354 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3025 - acc: 0.7027 - val_loss: 3.6801 - val_acc: 0.5779\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2307 - acc: 0.7234 - val_loss: 3.6358 - val_acc: 0.5870\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1843 - acc: 0.7343 - val_loss: 3.6380 - val_acc: 0.5833\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1400 - acc: 0.7421 - val_loss: 3.6278 - val_acc: 0.5833\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0957 - acc: 0.7467 - val_loss: 3.5946 - val_acc: 0.5897\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0473 - acc: 0.7541 - val_loss: 3.5677 - val_acc: 0.5915\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0149 - acc: 0.7611 - val_loss: 3.5543 - val_acc: 0.5788\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9659 - acc: 0.7701 - val_loss: 3.5344 - val_acc: 0.5761\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9133 - acc: 0.7832 - val_loss: 3.5297 - val_acc: 0.5888\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8633 - acc: 0.7911 - val_loss: 3.5241 - val_acc: 0.5861\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8223 - acc: 0.8030 - val_loss: 3.5034 - val_acc: 0.5824\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7805 - acc: 0.8075 - val_loss: 3.4640 - val_acc: 0.5951\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7421 - acc: 0.8148 - val_loss: 3.4622 - val_acc: 0.5960\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7025 - acc: 0.8181 - val_loss: 3.4519 - val_acc: 0.5879\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6557 - acc: 0.8311 - val_loss: 3.4573 - val_acc: 0.5779\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6319 - acc: 0.8326 - val_loss: 3.4314 - val_acc: 0.5879\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5855 - acc: 0.8414 - val_loss: 3.4309 - val_acc: 0.5924\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5454 - acc: 0.8525 - val_loss: 3.4274 - val_acc: 0.5906\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5039 - acc: 0.8556 - val_loss: 3.3825 - val_acc: 0.5833\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4663 - acc: 0.8645 - val_loss: 3.3651 - val_acc: 0.5870\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4375 - acc: 0.8609 - val_loss: 3.3635 - val_acc: 0.5879\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.3873 - acc: 0.8765 - val_loss: 3.3309 - val_acc: 0.5824\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.3495 - acc: 0.8802 - val_loss: 3.3455 - val_acc: 0.5870\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 45s 5ms/step - loss: 263.9683 - acc: 0.3051 - val_loss: 245.1443 - val_acc: 0.4665\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 231.0349 - acc: 0.4420 - val_loss: 214.2543 - val_acc: 0.4891\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 201.7580 - acc: 0.4685 - val_loss: 186.9330 - val_acc: 0.5036\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 175.9019 - acc: 0.4920 - val_loss: 162.8661 - val_acc: 0.5082\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 153.1365 - acc: 0.5082 - val_loss: 141.6966 - val_acc: 0.5208\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 133.1378 - acc: 0.5217 - val_loss: 123.1347 - val_acc: 0.5254\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 115.5935 - acc: 0.5382 - val_loss: 106.8608 - val_acc: 0.5371\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 735us/step - loss: 100.2655 - acc: 0.5498 - val_loss: 92.6650 - val_acc: 0.5272\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 86.8566 - acc: 0.5694 - val_loss: 80.2733 - val_acc: 0.5417\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 75.1837 - acc: 0.5647 - val_loss: 69.5181 - val_acc: 0.5317\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 65.0395 - acc: 0.5708 - val_loss: 60.1888 - val_acc: 0.5299\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 56.2446 - acc: 0.5742 - val_loss: 52.0646 - val_acc: 0.5426\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 762us/step - loss: 48.6068 - acc: 0.5870 - val_loss: 45.0586 - val_acc: 0.5534\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 42.0056 - acc: 0.5886 - val_loss: 39.0480 - val_acc: 0.5172\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 36.2989 - acc: 0.5988 - val_loss: 33.8536 - val_acc: 0.5245\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 31.3803 - acc: 0.6064 - val_loss: 29.3578 - val_acc: 0.5181\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 27.1554 - acc: 0.6044 - val_loss: 25.5015 - val_acc: 0.5208\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 773us/step - loss: 23.5327 - acc: 0.6123 - val_loss: 22.1536 - val_acc: 0.5453\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 20.4078 - acc: 0.6081 - val_loss: 19.3392 - val_acc: 0.5063\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 777us/step - loss: 17.7282 - acc: 0.6212 - val_loss: 16.9080 - val_acc: 0.5254\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 15.4485 - acc: 0.6233 - val_loss: 14.8187 - val_acc: 0.5326\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 13.4643 - acc: 0.6371 - val_loss: 13.0498 - val_acc: 0.5109\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 754us/step - loss: 11.8019 - acc: 0.6327 - val_loss: 11.4763 - val_acc: 0.5208\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 45s 5ms/step - loss: 279.3230 - acc: 0.3606 - val_loss: 247.7769 - val_acc: 0.4882\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 723us/step - loss: 224.9393 - acc: 0.4771 - val_loss: 198.8241 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 180.1368 - acc: 0.5106 - val_loss: 158.8994 - val_acc: 0.5362\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 143.7565 - acc: 0.5224 - val_loss: 126.6705 - val_acc: 0.4928\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 114.3858 - acc: 0.5371 - val_loss: 100.6942 - val_acc: 0.5290\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 90.7844 - acc: 0.5651 - val_loss: 79.8781 - val_acc: 0.5290\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 762us/step - loss: 71.9164 - acc: 0.5699 - val_loss: 63.3641 - val_acc: 0.5145\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 56.9256 - acc: 0.5663 - val_loss: 50.2204 - val_acc: 0.4955\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 45.0165 - acc: 0.5792 - val_loss: 39.8691 - val_acc: 0.5045\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 780us/step - loss: 35.6286 - acc: 0.5771 - val_loss: 31.7241 - val_acc: 0.5072\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 28.2057 - acc: 0.5929 - val_loss: 25.3440 - val_acc: 0.5045\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 22.4224 - acc: 0.5902 - val_loss: 20.2960 - val_acc: 0.4955\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 17.8875 - acc: 0.5970 - val_loss: 16.3852 - val_acc: 0.4846\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 1108.8769 - acc: 0.1417 - val_loss: 1034.9755 - val_acc: 0.3043\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 978.3441 - acc: 0.2606 - val_loss: 911.8822 - val_acc: 0.3995\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 861.9799 - acc: 0.3144 - val_loss: 803.3836 - val_acc: 0.4312\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 759.2951 - acc: 0.3688 - val_loss: 707.4890 - val_acc: 0.4393\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 740us/step - loss: 668.4684 - acc: 0.4020 - val_loss: 622.6257 - val_acc: 0.4574\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 782us/step - loss: 588.1375 - acc: 0.4273 - val_loss: 547.7064 - val_acc: 0.4746\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 517.2085 - acc: 0.4614 - val_loss: 481.4578 - val_acc: 0.4764\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 784us/step - loss: 454.4410 - acc: 0.4742 - val_loss: 422.8091 - val_acc: 0.4928\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 398.8731 - acc: 0.4868 - val_loss: 370.9363 - val_acc: 0.4909\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 349.7408 - acc: 0.4956 - val_loss: 325.0968 - val_acc: 0.4991\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 306.3399 - acc: 0.5142 - val_loss: 284.6540 - val_acc: 0.5018\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 803us/step - loss: 268.0583 - acc: 0.5220 - val_loss: 249.0062 - val_acc: 0.5027\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 234.3418 - acc: 0.5199 - val_loss: 217.6356 - val_acc: 0.5118\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 204.6648 - acc: 0.5375 - val_loss: 190.0565 - val_acc: 0.5154\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 178.5948 - acc: 0.5387 - val_loss: 165.8531 - val_acc: 0.5063\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 155.7136 - acc: 0.5484 - val_loss: 144.6387 - val_acc: 0.5091\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 135.6674 - acc: 0.5498 - val_loss: 126.0696 - val_acc: 0.5009\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 118.1237 - acc: 0.5546 - val_loss: 109.8286 - val_acc: 0.4909\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 102.7918 - acc: 0.5573 - val_loss: 95.6548 - val_acc: 0.4855\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 89.4125 - acc: 0.5629 - val_loss: 83.2767 - val_acc: 0.4928\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 6s 721us/step - loss: 77.7570 - acc: 0.5638 - val_loss: 72.5060 - val_acc: 0.4792\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 67.6079 - acc: 0.5671 - val_loss: 63.1320 - val_acc: 0.4909\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 58.7779 - acc: 0.5716 - val_loss: 54.9762 - val_acc: 0.4864\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 51.1159 - acc: 0.5755 - val_loss: 47.8938 - val_acc: 0.4683\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 161.7133 - acc: 0.3428 - val_loss: 146.5279 - val_acc: 0.4792\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 8s 859us/step - loss: 135.2588 - acc: 0.4739 - val_loss: 122.1189 - val_acc: 0.4973\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 833us/step - loss: 112.5576 - acc: 0.4913 - val_loss: 101.4776 - val_acc: 0.5308\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 822us/step - loss: 93.4490 - acc: 0.5169 - val_loss: 84.1831 - val_acc: 0.5281\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 825us/step - loss: 77.4006 - acc: 0.5351 - val_loss: 69.6857 - val_acc: 0.5335\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 815us/step - loss: 64.0235 - acc: 0.5437 - val_loss: 57.6422 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 802us/step - loss: 52.9041 - acc: 0.5609 - val_loss: 47.6534 - val_acc: 0.5245\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 813us/step - loss: 43.7035 - acc: 0.5698 - val_loss: 39.4538 - val_acc: 0.5100\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 36.1183 - acc: 0.5749 - val_loss: 32.6460 - val_acc: 0.5299\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 796us/step - loss: 29.8405 - acc: 0.5825 - val_loss: 27.0548 - val_acc: 0.5408\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 815us/step - loss: 24.6971 - acc: 0.5898 - val_loss: 22.5301 - val_acc: 0.5154\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 807us/step - loss: 20.4810 - acc: 0.5875 - val_loss: 18.7910 - val_acc: 0.5199\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 818us/step - loss: 17.0430 - acc: 0.5967 - val_loss: 15.7554 - val_acc: 0.5100\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 14.2271 - acc: 0.5998 - val_loss: 13.3076 - val_acc: 0.5154\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 810us/step - loss: 11.9564 - acc: 0.6058 - val_loss: 11.3354 - val_acc: 0.4909\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 10.0917 - acc: 0.6099 - val_loss: 9.6652 - val_acc: 0.5136\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 812us/step - loss: 8.5795 - acc: 0.6180 - val_loss: 8.2879 - val_acc: 0.5181\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 813us/step - loss: 7.3680 - acc: 0.6133 - val_loss: 7.2153 - val_acc: 0.4909\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 8s 852us/step - loss: 6.3523 - acc: 0.6222 - val_loss: 6.3192 - val_acc: 0.5263\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 8s 858us/step - loss: 5.5046 - acc: 0.6405 - val_loss: 5.6083 - val_acc: 0.5181\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 5.4180 - acc: 0.2266 - val_loss: 4.1335 - val_acc: 0.3243\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 598us/step - loss: 3.8985 - acc: 0.4021 - val_loss: 3.7185 - val_acc: 0.4420\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: 3.6197 - acc: 0.4802 - val_loss: 3.5338 - val_acc: 0.4918\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 648us/step - loss: 3.3858 - acc: 0.5201 - val_loss: 3.3873 - val_acc: 0.5027\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 3.1602 - acc: 0.5423 - val_loss: 3.1761 - val_acc: 0.5118\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 652us/step - loss: 2.9617 - acc: 0.5674 - val_loss: 3.0770 - val_acc: 0.5308\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 2.7853 - acc: 0.5835 - val_loss: 2.8998 - val_acc: 0.5353\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 590us/step - loss: 2.6040 - acc: 0.6039 - val_loss: 2.8737 - val_acc: 0.5281\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 588us/step - loss: 2.5265 - acc: 0.5943 - val_loss: 2.6945 - val_acc: 0.5226\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 579us/step - loss: 2.3640 - acc: 0.6197 - val_loss: 2.5825 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 585us/step - loss: 2.2420 - acc: 0.6299 - val_loss: 2.5593 - val_acc: 0.5217\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 2.1615 - acc: 0.6368 - val_loss: 2.4614 - val_acc: 0.5380\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 2.0684 - acc: 0.6508 - val_loss: 2.4893 - val_acc: 0.5263\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 1.9929 - acc: 0.6628 - val_loss: 2.4267 - val_acc: 0.5389\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 1.9450 - acc: 0.6669 - val_loss: 2.3472 - val_acc: 0.5435\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 1.9219 - acc: 0.6603 - val_loss: 2.3356 - val_acc: 0.5380\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 1.8360 - acc: 0.6767 - val_loss: 2.4478 - val_acc: 0.5353\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 1.8116 - acc: 0.6886 - val_loss: 2.3217 - val_acc: 0.5516\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 1.7303 - acc: 0.7047 - val_loss: 2.3199 - val_acc: 0.5281\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 1.7310 - acc: 0.7014 - val_loss: 2.3610 - val_acc: 0.5453\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.6918 - acc: 0.7108 - val_loss: 2.2406 - val_acc: 0.5562\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 1.6214 - acc: 0.7342 - val_loss: 2.4001 - val_acc: 0.5335\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 1.6091 - acc: 0.7298 - val_loss: 2.2751 - val_acc: 0.5489\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 1.5742 - acc: 0.7435 - val_loss: 2.3000 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 1.5324 - acc: 0.7549 - val_loss: 2.2848 - val_acc: 0.5562\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: 1.5028 - acc: 0.7682 - val_loss: 2.2987 - val_acc: 0.5344\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 538us/step - loss: 1.4763 - acc: 0.7723 - val_loss: 2.3120 - val_acc: 0.5444\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 1.4827 - acc: 0.7732 - val_loss: 2.3352 - val_acc: 0.5408\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 1.4991 - acc: 0.7677 - val_loss: 2.3369 - val_acc: 0.5380\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 1.4713 - acc: 0.7846 - val_loss: 2.3720 - val_acc: 0.5498\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 1.4611 - acc: 0.7924 - val_loss: 2.3657 - val_acc: 0.5543\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 1.4490 - acc: 0.7956 - val_loss: 2.3644 - val_acc: 0.5399\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 1.4418 - acc: 0.7974 - val_loss: 2.3986 - val_acc: 0.5435\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: 1.4294 - acc: 0.8070 - val_loss: 2.4286 - val_acc: 0.5199\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 1.4483 - acc: 0.7988 - val_loss: 2.3744 - val_acc: 0.5489\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 19.6944 - acc: 0.3621 - val_loss: 15.8043 - val_acc: 0.4592\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 711us/step - loss: 12.7681 - acc: 0.5020 - val_loss: 9.5377 - val_acc: 0.4909\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 7.6151 - acc: 0.5238 - val_loss: 6.1424 - val_acc: 0.4502\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 5.0114 - acc: 0.5114 - val_loss: 4.3003 - val_acc: 0.4783\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 3.6138 - acc: 0.5327 - val_loss: 3.3160 - val_acc: 0.4973\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: 2.9680 - acc: 0.5240 - val_loss: 2.8698 - val_acc: 0.4692\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 735us/step - loss: 2.5573 - acc: 0.5318 - val_loss: 2.5735 - val_acc: 0.4855\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 2.2816 - acc: 0.5425 - val_loss: 2.6217 - val_acc: 0.3895\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 2.2656 - acc: 0.5133 - val_loss: 2.3073 - val_acc: 0.4909\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 2.0894 - acc: 0.5400 - val_loss: 2.2698 - val_acc: 0.4692\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: 2.0091 - acc: 0.5334 - val_loss: 2.1708 - val_acc: 0.4629\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 812us/step - loss: 1.9559 - acc: 0.5445 - val_loss: 2.1932 - val_acc: 0.4484\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 1.9346 - acc: 0.5364 - val_loss: 2.1694 - val_acc: 0.4384\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 1.9284 - acc: 0.5381 - val_loss: 2.0430 - val_acc: 0.4909\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 1.8755 - acc: 0.5473 - val_loss: 2.0656 - val_acc: 0.4547\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 6.1619 - acc: 0.1884 - val_loss: 4.8964 - val_acc: 0.2219\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 4.6734 - acc: 0.2998 - val_loss: 4.5763 - val_acc: 0.3324\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 582us/step - loss: 4.4278 - acc: 0.3775 - val_loss: 4.2860 - val_acc: 0.3650\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 4.0316 - acc: 0.4312 - val_loss: 3.8137 - val_acc: 0.4339\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 585us/step - loss: 3.6130 - acc: 0.4668 - val_loss: 3.4846 - val_acc: 0.4511\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 3.2793 - acc: 0.4765 - val_loss: 3.1557 - val_acc: 0.4746\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 2.9752 - acc: 0.5021 - val_loss: 2.9071 - val_acc: 0.4710\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 617us/step - loss: 2.7502 - acc: 0.5044 - val_loss: 2.6682 - val_acc: 0.4946\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 2.5471 - acc: 0.5169 - val_loss: 2.6839 - val_acc: 0.4638\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 622us/step - loss: 2.4376 - acc: 0.5185 - val_loss: 2.5011 - val_acc: 0.4484\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 2.2788 - acc: 0.5411 - val_loss: 2.3581 - val_acc: 0.4873\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 619us/step - loss: 2.1777 - acc: 0.5439 - val_loss: 2.3207 - val_acc: 0.4683\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 631us/step - loss: 2.0835 - acc: 0.5614 - val_loss: 2.2262 - val_acc: 0.4918\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 2.0049 - acc: 0.5628 - val_loss: 2.1669 - val_acc: 0.4964\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 1.9421 - acc: 0.5661 - val_loss: 2.1877 - val_acc: 0.4864\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 1.9007 - acc: 0.5696 - val_loss: 2.0704 - val_acc: 0.5236\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 621us/step - loss: 1.8621 - acc: 0.5763 - val_loss: 2.1298 - val_acc: 0.4755\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 1.8919 - acc: 0.5629 - val_loss: 2.0483 - val_acc: 0.5199\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 1.8135 - acc: 0.5866 - val_loss: 1.9903 - val_acc: 0.5371\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 1.7717 - acc: 0.5938 - val_loss: 2.0282 - val_acc: 0.5172\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: 1.7542 - acc: 0.6001 - val_loss: 2.0398 - val_acc: 0.5018\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: 1.7355 - acc: 0.5935 - val_loss: 2.0133 - val_acc: 0.5072\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 625us/step - loss: 1.7010 - acc: 0.6099 - val_loss: 2.0533 - val_acc: 0.5172\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 629us/step - loss: 1.6847 - acc: 0.6123 - val_loss: 1.9832 - val_acc: 0.5199\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 1.6237 - acc: 0.6251 - val_loss: 2.0049 - val_acc: 0.5217\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 638us/step - loss: 1.6348 - acc: 0.6235 - val_loss: 2.0258 - val_acc: 0.5063\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 1.6602 - acc: 0.6219 - val_loss: 2.0500 - val_acc: 0.5208\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 1.6422 - acc: 0.6291 - val_loss: 1.9686 - val_acc: 0.5335\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: 1.5930 - acc: 0.6446 - val_loss: 2.0454 - val_acc: 0.5326\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: 5.0077 - acc: 0.2203 - val_loss: 3.5949 - val_acc: 0.3551\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 3.3693 - acc: 0.4168 - val_loss: 3.2768 - val_acc: 0.4312\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 595us/step - loss: 3.1029 - acc: 0.4882 - val_loss: 3.0911 - val_acc: 0.4846\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 613us/step - loss: 2.8961 - acc: 0.5339 - val_loss: 2.9466 - val_acc: 0.4937\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 2.7369 - acc: 0.5542 - val_loss: 2.8554 - val_acc: 0.5072\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 2.5933 - acc: 0.5730 - val_loss: 2.7844 - val_acc: 0.4783\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 2.5001 - acc: 0.5737 - val_loss: 2.6213 - val_acc: 0.5344\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 2.3347 - acc: 0.6039 - val_loss: 2.5459 - val_acc: 0.5299\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 2.2243 - acc: 0.6152 - val_loss: 2.4641 - val_acc: 0.5417\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 643us/step - loss: 2.1075 - acc: 0.6313 - val_loss: 2.5174 - val_acc: 0.5181\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 2.0271 - acc: 0.6397 - val_loss: 2.3484 - val_acc: 0.5444\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 617us/step - loss: 1.9157 - acc: 0.6636 - val_loss: 2.3386 - val_acc: 0.5453\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 632us/step - loss: 1.8182 - acc: 0.6818 - val_loss: 2.3057 - val_acc: 0.5444\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 6s 631us/step - loss: 1.7659 - acc: 0.6841 - val_loss: 2.2779 - val_acc: 0.5444\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: 1.6770 - acc: 0.7098 - val_loss: 2.2740 - val_acc: 0.5290\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 615us/step - loss: 1.6236 - acc: 0.7174 - val_loss: 2.2481 - val_acc: 0.5498\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 1.5994 - acc: 0.7155 - val_loss: 2.2182 - val_acc: 0.5580\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 628us/step - loss: 1.5200 - acc: 0.7424 - val_loss: 2.2598 - val_acc: 0.5489\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 1.5180 - acc: 0.7385 - val_loss: 2.3607 - val_acc: 0.5308\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 613us/step - loss: 1.5005 - acc: 0.7380 - val_loss: 2.2220 - val_acc: 0.5661\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: 1.4192 - acc: 0.7704 - val_loss: 2.3365 - val_acc: 0.5326\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 617us/step - loss: 1.4124 - acc: 0.7653 - val_loss: 2.4610 - val_acc: 0.5054\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 1.4040 - acc: 0.7678 - val_loss: 2.2294 - val_acc: 0.5580\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 613us/step - loss: 1.3130 - acc: 0.8041 - val_loss: 2.3045 - val_acc: 0.5516\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 613us/step - loss: 1.2269 - acc: 0.8320 - val_loss: 2.3522 - val_acc: 0.5426\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 1.2309 - acc: 0.8276 - val_loss: 2.3203 - val_acc: 0.5516\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 1.2023 - acc: 0.8383 - val_loss: 2.4290 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: 1.1680 - acc: 0.8492 - val_loss: 2.3507 - val_acc: 0.5607\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 647us/step - loss: 1.1352 - acc: 0.8593 - val_loss: 2.4514 - val_acc: 0.5498\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: 1.1343 - acc: 0.8642 - val_loss: 2.3632 - val_acc: 0.5562\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: nan - acc: 0.0681 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 495us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 517us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 507us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 48s 5ms/step - loss: 5.2747 - acc: 0.2500 - val_loss: 3.7845 - val_acc: 0.3976\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 632us/step - loss: 3.6094 - acc: 0.4285 - val_loss: 3.4844 - val_acc: 0.4683\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 3.3467 - acc: 0.5041 - val_loss: 3.3320 - val_acc: 0.5018\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 3.1314 - acc: 0.5456 - val_loss: 3.1734 - val_acc: 0.5045\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 623us/step - loss: 2.9441 - acc: 0.5689 - val_loss: 3.0580 - val_acc: 0.5072\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 2.7597 - acc: 0.5961 - val_loss: 2.9117 - val_acc: 0.5199\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 2.6270 - acc: 0.6081 - val_loss: 2.8627 - val_acc: 0.5344\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 2.4646 - acc: 0.6304 - val_loss: 2.7500 - val_acc: 0.5136\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 2.3113 - acc: 0.6590 - val_loss: 2.7198 - val_acc: 0.5326\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 2.2190 - acc: 0.6589 - val_loss: 2.6831 - val_acc: 0.5208\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 2.1411 - acc: 0.6678 - val_loss: 2.5385 - val_acc: 0.5480\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 595us/step - loss: 2.0003 - acc: 0.6925 - val_loss: 2.5437 - val_acc: 0.5399\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 1.9214 - acc: 0.7039 - val_loss: 2.4961 - val_acc: 0.5498\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 1.8146 - acc: 0.7214 - val_loss: 2.4130 - val_acc: 0.5317\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: 1.7145 - acc: 0.7455 - val_loss: 2.3819 - val_acc: 0.5625\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 1.6106 - acc: 0.7726 - val_loss: 2.3539 - val_acc: 0.5417\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: 1.5192 - acc: 0.7951 - val_loss: 2.5587 - val_acc: 0.5163\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 1.4938 - acc: 0.7862 - val_loss: 2.3928 - val_acc: 0.5408\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: 1.4326 - acc: 0.7996 - val_loss: 2.4130 - val_acc: 0.5362\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 1.4188 - acc: 0.8029 - val_loss: 2.4574 - val_acc: 0.5154\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: 1.3580 - acc: 0.8218 - val_loss: 2.4060 - val_acc: 0.5435\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 591us/step - loss: 1.3138 - acc: 0.8273 - val_loss: 2.4011 - val_acc: 0.5480\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 609us/step - loss: 1.2690 - acc: 0.8396 - val_loss: 2.4614 - val_acc: 0.5489\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 1.2216 - acc: 0.8531 - val_loss: 2.4492 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 1.1716 - acc: 0.8716 - val_loss: 2.3863 - val_acc: 0.5562\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 48s 5ms/step - loss: 7.4875 - acc: 0.3460 - val_loss: 6.5875 - val_acc: 0.4592\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 810us/step - loss: 6.1245 - acc: 0.5075 - val_loss: 5.7788 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 5.2873 - acc: 0.5421 - val_loss: 4.9982 - val_acc: 0.5045\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 780us/step - loss: 4.5381 - acc: 0.5754 - val_loss: 4.5043 - val_acc: 0.4792\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 777us/step - loss: 3.9464 - acc: 0.5830 - val_loss: 3.9732 - val_acc: 0.5027\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 3.4475 - acc: 0.6002 - val_loss: 3.4690 - val_acc: 0.5217\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 3.0233 - acc: 0.6222 - val_loss: 3.2234 - val_acc: 0.5226\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 2.7998 - acc: 0.6066 - val_loss: 3.0215 - val_acc: 0.5018\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 2.5397 - acc: 0.6192 - val_loss: 2.8399 - val_acc: 0.5100\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 2.3738 - acc: 0.6203 - val_loss: 2.6273 - val_acc: 0.5208\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 770us/step - loss: 2.1739 - acc: 0.6449 - val_loss: 2.4451 - val_acc: 0.5299\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 2.0286 - acc: 0.6521 - val_loss: 2.3873 - val_acc: 0.5534\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 757us/step - loss: 1.9442 - acc: 0.6538 - val_loss: 2.4952 - val_acc: 0.5109\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 1.8882 - acc: 0.6576 - val_loss: 2.3270 - val_acc: 0.5172\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 1.7789 - acc: 0.6697 - val_loss: 2.2843 - val_acc: 0.5145\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 794us/step - loss: 1.6910 - acc: 0.6899 - val_loss: 2.2470 - val_acc: 0.5489\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 784us/step - loss: 1.6517 - acc: 0.6884 - val_loss: 2.2420 - val_acc: 0.5236\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 823us/step - loss: 1.6572 - acc: 0.6806 - val_loss: 2.1687 - val_acc: 0.5453\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 1.6503 - acc: 0.6807 - val_loss: 2.1134 - val_acc: 0.5453\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 1.5970 - acc: 0.6972 - val_loss: 2.1544 - val_acc: 0.5272\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 1.5561 - acc: 0.7030 - val_loss: 2.1896 - val_acc: 0.5154\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 1.5784 - acc: 0.6967 - val_loss: 2.2520 - val_acc: 0.5199\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 48s 5ms/step - loss: nan - acc: 0.0737 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 658us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 640us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 641us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 628us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 723us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 694us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 649us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 9.8683 - acc: 0.3346 - val_loss: 9.4957 - val_acc: 0.4746\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: 9.2432 - acc: 0.4942 - val_loss: 9.1083 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 8.9703 - acc: 0.5147 - val_loss: 8.9027 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 8.7232 - acc: 0.5365 - val_loss: 8.6757 - val_acc: 0.5435\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 8.4713 - acc: 0.5579 - val_loss: 8.4547 - val_acc: 0.5371\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 8.2389 - acc: 0.5718 - val_loss: 8.2575 - val_acc: 0.5471\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 8.0081 - acc: 0.5926 - val_loss: 8.0873 - val_acc: 0.5362\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 579us/step - loss: 7.7976 - acc: 0.5995 - val_loss: 7.9037 - val_acc: 0.5435\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 7.5839 - acc: 0.6163 - val_loss: 7.6863 - val_acc: 0.5598\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 585us/step - loss: 7.3779 - acc: 0.6277 - val_loss: 7.4937 - val_acc: 0.5670\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 7.1650 - acc: 0.6408 - val_loss: 7.3296 - val_acc: 0.5607\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 581us/step - loss: 6.9683 - acc: 0.6539 - val_loss: 7.1302 - val_acc: 0.5688\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 6.7735 - acc: 0.6609 - val_loss: 7.0304 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 6.5824 - acc: 0.6659 - val_loss: 6.7993 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 6.3950 - acc: 0.6791 - val_loss: 6.6554 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 6.2101 - acc: 0.6923 - val_loss: 6.4951 - val_acc: 0.5752\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 6.0267 - acc: 0.6980 - val_loss: 6.3394 - val_acc: 0.5743\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 5.8581 - acc: 0.7119 - val_loss: 6.2190 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 5.7004 - acc: 0.7198 - val_loss: 6.0624 - val_acc: 0.5797\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 5.5322 - acc: 0.7268 - val_loss: 5.9327 - val_acc: 0.5743\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 5.3683 - acc: 0.7363 - val_loss: 5.7836 - val_acc: 0.5870\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 588us/step - loss: 5.2125 - acc: 0.7446 - val_loss: 5.6870 - val_acc: 0.5752\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 5.0627 - acc: 0.7541 - val_loss: 5.4966 - val_acc: 0.5924\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 4.9173 - acc: 0.7600 - val_loss: 5.4291 - val_acc: 0.5806\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 4.7800 - acc: 0.7701 - val_loss: 5.3198 - val_acc: 0.5888\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 585us/step - loss: 4.6424 - acc: 0.7748 - val_loss: 5.2171 - val_acc: 0.5797\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 4.5059 - acc: 0.7820 - val_loss: 5.0929 - val_acc: 0.5924\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 4.3899 - acc: 0.7822 - val_loss: 5.0014 - val_acc: 0.5870\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 4.2711 - acc: 0.7916 - val_loss: 4.8636 - val_acc: 0.5897\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 580us/step - loss: 4.1380 - acc: 0.8009 - val_loss: 4.7986 - val_acc: 0.5851\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 545us/step - loss: 4.0144 - acc: 0.8106 - val_loss: 4.7003 - val_acc: 0.5743\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 589us/step - loss: 3.9005 - acc: 0.8155 - val_loss: 4.6009 - val_acc: 0.5924\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 5s 583us/step - loss: 3.7916 - acc: 0.8208 - val_loss: 4.5774 - val_acc: 0.5743\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 8.5194 - acc: 0.3775 - val_loss: 8.1463 - val_acc: 0.5009\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 7.9089 - acc: 0.5098 - val_loss: 7.8575 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 7.6240 - acc: 0.5476 - val_loss: 7.6147 - val_acc: 0.5380\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: 7.3703 - acc: 0.5887 - val_loss: 7.4495 - val_acc: 0.5335\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 525us/step - loss: 7.1503 - acc: 0.6091 - val_loss: 7.2421 - val_acc: 0.5507\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 6.9166 - acc: 0.6413 - val_loss: 7.0631 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 6.7059 - acc: 0.6616 - val_loss: 6.8998 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 6.4991 - acc: 0.6815 - val_loss: 6.7388 - val_acc: 0.5543\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 6.3107 - acc: 0.6963 - val_loss: 6.5950 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 6.1058 - acc: 0.7181 - val_loss: 6.4547 - val_acc: 0.5716\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 541us/step - loss: 5.9251 - acc: 0.7226 - val_loss: 6.3917 - val_acc: 0.5516\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 5.7508 - acc: 0.7377 - val_loss: 6.1632 - val_acc: 0.5661\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 5.5631 - acc: 0.7586 - val_loss: 6.0223 - val_acc: 0.5716\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 5.3911 - acc: 0.7693 - val_loss: 5.8810 - val_acc: 0.5752\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 5.2097 - acc: 0.7899 - val_loss: 5.7311 - val_acc: 0.5734\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 637us/step - loss: 5.0439 - acc: 0.8056 - val_loss: 5.6304 - val_acc: 0.5716\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 620us/step - loss: 4.8805 - acc: 0.8187 - val_loss: 5.5321 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 4.7559 - acc: 0.8120 - val_loss: 5.4258 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 4.5986 - acc: 0.8283 - val_loss: 5.3012 - val_acc: 0.5752\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 4.4490 - acc: 0.8462 - val_loss: 5.2004 - val_acc: 0.5788\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 589us/step - loss: 4.3005 - acc: 0.8607 - val_loss: 5.1060 - val_acc: 0.5761\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 4.1670 - acc: 0.8674 - val_loss: 5.0326 - val_acc: 0.5616\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: 4.0492 - acc: 0.8673 - val_loss: 4.8694 - val_acc: 0.5806\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: 3.9114 - acc: 0.8825 - val_loss: 4.7917 - val_acc: 0.5725\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 3.7986 - acc: 0.8875 - val_loss: 4.7507 - val_acc: 0.5688\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 579us/step - loss: 3.7011 - acc: 0.8799 - val_loss: 4.6908 - val_acc: 0.5534\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 3.5812 - acc: 0.8959 - val_loss: 4.5919 - val_acc: 0.5661\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 3.4785 - acc: 0.8973 - val_loss: 4.5024 - val_acc: 0.5707\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: 3.3582 - acc: 0.9177 - val_loss: 4.4341 - val_acc: 0.5616\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: 3.2551 - acc: 0.9217 - val_loss: 4.3534 - val_acc: 0.5716\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 3.1751 - acc: 0.9203 - val_loss: 4.3274 - val_acc: 0.5752\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 3.0875 - acc: 0.9208 - val_loss: 4.2056 - val_acc: 0.5688\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 2.9899 - acc: 0.9300 - val_loss: 4.1041 - val_acc: 0.5815\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 2.8980 - acc: 0.9325 - val_loss: 4.1081 - val_acc: 0.5815\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: 2.8114 - acc: 0.9368 - val_loss: 3.9888 - val_acc: 0.5743\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 2.7230 - acc: 0.9477 - val_loss: 3.9041 - val_acc: 0.5933\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 2.6456 - acc: 0.9488 - val_loss: 3.9146 - val_acc: 0.5607\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 5s 616us/step - loss: 2.5713 - acc: 0.9536 - val_loss: 3.7912 - val_acc: 0.5688\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 2.4895 - acc: 0.9592 - val_loss: 3.7756 - val_acc: 0.5707\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 2.4120 - acc: 0.9644 - val_loss: 3.7034 - val_acc: 0.5770\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 5s 595us/step - loss: 2.3472 - acc: 0.9619 - val_loss: 3.6579 - val_acc: 0.5688\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 5s 597us/step - loss: 2.2861 - acc: 0.9635 - val_loss: 3.6400 - val_acc: 0.5625\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 2.2140 - acc: 0.9689 - val_loss: 3.6094 - val_acc: 0.5625\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 2.1591 - acc: 0.9669 - val_loss: 3.4923 - val_acc: 0.5870\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 2.1026 - acc: 0.9666 - val_loss: 3.4272 - val_acc: 0.5861\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 2.0458 - acc: 0.9662 - val_loss: 3.4227 - val_acc: 0.5797\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 142.2059 - acc: 0.4075 - val_loss: 120.0381 - val_acc: 0.5045\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 104.4778 - acc: 0.5104 - val_loss: 87.2141 - val_acc: 0.4973\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 75.5602 - acc: 0.5363 - val_loss: 62.8805 - val_acc: 0.5100\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 54.3288 - acc: 0.5537 - val_loss: 45.2422 - val_acc: 0.5018\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 38.9815 - acc: 0.5635 - val_loss: 32.5824 - val_acc: 0.5063\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 28.0417 - acc: 0.5659 - val_loss: 23.5981 - val_acc: 0.5045\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 20.2744 - acc: 0.5776 - val_loss: 17.3375 - val_acc: 0.4937\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 14.8266 - acc: 0.5713 - val_loss: 12.8645 - val_acc: 0.5136\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 10.9839 - acc: 0.5738 - val_loss: 9.7692 - val_acc: 0.5009\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 8.2766 - acc: 0.5878 - val_loss: 7.6523 - val_acc: 0.4348\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 6.3810 - acc: 0.5903 - val_loss: 6.1116 - val_acc: 0.4837\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 5.1040 - acc: 0.5866 - val_loss: 5.0277 - val_acc: 0.4692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 4.1799 - acc: 0.5966 - val_loss: 4.2516 - val_acc: 0.4846\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 3.5215 - acc: 0.5995 - val_loss: 3.7252 - val_acc: 0.4710\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 3.0547 - acc: 0.5986 - val_loss: 3.3066 - val_acc: 0.4719\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 2.6905 - acc: 0.6122 - val_loss: 2.9916 - val_acc: 0.4900\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 2.4194 - acc: 0.6231 - val_loss: 2.7825 - val_acc: 0.5009\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 2.2931 - acc: 0.6065 - val_loss: 2.5527 - val_acc: 0.5217\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 2.1252 - acc: 0.6215 - val_loss: 2.4689 - val_acc: 0.4511\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 1.9689 - acc: 0.6309 - val_loss: 2.3225 - val_acc: 0.4928\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 783us/step - loss: 1.8729 - acc: 0.6495 - val_loss: 2.2612 - val_acc: 0.5063\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 1.8044 - acc: 0.6415 - val_loss: 2.1555 - val_acc: 0.5100\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 1.7480 - acc: 0.6434 - val_loss: 2.0855 - val_acc: 0.5226\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 1.7270 - acc: 0.6370 - val_loss: 2.0799 - val_acc: 0.4982\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 756us/step - loss: 1.6552 - acc: 0.6550 - val_loss: 1.9950 - val_acc: 0.5299\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 1.5794 - acc: 0.6701 - val_loss: 2.0769 - val_acc: 0.5082\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 1.6534 - acc: 0.6419 - val_loss: 1.9494 - val_acc: 0.5072\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 1.5677 - acc: 0.6593 - val_loss: 1.9587 - val_acc: 0.5100\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 1.5344 - acc: 0.6613 - val_loss: 1.9100 - val_acc: 0.5453\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 1.5366 - acc: 0.6541 - val_loss: 1.9699 - val_acc: 0.5109\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 775us/step - loss: 1.4841 - acc: 0.6710 - val_loss: 1.8385 - val_acc: 0.5181\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 1.4361 - acc: 0.6851 - val_loss: 1.9007 - val_acc: 0.5236\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 1.4265 - acc: 0.6850 - val_loss: 1.8433 - val_acc: 0.5317\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 1.4059 - acc: 0.6891 - val_loss: 1.8860 - val_acc: 0.5399\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 1.4153 - acc: 0.6842 - val_loss: 1.8565 - val_acc: 0.5408\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 773us/step - loss: 1.3914 - acc: 0.6907 - val_loss: 1.8490 - val_acc: 0.5254\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 1.3445 - acc: 0.7063 - val_loss: 1.8321 - val_acc: 0.5380\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 1.4271 - acc: 0.6761 - val_loss: 1.8530 - val_acc: 0.5254\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: 1.3435 - acc: 0.7062 - val_loss: 1.8522 - val_acc: 0.5480\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: 1.3400 - acc: 0.7034 - val_loss: 1.7778 - val_acc: 0.5516\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 1.3185 - acc: 0.7111 - val_loss: 1.9088 - val_acc: 0.5217\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 1.3192 - acc: 0.7113 - val_loss: 1.9493 - val_acc: 0.5109\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 1.2776 - acc: 0.7253 - val_loss: 1.9141 - val_acc: 0.5254\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 1.2838 - acc: 0.7241 - val_loss: 1.8588 - val_acc: 0.5389\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 1.2559 - acc: 0.7273 - val_loss: 2.0016 - val_acc: 0.5063\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 1.2940 - acc: 0.7230 - val_loss: 1.9791 - val_acc: 0.5154\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 1.2503 - acc: 0.7376 - val_loss: 1.8983 - val_acc: 0.5616\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 1.2659 - acc: 0.7225 - val_loss: 1.9252 - val_acc: 0.5317\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 1.2567 - acc: 0.7304 - val_loss: 2.0917 - val_acc: 0.5154\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 1.3141 - acc: 0.7131 - val_loss: 1.9067 - val_acc: 0.5362\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 1.2248 - acc: 0.7474 - val_loss: 2.1335 - val_acc: 0.4837\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 1.2469 - acc: 0.7370 - val_loss: 1.8678 - val_acc: 0.5254\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 1.1646 - acc: 0.7645 - val_loss: 2.0139 - val_acc: 0.5226\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 1.1620 - acc: 0.7607 - val_loss: 1.9583 - val_acc: 0.5281\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 1.2266 - acc: 0.7444 - val_loss: 1.8864 - val_acc: 0.5353\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 7s 762us/step - loss: 1.1776 - acc: 0.7651 - val_loss: 2.2097 - val_acc: 0.5136\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 1.1953 - acc: 0.7592 - val_loss: 1.8713 - val_acc: 0.5462\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 187.1681 - acc: 0.3620 - val_loss: 154.3548 - val_acc: 0.4846\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 132.2549 - acc: 0.4784 - val_loss: 107.9343 - val_acc: 0.4937\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 92.0296 - acc: 0.5059 - val_loss: 74.7412 - val_acc: 0.5199\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 770us/step - loss: 63.5958 - acc: 0.5152 - val_loss: 51.6770 - val_acc: 0.5063\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 43.8544 - acc: 0.5345 - val_loss: 35.7245 - val_acc: 0.4991\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: 30.2770 - acc: 0.5404 - val_loss: 24.8760 - val_acc: 0.5009\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 21.0197 - acc: 0.5519 - val_loss: 17.5835 - val_acc: 0.5027\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 14.7555 - acc: 0.5627 - val_loss: 12.6447 - val_acc: 0.4891\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 10.5680 - acc: 0.5561 - val_loss: 9.3652 - val_acc: 0.4783\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 7.7378 - acc: 0.5677 - val_loss: 7.1363 - val_acc: 0.4810\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 770us/step - loss: 5.8446 - acc: 0.5699 - val_loss: 5.6750 - val_acc: 0.4529\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 4.5584 - acc: 0.5808 - val_loss: 4.6349 - val_acc: 0.4447\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 3.7126 - acc: 0.5857 - val_loss: 3.8584 - val_acc: 0.4946\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 46s 5ms/step - loss: nan - acc: 0.0729 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 630us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 695us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 607us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 679us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 634us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 630us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 63s 7ms/step - loss: 30.9287 - acc: 0.4148 - val_loss: 22.0623 - val_acc: 0.4792\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 15.8361 - acc: 0.4884 - val_loss: 10.8071 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 7.8612 - acc: 0.5152 - val_loss: 5.7443 - val_acc: 0.4855\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 4.4223 - acc: 0.5116 - val_loss: 3.6444 - val_acc: 0.4737\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 3.0297 - acc: 0.5100 - val_loss: 2.6519 - val_acc: 0.4855\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.4405 - acc: 0.5132 - val_loss: 2.2954 - val_acc: 0.5308\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 2.1860 - acc: 0.5168 - val_loss: 2.2594 - val_acc: 0.4629\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.0536 - acc: 0.5124 - val_loss: 2.1406 - val_acc: 0.4683\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9785 - acc: 0.5115 - val_loss: 2.0337 - val_acc: 0.4701\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9185 - acc: 0.5170 - val_loss: 1.9547 - val_acc: 0.4973\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9011 - acc: 0.5186 - val_loss: 1.9719 - val_acc: 0.4783\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 1.8926 - acc: 0.5152 - val_loss: 1.8893 - val_acc: 0.5236\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.8563 - acc: 0.5314 - val_loss: 1.9008 - val_acc: 0.5217\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.8537 - acc: 0.5212 - val_loss: 1.9639 - val_acc: 0.4719\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.8501 - acc: 0.5291 - val_loss: 1.8323 - val_acc: 0.5299\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.8381 - acc: 0.5306 - val_loss: 1.9082 - val_acc: 0.4946\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 7.2914 - acc: 0.3465 - val_loss: 6.9951 - val_acc: 0.4792\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 6.7759 - acc: 0.4850 - val_loss: 6.7028 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 582us/step - loss: 6.5598 - acc: 0.5227 - val_loss: 6.5443 - val_acc: 0.5317\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 6.3900 - acc: 0.5479 - val_loss: 6.4187 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 6.2334 - acc: 0.5687 - val_loss: 6.2766 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 6.1101 - acc: 0.5768 - val_loss: 6.2241 - val_acc: 0.5426\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: 5.9826 - acc: 0.5909 - val_loss: 6.0970 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 5.8504 - acc: 0.6022 - val_loss: 5.9950 - val_acc: 0.5480\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 5.7195 - acc: 0.6146 - val_loss: 5.8728 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 5.5967 - acc: 0.6312 - val_loss: 5.7762 - val_acc: 0.5725\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 5.4776 - acc: 0.6391 - val_loss: 5.6934 - val_acc: 0.5516\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 5.3621 - acc: 0.6527 - val_loss: 5.5954 - val_acc: 0.5607\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 5.2425 - acc: 0.6637 - val_loss: 5.4947 - val_acc: 0.5779\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 5.1396 - acc: 0.6724 - val_loss: 5.4043 - val_acc: 0.5571\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 5.0262 - acc: 0.6738 - val_loss: 5.3221 - val_acc: 0.5688\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 4.9039 - acc: 0.6960 - val_loss: 5.2269 - val_acc: 0.5906\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 4.7862 - acc: 0.7039 - val_loss: 5.1518 - val_acc: 0.5643\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 4.6960 - acc: 0.7097 - val_loss: 5.0844 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 4.5819 - acc: 0.7282 - val_loss: 4.9815 - val_acc: 0.5788\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 4.4763 - acc: 0.7380 - val_loss: 4.9494 - val_acc: 0.5797\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 581us/step - loss: 4.3757 - acc: 0.7411 - val_loss: 4.8590 - val_acc: 0.5806\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 4.2758 - acc: 0.7550 - val_loss: 4.8062 - val_acc: 0.5743\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 4.1822 - acc: 0.7593 - val_loss: 4.7640 - val_acc: 0.5643\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 4.0972 - acc: 0.7643 - val_loss: 4.6815 - val_acc: 0.5788\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 3.9929 - acc: 0.7777 - val_loss: 4.5890 - val_acc: 0.5679\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 3.9063 - acc: 0.7855 - val_loss: 4.5257 - val_acc: 0.5833\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 6.2760 - acc: 0.1990 - val_loss: 4.4006 - val_acc: 0.2627\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 4.2253 - acc: 0.3120 - val_loss: 4.0713 - val_acc: 0.3841\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 642us/step - loss: 3.9297 - acc: 0.4271 - val_loss: 3.8077 - val_acc: 0.4475\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 620us/step - loss: 3.6535 - acc: 0.4670 - val_loss: 3.5278 - val_acc: 0.4638\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 3.3715 - acc: 0.4956 - val_loss: 3.2999 - val_acc: 0.4891\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 3.1153 - acc: 0.5217 - val_loss: 3.1075 - val_acc: 0.4882\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 5s 596us/step - loss: 2.9009 - acc: 0.5330 - val_loss: 3.0052 - val_acc: 0.4928\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: 2.7307 - acc: 0.5379 - val_loss: 2.7612 - val_acc: 0.5036\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 2.5714 - acc: 0.5479 - val_loss: 2.6324 - val_acc: 0.5009\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 588us/step - loss: 2.3962 - acc: 0.5678 - val_loss: 2.4848 - val_acc: 0.5208\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 2.2389 - acc: 0.5869 - val_loss: 2.3552 - val_acc: 0.5380\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 606us/step - loss: 2.1208 - acc: 0.5983 - val_loss: 2.2852 - val_acc: 0.5326\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 2.0403 - acc: 0.5953 - val_loss: 2.2098 - val_acc: 0.5326\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 1.9407 - acc: 0.6052 - val_loss: 2.2276 - val_acc: 0.5181\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 1.9074 - acc: 0.6012 - val_loss: 2.1711 - val_acc: 0.5136\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 1.8166 - acc: 0.6235 - val_loss: 2.0955 - val_acc: 0.5299\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: 1.7187 - acc: 0.6397 - val_loss: 2.0361 - val_acc: 0.5516\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 1.6518 - acc: 0.6445 - val_loss: 2.0597 - val_acc: 0.5507\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 1.6382 - acc: 0.6493 - val_loss: 2.0783 - val_acc: 0.5598\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 1.6167 - acc: 0.6484 - val_loss: 2.0372 - val_acc: 0.5353\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 1.5782 - acc: 0.6575 - val_loss: 2.0032 - val_acc: 0.5335\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 620us/step - loss: 1.5258 - acc: 0.6773 - val_loss: 2.1437 - val_acc: 0.5362\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 591us/step - loss: 1.5017 - acc: 0.6752 - val_loss: 2.0485 - val_acc: 0.5326\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 598us/step - loss: 1.4688 - acc: 0.6881 - val_loss: 2.0185 - val_acc: 0.5444\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 598us/step - loss: 1.4227 - acc: 0.7068 - val_loss: 2.0351 - val_acc: 0.5199\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 1.4149 - acc: 0.7006 - val_loss: 1.9873 - val_acc: 0.5489\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 1.3487 - acc: 0.7291 - val_loss: 1.9848 - val_acc: 0.5543\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 598us/step - loss: 1.2825 - acc: 0.7537 - val_loss: 2.0862 - val_acc: 0.5444\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 1.3071 - acc: 0.7439 - val_loss: 2.0565 - val_acc: 0.5453\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 7.6640 - acc: 0.3259 - val_loss: 7.2698 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 804us/step - loss: 7.1930 - acc: 0.4720 - val_loss: 7.1123 - val_acc: 0.4955\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 7.0413 - acc: 0.4985 - val_loss: 7.0028 - val_acc: 0.5208\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 6.9437 - acc: 0.5192 - val_loss: 6.9481 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 6.8506 - acc: 0.5353 - val_loss: 6.8965 - val_acc: 0.5263\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 719us/step - loss: 6.7581 - acc: 0.5479 - val_loss: 6.8362 - val_acc: 0.5190\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 6.6865 - acc: 0.5566 - val_loss: 6.7567 - val_acc: 0.5435\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 6.6041 - acc: 0.5779 - val_loss: 6.7017 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 6.5423 - acc: 0.5813 - val_loss: 6.6414 - val_acc: 0.5426\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 773us/step - loss: 6.4707 - acc: 0.5926 - val_loss: 6.6121 - val_acc: 0.5435\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 6.4005 - acc: 0.6011 - val_loss: 6.5623 - val_acc: 0.5408\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 6.3352 - acc: 0.6064 - val_loss: 6.5152 - val_acc: 0.5462\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: 6.2677 - acc: 0.6108 - val_loss: 6.4747 - val_acc: 0.5417\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 762us/step - loss: 6.2003 - acc: 0.6222 - val_loss: 6.4190 - val_acc: 0.5435\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 6.1410 - acc: 0.6345 - val_loss: 6.3686 - val_acc: 0.5498\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 6.0906 - acc: 0.6364 - val_loss: 6.3164 - val_acc: 0.5489\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 799us/step - loss: 6.0293 - acc: 0.6414 - val_loss: 6.2713 - val_acc: 0.5598\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 799us/step - loss: 5.9697 - acc: 0.6490 - val_loss: 6.2184 - val_acc: 0.5616\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: 5.9067 - acc: 0.6511 - val_loss: 6.1875 - val_acc: 0.5580\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 796us/step - loss: 5.8491 - acc: 0.6609 - val_loss: 6.1424 - val_acc: 0.5553\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 783us/step - loss: 5.7835 - acc: 0.6731 - val_loss: 6.1103 - val_acc: 0.5670\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 5.7303 - acc: 0.6767 - val_loss: 6.0655 - val_acc: 0.5661\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 5.6789 - acc: 0.6745 - val_loss: 6.0369 - val_acc: 0.5580\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 5.6159 - acc: 0.6926 - val_loss: 5.9941 - val_acc: 0.5697\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 5.5625 - acc: 0.6893 - val_loss: 5.9318 - val_acc: 0.5661\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 5.5053 - acc: 0.7031 - val_loss: 5.9037 - val_acc: 0.5688\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 5.4455 - acc: 0.7079 - val_loss: 5.8649 - val_acc: 0.5634\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 5.3935 - acc: 0.7181 - val_loss: 5.8283 - val_acc: 0.5652\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: 5.3362 - acc: 0.7184 - val_loss: 5.7827 - val_acc: 0.5734\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 754us/step - loss: 5.2909 - acc: 0.7234 - val_loss: 5.7530 - val_acc: 0.5625\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 5.2377 - acc: 0.7248 - val_loss: 5.6935 - val_acc: 0.5851\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 5.1909 - acc: 0.7277 - val_loss: 5.6612 - val_acc: 0.5688\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 5.1325 - acc: 0.7305 - val_loss: 5.6308 - val_acc: 0.5688\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 5.0765 - acc: 0.7441 - val_loss: 5.6174 - val_acc: 0.5670\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 5.0348 - acc: 0.7482 - val_loss: 5.5773 - val_acc: 0.5752\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 4.9696 - acc: 0.7563 - val_loss: 5.5193 - val_acc: 0.5734\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 4.9246 - acc: 0.7583 - val_loss: 5.5102 - val_acc: 0.5770\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 7s 791us/step - loss: 4.8754 - acc: 0.7644 - val_loss: 5.4437 - val_acc: 0.5697\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 814us/step - loss: 4.8367 - acc: 0.7649 - val_loss: 5.4409 - val_acc: 0.5743\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 4.7913 - acc: 0.7710 - val_loss: 5.3963 - val_acc: 0.5716\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 4.7343 - acc: 0.7736 - val_loss: 5.3640 - val_acc: 0.5725\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 68s 8ms/step - loss: 45.2466 - acc: 0.4076 - val_loss: 22.2290 - val_acc: 0.4674\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 12.5366 - acc: 0.4749 - val_loss: 6.5783 - val_acc: 0.4620\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 4.4558 - acc: 0.4774 - val_loss: 3.2393 - val_acc: 0.4719\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 2.7453 - acc: 0.4723 - val_loss: 2.4003 - val_acc: 0.4638\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 2.3059 - acc: 0.4726 - val_loss: 2.1901 - val_acc: 0.4529\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 2.1405 - acc: 0.4748 - val_loss: 2.1245 - val_acc: 0.4638\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 25s 3ms/step - loss: 2.0202 - acc: 0.4916 - val_loss: 1.9703 - val_acc: 0.4810\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 24s 3ms/step - loss: 2.0431 - acc: 0.4784 - val_loss: 1.9909 - val_acc: 0.4719\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 2.0189 - acc: 0.4815 - val_loss: 1.9902 - val_acc: 0.4810\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9847 - acc: 0.4890 - val_loss: 2.0063 - val_acc: 0.4511\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9719 - acc: 0.4931 - val_loss: 2.0005 - val_acc: 0.4946\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9662 - acc: 0.4884 - val_loss: 1.9977 - val_acc: 0.4828\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.9848 - acc: 0.4877 - val_loss: 1.9701 - val_acc: 0.4701\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9594 - acc: 0.4971 - val_loss: 1.9863 - val_acc: 0.4647\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9545 - acc: 0.4922 - val_loss: 1.9729 - val_acc: 0.4665\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 1.9858 - acc: 0.4975 - val_loss: 2.0400 - val_acc: 0.4701\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 23s 3ms/step - loss: 1.9695 - acc: 0.4980 - val_loss: 2.0469 - val_acc: 0.4629\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 1.9853 - acc: 0.4856 - val_loss: 2.0294 - val_acc: 0.4783\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9881 - acc: 0.4930 - val_loss: 2.0351 - val_acc: 0.4647\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9685 - acc: 0.4985 - val_loss: 1.9305 - val_acc: 0.4864\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9687 - acc: 0.5011 - val_loss: 1.8857 - val_acc: 0.5036\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9340 - acc: 0.5042 - val_loss: 2.0010 - val_acc: 0.4692\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9533 - acc: 0.4995 - val_loss: 1.9259 - val_acc: 0.4991\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9281 - acc: 0.5037 - val_loss: 1.9181 - val_acc: 0.5018\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9211 - acc: 0.5052 - val_loss: 1.9548 - val_acc: 0.5045\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9289 - acc: 0.5008 - val_loss: 2.0970 - val_acc: 0.4502\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9396 - acc: 0.5092 - val_loss: 1.9706 - val_acc: 0.4728\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9103 - acc: 0.5086 - val_loss: 1.9655 - val_acc: 0.5018\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9289 - acc: 0.5092 - val_loss: 2.0193 - val_acc: 0.4547\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9456 - acc: 0.5031 - val_loss: 2.0519 - val_acc: 0.4683\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9664 - acc: 0.4969 - val_loss: 1.9650 - val_acc: 0.4837\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9051 - acc: 0.5176 - val_loss: 2.0257 - val_acc: 0.4764\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9270 - acc: 0.5109 - val_loss: 2.0567 - val_acc: 0.4746\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9382 - acc: 0.5042 - val_loss: 2.0980 - val_acc: 0.4520\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 21s 2ms/step - loss: 1.9070 - acc: 0.5204 - val_loss: 1.9620 - val_acc: 0.4819\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 114s 13ms/step - loss: 1414.3467 - acc: 0.3527 - val_loss: 86.9130 - val_acc: 0.3668\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 21.3683 - acc: 0.2898 - val_loss: 3.5088 - val_acc: 0.2817\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.7238 - acc: 0.2783 - val_loss: 2.4807 - val_acc: 0.3116\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4909 - acc: 0.2807 - val_loss: 2.4212 - val_acc: 0.2871\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4680 - acc: 0.2704 - val_loss: 2.4163 - val_acc: 0.2799\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 71s 8ms/step - loss: 2.4597 - acc: 0.2673 - val_loss: 2.4541 - val_acc: 0.1839\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 71s 8ms/step - loss: 2.4477 - acc: 0.2574 - val_loss: 2.4150 - val_acc: 0.2862\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4381 - acc: 0.2553 - val_loss: 2.3500 - val_acc: 0.3034\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 73s 8ms/step - loss: 2.4043 - acc: 0.2108 - val_loss: 2.3825 - val_acc: 0.1504\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 75s 8ms/step - loss: 2.3933 - acc: 0.1565 - val_loss: 2.3841 - val_acc: 0.1549\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 77s 9ms/step - loss: 2.3860 - acc: 0.1565 - val_loss: 2.3066 - val_acc: 0.1576\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 52s 6ms/step - loss: 146.3650 - acc: 0.4183 - val_loss: 113.4983 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 92.2285 - acc: 0.5118 - val_loss: 69.9755 - val_acc: 0.5063\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 56.5161 - acc: 0.5369 - val_loss: 42.8447 - val_acc: 0.4837\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 738us/step - loss: 34.4886 - acc: 0.5375 - val_loss: 26.3324 - val_acc: 0.4728\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 21.2072 - acc: 0.5409 - val_loss: 16.5362 - val_acc: 0.4737\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 13.2851 - acc: 0.5584 - val_loss: 10.8140 - val_acc: 0.4384\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 8.6632 - acc: 0.5550 - val_loss: 7.4330 - val_acc: 0.4194\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 5.9814 - acc: 0.5552 - val_loss: 5.4446 - val_acc: 0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 4.3845 - acc: 0.5573 - val_loss: 4.4975 - val_acc: 0.3668\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.5137 - acc: 0.5413 - val_loss: 3.5002 - val_acc: 0.4511\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 779us/step - loss: 2.8293 - acc: 0.5744 - val_loss: 3.0881 - val_acc: 0.4511\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 792us/step - loss: 2.4391 - acc: 0.5705 - val_loss: 2.7958 - val_acc: 0.4203\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 48s 5ms/step - loss: 8.0807 - acc: 0.3622 - val_loss: 7.7076 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 7.5567 - acc: 0.5020 - val_loss: 7.5039 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 7.3489 - acc: 0.5351 - val_loss: 7.3330 - val_acc: 0.5399\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 7.1907 - acc: 0.5616 - val_loss: 7.2366 - val_acc: 0.5245\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 7.0369 - acc: 0.5793 - val_loss: 7.1087 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 6.8908 - acc: 0.5990 - val_loss: 6.9964 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 6.7584 - acc: 0.6094 - val_loss: 6.9107 - val_acc: 0.5380\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 6.6327 - acc: 0.6182 - val_loss: 6.7848 - val_acc: 0.5408\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 6.4897 - acc: 0.6472 - val_loss: 6.6921 - val_acc: 0.5489\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 6.3725 - acc: 0.6517 - val_loss: 6.5989 - val_acc: 0.5534\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 6.2410 - acc: 0.6660 - val_loss: 6.5149 - val_acc: 0.5489\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 6.1169 - acc: 0.6847 - val_loss: 6.4148 - val_acc: 0.5580\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 6.0017 - acc: 0.6907 - val_loss: 6.3259 - val_acc: 0.5471\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 5.8961 - acc: 0.6957 - val_loss: 6.2240 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 5.7721 - acc: 0.7048 - val_loss: 6.1664 - val_acc: 0.5634\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 5.6513 - acc: 0.7291 - val_loss: 6.0901 - val_acc: 0.5607\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 5.5533 - acc: 0.7259 - val_loss: 6.0076 - val_acc: 0.5652\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 5.4540 - acc: 0.7328 - val_loss: 5.9212 - val_acc: 0.5707\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 5.3409 - acc: 0.7458 - val_loss: 5.8276 - val_acc: 0.5770\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 5.2165 - acc: 0.7711 - val_loss: 5.7420 - val_acc: 0.5915\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 5.1208 - acc: 0.7717 - val_loss: 5.6873 - val_acc: 0.5616\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 5.0195 - acc: 0.7808 - val_loss: 5.6199 - val_acc: 0.5697\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 4.9179 - acc: 0.7907 - val_loss: 5.5629 - val_acc: 0.5697\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 4.8303 - acc: 0.7935 - val_loss: 5.4603 - val_acc: 0.5752\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 4.7244 - acc: 0.8106 - val_loss: 5.4091 - val_acc: 0.5788\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 4.6389 - acc: 0.8098 - val_loss: 5.3375 - val_acc: 0.5725\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 4.5375 - acc: 0.8268 - val_loss: 5.2999 - val_acc: 0.5725\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 4.4520 - acc: 0.8285 - val_loss: 5.2052 - val_acc: 0.5842\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 4.3635 - acc: 0.8388 - val_loss: 5.1485 - val_acc: 0.5779\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 4.2785 - acc: 0.8396 - val_loss: 5.0753 - val_acc: 0.5933\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 589us/step - loss: 4.1967 - acc: 0.8505 - val_loss: 5.0546 - val_acc: 0.5661\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 4.1165 - acc: 0.8539 - val_loss: 5.0096 - val_acc: 0.5616\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 540us/step - loss: 4.0357 - acc: 0.8609 - val_loss: 4.9115 - val_acc: 0.5661\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 3.9520 - acc: 0.8632 - val_loss: 4.8550 - val_acc: 0.5779\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 3.8934 - acc: 0.8649 - val_loss: 4.8320 - val_acc: 0.5815\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 3.7879 - acc: 0.8884 - val_loss: 4.7317 - val_acc: 0.5833\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 3.7156 - acc: 0.8890 - val_loss: 4.7447 - val_acc: 0.5716\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 5s 543us/step - loss: 3.6428 - acc: 0.8948 - val_loss: 4.6482 - val_acc: 0.5842\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 3.5692 - acc: 0.8996 - val_loss: 4.5975 - val_acc: 0.5788\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 3.5047 - acc: 0.9013 - val_loss: 4.5820 - val_acc: 0.5734\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: 6.3886 - acc: 0.3831 - val_loss: 6.0774 - val_acc: 0.4909\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 5.8825 - acc: 0.5169 - val_loss: 5.9020 - val_acc: 0.5027\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 5.6942 - acc: 0.5551 - val_loss: 5.8031 - val_acc: 0.5118\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: 5.5356 - acc: 0.5930 - val_loss: 5.6897 - val_acc: 0.5299\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 5.3989 - acc: 0.6140 - val_loss: 5.5795 - val_acc: 0.5408\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 559us/step - loss: 5.2721 - acc: 0.6408 - val_loss: 5.4993 - val_acc: 0.5408\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 5.1518 - acc: 0.6604 - val_loss: 5.4238 - val_acc: 0.5516\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 5.0400 - acc: 0.6773 - val_loss: 5.3731 - val_acc: 0.5471\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: 4.9441 - acc: 0.6957 - val_loss: 5.2919 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 4.8510 - acc: 0.7094 - val_loss: 5.2452 - val_acc: 0.5616\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 623us/step - loss: 4.7356 - acc: 0.7326 - val_loss: 5.1929 - val_acc: 0.5589\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: 4.6393 - acc: 0.7410 - val_loss: 5.1407 - val_acc: 0.5652\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 4.5394 - acc: 0.7608 - val_loss: 5.0805 - val_acc: 0.5652\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 4.4585 - acc: 0.7645 - val_loss: 5.0100 - val_acc: 0.5707\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 4.3549 - acc: 0.7839 - val_loss: 4.9476 - val_acc: 0.5716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 4.2646 - acc: 0.8008 - val_loss: 4.9362 - val_acc: 0.5734\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 4.1784 - acc: 0.8116 - val_loss: 4.8511 - val_acc: 0.5734\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 557us/step - loss: 4.0843 - acc: 0.8250 - val_loss: 4.8026 - val_acc: 0.5888\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 4.0073 - acc: 0.8306 - val_loss: 4.7640 - val_acc: 0.5761\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 3.9343 - acc: 0.8376 - val_loss: 4.6948 - val_acc: 0.5752\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 3.8498 - acc: 0.8479 - val_loss: 4.6706 - val_acc: 0.5725\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 3.7726 - acc: 0.8639 - val_loss: 4.6170 - val_acc: 0.5824\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 3.6892 - acc: 0.8755 - val_loss: 4.6264 - val_acc: 0.5661\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 547us/step - loss: 3.6158 - acc: 0.8848 - val_loss: 4.6059 - val_acc: 0.5779\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 3.5411 - acc: 0.8940 - val_loss: 4.5516 - val_acc: 0.5661\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 3.4737 - acc: 0.8959 - val_loss: 4.4387 - val_acc: 0.5933\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 3.3972 - acc: 0.9094 - val_loss: 4.4283 - val_acc: 0.5697\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 3.3350 - acc: 0.9137 - val_loss: 4.3994 - val_acc: 0.5861\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 3.2673 - acc: 0.9209 - val_loss: 4.3805 - val_acc: 0.5734\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 3.2081 - acc: 0.9199 - val_loss: 4.3361 - val_acc: 0.5833\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 3.1455 - acc: 0.9309 - val_loss: 4.3146 - val_acc: 0.5734\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 3.0908 - acc: 0.9311 - val_loss: 4.2817 - val_acc: 0.5625\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 3.0225 - acc: 0.9386 - val_loss: 4.2272 - val_acc: 0.5707\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 2.9738 - acc: 0.9382 - val_loss: 4.2009 - val_acc: 0.5688\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 2.9156 - acc: 0.9461 - val_loss: 4.1404 - val_acc: 0.5697\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 2.8573 - acc: 0.9477 - val_loss: 4.0986 - val_acc: 0.5743\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 47s 5ms/step - loss: nan - acc: 0.0677 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 4s 457us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 468us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 484us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 487us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 488us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 513us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 505us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 501us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 476us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 5ms/step - loss: 5.8687 - acc: 0.3739 - val_loss: 5.5309 - val_acc: 0.4955\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 725us/step - loss: 5.4214 - acc: 0.5075 - val_loss: 5.4080 - val_acc: 0.5045\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 736us/step - loss: 5.2856 - acc: 0.5365 - val_loss: 5.3396 - val_acc: 0.5181\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 5.1870 - acc: 0.5633 - val_loss: 5.2954 - val_acc: 0.5263\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 716us/step - loss: 5.1135 - acc: 0.5793 - val_loss: 5.2254 - val_acc: 0.5353\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 5.0373 - acc: 0.5959 - val_loss: 5.1597 - val_acc: 0.5444\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 4.9730 - acc: 0.6129 - val_loss: 5.1509 - val_acc: 0.5462\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 4.9018 - acc: 0.6294 - val_loss: 5.1257 - val_acc: 0.5380\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 4.8433 - acc: 0.6448 - val_loss: 5.0752 - val_acc: 0.5471\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 4.7800 - acc: 0.6526 - val_loss: 5.0487 - val_acc: 0.5580\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 4.7170 - acc: 0.6707 - val_loss: 5.0209 - val_acc: 0.5553\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 811us/step - loss: 4.6831 - acc: 0.6720 - val_loss: 5.0114 - val_acc: 0.5607\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 4.6216 - acc: 0.6920 - val_loss: 4.9624 - val_acc: 0.5580\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 4.5714 - acc: 0.7014 - val_loss: 4.9327 - val_acc: 0.5716\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 4.5216 - acc: 0.7063 - val_loss: 4.9015 - val_acc: 0.5697\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 4.4789 - acc: 0.7202 - val_loss: 4.8669 - val_acc: 0.5779\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 4.4258 - acc: 0.7320 - val_loss: 4.8739 - val_acc: 0.5670\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 4.3841 - acc: 0.7382 - val_loss: 4.8410 - val_acc: 0.5607\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 4.3377 - acc: 0.7399 - val_loss: 4.8382 - val_acc: 0.5752\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 4.2910 - acc: 0.7567 - val_loss: 4.8197 - val_acc: 0.5598\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: 4.2498 - acc: 0.7606 - val_loss: 4.7636 - val_acc: 0.5743\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 4.2046 - acc: 0.7693 - val_loss: 4.7501 - val_acc: 0.5707\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 4.1523 - acc: 0.7860 - val_loss: 4.7816 - val_acc: 0.5743\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 4.1209 - acc: 0.7914 - val_loss: 4.7257 - val_acc: 0.5743\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 754us/step - loss: 4.0764 - acc: 0.7973 - val_loss: 4.7050 - val_acc: 0.5833\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 803us/step - loss: 4.0375 - acc: 0.8077 - val_loss: 4.6967 - val_acc: 0.5806\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 796us/step - loss: 3.9886 - acc: 0.8155 - val_loss: 4.6452 - val_acc: 0.5797\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 775us/step - loss: 3.9476 - acc: 0.8231 - val_loss: 4.6509 - val_acc: 0.5879\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 3.9035 - acc: 0.8333 - val_loss: 4.6488 - val_acc: 0.5752\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 798us/step - loss: 3.8681 - acc: 0.8316 - val_loss: 4.6024 - val_acc: 0.5797\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 799us/step - loss: 3.8189 - acc: 0.8475 - val_loss: 4.6038 - val_acc: 0.5824\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 3.7842 - acc: 0.8496 - val_loss: 4.5843 - val_acc: 0.5806\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 775us/step - loss: 3.7541 - acc: 0.8507 - val_loss: 4.5636 - val_acc: 0.5870\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 3.7107 - acc: 0.8684 - val_loss: 4.5414 - val_acc: 0.5888\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 3.6791 - acc: 0.8601 - val_loss: 4.5202 - val_acc: 0.5933\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 775us/step - loss: 3.6398 - acc: 0.8742 - val_loss: 4.5309 - val_acc: 0.5788\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: 3.6041 - acc: 0.8785 - val_loss: 4.4879 - val_acc: 0.5797\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 3.5615 - acc: 0.8907 - val_loss: 4.4723 - val_acc: 0.5842\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 3.5288 - acc: 0.8895 - val_loss: 4.5066 - val_acc: 0.5752\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 3.4958 - acc: 0.8964 - val_loss: 4.4637 - val_acc: 0.5924\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: 3.4700 - acc: 0.8964 - val_loss: 4.4388 - val_acc: 0.5851\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 7s 760us/step - loss: 3.4258 - acc: 0.9071 - val_loss: 4.4002 - val_acc: 0.5942\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 7s 757us/step - loss: 3.3898 - acc: 0.9155 - val_loss: 4.4078 - val_acc: 0.5797\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 3.3618 - acc: 0.9153 - val_loss: 4.4102 - val_acc: 0.5879\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 3.3314 - acc: 0.9177 - val_loss: 4.3928 - val_acc: 0.5752\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 3.2984 - acc: 0.9216 - val_loss: 4.3680 - val_acc: 0.5906\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 3.2721 - acc: 0.9264 - val_loss: 4.3734 - val_acc: 0.5833\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 7s 770us/step - loss: 3.2423 - acc: 0.9277 - val_loss: 4.3238 - val_acc: 0.5743\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 3.2105 - acc: 0.9311 - val_loss: 4.3721 - val_acc: 0.5761\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 7s 773us/step - loss: 3.1832 - acc: 0.9322 - val_loss: 4.3380 - val_acc: 0.5842\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 3.1473 - acc: 0.9394 - val_loss: 4.3355 - val_acc: 0.5824\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 3.1230 - acc: 0.9403 - val_loss: 4.3352 - val_acc: 0.5770\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 6ms/step - loss: 7.6500 - acc: 0.3761 - val_loss: 7.2596 - val_acc: 0.4864\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 7.0595 - acc: 0.5300 - val_loss: 7.0187 - val_acc: 0.5226\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 578us/step - loss: 6.8312 - acc: 0.5661 - val_loss: 6.8756 - val_acc: 0.5299\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 6.6480 - acc: 0.6056 - val_loss: 6.7586 - val_acc: 0.5344\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 6.4688 - acc: 0.6290 - val_loss: 6.6432 - val_acc: 0.5534\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 6.3126 - acc: 0.6533 - val_loss: 6.5462 - val_acc: 0.5417\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 6.1574 - acc: 0.6792 - val_loss: 6.4102 - val_acc: 0.5625\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 6.0068 - acc: 0.6986 - val_loss: 6.3114 - val_acc: 0.5498\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 5.8664 - acc: 0.7131 - val_loss: 6.2306 - val_acc: 0.5679\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 5.7303 - acc: 0.7275 - val_loss: 6.1189 - val_acc: 0.5634\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 5.5929 - acc: 0.7453 - val_loss: 6.0371 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 579us/step - loss: 5.4793 - acc: 0.7575 - val_loss: 5.9983 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 5.3305 - acc: 0.7798 - val_loss: 5.8719 - val_acc: 0.5688\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 5.2001 - acc: 0.7961 - val_loss: 5.7632 - val_acc: 0.5707\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 5.0718 - acc: 0.8047 - val_loss: 5.6608 - val_acc: 0.5716\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 4.9524 - acc: 0.8257 - val_loss: 5.6134 - val_acc: 0.5761\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 4.8323 - acc: 0.8318 - val_loss: 5.5050 - val_acc: 0.5652\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 582us/step - loss: 4.7183 - acc: 0.8462 - val_loss: 5.4155 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 579us/step - loss: 4.5999 - acc: 0.8631 - val_loss: 5.3511 - val_acc: 0.5888\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 4.4876 - acc: 0.8702 - val_loss: 5.3036 - val_acc: 0.5716\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 4.3802 - acc: 0.8825 - val_loss: 5.2003 - val_acc: 0.5806\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 582us/step - loss: 4.2725 - acc: 0.8957 - val_loss: 5.1607 - val_acc: 0.5734\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 4.1885 - acc: 0.8936 - val_loss: 5.0997 - val_acc: 0.5761\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 4.0846 - acc: 0.9078 - val_loss: 5.0461 - val_acc: 0.5851\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 3.9843 - acc: 0.9121 - val_loss: 4.9499 - val_acc: 0.5734\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 3.8860 - acc: 0.9255 - val_loss: 4.9646 - val_acc: 0.5752\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 584us/step - loss: 3.7970 - acc: 0.9285 - val_loss: 4.8735 - val_acc: 0.5725\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 3.7051 - acc: 0.9361 - val_loss: 4.7552 - val_acc: 0.5779\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 586us/step - loss: 3.6226 - acc: 0.9392 - val_loss: 4.7517 - val_acc: 0.5679\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 5.4080 - acc: 0.3231 - val_loss: 5.0440 - val_acc: 0.4710\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 4.9572 - acc: 0.4617 - val_loss: 4.8947 - val_acc: 0.5009\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 703us/step - loss: 4.8340 - acc: 0.4975 - val_loss: 4.8326 - val_acc: 0.4991\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 4.7501 - acc: 0.5116 - val_loss: 4.7983 - val_acc: 0.5136\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 736us/step - loss: 4.6818 - acc: 0.5276 - val_loss: 4.7759 - val_acc: 0.5163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 4.6246 - acc: 0.5458 - val_loss: 4.7222 - val_acc: 0.5263\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 815us/step - loss: 4.5632 - acc: 0.5544 - val_loss: 4.6795 - val_acc: 0.5344\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 816us/step - loss: 4.5252 - acc: 0.5621 - val_loss: 4.6505 - val_acc: 0.5471\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 4.4811 - acc: 0.5747 - val_loss: 4.6403 - val_acc: 0.5389\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 777us/step - loss: 4.4353 - acc: 0.5806 - val_loss: 4.5895 - val_acc: 0.5453\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 4.3962 - acc: 0.5984 - val_loss: 4.5587 - val_acc: 0.5389\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 4.3551 - acc: 0.5966 - val_loss: 4.5322 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: 4.3140 - acc: 0.6091 - val_loss: 4.5183 - val_acc: 0.5525\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 4.2785 - acc: 0.6202 - val_loss: 4.5053 - val_acc: 0.5580\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 810us/step - loss: 4.2417 - acc: 0.6194 - val_loss: 4.4939 - val_acc: 0.5607\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 4.2173 - acc: 0.6193 - val_loss: 4.4523 - val_acc: 0.5580\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 4.1735 - acc: 0.6394 - val_loss: 4.4247 - val_acc: 0.5634\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 4.1415 - acc: 0.6380 - val_loss: 4.4033 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 784us/step - loss: 4.1090 - acc: 0.6496 - val_loss: 4.3932 - val_acc: 0.5707\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 773us/step - loss: 4.0832 - acc: 0.6502 - val_loss: 4.3729 - val_acc: 0.5734\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 4.0400 - acc: 0.6629 - val_loss: 4.3358 - val_acc: 0.5697\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 776us/step - loss: 4.0111 - acc: 0.6633 - val_loss: 4.3380 - val_acc: 0.5770\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 747us/step - loss: 3.9891 - acc: 0.6685 - val_loss: 4.3117 - val_acc: 0.5679\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 3.9546 - acc: 0.6792 - val_loss: 4.3016 - val_acc: 0.5679\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 3.9197 - acc: 0.6824 - val_loss: 4.2850 - val_acc: 0.5770\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 3.8858 - acc: 0.6875 - val_loss: 4.2682 - val_acc: 0.5761\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 3.8586 - acc: 0.6928 - val_loss: 4.2450 - val_acc: 0.5770\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 3.8329 - acc: 0.7013 - val_loss: 4.2479 - val_acc: 0.5788\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 3.8090 - acc: 0.7040 - val_loss: 4.2096 - val_acc: 0.5815\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 754us/step - loss: 3.7787 - acc: 0.7088 - val_loss: 4.2051 - val_acc: 0.5842\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 757us/step - loss: 3.7416 - acc: 0.7136 - val_loss: 4.2100 - val_acc: 0.5861\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 3.7259 - acc: 0.7177 - val_loss: 4.1679 - val_acc: 0.5897\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 3.6898 - acc: 0.7238 - val_loss: 4.1742 - val_acc: 0.5833\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 3.6752 - acc: 0.7233 - val_loss: 4.1502 - val_acc: 0.5888\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 3.6298 - acc: 0.7356 - val_loss: 4.1433 - val_acc: 0.5851\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 3.6043 - acc: 0.7456 - val_loss: 4.1200 - val_acc: 0.5879\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 3.5721 - acc: 0.7466 - val_loss: 4.1147 - val_acc: 0.5906\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 7s 769us/step - loss: 3.5449 - acc: 0.7524 - val_loss: 4.1040 - val_acc: 0.5770\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 7s 770us/step - loss: 3.5107 - acc: 0.7592 - val_loss: 4.0873 - val_acc: 0.5906\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 7s 784us/step - loss: 3.4883 - acc: 0.7608 - val_loss: 4.0838 - val_acc: 0.5833\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 3.4707 - acc: 0.7608 - val_loss: 4.0431 - val_acc: 0.5915\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 7s 760us/step - loss: 3.4380 - acc: 0.7702 - val_loss: 4.0650 - val_acc: 0.5906\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 3.4135 - acc: 0.7727 - val_loss: 4.0185 - val_acc: 0.5906\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 7s 779us/step - loss: 3.3829 - acc: 0.7787 - val_loss: 3.9950 - val_acc: 0.5906\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 7s 777us/step - loss: 3.3568 - acc: 0.7846 - val_loss: 4.0113 - val_acc: 0.6005\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 3.3394 - acc: 0.7857 - val_loss: 4.0009 - val_acc: 0.5933\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 3.3090 - acc: 0.7920 - val_loss: 4.0115 - val_acc: 0.5906\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 7s 804us/step - loss: 3.2914 - acc: 0.7927 - val_loss: 4.0089 - val_acc: 0.5978\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 3.2619 - acc: 0.7970 - val_loss: 3.9723 - val_acc: 0.6014\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 7s 765us/step - loss: 3.2400 - acc: 0.8005 - val_loss: 3.9672 - val_acc: 0.5924\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 3.2014 - acc: 0.8103 - val_loss: 3.9297 - val_acc: 0.5951\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 3.1830 - acc: 0.8154 - val_loss: 3.9610 - val_acc: 0.5897\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.1581 - acc: 0.8159 - val_loss: 3.9342 - val_acc: 0.6069\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 3.1323 - acc: 0.8176 - val_loss: 3.9213 - val_acc: 0.5996\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 7s 767us/step - loss: 3.1064 - acc: 0.8285 - val_loss: 3.9189 - val_acc: 0.5897\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 3.0940 - acc: 0.8240 - val_loss: 3.8965 - val_acc: 0.5942\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 7s 783us/step - loss: 3.0584 - acc: 0.8275 - val_loss: 3.8891 - val_acc: 0.6024\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 3.0323 - acc: 0.8400 - val_loss: 3.8660 - val_acc: 0.5924\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 7s 779us/step - loss: 3.0087 - acc: 0.8401 - val_loss: 3.8713 - val_acc: 0.5960\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 2.9896 - acc: 0.8412 - val_loss: 3.8485 - val_acc: 0.5933\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 7s 757us/step - loss: 2.9544 - acc: 0.8481 - val_loss: 3.8585 - val_acc: 0.5870\n",
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 2.9443 - acc: 0.8506 - val_loss: 3.8574 - val_acc: 0.5870\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 2.9115 - acc: 0.8637 - val_loss: 3.8097 - val_acc: 0.6033\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 115s 13ms/step - loss: 1415.9407 - acc: 0.3546 - val_loss: 87.3331 - val_acc: 0.3587\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 71s 8ms/step - loss: 21.4734 - acc: 0.2982 - val_loss: 3.5347 - val_acc: 0.3016\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.7254 - acc: 0.2783 - val_loss: 2.4686 - val_acc: 0.2908\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 71s 8ms/step - loss: 2.4925 - acc: 0.2760 - val_loss: 2.4376 - val_acc: 0.2871\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4659 - acc: 0.2773 - val_loss: 2.4098 - val_acc: 0.2808\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4495 - acc: 0.2714 - val_loss: 2.4217 - val_acc: 0.2717\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4459 - acc: 0.2539 - val_loss: 2.4766 - val_acc: 0.1612\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4104 - acc: 0.1485 - val_loss: 2.4326 - val_acc: 0.1585\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.4018 - acc: 0.1485 - val_loss: 2.3404 - val_acc: 0.1585\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.3867 - acc: 0.1605 - val_loss: 2.3146 - val_acc: 0.1694\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 72s 8ms/step - loss: 2.3961 - acc: 0.1536 - val_loss: 2.4178 - val_acc: 0.1558\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 6ms/step - loss: 8.0185 - acc: 0.1626 - val_loss: 7.0927 - val_acc: 0.2219\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 551us/step - loss: 7.1288 - acc: 0.2516 - val_loss: 6.9555 - val_acc: 0.2763\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 6.5381 - acc: 0.3230 - val_loss: 6.0106 - val_acc: 0.3062\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 5.4518 - acc: 0.3825 - val_loss: 4.8834 - val_acc: 0.3904\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 555us/step - loss: 4.4586 - acc: 0.4202 - val_loss: 4.0256 - val_acc: 0.4203\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 3.7014 - acc: 0.4432 - val_loss: 3.4849 - val_acc: 0.4221\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 3.2425 - acc: 0.4492 - val_loss: 3.1965 - val_acc: 0.3995\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 556us/step - loss: 3.0364 - acc: 0.4295 - val_loss: 2.9345 - val_acc: 0.4230\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 2.7599 - acc: 0.4659 - val_loss: 2.6963 - val_acc: 0.4565\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 2.5497 - acc: 0.4881 - val_loss: 2.6503 - val_acc: 0.4375\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 2.4797 - acc: 0.4654 - val_loss: 2.5441 - val_acc: 0.4447\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 566us/step - loss: 2.3946 - acc: 0.4842 - val_loss: 2.3898 - val_acc: 0.4764\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 2.2618 - acc: 0.5083 - val_loss: 2.3361 - val_acc: 0.4710\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: 2.2100 - acc: 0.5039 - val_loss: 2.3501 - val_acc: 0.4601\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 2.1622 - acc: 0.5161 - val_loss: 2.1992 - val_acc: 0.4882\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 2.1215 - acc: 0.5301 - val_loss: 2.1989 - val_acc: 0.4891\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 2.0924 - acc: 0.5303 - val_loss: 2.2421 - val_acc: 0.4701\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 2.1141 - acc: 0.5178 - val_loss: 2.3657 - val_acc: 0.4420\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 2.1665 - acc: 0.5129 - val_loss: 2.2697 - val_acc: 0.4656\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 2.1460 - acc: 0.5268 - val_loss: 2.2706 - val_acc: 0.4937\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 2.0888 - acc: 0.5422 - val_loss: 2.1855 - val_acc: 0.5109\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 2.0146 - acc: 0.5483 - val_loss: 2.1924 - val_acc: 0.4819\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 2.0818 - acc: 0.5191 - val_loss: 2.3244 - val_acc: 0.4366\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 2.0976 - acc: 0.5382 - val_loss: 2.1876 - val_acc: 0.5009\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 2.0851 - acc: 0.5314 - val_loss: 2.2498 - val_acc: 0.5082\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 2.0169 - acc: 0.5527 - val_loss: 2.2134 - val_acc: 0.4701\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 580us/step - loss: 1.9898 - acc: 0.5467 - val_loss: 2.4637 - val_acc: 0.4611\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 2.1013 - acc: 0.5270 - val_loss: 2.2430 - val_acc: 0.4937\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 581us/step - loss: 2.0994 - acc: 0.5660 - val_loss: 2.2779 - val_acc: 0.5154\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 593us/step - loss: 2.0586 - acc: 0.5644 - val_loss: 2.6264 - val_acc: 0.4312\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 2.2224 - acc: 0.5119 - val_loss: 2.2928 - val_acc: 0.4746\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 2.0941 - acc: 0.5568 - val_loss: 2.1821 - val_acc: 0.5127\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 2.0482 - acc: 0.5594 - val_loss: 2.2948 - val_acc: 0.4855\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 583us/step - loss: 2.0362 - acc: 0.5618 - val_loss: 2.2091 - val_acc: 0.4964\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 575us/step - loss: 1.9773 - acc: 0.5703 - val_loss: 2.2730 - val_acc: 0.5154\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 2.0428 - acc: 0.5437 - val_loss: 2.2312 - val_acc: 0.4764\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 2.0528 - acc: 0.5624 - val_loss: 2.1595 - val_acc: 0.5199\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 5s 570us/step - loss: 2.0499 - acc: 0.5573 - val_loss: 2.3759 - val_acc: 0.4656\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 5s 563us/step - loss: 2.1002 - acc: 0.5542 - val_loss: 2.2887 - val_acc: 0.5136\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 2.0902 - acc: 0.5534 - val_loss: 2.2027 - val_acc: 0.5100\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 5s 568us/step - loss: 1.9950 - acc: 0.5693 - val_loss: 2.2618 - val_acc: 0.5082\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 5s 569us/step - loss: 1.9638 - acc: 0.5697 - val_loss: 2.2183 - val_acc: 0.4855\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 2.0844 - acc: 0.5432 - val_loss: 2.2252 - val_acc: 0.5263\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 1.9891 - acc: 0.5869 - val_loss: 2.3395 - val_acc: 0.4801\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 5s 574us/step - loss: 1.9765 - acc: 0.5620 - val_loss: 2.2133 - val_acc: 0.5000\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 1.9817 - acc: 0.5617 - val_loss: 2.1351 - val_acc: 0.5127\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 5s 564us/step - loss: 1.9539 - acc: 0.5739 - val_loss: 2.2808 - val_acc: 0.4909\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.9856 - acc: 0.5699 - val_loss: 2.4247 - val_acc: 0.4620\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.9950 - acc: 0.5738 - val_loss: 2.2482 - val_acc: 0.5127\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 5s 560us/step - loss: 2.0206 - acc: 0.5689 - val_loss: 2.1045 - val_acc: 0.5344\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 5s 571us/step - loss: 1.9466 - acc: 0.5864 - val_loss: 2.1702 - val_acc: 0.4991\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 1.9972 - acc: 0.5711 - val_loss: 2.2636 - val_acc: 0.4909\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 5s 591us/step - loss: 2.0102 - acc: 0.5785 - val_loss: 2.3669 - val_acc: 0.4538\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 1.9744 - acc: 0.5821 - val_loss: 2.1771 - val_acc: 0.4991\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 1.8926 - acc: 0.6013 - val_loss: 2.1957 - val_acc: 0.4937\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 5s 577us/step - loss: 1.9729 - acc: 0.5696 - val_loss: 2.2747 - val_acc: 0.4991\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 2.0214 - acc: 0.5825 - val_loss: 2.3236 - val_acc: 0.4982\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 5s 580us/step - loss: 2.0237 - acc: 0.5781 - val_loss: 2.2432 - val_acc: 0.5290\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 5s 572us/step - loss: 1.9321 - acc: 0.5990 - val_loss: 2.2105 - val_acc: 0.5091\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 5s 562us/step - loss: 1.8882 - acc: 0.6072 - val_loss: 2.2033 - val_acc: 0.4982\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 4.5598 - acc: 0.3564 - val_loss: 4.1653 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 666us/step - loss: 4.1220 - acc: 0.4897 - val_loss: 4.0647 - val_acc: 0.5199\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 714us/step - loss: 3.9966 - acc: 0.5243 - val_loss: 4.0024 - val_acc: 0.5154\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 696us/step - loss: 3.9075 - acc: 0.5524 - val_loss: 3.9764 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 3.8453 - acc: 0.5691 - val_loss: 3.9406 - val_acc: 0.5389\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 3.7929 - acc: 0.5758 - val_loss: 3.8901 - val_acc: 0.5489\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 3.7411 - acc: 0.5951 - val_loss: 3.8876 - val_acc: 0.5444\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 736us/step - loss: 3.6831 - acc: 0.6131 - val_loss: 3.8500 - val_acc: 0.5625\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 712us/step - loss: 3.6381 - acc: 0.6223 - val_loss: 3.8302 - val_acc: 0.5616\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 715us/step - loss: 3.5895 - acc: 0.6333 - val_loss: 3.8172 - val_acc: 0.5670\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 3.5550 - acc: 0.6436 - val_loss: 3.7789 - val_acc: 0.5670\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 3.5255 - acc: 0.6485 - val_loss: 3.7722 - val_acc: 0.5643\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 3.4802 - acc: 0.6669 - val_loss: 3.7809 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 724us/step - loss: 3.4499 - acc: 0.6703 - val_loss: 3.7308 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 3.4173 - acc: 0.6816 - val_loss: 3.7239 - val_acc: 0.5752\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 3.3822 - acc: 0.6847 - val_loss: 3.7169 - val_acc: 0.5833\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 3.3508 - acc: 0.6997 - val_loss: 3.6869 - val_acc: 0.5833\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: 3.3113 - acc: 0.7139 - val_loss: 3.6803 - val_acc: 0.5897\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 748us/step - loss: 3.2777 - acc: 0.7122 - val_loss: 3.7048 - val_acc: 0.5797\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.2462 - acc: 0.7270 - val_loss: 3.6708 - val_acc: 0.5924\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 3.2153 - acc: 0.7353 - val_loss: 3.6488 - val_acc: 0.5915\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 3.1843 - acc: 0.7457 - val_loss: 3.6707 - val_acc: 0.5879\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 3.1590 - acc: 0.7464 - val_loss: 3.6425 - val_acc: 0.5833\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 732us/step - loss: 3.1304 - acc: 0.7660 - val_loss: 3.6482 - val_acc: 0.5870\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 6s 717us/step - loss: 3.0940 - acc: 0.7693 - val_loss: 3.6092 - val_acc: 0.5879\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 3.0770 - acc: 0.7717 - val_loss: 3.6461 - val_acc: 0.5743\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 701us/step - loss: 3.0428 - acc: 0.7779 - val_loss: 3.6175 - val_acc: 0.5779\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 759us/step - loss: 3.0216 - acc: 0.7800 - val_loss: 3.6036 - val_acc: 0.5824\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 752us/step - loss: 2.9927 - acc: 0.7847 - val_loss: 3.6146 - val_acc: 0.5788\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 2.9620 - acc: 0.8036 - val_loss: 3.6060 - val_acc: 0.5815\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 5.1471 - acc: 0.3701 - val_loss: 4.7802 - val_acc: 0.4991\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 4.7109 - acc: 0.4990 - val_loss: 4.6698 - val_acc: 0.5172\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 4.5938 - acc: 0.5241 - val_loss: 4.5907 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 4.4838 - acc: 0.5477 - val_loss: 4.5567 - val_acc: 0.5453\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: 4.4180 - acc: 0.5718 - val_loss: 4.4913 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 812us/step - loss: 4.3440 - acc: 0.5847 - val_loss: 4.4621 - val_acc: 0.5571\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 4.2891 - acc: 0.5966 - val_loss: 4.4128 - val_acc: 0.5670\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 4.2279 - acc: 0.6082 - val_loss: 4.4218 - val_acc: 0.5607\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 788us/step - loss: 4.1781 - acc: 0.6157 - val_loss: 4.3691 - val_acc: 0.5716\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 723us/step - loss: 4.1243 - acc: 0.6362 - val_loss: 4.3341 - val_acc: 0.5716\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 4.0625 - acc: 0.6474 - val_loss: 4.3122 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 4.0082 - acc: 0.6598 - val_loss: 4.3038 - val_acc: 0.5661\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 3.9690 - acc: 0.6655 - val_loss: 4.2716 - val_acc: 0.5616\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.9183 - acc: 0.6809 - val_loss: 4.2740 - val_acc: 0.5652\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 758us/step - loss: 3.8717 - acc: 0.6889 - val_loss: 4.2245 - val_acc: 0.5770\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 756us/step - loss: 3.8228 - acc: 0.7026 - val_loss: 4.1996 - val_acc: 0.5770\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 3.7822 - acc: 0.7130 - val_loss: 4.1911 - val_acc: 0.5761\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 3.7469 - acc: 0.7127 - val_loss: 4.1530 - val_acc: 0.5770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 744us/step - loss: 3.7003 - acc: 0.7300 - val_loss: 4.1509 - val_acc: 0.5779\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 3.6627 - acc: 0.7318 - val_loss: 4.1079 - val_acc: 0.5761\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 760us/step - loss: 3.6211 - acc: 0.7387 - val_loss: 4.0877 - val_acc: 0.5888\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 743us/step - loss: 3.5797 - acc: 0.7487 - val_loss: 4.0845 - val_acc: 0.5743\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.5402 - acc: 0.7569 - val_loss: 4.0540 - val_acc: 0.5870\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 749us/step - loss: 3.4984 - acc: 0.7676 - val_loss: 4.0445 - val_acc: 0.5879\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 3.4547 - acc: 0.7745 - val_loss: 4.0362 - val_acc: 0.5870\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 3.4147 - acc: 0.7834 - val_loss: 4.0349 - val_acc: 0.5752\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 3.3756 - acc: 0.7933 - val_loss: 4.0205 - val_acc: 0.5806\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 3.3448 - acc: 0.7981 - val_loss: 4.0180 - val_acc: 0.5806\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 733us/step - loss: 3.3138 - acc: 0.7987 - val_loss: 4.0226 - val_acc: 0.5761\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 723us/step - loss: 3.2735 - acc: 0.8076 - val_loss: 3.9823 - val_acc: 0.5697\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 745us/step - loss: 3.2335 - acc: 0.8191 - val_loss: 3.9993 - val_acc: 0.5788\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 55s 6ms/step - loss: 7.1292 - acc: 0.4755 - val_loss: 6.8986 - val_acc: 0.5245\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 6.5602 - acc: 0.6222 - val_loss: 6.6937 - val_acc: 0.5245\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 6.2559 - acc: 0.6966 - val_loss: 6.5726 - val_acc: 0.5417\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.9735 - acc: 0.7697 - val_loss: 6.4310 - val_acc: 0.5525\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.7442 - acc: 0.8152 - val_loss: 6.3194 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.5208 - acc: 0.8506 - val_loss: 6.1594 - val_acc: 0.5580\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.3207 - acc: 0.8878 - val_loss: 6.0731 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.1129 - acc: 0.9156 - val_loss: 5.8884 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.9108 - acc: 0.9478 - val_loss: 5.8036 - val_acc: 0.5716\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.7452 - acc: 0.9557 - val_loss: 5.6758 - val_acc: 0.5779\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5633 - acc: 0.9711 - val_loss: 5.5705 - val_acc: 0.5670\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.3997 - acc: 0.9804 - val_loss: 5.4832 - val_acc: 0.5752\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.2462 - acc: 0.9854 - val_loss: 5.3652 - val_acc: 0.5643\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1104 - acc: 0.9823 - val_loss: 5.2597 - val_acc: 0.5797\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9728 - acc: 0.9858 - val_loss: 5.1778 - val_acc: 0.5743\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8156 - acc: 0.9933 - val_loss: 5.0836 - val_acc: 0.5851\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.6941 - acc: 0.9896 - val_loss: 5.0291 - val_acc: 0.5707\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.5987 - acc: 0.9804 - val_loss: 4.8857 - val_acc: 0.5616\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.4880 - acc: 0.9764 - val_loss: 4.7415 - val_acc: 0.5607\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3444 - acc: 0.9882 - val_loss: 4.6765 - val_acc: 0.5679\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.2131 - acc: 0.9928 - val_loss: 4.5192 - val_acc: 0.5707\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.0781 - acc: 0.9978 - val_loss: 4.3929 - val_acc: 0.5697\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0054 - acc: 0.9834 - val_loss: 4.5063 - val_acc: 0.5543\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9584 - acc: 0.9660 - val_loss: 4.3344 - val_acc: 0.5661\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.8166 - acc: 0.9845 - val_loss: 4.1858 - val_acc: 0.5707\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.6876 - acc: 0.9934 - val_loss: 4.0645 - val_acc: 0.5842\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 6ms/step - loss: 9.7792 - acc: 0.3623 - val_loss: 9.4434 - val_acc: 0.4592\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 554us/step - loss: 9.1991 - acc: 0.5020 - val_loss: 9.1109 - val_acc: 0.5036\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 8.9185 - acc: 0.5421 - val_loss: 8.9098 - val_acc: 0.5335\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 8.6873 - acc: 0.5689 - val_loss: 8.7235 - val_acc: 0.5299\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 8.4807 - acc: 0.5910 - val_loss: 8.5397 - val_acc: 0.5453\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 8.2689 - acc: 0.6040 - val_loss: 8.3753 - val_acc: 0.5326\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 8.0730 - acc: 0.6225 - val_loss: 8.2010 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 7.8869 - acc: 0.6312 - val_loss: 8.0401 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 550us/step - loss: 7.6884 - acc: 0.6490 - val_loss: 7.8873 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 573us/step - loss: 7.4953 - acc: 0.6715 - val_loss: 7.7126 - val_acc: 0.5688\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 565us/step - loss: 7.3085 - acc: 0.6803 - val_loss: 7.5603 - val_acc: 0.5562\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 567us/step - loss: 7.1291 - acc: 0.6937 - val_loss: 7.4155 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 590us/step - loss: 6.9604 - acc: 0.7009 - val_loss: 7.2822 - val_acc: 0.5652\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 633us/step - loss: 6.7879 - acc: 0.7153 - val_loss: 7.1819 - val_acc: 0.5571\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 6.6255 - acc: 0.7313 - val_loss: 7.0197 - val_acc: 0.5670\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 6.4599 - acc: 0.7379 - val_loss: 6.8916 - val_acc: 0.5707\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 6.3032 - acc: 0.7435 - val_loss: 6.7439 - val_acc: 0.5761\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 612us/step - loss: 6.1457 - acc: 0.7576 - val_loss: 6.6081 - val_acc: 0.5725\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 627us/step - loss: 5.9906 - acc: 0.7689 - val_loss: 6.4865 - val_acc: 0.5697\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 635us/step - loss: 5.8457 - acc: 0.7799 - val_loss: 6.3844 - val_acc: 0.5743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 640us/step - loss: 5.7074 - acc: 0.7832 - val_loss: 6.3172 - val_acc: 0.5598\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 618us/step - loss: 5.5650 - acc: 0.7930 - val_loss: 6.1518 - val_acc: 0.5734\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 6s 624us/step - loss: 5.4317 - acc: 0.8012 - val_loss: 6.0545 - val_acc: 0.5679\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 603us/step - loss: 5.2886 - acc: 0.8161 - val_loss: 5.9629 - val_acc: 0.5652\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 5.1641 - acc: 0.8205 - val_loss: 5.8151 - val_acc: 0.5851\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 5.0231 - acc: 0.8343 - val_loss: 5.7757 - val_acc: 0.5734\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 610us/step - loss: 4.9156 - acc: 0.8324 - val_loss: 5.6363 - val_acc: 0.5734\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 4.7899 - acc: 0.8393 - val_loss: 5.5491 - val_acc: 0.5806\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 600us/step - loss: 4.6781 - acc: 0.8488 - val_loss: 5.4863 - val_acc: 0.5779\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 4.5602 - acc: 0.8542 - val_loss: 5.4088 - val_acc: 0.5679\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: 4.4436 - acc: 0.8679 - val_loss: 5.2850 - val_acc: 0.5761\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 5s 576us/step - loss: 4.3283 - acc: 0.8735 - val_loss: 5.2415 - val_acc: 0.5697\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 4.2307 - acc: 0.8716 - val_loss: 5.1484 - val_acc: 0.5697\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: 4.1151 - acc: 0.8890 - val_loss: 5.0409 - val_acc: 0.5761\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 5s 592us/step - loss: 4.0097 - acc: 0.8963 - val_loss: 4.9911 - val_acc: 0.5697\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 6.7910 - acc: 0.3792 - val_loss: 6.4405 - val_acc: 0.5018\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 6.2237 - acc: 0.5194 - val_loss: 6.1913 - val_acc: 0.5100\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: 5.9836 - acc: 0.5686 - val_loss: 6.0600 - val_acc: 0.5254\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: 5.8105 - acc: 0.5951 - val_loss: 5.9319 - val_acc: 0.5317\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 609us/step - loss: 5.6495 - acc: 0.6190 - val_loss: 5.8226 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 620us/step - loss: 5.5018 - acc: 0.6416 - val_loss: 5.7091 - val_acc: 0.5516\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 609us/step - loss: 5.3435 - acc: 0.6652 - val_loss: 5.6426 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 5.2121 - acc: 0.6872 - val_loss: 5.5302 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 602us/step - loss: 5.0774 - acc: 0.6978 - val_loss: 5.4530 - val_acc: 0.5516\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 4.9433 - acc: 0.7164 - val_loss: 5.3600 - val_acc: 0.5607\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 4.8063 - acc: 0.7367 - val_loss: 5.2645 - val_acc: 0.5634\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 597us/step - loss: 4.6811 - acc: 0.7483 - val_loss: 5.1753 - val_acc: 0.5743\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 4.5475 - acc: 0.7736 - val_loss: 5.1386 - val_acc: 0.5752\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 4.4340 - acc: 0.7897 - val_loss: 5.0469 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 587us/step - loss: 4.3141 - acc: 0.8018 - val_loss: 4.9844 - val_acc: 0.5589\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 599us/step - loss: 4.1892 - acc: 0.8147 - val_loss: 4.9453 - val_acc: 0.5580\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 5s 590us/step - loss: 4.0817 - acc: 0.8226 - val_loss: 4.8476 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 3.9802 - acc: 0.8379 - val_loss: 4.7935 - val_acc: 0.5815\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 605us/step - loss: 3.8825 - acc: 0.8480 - val_loss: 4.7591 - val_acc: 0.5688\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 614us/step - loss: 3.7819 - acc: 0.8583 - val_loss: 4.6562 - val_acc: 0.5625\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 591us/step - loss: 3.6734 - acc: 0.8730 - val_loss: 4.5592 - val_acc: 0.5842\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 596us/step - loss: 3.5797 - acc: 0.8760 - val_loss: 4.5259 - val_acc: 0.5562\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 3.4788 - acc: 0.8929 - val_loss: 4.4878 - val_acc: 0.5598\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 598us/step - loss: 3.3909 - acc: 0.9027 - val_loss: 4.3605 - val_acc: 0.5833\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 601us/step - loss: 3.3044 - acc: 0.9067 - val_loss: 4.3942 - val_acc: 0.5688\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 5s 604us/step - loss: 3.2341 - acc: 0.9034 - val_loss: 4.3164 - val_acc: 0.5679\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 5s 621us/step - loss: 3.1313 - acc: 0.9232 - val_loss: 4.2043 - val_acc: 0.5725\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 5s 594us/step - loss: 3.0652 - acc: 0.9241 - val_loss: 4.2106 - val_acc: 0.5734\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: 2.9765 - acc: 0.9334 - val_loss: 4.2237 - val_acc: 0.5589\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 5s 611us/step - loss: 2.9065 - acc: 0.9371 - val_loss: 4.1288 - val_acc: 0.5707\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 5s 582us/step - loss: 2.8405 - acc: 0.9357 - val_loss: 4.0961 - val_acc: 0.5553\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 66s 8ms/step - loss: 22.2566 - acc: 0.3973 - val_loss: 11.1583 - val_acc: 0.4538\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 6.7242 - acc: 0.4476 - val_loss: 4.0455 - val_acc: 0.4312\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 3.2468 - acc: 0.4451 - val_loss: 2.7783 - val_acc: 0.4402\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.5699 - acc: 0.4560 - val_loss: 2.3377 - val_acc: 0.4864\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.3631 - acc: 0.4523 - val_loss: 2.4047 - val_acc: 0.4411\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.3182 - acc: 0.4597 - val_loss: 2.2603 - val_acc: 0.4737\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.3695 - acc: 0.4495 - val_loss: 2.2205 - val_acc: 0.4484\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.2246 - acc: 0.4629 - val_loss: 2.1539 - val_acc: 0.4764\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 22s 2ms/step - loss: 2.2526 - acc: 0.4597 - val_loss: 2.2633 - val_acc: 0.4384\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.2104 - acc: 0.4655 - val_loss: 2.1873 - val_acc: 0.4656\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.2374 - acc: 0.4611 - val_loss: 2.2712 - val_acc: 0.4230\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.2288 - acc: 0.4584 - val_loss: 2.2226 - val_acc: 0.4266\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.2202 - acc: 0.4537 - val_loss: 2.1496 - val_acc: 0.4601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 22s 3ms/step - loss: 2.1709 - acc: 0.4765 - val_loss: 2.2194 - val_acc: 0.4447\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 59s 7ms/step - loss: 5.3176 - acc: 0.1912 - val_loss: 4.0452 - val_acc: 0.2518\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8029 - acc: 0.2639 - val_loss: 3.4295 - val_acc: 0.2871\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1792 - acc: 0.2983 - val_loss: 3.0986 - val_acc: 0.2998\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9925 - acc: 0.3607 - val_loss: 2.9144 - val_acc: 0.3913\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9574 - acc: 0.3888 - val_loss: 3.0007 - val_acc: 0.3967\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0591 - acc: 0.4183 - val_loss: 3.1890 - val_acc: 0.3614\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1347 - acc: 0.4088 - val_loss: 3.0878 - val_acc: 0.3859\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9502 - acc: 0.4344 - val_loss: 3.1792 - val_acc: 0.4139\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0065 - acc: 0.4357 - val_loss: 3.0007 - val_acc: 0.4013\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0046 - acc: 0.4358 - val_loss: 3.0638 - val_acc: 0.4484\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9929 - acc: 0.4529 - val_loss: 2.9773 - val_acc: 0.4221\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0175 - acc: 0.4525 - val_loss: 2.9904 - val_acc: 0.4475\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8932 - acc: 0.4618 - val_loss: 3.0352 - val_acc: 0.4484\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.0508 - acc: 0.4423 - val_loss: 2.9533 - val_acc: 0.4674\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9472 - acc: 0.4665 - val_loss: 3.0665 - val_acc: 0.4466\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0699 - acc: 0.4511 - val_loss: 3.0174 - val_acc: 0.4538\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0352 - acc: 0.4494 - val_loss: 3.0154 - val_acc: 0.4312\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0548 - acc: 0.4475 - val_loss: 3.1059 - val_acc: 0.4429\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0373 - acc: 0.4596 - val_loss: 3.1635 - val_acc: 0.4312\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0899 - acc: 0.4695 - val_loss: 3.0942 - val_acc: 0.4520\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0822 - acc: 0.4731 - val_loss: 3.0822 - val_acc: 0.4583\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.1295 - acc: 0.4731 - val_loss: 3.3111 - val_acc: 0.4484\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.1223 - acc: 0.4811 - val_loss: 3.0921 - val_acc: 0.4538\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0347 - acc: 0.4739 - val_loss: 3.1176 - val_acc: 0.4112\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 51s 6ms/step - loss: 4.3697 - acc: 0.3273 - val_loss: 3.9972 - val_acc: 0.4774\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 720us/step - loss: 3.9229 - acc: 0.4685 - val_loss: 3.8587 - val_acc: 0.5063\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 730us/step - loss: 3.8141 - acc: 0.4977 - val_loss: 3.7949 - val_acc: 0.5190\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 3.7369 - acc: 0.5172 - val_loss: 3.7527 - val_acc: 0.5299\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 3.6800 - acc: 0.5275 - val_loss: 3.7418 - val_acc: 0.5190\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 753us/step - loss: 3.6235 - acc: 0.5441 - val_loss: 3.6838 - val_acc: 0.5453\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 726us/step - loss: 3.5834 - acc: 0.5507 - val_loss: 3.6820 - val_acc: 0.5389\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 3.5501 - acc: 0.5578 - val_loss: 3.6272 - val_acc: 0.5498\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 3.4937 - acc: 0.5761 - val_loss: 3.6261 - val_acc: 0.5408\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 768us/step - loss: 3.4618 - acc: 0.5868 - val_loss: 3.6040 - val_acc: 0.5408\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 722us/step - loss: 3.4346 - acc: 0.5884 - val_loss: 3.5758 - val_acc: 0.5426\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 6s 728us/step - loss: 3.3966 - acc: 0.6000 - val_loss: 3.5701 - val_acc: 0.5507\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 3.3641 - acc: 0.6056 - val_loss: 3.5397 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 731us/step - loss: 3.3343 - acc: 0.6132 - val_loss: 3.5286 - val_acc: 0.5462\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 740us/step - loss: 3.3077 - acc: 0.6165 - val_loss: 3.5203 - val_acc: 0.5480\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 6s 734us/step - loss: 3.2743 - acc: 0.6269 - val_loss: 3.5264 - val_acc: 0.5525\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 750us/step - loss: 3.2590 - acc: 0.6311 - val_loss: 3.4940 - val_acc: 0.5553\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 6s 710us/step - loss: 3.2267 - acc: 0.6342 - val_loss: 3.4812 - val_acc: 0.5589\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 6s 708us/step - loss: 3.2020 - acc: 0.6455 - val_loss: 3.4635 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 6s 718us/step - loss: 3.1773 - acc: 0.6463 - val_loss: 3.4829 - val_acc: 0.5471\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 6s 729us/step - loss: 3.1528 - acc: 0.6502 - val_loss: 3.4568 - val_acc: 0.5589\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 755us/step - loss: 3.1175 - acc: 0.6629 - val_loss: 3.4529 - val_acc: 0.5598\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 737us/step - loss: 3.1124 - acc: 0.6639 - val_loss: 3.4198 - val_acc: 0.5688\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 6s 705us/step - loss: 3.0769 - acc: 0.6717 - val_loss: 3.4244 - val_acc: 0.5616\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 742us/step - loss: 3.0436 - acc: 0.6798 - val_loss: 3.4095 - val_acc: 0.5580\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 6s 727us/step - loss: 3.0336 - acc: 0.6835 - val_loss: 3.4004 - val_acc: 0.5571\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 736us/step - loss: 3.0118 - acc: 0.6864 - val_loss: 3.4036 - val_acc: 0.5562\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 2.9749 - acc: 0.6988 - val_loss: 3.4027 - val_acc: 0.5553\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 6s 702us/step - loss: 2.9519 - acc: 0.7013 - val_loss: 3.3700 - val_acc: 0.5625\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 6s 707us/step - loss: 2.9286 - acc: 0.7053 - val_loss: 3.3742 - val_acc: 0.5553\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 6s 721us/step - loss: 2.9127 - acc: 0.7133 - val_loss: 3.3657 - val_acc: 0.5607\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 2.8999 - acc: 0.7076 - val_loss: 3.3589 - val_acc: 0.5562\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 741us/step - loss: 2.8631 - acc: 0.7261 - val_loss: 3.3449 - val_acc: 0.5652\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 6ms/step - loss: nan - acc: 0.0703 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 608us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 646us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 6s 691us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 6s 678us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 6s 655us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 6s 681us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 6s 706us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 6s 680us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 49s 6ms/step - loss: 19.5784 - acc: 0.2948 - val_loss: 17.6145 - val_acc: 0.4067\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 16.3783 - acc: 0.4953 - val_loss: 14.8290 - val_acc: 0.5054\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 13.4935 - acc: 0.5604 - val_loss: 12.1487 - val_acc: 0.5127\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 10.8564 - acc: 0.5877 - val_loss: 9.7708 - val_acc: 0.5118\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 8.6571 - acc: 0.6252 - val_loss: 7.9345 - val_acc: 0.5226\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 7.0347 - acc: 0.6257 - val_loss: 6.5824 - val_acc: 0.5507\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 4s 508us/step - loss: 5.8118 - acc: 0.6245 - val_loss: 5.6175 - val_acc: 0.5054\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 543us/step - loss: 4.9097 - acc: 0.6283 - val_loss: 4.8388 - val_acc: 0.5100\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 4.1638 - acc: 0.6447 - val_loss: 4.1707 - val_acc: 0.5489\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 528us/step - loss: 3.6242 - acc: 0.6510 - val_loss: 3.7730 - val_acc: 0.5245\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 542us/step - loss: 3.1896 - acc: 0.6622 - val_loss: 3.4315 - val_acc: 0.5236\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 535us/step - loss: 2.8337 - acc: 0.6763 - val_loss: 3.1906 - val_acc: 0.5082\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 2.6385 - acc: 0.6528 - val_loss: 3.1509 - val_acc: 0.4837\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 5s 515us/step - loss: 2.6043 - acc: 0.6073 - val_loss: 2.7634 - val_acc: 0.5254\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 543us/step - loss: 2.3072 - acc: 0.6606 - val_loss: 2.6610 - val_acc: 0.5245\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 516us/step - loss: 2.0896 - acc: 0.6950 - val_loss: 2.5015 - val_acc: 0.5399\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 58s 7ms/step - loss: 6.2257 - acc: 0.4563 - val_loss: 5.9874 - val_acc: 0.4973\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.7880 - acc: 0.5703 - val_loss: 5.7943 - val_acc: 0.5562\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.5715 - acc: 0.6147 - val_loss: 5.7689 - val_acc: 0.5272\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.3912 - acc: 0.6620 - val_loss: 5.6404 - val_acc: 0.5435\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.2351 - acc: 0.6917 - val_loss: 5.5584 - val_acc: 0.5462\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.0732 - acc: 0.7302 - val_loss: 5.4913 - val_acc: 0.5562\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.9326 - acc: 0.7609 - val_loss: 5.4277 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.7936 - acc: 0.7882 - val_loss: 5.3629 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.6636 - acc: 0.8060 - val_loss: 5.2838 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5362 - acc: 0.8268 - val_loss: 5.2077 - val_acc: 0.5652\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.4064 - acc: 0.8546 - val_loss: 5.1535 - val_acc: 0.5580\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.3000 - acc: 0.8686 - val_loss: 5.1020 - val_acc: 0.5516\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1671 - acc: 0.8975 - val_loss: 5.0084 - val_acc: 0.5734\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.0615 - acc: 0.9095 - val_loss: 4.9952 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9690 - acc: 0.9137 - val_loss: 4.9057 - val_acc: 0.5643\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8656 - acc: 0.9231 - val_loss: 4.8928 - val_acc: 0.5607\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7692 - acc: 0.9353 - val_loss: 4.8273 - val_acc: 0.5652\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.6727 - acc: 0.9462 - val_loss: 4.7976 - val_acc: 0.5571\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.5709 - acc: 0.9580 - val_loss: 4.7378 - val_acc: 0.5643\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 3.4896 - acc: 0.9626 - val_loss: 4.6995 - val_acc: 0.5525\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3966 - acc: 0.9682 - val_loss: 4.6224 - val_acc: 0.5625\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3127 - acc: 0.9728 - val_loss: 4.5729 - val_acc: 0.5562\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.2352 - acc: 0.9715 - val_loss: 4.5153 - val_acc: 0.5616\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 58s 7ms/step - loss: 6.9364 - acc: 0.4450 - val_loss: 6.6476 - val_acc: 0.5127\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 6.4576 - acc: 0.5565 - val_loss: 6.4436 - val_acc: 0.5353\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 6.2088 - acc: 0.6118 - val_loss: 6.3549 - val_acc: 0.5435\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 6.0230 - acc: 0.6387 - val_loss: 6.1977 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.8353 - acc: 0.6780 - val_loss: 6.1025 - val_acc: 0.5562\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.6561 - acc: 0.7066 - val_loss: 6.0013 - val_acc: 0.5444\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.4802 - acc: 0.7352 - val_loss: 5.8554 - val_acc: 0.5707\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.3255 - acc: 0.7524 - val_loss: 5.7615 - val_acc: 0.5516\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.1755 - acc: 0.7720 - val_loss: 5.6713 - val_acc: 0.5716\n",
      "Epoch 10/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.0150 - acc: 0.7998 - val_loss: 5.5650 - val_acc: 0.5697\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.8667 - acc: 0.8139 - val_loss: 5.5274 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.7351 - acc: 0.8327 - val_loss: 5.4286 - val_acc: 0.5589\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5830 - acc: 0.8532 - val_loss: 5.3314 - val_acc: 0.5725\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.4524 - acc: 0.8648 - val_loss: 5.2416 - val_acc: 0.5670\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.3125 - acc: 0.8855 - val_loss: 5.1865 - val_acc: 0.5716\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1985 - acc: 0.8925 - val_loss: 5.0918 - val_acc: 0.5725\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.0664 - acc: 0.9110 - val_loss: 4.9764 - val_acc: 0.5743\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9356 - acc: 0.9248 - val_loss: 4.8958 - val_acc: 0.5788\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8215 - acc: 0.9320 - val_loss: 4.8376 - val_acc: 0.5616\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7277 - acc: 0.9342 - val_loss: 4.7881 - val_acc: 0.5734\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.6196 - acc: 0.9417 - val_loss: 4.6988 - val_acc: 0.5770\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.5116 - acc: 0.9511 - val_loss: 4.6167 - val_acc: 0.5734\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.4098 - acc: 0.9541 - val_loss: 4.5095 - val_acc: 0.5725\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3073 - acc: 0.9617 - val_loss: 4.4984 - val_acc: 0.5788\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2127 - acc: 0.9664 - val_loss: 4.5042 - val_acc: 0.5652\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1326 - acc: 0.9639 - val_loss: 4.3537 - val_acc: 0.5788\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0328 - acc: 0.9734 - val_loss: 4.2556 - val_acc: 0.5851\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9507 - acc: 0.9702 - val_loss: 4.2173 - val_acc: 0.5888\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.8743 - acc: 0.9702 - val_loss: 4.1631 - val_acc: 0.5851\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.7894 - acc: 0.9732 - val_loss: 4.0937 - val_acc: 0.5697\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7150 - acc: 0.9726 - val_loss: 4.0792 - val_acc: 0.5725\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.6304 - acc: 0.9772 - val_loss: 3.9226 - val_acc: 0.5960\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.5634 - acc: 0.9745 - val_loss: 3.9654 - val_acc: 0.5670\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.4943 - acc: 0.9741 - val_loss: 3.8675 - val_acc: 0.5670\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.4156 - acc: 0.9800 - val_loss: 3.8867 - val_acc: 0.5788\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3462 - acc: 0.9807 - val_loss: 3.8186 - val_acc: 0.5625\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.2857 - acc: 0.9777 - val_loss: 3.7084 - val_acc: 0.5779\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2187 - acc: 0.9800 - val_loss: 3.7177 - val_acc: 0.5707\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1592 - acc: 0.9793 - val_loss: 3.6299 - val_acc: 0.5679\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0958 - acc: 0.9792 - val_loss: 3.5506 - val_acc: 0.5806\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0351 - acc: 0.9815 - val_loss: 3.5695 - val_acc: 0.5815\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9765 - acc: 0.9798 - val_loss: 3.4590 - val_acc: 0.5851\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 58s 7ms/step - loss: 6.0451 - acc: 0.4655 - val_loss: 5.8163 - val_acc: 0.5091\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.5460 - acc: 0.6030 - val_loss: 5.6907 - val_acc: 0.5308\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.3123 - acc: 0.6675 - val_loss: 5.5657 - val_acc: 0.5543\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.1181 - acc: 0.7180 - val_loss: 5.4985 - val_acc: 0.5426\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.9443 - acc: 0.7607 - val_loss: 5.4103 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.7874 - acc: 0.7935 - val_loss: 5.3734 - val_acc: 0.5543\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.6162 - acc: 0.8423 - val_loss: 5.2800 - val_acc: 0.5643\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.4771 - acc: 0.8639 - val_loss: 5.2133 - val_acc: 0.5607\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.3478 - acc: 0.8888 - val_loss: 5.1585 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.2056 - acc: 0.9152 - val_loss: 5.1075 - val_acc: 0.5652\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.0810 - acc: 0.9342 - val_loss: 5.0283 - val_acc: 0.5616\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.9765 - acc: 0.9433 - val_loss: 4.9909 - val_acc: 0.5580\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.8605 - acc: 0.9592 - val_loss: 4.8980 - val_acc: 0.5679\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.7485 - acc: 0.9677 - val_loss: 4.9101 - val_acc: 0.5562\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6473 - acc: 0.9770 - val_loss: 4.8106 - val_acc: 0.5725\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.5493 - acc: 0.9831 - val_loss: 4.7327 - val_acc: 0.5716\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.4535 - acc: 0.9855 - val_loss: 4.6859 - val_acc: 0.5625\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.3615 - acc: 0.9891 - val_loss: 4.6551 - val_acc: 0.5707\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2797 - acc: 0.9875 - val_loss: 4.6488 - val_acc: 0.5589\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.2048 - acc: 0.9840 - val_loss: 4.5429 - val_acc: 0.5661\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.1231 - acc: 0.9861 - val_loss: 4.4718 - val_acc: 0.5688\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.0311 - acc: 0.9899 - val_loss: 4.4207 - val_acc: 0.5770\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.9481 - acc: 0.9930 - val_loss: 4.3389 - val_acc: 0.5679\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8718 - acc: 0.9928 - val_loss: 4.2773 - val_acc: 0.5580\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.8075 - acc: 0.9880 - val_loss: 4.2849 - val_acc: 0.5743\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.7392 - acc: 0.9872 - val_loss: 4.1931 - val_acc: 0.5661\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.6802 - acc: 0.9802 - val_loss: 4.1268 - val_acc: 0.5534\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5946 - acc: 0.9882 - val_loss: 4.0777 - val_acc: 0.5697\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.5147 - acc: 0.9916 - val_loss: 3.9933 - val_acc: 0.5553\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.4446 - acc: 0.9932 - val_loss: 4.0102 - val_acc: 0.5525\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 2.3754 - acc: 0.9924 - val_loss: 3.8869 - val_acc: 0.5661\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.3230 - acc: 0.9882 - val_loss: 3.8984 - val_acc: 0.5553\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 58s 7ms/step - loss: 5.2965 - acc: 0.4306 - val_loss: 5.0351 - val_acc: 0.4955\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.8879 - acc: 0.5480 - val_loss: 4.9423 - val_acc: 0.5154\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.7098 - acc: 0.5946 - val_loss: 4.8252 - val_acc: 0.5507\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5609 - acc: 0.6278 - val_loss: 4.7888 - val_acc: 0.5489\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.4418 - acc: 0.6545 - val_loss: 4.7221 - val_acc: 0.5652\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.3205 - acc: 0.6883 - val_loss: 4.6787 - val_acc: 0.5543\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.2108 - acc: 0.7111 - val_loss: 4.6246 - val_acc: 0.5643\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.0953 - acc: 0.7418 - val_loss: 4.5211 - val_acc: 0.5788\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 3.9930 - acc: 0.7601 - val_loss: 4.5140 - val_acc: 0.5607\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8982 - acc: 0.7770 - val_loss: 4.4719 - val_acc: 0.5652\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7973 - acc: 0.8050 - val_loss: 4.3648 - val_acc: 0.5870\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7076 - acc: 0.8224 - val_loss: 4.3718 - val_acc: 0.5879\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.6138 - acc: 0.8425 - val_loss: 4.3644 - val_acc: 0.5652\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.5367 - acc: 0.8492 - val_loss: 4.3388 - val_acc: 0.5761\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.4540 - acc: 0.8691 - val_loss: 4.2555 - val_acc: 0.5924\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3709 - acc: 0.8824 - val_loss: 4.2177 - val_acc: 0.5815\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.2827 - acc: 0.8963 - val_loss: 4.2339 - val_acc: 0.5643\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.2194 - acc: 0.8993 - val_loss: 4.1709 - val_acc: 0.5870\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1313 - acc: 0.9180 - val_loss: 4.1670 - val_acc: 0.5716\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0599 - acc: 0.9286 - val_loss: 4.0993 - val_acc: 0.5824\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9962 - acc: 0.9337 - val_loss: 4.0483 - val_acc: 0.5879\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.9244 - acc: 0.9443 - val_loss: 4.0527 - val_acc: 0.5797\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.8765 - acc: 0.9427 - val_loss: 4.0490 - val_acc: 0.5788\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.8040 - acc: 0.9523 - val_loss: 4.0005 - val_acc: 0.5824\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.7401 - acc: 0.9595 - val_loss: 3.9650 - val_acc: 0.5761\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 90s 10ms/step - loss: 2510.2943 - acc: 0.3596 - val_loss: 764.3660 - val_acc: 0.4466\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 313.4481 - acc: 0.4275 - val_loss: 86.3871 - val_acc: 0.3687\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 36.1641 - acc: 0.3188 - val_loss: 11.6862 - val_acc: 0.3043\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 6.1722 - acc: 0.3077 - val_loss: 3.4444 - val_acc: 0.3053\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.8383 - acc: 0.3052 - val_loss: 2.5177 - val_acc: 0.3134\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.4795 - acc: 0.3071 - val_loss: 2.4190 - val_acc: 0.3243\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.4338 - acc: 0.3009 - val_loss: 2.4178 - val_acc: 0.3062\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.4132 - acc: 0.3078 - val_loss: 2.3900 - val_acc: 0.3025\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.3963 - acc: 0.3080 - val_loss: 2.3951 - val_acc: 0.2817\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.3833 - acc: 0.2989 - val_loss: 2.3716 - val_acc: 0.3025\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 38s 4ms/step - loss: 2.3669 - acc: 0.3012 - val_loss: 2.3478 - val_acc: 0.3216\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 60s 7ms/step - loss: 5.8296 - acc: 0.4595 - val_loss: 5.5989 - val_acc: 0.5018\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.3487 - acc: 0.5774 - val_loss: 5.4619 - val_acc: 0.5181\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.1108 - acc: 0.6329 - val_loss: 5.2707 - val_acc: 0.5453\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.8993 - acc: 0.6779 - val_loss: 5.2097 - val_acc: 0.5589\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.7221 - acc: 0.7113 - val_loss: 5.0513 - val_acc: 0.5580\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.5308 - acc: 0.7462 - val_loss: 4.9980 - val_acc: 0.5553\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.3615 - acc: 0.7816 - val_loss: 4.9143 - val_acc: 0.5598\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1904 - acc: 0.8106 - val_loss: 4.8028 - val_acc: 0.5725\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.0378 - acc: 0.8363 - val_loss: 4.7384 - val_acc: 0.5553\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.8985 - acc: 0.8557 - val_loss: 4.6651 - val_acc: 0.5598\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7475 - acc: 0.8773 - val_loss: 4.5515 - val_acc: 0.5752\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.6045 - acc: 0.9000 - val_loss: 4.4440 - val_acc: 0.5824\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.4715 - acc: 0.9186 - val_loss: 4.4404 - val_acc: 0.5734\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.3527 - acc: 0.9257 - val_loss: 4.3902 - val_acc: 0.5607\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2281 - acc: 0.9414 - val_loss: 4.3081 - val_acc: 0.5697\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.1144 - acc: 0.9506 - val_loss: 4.2263 - val_acc: 0.5734\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0148 - acc: 0.9520 - val_loss: 4.1978 - val_acc: 0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.9089 - acc: 0.9622 - val_loss: 4.0973 - val_acc: 0.5761\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.8123 - acc: 0.9656 - val_loss: 4.0880 - val_acc: 0.5562\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7250 - acc: 0.9652 - val_loss: 3.9525 - val_acc: 0.5770\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.6240 - acc: 0.9728 - val_loss: 3.8846 - val_acc: 0.5688\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5457 - acc: 0.9732 - val_loss: 3.8385 - val_acc: 0.5752\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 58s 7ms/step - loss: nan - acc: 0.0701 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 62s 7ms/step - loss: 5.7726 - acc: 0.4566 - val_loss: 5.5273 - val_acc: 0.4982\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.3354 - acc: 0.5691 - val_loss: 5.4170 - val_acc: 0.5263\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.1411 - acc: 0.6141 - val_loss: 5.3085 - val_acc: 0.5453\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.9643 - acc: 0.6547 - val_loss: 5.2116 - val_acc: 0.5516\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.8029 - acc: 0.6996 - val_loss: 5.1547 - val_acc: 0.5471\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.6817 - acc: 0.7228 - val_loss: 5.0897 - val_acc: 0.5607\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.5342 - acc: 0.7557 - val_loss: 5.0687 - val_acc: 0.5580\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.4167 - acc: 0.7819 - val_loss: 4.9887 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.2965 - acc: 0.8021 - val_loss: 4.9060 - val_acc: 0.5788\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.1685 - acc: 0.8355 - val_loss: 4.8720 - val_acc: 0.5643\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.0519 - acc: 0.8525 - val_loss: 4.8022 - val_acc: 0.5806\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9541 - acc: 0.8686 - val_loss: 4.7778 - val_acc: 0.5679\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.8485 - acc: 0.8836 - val_loss: 4.7087 - val_acc: 0.5815\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.7516 - acc: 0.8998 - val_loss: 4.6505 - val_acc: 0.5842\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.6414 - acc: 0.9185 - val_loss: 4.6214 - val_acc: 0.5770\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.5492 - acc: 0.9300 - val_loss: 4.5806 - val_acc: 0.5761\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.4567 - acc: 0.9416 - val_loss: 4.5257 - val_acc: 0.5770\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.3749 - acc: 0.9478 - val_loss: 4.4876 - val_acc: 0.5716\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2847 - acc: 0.9582 - val_loss: 4.4726 - val_acc: 0.5652\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2087 - acc: 0.9640 - val_loss: 4.3933 - val_acc: 0.5725\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1296 - acc: 0.9675 - val_loss: 4.3521 - val_acc: 0.5797\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0570 - acc: 0.9701 - val_loss: 4.2782 - val_acc: 0.5688\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9806 - acc: 0.9747 - val_loss: 4.2524 - val_acc: 0.5815\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9125 - acc: 0.9745 - val_loss: 4.2550 - val_acc: 0.5716\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 55s 6ms/step - loss: 213.1573 - acc: 0.4076 - val_loss: 175.4784 - val_acc: 0.4828\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 7s 801us/step - loss: 150.0364 - acc: 0.5082 - val_loss: 122.3557 - val_acc: 0.4946\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 7s 810us/step - loss: 104.1064 - acc: 0.5219 - val_loss: 84.5603 - val_acc: 0.4982\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 807us/step - loss: 71.7469 - acc: 0.5432 - val_loss: 58.2502 - val_acc: 0.4955\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 796us/step - loss: 49.2800 - acc: 0.5458 - val_loss: 40.1059 - val_acc: 0.4955\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 774us/step - loss: 33.8302 - acc: 0.5565 - val_loss: 27.7823 - val_acc: 0.5009\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 23.3393 - acc: 0.5592 - val_loss: 19.4539 - val_acc: 0.4746\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 760us/step - loss: 16.2561 - acc: 0.5631 - val_loss: 13.9169 - val_acc: 0.4574\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 11.5219 - acc: 0.5663 - val_loss: 10.1613 - val_acc: 0.4638\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 8.3325 - acc: 0.5814 - val_loss: 7.7216 - val_acc: 0.4656\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 6.2066 - acc: 0.5890 - val_loss: 5.9714 - val_acc: 0.4592\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 802us/step - loss: 4.8128 - acc: 0.5822 - val_loss: 4.9015 - val_acc: 0.4384\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 772us/step - loss: 3.8723 - acc: 0.5826 - val_loss: 4.0997 - val_acc: 0.4574\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 7s 791us/step - loss: 3.2056 - acc: 0.5934 - val_loss: 3.4980 - val_acc: 0.4321\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 7s 798us/step - loss: 2.7639 - acc: 0.5967 - val_loss: 3.1371 - val_acc: 0.4737\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 778us/step - loss: 2.4452 - acc: 0.5921 - val_loss: 2.8440 - val_acc: 0.4574\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 62s 7ms/step - loss: 7.6061 - acc: 0.4640 - val_loss: 7.3492 - val_acc: 0.5136\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 7.0613 - acc: 0.5882 - val_loss: 7.0901 - val_acc: 0.5417\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 6.7447 - acc: 0.6534 - val_loss: 6.9394 - val_acc: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 6.4925 - acc: 0.6907 - val_loss: 6.7647 - val_acc: 0.5553\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 6.2428 - acc: 0.7281 - val_loss: 6.6160 - val_acc: 0.5543\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.9929 - acc: 0.7746 - val_loss: 6.4262 - val_acc: 0.5725\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.7649 - acc: 0.8052 - val_loss: 6.3399 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.5509 - acc: 0.8286 - val_loss: 6.1511 - val_acc: 0.5580\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.3431 - acc: 0.8516 - val_loss: 6.0540 - val_acc: 0.5643\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.1318 - acc: 0.8801 - val_loss: 5.9066 - val_acc: 0.5661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.9405 - acc: 0.8991 - val_loss: 5.8060 - val_acc: 0.5571\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.7653 - acc: 0.9121 - val_loss: 5.6320 - val_acc: 0.5688\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.5863 - acc: 0.9233 - val_loss: 5.5237 - val_acc: 0.5743\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.4118 - acc: 0.9418 - val_loss: 5.4026 - val_acc: 0.5634\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.2601 - acc: 0.9433 - val_loss: 5.3432 - val_acc: 0.5589\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.1012 - acc: 0.9555 - val_loss: 5.1663 - val_acc: 0.5688\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.9451 - acc: 0.9642 - val_loss: 5.0803 - val_acc: 0.5697\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.7978 - acc: 0.9715 - val_loss: 5.0024 - val_acc: 0.5734\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.6633 - acc: 0.9736 - val_loss: 4.8796 - val_acc: 0.5643\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.5278 - acc: 0.9746 - val_loss: 4.7677 - val_acc: 0.5625\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.4102 - acc: 0.9746 - val_loss: 4.7118 - val_acc: 0.5489\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.2796 - acc: 0.9784 - val_loss: 4.5191 - val_acc: 0.5580\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1703 - acc: 0.9743 - val_loss: 4.5104 - val_acc: 0.5625\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 60s 7ms/step - loss: 6.0280 - acc: 0.2722 - val_loss: 4.5887 - val_acc: 0.3777\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 558us/step - loss: 4.4049 - acc: 0.4311 - val_loss: 4.2373 - val_acc: 0.4611\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 4.0855 - acc: 0.5061 - val_loss: 4.0347 - val_acc: 0.4873\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 3.8112 - acc: 0.5486 - val_loss: 3.7826 - val_acc: 0.5272\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 3.5587 - acc: 0.5793 - val_loss: 3.6073 - val_acc: 0.5226\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 532us/step - loss: 3.3340 - acc: 0.5934 - val_loss: 3.4471 - val_acc: 0.5399\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 5s 533us/step - loss: 3.1225 - acc: 0.6156 - val_loss: 3.2745 - val_acc: 0.5417\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 2.9305 - acc: 0.6245 - val_loss: 3.1568 - val_acc: 0.5335\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 5s 521us/step - loss: 2.7287 - acc: 0.6504 - val_loss: 3.1304 - val_acc: 0.5000\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 5s 539us/step - loss: 2.5957 - acc: 0.6555 - val_loss: 2.9669 - val_acc: 0.5362\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 5s 561us/step - loss: 2.4583 - acc: 0.6624 - val_loss: 2.9740 - val_acc: 0.5127\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 5s 551us/step - loss: 2.3707 - acc: 0.6522 - val_loss: 2.7795 - val_acc: 0.5263\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 5s 548us/step - loss: 2.2688 - acc: 0.6659 - val_loss: 2.7116 - val_acc: 0.5344\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 506us/step - loss: 2.1273 - acc: 0.6986 - val_loss: 2.6267 - val_acc: 0.5254\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 5s 549us/step - loss: 2.0313 - acc: 0.7134 - val_loss: 2.5378 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 5s 546us/step - loss: 1.9731 - acc: 0.7044 - val_loss: 2.6097 - val_acc: 0.5380\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 483us/step - loss: 1.9058 - acc: 0.7204 - val_loss: 2.5286 - val_acc: 0.5362\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 5s 534us/step - loss: 1.8189 - acc: 0.7378 - val_loss: 2.5414 - val_acc: 0.5154\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 5s 524us/step - loss: 1.7787 - acc: 0.7380 - val_loss: 2.4552 - val_acc: 0.5408\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 5s 529us/step - loss: 1.7196 - acc: 0.7500 - val_loss: 2.4460 - val_acc: 0.5408\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 5s 547us/step - loss: 1.6924 - acc: 0.7478 - val_loss: 2.4273 - val_acc: 0.5317\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 5s 519us/step - loss: 1.6034 - acc: 0.7760 - val_loss: 2.4580 - val_acc: 0.5317\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 491us/step - loss: 1.5816 - acc: 0.7766 - val_loss: 2.4532 - val_acc: 0.5226\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 5s 538us/step - loss: 1.5166 - acc: 0.7994 - val_loss: 2.3559 - val_acc: 0.5471\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 5s 544us/step - loss: 1.4637 - acc: 0.8085 - val_loss: 2.5297 - val_acc: 0.5172\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 61s 7ms/step - loss: 4.4600 - acc: 0.4527 - val_loss: 4.2347 - val_acc: 0.5163\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.0619 - acc: 0.5673 - val_loss: 4.1132 - val_acc: 0.5353\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.8842 - acc: 0.6168 - val_loss: 4.0420 - val_acc: 0.5571\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.7388 - acc: 0.6679 - val_loss: 3.9869 - val_acc: 0.5661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 3.6333 - acc: 0.6936 - val_loss: 3.9822 - val_acc: 0.5408\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.5195 - acc: 0.7292 - val_loss: 3.9505 - val_acc: 0.5616\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.4134 - acc: 0.7604 - val_loss: 3.9369 - val_acc: 0.5507\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3209 - acc: 0.7870 - val_loss: 3.9322 - val_acc: 0.5589\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.2398 - acc: 0.8076 - val_loss: 3.8550 - val_acc: 0.5571\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1486 - acc: 0.8379 - val_loss: 3.8371 - val_acc: 0.5643\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0682 - acc: 0.8575 - val_loss: 3.8222 - val_acc: 0.5625\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9882 - acc: 0.8760 - val_loss: 3.7887 - val_acc: 0.5797\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9023 - acc: 0.8991 - val_loss: 3.7820 - val_acc: 0.5716\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.8319 - acc: 0.9149 - val_loss: 3.8026 - val_acc: 0.5743\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.7644 - acc: 0.9265 - val_loss: 3.7756 - val_acc: 0.5697\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.7051 - acc: 0.9363 - val_loss: 3.7553 - val_acc: 0.5598\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.6367 - acc: 0.9529 - val_loss: 3.6838 - val_acc: 0.5661\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.5978 - acc: 0.9519 - val_loss: 3.6937 - val_acc: 0.5670\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.5366 - acc: 0.9647 - val_loss: 3.7115 - val_acc: 0.5661\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.4859 - acc: 0.9660 - val_loss: 3.7011 - val_acc: 0.5697\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.4376 - acc: 0.9711 - val_loss: 3.7151 - val_acc: 0.5408\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3951 - acc: 0.9734 - val_loss: 3.6618 - val_acc: 0.5734\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 61s 7ms/step - loss: 5.3624 - acc: 0.4713 - val_loss: 5.0892 - val_acc: 0.5172\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.8179 - acc: 0.6139 - val_loss: 4.9469 - val_acc: 0.5498\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5431 - acc: 0.6922 - val_loss: 4.8710 - val_acc: 0.5480\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.3181 - acc: 0.7493 - val_loss: 4.7545 - val_acc: 0.5598\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1081 - acc: 0.8019 - val_loss: 4.6947 - val_acc: 0.5543\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9248 - acc: 0.8453 - val_loss: 4.5673 - val_acc: 0.5697\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7510 - acc: 0.8835 - val_loss: 4.5742 - val_acc: 0.5616\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.5953 - acc: 0.9083 - val_loss: 4.4659 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.4312 - acc: 0.9420 - val_loss: 4.4463 - val_acc: 0.5652\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2953 - acc: 0.9557 - val_loss: 4.3103 - val_acc: 0.5707\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1714 - acc: 0.9633 - val_loss: 4.2282 - val_acc: 0.5752\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.0493 - acc: 0.9750 - val_loss: 4.1744 - val_acc: 0.5725\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9258 - acc: 0.9850 - val_loss: 4.0835 - val_acc: 0.5770\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.8107 - acc: 0.9890 - val_loss: 4.0544 - val_acc: 0.5779\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.7174 - acc: 0.9905 - val_loss: 4.0101 - val_acc: 0.5707\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.6314 - acc: 0.9867 - val_loss: 3.9459 - val_acc: 0.5697\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.5380 - acc: 0.9889 - val_loss: 3.9192 - val_acc: 0.5634\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.4510 - acc: 0.9897 - val_loss: 3.8301 - val_acc: 0.5743\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3645 - acc: 0.9879 - val_loss: 3.7705 - val_acc: 0.5598\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3007 - acc: 0.9823 - val_loss: 3.7326 - val_acc: 0.5616\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.2282 - acc: 0.9784 - val_loss: 3.7118 - val_acc: 0.5489\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.1889 - acc: 0.9669 - val_loss: 3.6412 - val_acc: 0.5498\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.0774 - acc: 0.9845 - val_loss: 3.4871 - val_acc: 0.5553\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.9857 - acc: 0.9905 - val_loss: 3.4449 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 60s 7ms/step - loss: 5.6995 - acc: 0.4151 - val_loss: 5.4198 - val_acc: 0.5054\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.3460 - acc: 0.5061 - val_loss: 5.2750 - val_acc: 0.5353\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.2023 - acc: 0.5391 - val_loss: 5.2039 - val_acc: 0.5498\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 5.0694 - acc: 0.5630 - val_loss: 5.1636 - val_acc: 0.5353\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.9684 - acc: 0.5789 - val_loss: 5.0603 - val_acc: 0.5344\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.8629 - acc: 0.6002 - val_loss: 5.0056 - val_acc: 0.5589\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.7750 - acc: 0.6186 - val_loss: 4.9538 - val_acc: 0.5679\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.6847 - acc: 0.6316 - val_loss: 4.8819 - val_acc: 0.5697\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.5916 - acc: 0.6539 - val_loss: 4.8546 - val_acc: 0.5589\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.5125 - acc: 0.6660 - val_loss: 4.7783 - val_acc: 0.5607\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.4354 - acc: 0.6717 - val_loss: 4.7272 - val_acc: 0.5562\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.3599 - acc: 0.6850 - val_loss: 4.6537 - val_acc: 0.5888\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.2727 - acc: 0.6996 - val_loss: 4.6153 - val_acc: 0.5725\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1799 - acc: 0.7145 - val_loss: 4.5902 - val_acc: 0.5752\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.1037 - acc: 0.7291 - val_loss: 4.5518 - val_acc: 0.5770\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.0408 - acc: 0.7341 - val_loss: 4.4970 - val_acc: 0.5933\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.9639 - acc: 0.7476 - val_loss: 4.4544 - val_acc: 0.5915\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.8898 - acc: 0.7592 - val_loss: 4.4521 - val_acc: 0.5779\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.8157 - acc: 0.7738 - val_loss: 4.3653 - val_acc: 0.5861\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.7497 - acc: 0.7756 - val_loss: 4.3629 - val_acc: 0.5752\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.6773 - acc: 0.7913 - val_loss: 4.3322 - val_acc: 0.5634\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.6067 - acc: 0.7986 - val_loss: 4.2684 - val_acc: 0.5824\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.5352 - acc: 0.8124 - val_loss: 4.2547 - val_acc: 0.5661\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.4808 - acc: 0.8156 - val_loss: 4.2131 - val_acc: 0.5734\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.4041 - acc: 0.8286 - val_loss: 4.1815 - val_acc: 0.5725\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3338 - acc: 0.8405 - val_loss: 4.1103 - val_acc: 0.5879\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 51s 6ms/step - loss: 3.3353 - acc: 0.0886 - val_loss: 2.6765 - val_acc: 0.2545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: 2.9559 - acc: 0.1848 - val_loss: 2.4800 - val_acc: 0.3496\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 2.7215 - acc: 0.2693 - val_loss: 2.3991 - val_acc: 0.3904\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 2.5778 - acc: 0.3281 - val_loss: 2.3547 - val_acc: 0.4248\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 2.4682 - acc: 0.3654 - val_loss: 2.3309 - val_acc: 0.4447\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 2.3870 - acc: 0.3875 - val_loss: 2.3097 - val_acc: 0.4601\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 2.3238 - acc: 0.4099 - val_loss: 2.2864 - val_acc: 0.4638\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 2.2664 - acc: 0.4230 - val_loss: 2.2680 - val_acc: 0.4683\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 2.2293 - acc: 0.4409 - val_loss: 2.2576 - val_acc: 0.4764\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.1911 - acc: 0.4534 - val_loss: 2.2498 - val_acc: 0.4828\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 2.1765 - acc: 0.4561 - val_loss: 2.2358 - val_acc: 0.4900\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 2.1421 - acc: 0.4668 - val_loss: 2.2177 - val_acc: 0.4891\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 401us/step - loss: 2.1153 - acc: 0.4732 - val_loss: 2.1995 - val_acc: 0.4937\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 2.0969 - acc: 0.4810 - val_loss: 2.1836 - val_acc: 0.4964\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 407us/step - loss: 2.0764 - acc: 0.4857 - val_loss: 2.1683 - val_acc: 0.4973\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 2.0664 - acc: 0.4899 - val_loss: 2.1526 - val_acc: 0.5018\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 2.0258 - acc: 0.4993 - val_loss: 2.1371 - val_acc: 0.5036\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.0201 - acc: 0.5050 - val_loss: 2.1225 - val_acc: 0.5054\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 414us/step - loss: 1.9969 - acc: 0.5069 - val_loss: 2.1075 - val_acc: 0.5063\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 413us/step - loss: 2.0027 - acc: 0.5076 - val_loss: 2.0926 - val_acc: 0.5036\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 1.9849 - acc: 0.5161 - val_loss: 2.0786 - val_acc: 0.5063\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.9628 - acc: 0.5149 - val_loss: 2.0657 - val_acc: 0.5100\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 1.9581 - acc: 0.5139 - val_loss: 2.0549 - val_acc: 0.5118\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.9417 - acc: 0.5241 - val_loss: 2.0459 - val_acc: 0.5145\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 398us/step - loss: 1.9309 - acc: 0.5289 - val_loss: 2.0390 - val_acc: 0.5172\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 1.9237 - acc: 0.5278 - val_loss: 2.0326 - val_acc: 0.5181\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 1.9117 - acc: 0.5304 - val_loss: 2.0264 - val_acc: 0.5199\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.9014 - acc: 0.5330 - val_loss: 2.0197 - val_acc: 0.5181\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 1.8948 - acc: 0.5339 - val_loss: 2.0123 - val_acc: 0.5199\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 404us/step - loss: 1.8845 - acc: 0.5411 - val_loss: 2.0056 - val_acc: 0.5163\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 3s 371us/step - loss: 1.8731 - acc: 0.5491 - val_loss: 1.9993 - val_acc: 0.5208\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: 1.8656 - acc: 0.5405 - val_loss: 1.9936 - val_acc: 0.5254\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 1.8617 - acc: 0.5454 - val_loss: 1.9887 - val_acc: 0.5299\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: 1.8511 - acc: 0.5528 - val_loss: 1.9833 - val_acc: 0.5299\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 1.8435 - acc: 0.5498 - val_loss: 1.9773 - val_acc: 0.5335\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.8404 - acc: 0.5533 - val_loss: 1.9718 - val_acc: 0.5335\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: 1.8220 - acc: 0.5574 - val_loss: 1.9661 - val_acc: 0.5326\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.8261 - acc: 0.5522 - val_loss: 1.9600 - val_acc: 0.5317\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.8144 - acc: 0.5558 - val_loss: 1.9549 - val_acc: 0.5353\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 3s 360us/step - loss: 1.8090 - acc: 0.5648 - val_loss: 1.9516 - val_acc: 0.5380\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 1.8015 - acc: 0.5673 - val_loss: 1.9498 - val_acc: 0.5380\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 3s 368us/step - loss: 1.7854 - acc: 0.5647 - val_loss: 1.9476 - val_acc: 0.5362\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 3s 369us/step - loss: 1.7823 - acc: 0.5719 - val_loss: 1.9439 - val_acc: 0.5417\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 3s 371us/step - loss: 1.7773 - acc: 0.5648 - val_loss: 1.9393 - val_acc: 0.5435\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 1.7658 - acc: 0.5761 - val_loss: 1.9341 - val_acc: 0.5444\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 1.7731 - acc: 0.5703 - val_loss: 1.9290 - val_acc: 0.5471\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 3s 366us/step - loss: 1.7668 - acc: 0.5728 - val_loss: 1.9258 - val_acc: 0.5498\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: 1.7564 - acc: 0.5780 - val_loss: 1.9226 - val_acc: 0.5507\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 1.7503 - acc: 0.5831 - val_loss: 1.9193 - val_acc: 0.5507\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 1.7489 - acc: 0.5798 - val_loss: 1.9159 - val_acc: 0.5507\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: 1.7344 - acc: 0.5843 - val_loss: 1.9137 - val_acc: 0.5516\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 1.7359 - acc: 0.5851 - val_loss: 1.9117 - val_acc: 0.5498\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 3s 371us/step - loss: 1.7138 - acc: 0.5898 - val_loss: 1.9096 - val_acc: 0.5498\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 1.7198 - acc: 0.5927 - val_loss: 1.9059 - val_acc: 0.5507\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 1.7265 - acc: 0.5852 - val_loss: 1.9038 - val_acc: 0.5480\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 1.7116 - acc: 0.5919 - val_loss: 1.9008 - val_acc: 0.5516\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.7065 - acc: 0.5944 - val_loss: 1.8982 - val_acc: 0.5525\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 1.7036 - acc: 0.5919 - val_loss: 1.8951 - val_acc: 0.5562\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 1.6957 - acc: 0.6003 - val_loss: 1.8923 - val_acc: 0.5534\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 1.6824 - acc: 0.6013 - val_loss: 1.8904 - val_acc: 0.5516\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.6908 - acc: 0.5993 - val_loss: 1.8887 - val_acc: 0.5507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 4s 416us/step - loss: 1.6754 - acc: 0.6009 - val_loss: 1.8861 - val_acc: 0.5507\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 1.6758 - acc: 0.6049 - val_loss: 1.8838 - val_acc: 0.5543\n",
      "Epoch 64/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.6761 - acc: 0.5995 - val_loss: 1.8808 - val_acc: 0.5534\n",
      "Epoch 65/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 1.6702 - acc: 0.6045 - val_loss: 1.8782 - val_acc: 0.5525\n",
      "Epoch 66/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 1.6548 - acc: 0.6081 - val_loss: 1.8744 - val_acc: 0.5580\n",
      "Epoch 67/150\n",
      "8829/8829 [==============================] - 3s 365us/step - loss: 1.6509 - acc: 0.6128 - val_loss: 1.8728 - val_acc: 0.5534\n",
      "Epoch 68/150\n",
      "8829/8829 [==============================] - 3s 370us/step - loss: 1.6454 - acc: 0.6058 - val_loss: 1.8688 - val_acc: 0.5543\n",
      "Epoch 69/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.6451 - acc: 0.6118 - val_loss: 1.8656 - val_acc: 0.5562\n",
      "Epoch 70/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 1.6396 - acc: 0.6106 - val_loss: 1.8643 - val_acc: 0.5553\n",
      "Epoch 71/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 1.6351 - acc: 0.6138 - val_loss: 1.8647 - val_acc: 0.5580\n",
      "Epoch 72/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 1.6204 - acc: 0.6222 - val_loss: 1.8639 - val_acc: 0.5607\n",
      "Epoch 73/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.6337 - acc: 0.6177 - val_loss: 1.8606 - val_acc: 0.5607\n",
      "Epoch 74/150\n",
      "8829/8829 [==============================] - 3s 372us/step - loss: 1.6170 - acc: 0.6164 - val_loss: 1.8565 - val_acc: 0.5625\n",
      "Epoch 75/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 1.6176 - acc: 0.6184 - val_loss: 1.8528 - val_acc: 0.5589\n",
      "Epoch 76/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 1.6106 - acc: 0.6226 - val_loss: 1.8494 - val_acc: 0.5607\n",
      "Epoch 77/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 1.6116 - acc: 0.6212 - val_loss: 1.8484 - val_acc: 0.5598\n",
      "Epoch 78/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 1.6012 - acc: 0.6271 - val_loss: 1.8491 - val_acc: 0.5625\n",
      "Epoch 79/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 1.6014 - acc: 0.6251 - val_loss: 1.8496 - val_acc: 0.5625\n",
      "Epoch 80/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: 1.5942 - acc: 0.6322 - val_loss: 1.8487 - val_acc: 0.5625\n",
      "Epoch 81/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.5844 - acc: 0.6337 - val_loss: 1.8470 - val_acc: 0.5589\n",
      "Epoch 82/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.5807 - acc: 0.6373 - val_loss: 1.8432 - val_acc: 0.5580\n",
      "Epoch 83/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.5814 - acc: 0.6296 - val_loss: 1.8389 - val_acc: 0.5607\n",
      "Epoch 84/150\n",
      "8829/8829 [==============================] - 3s 370us/step - loss: 1.5825 - acc: 0.6311 - val_loss: 1.8345 - val_acc: 0.5625\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 60s 7ms/step - loss: 4.5008 - acc: 0.4692 - val_loss: 4.2768 - val_acc: 0.5236\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.0586 - acc: 0.5795 - val_loss: 4.1982 - val_acc: 0.5181\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.8606 - acc: 0.6462 - val_loss: 4.0752 - val_acc: 0.5589\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.6817 - acc: 0.6972 - val_loss: 4.0508 - val_acc: 0.5489\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.5407 - acc: 0.7343 - val_loss: 3.9991 - val_acc: 0.5543\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.4021 - acc: 0.7697 - val_loss: 3.9357 - val_acc: 0.5598\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.2704 - acc: 0.8089 - val_loss: 3.9066 - val_acc: 0.5670\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.1430 - acc: 0.8414 - val_loss: 3.8591 - val_acc: 0.5616\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0342 - acc: 0.8666 - val_loss: 3.8831 - val_acc: 0.5453\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.9198 - acc: 0.8938 - val_loss: 3.8091 - val_acc: 0.5707\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.8279 - acc: 0.9098 - val_loss: 3.8262 - val_acc: 0.5516\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.7354 - acc: 0.9246 - val_loss: 3.7688 - val_acc: 0.5725\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.6437 - acc: 0.9410 - val_loss: 3.7143 - val_acc: 0.5625\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5420 - acc: 0.9610 - val_loss: 3.7080 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.4632 - acc: 0.9698 - val_loss: 3.6706 - val_acc: 0.5661\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.4117 - acc: 0.9660 - val_loss: 3.6557 - val_acc: 0.5670\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.3463 - acc: 0.9694 - val_loss: 3.5955 - val_acc: 0.5761\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2825 - acc: 0.9730 - val_loss: 3.5648 - val_acc: 0.5652\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2089 - acc: 0.9809 - val_loss: 3.5705 - val_acc: 0.5580\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1481 - acc: 0.9835 - val_loss: 3.5477 - val_acc: 0.5761\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0814 - acc: 0.9899 - val_loss: 3.5842 - val_acc: 0.5607\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0347 - acc: 0.9846 - val_loss: 3.4465 - val_acc: 0.5697\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0018 - acc: 0.9780 - val_loss: 3.4728 - val_acc: 0.5553\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9362 - acc: 0.9847 - val_loss: 3.4134 - val_acc: 0.5725\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8796 - acc: 0.9884 - val_loss: 3.3881 - val_acc: 0.5616\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8303 - acc: 0.9874 - val_loss: 3.4326 - val_acc: 0.5498\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8199 - acc: 0.9741 - val_loss: 3.5096 - val_acc: 0.5371\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.7646 - acc: 0.9795 - val_loss: 3.3794 - val_acc: 0.5471\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.7014 - acc: 0.9864 - val_loss: 3.2388 - val_acc: 0.5670\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.6356 - acc: 0.9917 - val_loss: 3.1361 - val_acc: 0.5625\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 50s 6ms/step - loss: 3.6294 - acc: 0.0881 - val_loss: 3.0105 - val_acc: 0.2699\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 357us/step - loss: 3.2244 - acc: 0.1958 - val_loss: 2.7615 - val_acc: 0.3668\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 3s 370us/step - loss: 2.9657 - acc: 0.2919 - val_loss: 2.6336 - val_acc: 0.4230\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 2.7939 - acc: 0.3498 - val_loss: 2.5662 - val_acc: 0.4366\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 402us/step - loss: 2.6646 - acc: 0.3925 - val_loss: 2.5365 - val_acc: 0.4556\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 4s 415us/step - loss: 2.5917 - acc: 0.4185 - val_loss: 2.5162 - val_acc: 0.4728\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 397us/step - loss: 2.5325 - acc: 0.4412 - val_loss: 2.4955 - val_acc: 0.4746\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 2.4896 - acc: 0.4550 - val_loss: 2.4780 - val_acc: 0.4810\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 406us/step - loss: 2.4361 - acc: 0.4695 - val_loss: 2.4618 - val_acc: 0.4864\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 4s 404us/step - loss: 2.4177 - acc: 0.4794 - val_loss: 2.4455 - val_acc: 0.4810\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 2.3778 - acc: 0.4875 - val_loss: 2.4278 - val_acc: 0.4900\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 4s 401us/step - loss: 2.3648 - acc: 0.4927 - val_loss: 2.4098 - val_acc: 0.4982\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 2.3344 - acc: 0.5022 - val_loss: 2.3921 - val_acc: 0.4928\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 3s 382us/step - loss: 2.3134 - acc: 0.5031 - val_loss: 2.3726 - val_acc: 0.5018\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 2.2891 - acc: 0.5133 - val_loss: 2.3527 - val_acc: 0.5027\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 403us/step - loss: 2.2705 - acc: 0.5197 - val_loss: 2.3332 - val_acc: 0.5091\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 2.2464 - acc: 0.5223 - val_loss: 2.3143 - val_acc: 0.5118\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 2.2269 - acc: 0.5319 - val_loss: 2.2977 - val_acc: 0.5136\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 2.2055 - acc: 0.5378 - val_loss: 2.2831 - val_acc: 0.5118\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 3s 395us/step - loss: 2.2027 - acc: 0.5313 - val_loss: 2.2711 - val_acc: 0.5190\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.1759 - acc: 0.5411 - val_loss: 2.2610 - val_acc: 0.5245\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 2.1672 - acc: 0.5490 - val_loss: 2.2530 - val_acc: 0.5263\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 2.1460 - acc: 0.5551 - val_loss: 2.2450 - val_acc: 0.5281\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 3s 395us/step - loss: 2.1332 - acc: 0.5524 - val_loss: 2.2371 - val_acc: 0.5299\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 2.1286 - acc: 0.5537 - val_loss: 2.2285 - val_acc: 0.5308\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 2.1176 - acc: 0.5575 - val_loss: 2.2197 - val_acc: 0.5317\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 2.1024 - acc: 0.5621 - val_loss: 2.2121 - val_acc: 0.5308\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 2.0941 - acc: 0.5667 - val_loss: 2.2050 - val_acc: 0.5380\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 2.0853 - acc: 0.5690 - val_loss: 2.1976 - val_acc: 0.5371\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 2.0685 - acc: 0.5725 - val_loss: 2.1907 - val_acc: 0.5380\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 2.0647 - acc: 0.5785 - val_loss: 2.1837 - val_acc: 0.5417\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 3s 396us/step - loss: 2.0603 - acc: 0.5744 - val_loss: 2.1774 - val_acc: 0.5453\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.0448 - acc: 0.5797 - val_loss: 2.1710 - val_acc: 0.5453\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 3s 392us/step - loss: 2.0306 - acc: 0.5906 - val_loss: 2.1651 - val_acc: 0.5462\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 2.0302 - acc: 0.5859 - val_loss: 2.1600 - val_acc: 0.5462\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 2.0184 - acc: 0.5870 - val_loss: 2.1566 - val_acc: 0.5480\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 2.0012 - acc: 0.5926 - val_loss: 2.1537 - val_acc: 0.5525\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: 1.9923 - acc: 0.5966 - val_loss: 2.1515 - val_acc: 0.5525\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 4s 462us/step - loss: 1.9889 - acc: 0.5997 - val_loss: 2.1489 - val_acc: 0.5534\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 4s 454us/step - loss: 1.9847 - acc: 0.6013 - val_loss: 2.1461 - val_acc: 0.5516\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 4s 412us/step - loss: 1.9818 - acc: 0.5997 - val_loss: 2.1420 - val_acc: 0.5553\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: 1.9718 - acc: 0.6019 - val_loss: 2.1375 - val_acc: 0.5553\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: 1.9587 - acc: 0.6082 - val_loss: 2.1333 - val_acc: 0.5534\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 1.9462 - acc: 0.6121 - val_loss: 2.1295 - val_acc: 0.5562\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 3s 395us/step - loss: 1.9288 - acc: 0.6208 - val_loss: 2.1265 - val_acc: 0.5607\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 4s 457us/step - loss: 1.9333 - acc: 0.6159 - val_loss: 2.1254 - val_acc: 0.5625\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 1.9204 - acc: 0.6174 - val_loss: 2.1248 - val_acc: 0.5625\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.9244 - acc: 0.6239 - val_loss: 2.1223 - val_acc: 0.5616\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.9108 - acc: 0.6288 - val_loss: 2.1198 - val_acc: 0.5607\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 1.8974 - acc: 0.6309 - val_loss: 2.1172 - val_acc: 0.5607\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 1.8923 - acc: 0.6347 - val_loss: 2.1135 - val_acc: 0.5580\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 1.8959 - acc: 0.6277 - val_loss: 2.1100 - val_acc: 0.5616\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: 1.8816 - acc: 0.6367 - val_loss: 2.1083 - val_acc: 0.5652\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.8795 - acc: 0.6326 - val_loss: 2.1067 - val_acc: 0.5670\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.8745 - acc: 0.6405 - val_loss: 2.1051 - val_acc: 0.5634\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.8607 - acc: 0.6428 - val_loss: 2.1023 - val_acc: 0.5661\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 1.8505 - acc: 0.6453 - val_loss: 2.0996 - val_acc: 0.5670\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 1.8561 - acc: 0.6461 - val_loss: 2.0988 - val_acc: 0.5679\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.8402 - acc: 0.6531 - val_loss: 2.0984 - val_acc: 0.5707\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.8387 - acc: 0.6484 - val_loss: 2.0966 - val_acc: 0.5707\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.8311 - acc: 0.6506 - val_loss: 2.0939 - val_acc: 0.5707\n",
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 1.8225 - acc: 0.6573 - val_loss: 2.0898 - val_acc: 0.5743\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.8226 - acc: 0.6522 - val_loss: 2.0872 - val_acc: 0.5707\n",
      "Epoch 64/150\n",
      "8829/8829 [==============================] - 3s 383us/step - loss: 1.8098 - acc: 0.6547 - val_loss: 2.0853 - val_acc: 0.5743\n",
      "Epoch 65/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.8084 - acc: 0.6559 - val_loss: 2.0846 - val_acc: 0.5743\n",
      "Epoch 66/150\n",
      "8829/8829 [==============================] - 4s 400us/step - loss: 1.7996 - acc: 0.6626 - val_loss: 2.0855 - val_acc: 0.5707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150\n",
      "8829/8829 [==============================] - 4s 425us/step - loss: 1.7913 - acc: 0.6685 - val_loss: 2.0849 - val_acc: 0.5725\n",
      "Epoch 68/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 1.7864 - acc: 0.6651 - val_loss: 2.0825 - val_acc: 0.5707\n",
      "Epoch 69/150\n",
      "8829/8829 [==============================] - 4s 450us/step - loss: 1.7777 - acc: 0.6678 - val_loss: 2.0789 - val_acc: 0.5734\n",
      "Epoch 70/150\n",
      "8829/8829 [==============================] - 4s 448us/step - loss: 1.7703 - acc: 0.6704 - val_loss: 2.0761 - val_acc: 0.5815\n",
      "Epoch 71/150\n",
      "8829/8829 [==============================] - 3s 396us/step - loss: 1.7694 - acc: 0.6738 - val_loss: 2.0744 - val_acc: 0.5806\n",
      "Epoch 72/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 1.7608 - acc: 0.6756 - val_loss: 2.0733 - val_acc: 0.5815\n",
      "Epoch 73/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.7517 - acc: 0.6763 - val_loss: 2.0732 - val_acc: 0.5806\n",
      "Epoch 74/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.7545 - acc: 0.6730 - val_loss: 2.0717 - val_acc: 0.5788\n",
      "Epoch 75/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.7461 - acc: 0.6798 - val_loss: 2.0681 - val_acc: 0.5788\n",
      "Epoch 76/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 1.7389 - acc: 0.6822 - val_loss: 2.0650 - val_acc: 0.5770\n",
      "Epoch 77/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.7341 - acc: 0.6866 - val_loss: 2.0645 - val_acc: 0.5806\n",
      "Epoch 78/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.7281 - acc: 0.6882 - val_loss: 2.0649 - val_acc: 0.5797\n",
      "Epoch 79/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 1.7169 - acc: 0.6936 - val_loss: 2.0657 - val_acc: 0.5797\n",
      "Epoch 80/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 1.7172 - acc: 0.6892 - val_loss: 2.0634 - val_acc: 0.5806\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 61s 7ms/step - loss: 6.5798 - acc: 0.4726 - val_loss: 6.2830 - val_acc: 0.5254\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.9707 - acc: 0.6004 - val_loss: 6.0693 - val_acc: 0.5263\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 5.5859 - acc: 0.6686 - val_loss: 5.7944 - val_acc: 0.5426\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 5.2311 - acc: 0.7288 - val_loss: 5.6331 - val_acc: 0.5498\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.9146 - acc: 0.7825 - val_loss: 5.4249 - val_acc: 0.5679\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.6237 - acc: 0.8125 - val_loss: 5.1982 - val_acc: 0.5571\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 4.3398 - acc: 0.8529 - val_loss: 5.0756 - val_acc: 0.5380\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 4.0851 - acc: 0.8789 - val_loss: 4.8310 - val_acc: 0.5643\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 3.8356 - acc: 0.9061 - val_loss: 4.6935 - val_acc: 0.5516\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.6063 - acc: 0.9239 - val_loss: 4.5820 - val_acc: 0.5435\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.3888 - acc: 0.9426 - val_loss: 4.3911 - val_acc: 0.5607\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.1847 - acc: 0.9551 - val_loss: 4.2544 - val_acc: 0.5580\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 3.0068 - acc: 0.9625 - val_loss: 4.1517 - val_acc: 0.5553\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.8410 - acc: 0.9650 - val_loss: 4.0532 - val_acc: 0.5553\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7053 - acc: 0.9592 - val_loss: 4.0177 - val_acc: 0.5245\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 54s 6ms/step - loss: 18.1974 - acc: 0.4105 - val_loss: 16.7385 - val_acc: 0.4855\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 6s 722us/step - loss: 15.4502 - acc: 0.5682 - val_loss: 14.2953 - val_acc: 0.5181\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 6s 698us/step - loss: 13.0276 - acc: 0.6156 - val_loss: 12.0979 - val_acc: 0.5290\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 7s 771us/step - loss: 10.8945 - acc: 0.6508 - val_loss: 10.2751 - val_acc: 0.5254\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 7s 800us/step - loss: 9.1425 - acc: 0.6607 - val_loss: 8.6891 - val_acc: 0.5453\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 7s 801us/step - loss: 7.6712 - acc: 0.6868 - val_loss: 7.3952 - val_acc: 0.5498\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 7s 780us/step - loss: 6.5037 - acc: 0.6927 - val_loss: 6.3659 - val_acc: 0.5480\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 7s 794us/step - loss: 5.5309 - acc: 0.7145 - val_loss: 5.6051 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 7s 817us/step - loss: 4.7869 - acc: 0.7100 - val_loss: 4.9702 - val_acc: 0.5380\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 7s 782us/step - loss: 4.2020 - acc: 0.7141 - val_loss: 4.4765 - val_acc: 0.5344\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 7s 756us/step - loss: 3.6955 - acc: 0.7291 - val_loss: 3.9843 - val_acc: 0.5498\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 7s 761us/step - loss: 3.2935 - acc: 0.7309 - val_loss: 3.7268 - val_acc: 0.5299\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 2.9950 - acc: 0.7241 - val_loss: 3.4176 - val_acc: 0.5317\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 6s 713us/step - loss: 2.7091 - acc: 0.7462 - val_loss: 3.2881 - val_acc: 0.5362\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 6s 704us/step - loss: 2.5166 - acc: 0.7386 - val_loss: 3.0644 - val_acc: 0.5299\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 7s 787us/step - loss: 2.3073 - acc: 0.7516 - val_loss: 2.9287 - val_acc: 0.5263\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 2.1753 - acc: 0.7531 - val_loss: 2.8218 - val_acc: 0.5145\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 7s 807us/step - loss: 2.0507 - acc: 0.7589 - val_loss: 2.7081 - val_acc: 0.5553\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 7s 779us/step - loss: 1.9040 - acc: 0.7772 - val_loss: 2.6131 - val_acc: 0.5534\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 1.7932 - acc: 0.7816 - val_loss: 2.6028 - val_acc: 0.5208\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 1.7345 - acc: 0.7768 - val_loss: 2.4883 - val_acc: 0.5190\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 7s 785us/step - loss: 1.6816 - acc: 0.7746 - val_loss: 2.3541 - val_acc: 0.5598\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 7s 746us/step - loss: 1.5959 - acc: 0.7883 - val_loss: 2.5470 - val_acc: 0.5308\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 7s 790us/step - loss: 1.5408 - acc: 0.7947 - val_loss: 2.4378 - val_acc: 0.5335\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 7s 751us/step - loss: 1.4773 - acc: 0.8019 - val_loss: 2.3251 - val_acc: 0.5679\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: 1.4304 - acc: 0.8079 - val_loss: 2.3346 - val_acc: 0.5625\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 1.4162 - acc: 0.8010 - val_loss: 2.2575 - val_acc: 0.5625\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 7s 781us/step - loss: 1.3732 - acc: 0.8084 - val_loss: 2.2854 - val_acc: 0.5553\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 7s 797us/step - loss: 1.3179 - acc: 0.8163 - val_loss: 2.3198 - val_acc: 0.5317\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 7s 793us/step - loss: 1.2870 - acc: 0.8234 - val_loss: 2.2227 - val_acc: 0.5516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 7s 764us/step - loss: 1.2400 - acc: 0.8334 - val_loss: 2.2395 - val_acc: 0.5417\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 7s 763us/step - loss: 1.1984 - acc: 0.8403 - val_loss: 2.4149 - val_acc: 0.5163\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 7s 739us/step - loss: 1.2494 - acc: 0.8170 - val_loss: 2.3440 - val_acc: 0.5362\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 7s 766us/step - loss: 1.2451 - acc: 0.8116 - val_loss: 2.3322 - val_acc: 0.5317\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 6s 726us/step - loss: 1.2021 - acc: 0.8323 - val_loss: 2.2243 - val_acc: 0.5453\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 57s 7ms/step - loss: 3.5052 - acc: 0.0914 - val_loss: 2.8355 - val_acc: 0.2871\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 5s 552us/step - loss: 3.0822 - acc: 0.2133 - val_loss: 2.6197 - val_acc: 0.3841\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 4s 422us/step - loss: 2.8277 - acc: 0.2955 - val_loss: 2.5317 - val_acc: 0.4203\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 2.6632 - acc: 0.3572 - val_loss: 2.5043 - val_acc: 0.4565\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 2.5559 - acc: 0.3998 - val_loss: 2.5029 - val_acc: 0.4620\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 5s 553us/step - loss: 2.4838 - acc: 0.4250 - val_loss: 2.4920 - val_acc: 0.4764\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 2.4206 - acc: 0.4469 - val_loss: 2.4758 - val_acc: 0.4837\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 3s 382us/step - loss: 2.3810 - acc: 0.4606 - val_loss: 2.4629 - val_acc: 0.4928\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 4s 397us/step - loss: 2.3438 - acc: 0.4743 - val_loss: 2.4485 - val_acc: 0.4891\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 2.3107 - acc: 0.4790 - val_loss: 2.4250 - val_acc: 0.4918\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 3s 382us/step - loss: 2.2901 - acc: 0.4832 - val_loss: 2.3964 - val_acc: 0.4937\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 2.2659 - acc: 0.4909 - val_loss: 2.3696 - val_acc: 0.4964\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 2.2377 - acc: 0.4987 - val_loss: 2.3462 - val_acc: 0.5009\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 4s 398us/step - loss: 2.2130 - acc: 0.5049 - val_loss: 2.3228 - val_acc: 0.5063\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 3s 374us/step - loss: 2.1851 - acc: 0.5115 - val_loss: 2.2985 - val_acc: 0.5127\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 4s 406us/step - loss: 2.1713 - acc: 0.5175 - val_loss: 2.2765 - val_acc: 0.5154\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 4s 469us/step - loss: 2.1532 - acc: 0.5203 - val_loss: 2.2554 - val_acc: 0.5118\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 4s 428us/step - loss: 2.1408 - acc: 0.5267 - val_loss: 2.2350 - val_acc: 0.5163\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 4s 460us/step - loss: 2.1122 - acc: 0.5293 - val_loss: 2.2173 - val_acc: 0.5217\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 4s 447us/step - loss: 2.1055 - acc: 0.5318 - val_loss: 2.2027 - val_acc: 0.5217\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 403us/step - loss: 2.0895 - acc: 0.5423 - val_loss: 2.1910 - val_acc: 0.5263\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 2.0725 - acc: 0.5462 - val_loss: 2.1819 - val_acc: 0.5254\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 3s 396us/step - loss: 2.0692 - acc: 0.5451 - val_loss: 2.1745 - val_acc: 0.5272\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 4s 416us/step - loss: 2.0488 - acc: 0.5468 - val_loss: 2.1679 - val_acc: 0.5272\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 4s 405us/step - loss: 2.0384 - acc: 0.5517 - val_loss: 2.1576 - val_acc: 0.5335\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 2.0258 - acc: 0.5554 - val_loss: 2.1457 - val_acc: 0.5380\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 2.0197 - acc: 0.5507 - val_loss: 2.1361 - val_acc: 0.5399\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 2.0159 - acc: 0.5571 - val_loss: 2.1317 - val_acc: 0.5453\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 3s 378us/step - loss: 2.0011 - acc: 0.5613 - val_loss: 2.1298 - val_acc: 0.5489\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 4s 416us/step - loss: 1.9945 - acc: 0.5609 - val_loss: 2.1266 - val_acc: 0.5543\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 1.9846 - acc: 0.5659 - val_loss: 2.1216 - val_acc: 0.5471\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.9655 - acc: 0.5691 - val_loss: 2.1179 - val_acc: 0.5426\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 3s 389us/step - loss: 1.9510 - acc: 0.5809 - val_loss: 2.1138 - val_acc: 0.5471\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 1.9531 - acc: 0.5723 - val_loss: 2.1096 - val_acc: 0.5507\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: 1.9387 - acc: 0.5827 - val_loss: 2.1062 - val_acc: 0.5543\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 4s 415us/step - loss: 1.9361 - acc: 0.5881 - val_loss: 2.1021 - val_acc: 0.5562\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.9199 - acc: 0.5881 - val_loss: 2.0981 - val_acc: 0.5543\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.9247 - acc: 0.5852 - val_loss: 2.0938 - val_acc: 0.5534\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.9137 - acc: 0.5901 - val_loss: 2.0911 - val_acc: 0.5507\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 1.9051 - acc: 0.5909 - val_loss: 2.0900 - val_acc: 0.5516\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 1.9041 - acc: 0.5926 - val_loss: 2.0882 - val_acc: 0.5516\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 4s 422us/step - loss: 1.8942 - acc: 0.5968 - val_loss: 2.0834 - val_acc: 0.5534\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 1.8768 - acc: 0.6023 - val_loss: 2.0794 - val_acc: 0.5553\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 4s 406us/step - loss: 1.8770 - acc: 0.6068 - val_loss: 2.0771 - val_acc: 0.5562\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 3s 391us/step - loss: 1.8659 - acc: 0.6070 - val_loss: 2.0749 - val_acc: 0.5562\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 4s 408us/step - loss: 1.8637 - acc: 0.6019 - val_loss: 2.0732 - val_acc: 0.5571\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 4s 398us/step - loss: 1.8500 - acc: 0.6111 - val_loss: 2.0718 - val_acc: 0.5607\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: 1.8410 - acc: 0.6087 - val_loss: 2.0697 - val_acc: 0.5580\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 4s 415us/step - loss: 1.8330 - acc: 0.6137 - val_loss: 2.0672 - val_acc: 0.5580\n",
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.8336 - acc: 0.6125 - val_loss: 2.0657 - val_acc: 0.5616\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 1.8237 - acc: 0.6124 - val_loss: 2.0641 - val_acc: 0.5625\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 4s 407us/step - loss: 1.8240 - acc: 0.6163 - val_loss: 2.0610 - val_acc: 0.5616\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 4s 431us/step - loss: 1.8114 - acc: 0.6163 - val_loss: 2.0579 - val_acc: 0.5616\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 1.8030 - acc: 0.6240 - val_loss: 2.0536 - val_acc: 0.5643\n",
      "Epoch 55/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 4s 433us/step - loss: 1.7941 - acc: 0.6273 - val_loss: 2.0506 - val_acc: 0.5697\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: 1.7913 - acc: 0.6245 - val_loss: 2.0473 - val_acc: 0.5688\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 1.7851 - acc: 0.6259 - val_loss: 2.0470 - val_acc: 0.5661\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 1.7774 - acc: 0.6306 - val_loss: 2.0457 - val_acc: 0.5634\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 4s 403us/step - loss: 1.7627 - acc: 0.6353 - val_loss: 2.0422 - val_acc: 0.5634\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 4s 420us/step - loss: 1.7680 - acc: 0.6318 - val_loss: 2.0363 - val_acc: 0.5661\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 4s 411us/step - loss: 1.7672 - acc: 0.6360 - val_loss: 2.0319 - val_acc: 0.5652\n",
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.7564 - acc: 0.6345 - val_loss: 2.0323 - val_acc: 0.5643\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 4s 404us/step - loss: 1.7523 - acc: 0.6411 - val_loss: 2.0343 - val_acc: 0.5652\n",
      "Epoch 64/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.7342 - acc: 0.6449 - val_loss: 2.0368 - val_acc: 0.5697\n",
      "Epoch 65/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 1.7335 - acc: 0.6432 - val_loss: 2.0337 - val_acc: 0.5679\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 54s 6ms/step - loss: 3.3582 - acc: 0.0871 - val_loss: 2.6324 - val_acc: 0.3252\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 355us/step - loss: 2.7726 - acc: 0.2647 - val_loss: 2.3921 - val_acc: 0.4067\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: 2.5127 - acc: 0.3576 - val_loss: 2.3063 - val_acc: 0.4511\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 2.3736 - acc: 0.4102 - val_loss: 2.2614 - val_acc: 0.4710\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 2.2925 - acc: 0.4355 - val_loss: 2.2328 - val_acc: 0.4746\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 3s 382us/step - loss: 2.2379 - acc: 0.4570 - val_loss: 2.2143 - val_acc: 0.4583\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 2.1848 - acc: 0.4663 - val_loss: 2.1881 - val_acc: 0.4719\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 3s 369us/step - loss: 2.1428 - acc: 0.4854 - val_loss: 2.1554 - val_acc: 0.4828\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 2.1046 - acc: 0.4946 - val_loss: 2.1243 - val_acc: 0.4973\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 2.0585 - acc: 0.5099 - val_loss: 2.0978 - val_acc: 0.5091\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 3s 369us/step - loss: 2.0373 - acc: 0.5139 - val_loss: 2.0731 - val_acc: 0.5263\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 3s 371us/step - loss: 2.0168 - acc: 0.5229 - val_loss: 2.0496 - val_acc: 0.5281\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.9781 - acc: 0.5313 - val_loss: 2.0280 - val_acc: 0.5254\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 3s 381us/step - loss: 1.9608 - acc: 0.5388 - val_loss: 2.0080 - val_acc: 0.5263\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.9373 - acc: 0.5363 - val_loss: 1.9898 - val_acc: 0.5290\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 3s 373us/step - loss: 1.9136 - acc: 0.5534 - val_loss: 1.9744 - val_acc: 0.5326\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 1.8953 - acc: 0.5520 - val_loss: 1.9628 - val_acc: 0.5308\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.8737 - acc: 0.5629 - val_loss: 1.9530 - val_acc: 0.5353\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.8548 - acc: 0.5689 - val_loss: 1.9449 - val_acc: 0.5399\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 3s 394us/step - loss: 1.8482 - acc: 0.5664 - val_loss: 1.9390 - val_acc: 0.5380\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 4s 399us/step - loss: 1.8228 - acc: 0.5793 - val_loss: 1.9338 - val_acc: 0.5453\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 3s 375us/step - loss: 1.8051 - acc: 0.5812 - val_loss: 1.9285 - val_acc: 0.5489\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 3s 388us/step - loss: 1.7949 - acc: 0.5866 - val_loss: 1.9217 - val_acc: 0.5498\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 3s 385us/step - loss: 1.7784 - acc: 0.5883 - val_loss: 1.9146 - val_acc: 0.5498\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.7736 - acc: 0.5889 - val_loss: 1.9090 - val_acc: 0.5480\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 4s 410us/step - loss: 1.7541 - acc: 0.5967 - val_loss: 1.9057 - val_acc: 0.5534\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 3s 387us/step - loss: 1.7424 - acc: 0.5998 - val_loss: 1.9031 - val_acc: 0.5525\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 3s 393us/step - loss: 1.7344 - acc: 0.6003 - val_loss: 1.9004 - val_acc: 0.5562\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 3s 384us/step - loss: 1.7128 - acc: 0.6114 - val_loss: 1.8949 - val_acc: 0.5580\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 3s 379us/step - loss: 1.7003 - acc: 0.6175 - val_loss: 1.8879 - val_acc: 0.5607\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 1.6920 - acc: 0.6140 - val_loss: 1.8800 - val_acc: 0.5634\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: 1.6892 - acc: 0.6199 - val_loss: 1.8732 - val_acc: 0.5643\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 4s 443us/step - loss: 1.6728 - acc: 0.6202 - val_loss: 1.8697 - val_acc: 0.5607\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: 1.6597 - acc: 0.6306 - val_loss: 1.8673 - val_acc: 0.5625\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 4s 417us/step - loss: 1.6561 - acc: 0.6256 - val_loss: 1.8647 - val_acc: 0.5625\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 4s 413us/step - loss: 1.6323 - acc: 0.6345 - val_loss: 1.8612 - val_acc: 0.5625\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 4s 402us/step - loss: 1.6252 - acc: 0.6412 - val_loss: 1.8570 - val_acc: 0.5643\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 1.6208 - acc: 0.6430 - val_loss: 1.8521 - val_acc: 0.5670\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 3s 345us/step - loss: 1.6096 - acc: 0.6458 - val_loss: 1.8478 - val_acc: 0.5679\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 3s 366us/step - loss: 1.5995 - acc: 0.6540 - val_loss: 1.8450 - val_acc: 0.5679\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 3s 376us/step - loss: 1.5904 - acc: 0.6560 - val_loss: 1.8432 - val_acc: 0.5716\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 3s 343us/step - loss: 1.5888 - acc: 0.6535 - val_loss: 1.8412 - val_acc: 0.5661\n",
      "Epoch 43/150\n",
      "8829/8829 [==============================] - 3s 344us/step - loss: 1.5698 - acc: 0.6616 - val_loss: 1.8377 - val_acc: 0.5679\n",
      "Epoch 44/150\n",
      "8829/8829 [==============================] - 3s 340us/step - loss: 1.5625 - acc: 0.6610 - val_loss: 1.8339 - val_acc: 0.5725\n",
      "Epoch 45/150\n",
      "8829/8829 [==============================] - 3s 341us/step - loss: 1.5564 - acc: 0.6647 - val_loss: 1.8314 - val_acc: 0.5734\n",
      "Epoch 46/150\n",
      "8829/8829 [==============================] - 3s 343us/step - loss: 1.5442 - acc: 0.6670 - val_loss: 1.8299 - val_acc: 0.5779\n",
      "Epoch 47/150\n",
      "8829/8829 [==============================] - 3s 352us/step - loss: 1.5392 - acc: 0.6731 - val_loss: 1.8275 - val_acc: 0.5779\n",
      "Epoch 48/150\n",
      "8829/8829 [==============================] - 3s 363us/step - loss: 1.5303 - acc: 0.6773 - val_loss: 1.8254 - val_acc: 0.5815\n",
      "Epoch 49/150\n",
      "8829/8829 [==============================] - 3s 364us/step - loss: 1.5127 - acc: 0.6839 - val_loss: 1.8242 - val_acc: 0.5824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "8829/8829 [==============================] - 3s 351us/step - loss: 1.5088 - acc: 0.6883 - val_loss: 1.8226 - val_acc: 0.5806\n",
      "Epoch 51/150\n",
      "8829/8829 [==============================] - 3s 390us/step - loss: 1.4981 - acc: 0.6898 - val_loss: 1.8217 - val_acc: 0.5779\n",
      "Epoch 52/150\n",
      "8829/8829 [==============================] - 3s 386us/step - loss: 1.4974 - acc: 0.6902 - val_loss: 1.8219 - val_acc: 0.5779\n",
      "Epoch 53/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: 1.4918 - acc: 0.6931 - val_loss: 1.8214 - val_acc: 0.5761\n",
      "Epoch 54/150\n",
      "8829/8829 [==============================] - 4s 398us/step - loss: 1.4818 - acc: 0.6979 - val_loss: 1.8197 - val_acc: 0.5770\n",
      "Epoch 55/150\n",
      "8829/8829 [==============================] - 4s 401us/step - loss: 1.4667 - acc: 0.6971 - val_loss: 1.8174 - val_acc: 0.5815\n",
      "Epoch 56/150\n",
      "8829/8829 [==============================] - 3s 380us/step - loss: 1.4660 - acc: 0.7002 - val_loss: 1.8146 - val_acc: 0.5815\n",
      "Epoch 57/150\n",
      "8829/8829 [==============================] - 3s 349us/step - loss: 1.4544 - acc: 0.7017 - val_loss: 1.8124 - val_acc: 0.5824\n",
      "Epoch 58/150\n",
      "8829/8829 [==============================] - 3s 359us/step - loss: 1.4512 - acc: 0.7086 - val_loss: 1.8109 - val_acc: 0.5842\n",
      "Epoch 59/150\n",
      "8829/8829 [==============================] - 3s 339us/step - loss: 1.4403 - acc: 0.7057 - val_loss: 1.8111 - val_acc: 0.5851\n",
      "Epoch 60/150\n",
      "8829/8829 [==============================] - 3s 344us/step - loss: 1.4349 - acc: 0.7107 - val_loss: 1.8092 - val_acc: 0.5870\n",
      "Epoch 61/150\n",
      "8829/8829 [==============================] - 3s 336us/step - loss: 1.4208 - acc: 0.7164 - val_loss: 1.8071 - val_acc: 0.5797\n",
      "Epoch 62/150\n",
      "8829/8829 [==============================] - 3s 342us/step - loss: 1.4151 - acc: 0.7197 - val_loss: 1.8067 - val_acc: 0.5815\n",
      "Epoch 63/150\n",
      "8829/8829 [==============================] - 3s 336us/step - loss: 1.4034 - acc: 0.7285 - val_loss: 1.8082 - val_acc: 0.5761\n",
      "Epoch 64/150\n",
      "8829/8829 [==============================] - 3s 344us/step - loss: 1.4006 - acc: 0.7250 - val_loss: 1.8092 - val_acc: 0.5806\n",
      "Epoch 65/150\n",
      "8829/8829 [==============================] - 3s 333us/step - loss: 1.3888 - acc: 0.7261 - val_loss: 1.8088 - val_acc: 0.5788\n",
      "Epoch 66/150\n",
      "8829/8829 [==============================] - 3s 332us/step - loss: 1.3832 - acc: 0.7299 - val_loss: 1.8083 - val_acc: 0.5797\n",
      "Epoch 67/150\n",
      "8829/8829 [==============================] - 3s 339us/step - loss: 1.3736 - acc: 0.7343 - val_loss: 1.8089 - val_acc: 0.5797\n",
      "Epoch 68/150\n",
      "8829/8829 [==============================] - 3s 366us/step - loss: 1.3640 - acc: 0.7356 - val_loss: 1.8095 - val_acc: 0.5761\n",
      "Epoch 69/150\n",
      "8829/8829 [==============================] - 4s 409us/step - loss: 1.3645 - acc: 0.7399 - val_loss: 1.8097 - val_acc: 0.5770\n",
      "Epoch 70/150\n",
      "8829/8829 [==============================] - 4s 430us/step - loss: 1.3541 - acc: 0.7432 - val_loss: 1.8097 - val_acc: 0.5752\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 52s 6ms/step - loss: 3.6380 - acc: 0.0876 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 3s 377us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 5s 510us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 4s 455us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 4s 482us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 3s 362us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 3s 336us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 3s 352us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 3s 346us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 3s 361us/step - loss: nan - acc: 0.0695 - val_loss: nan - val_acc: 0.0661\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 64s 7ms/step - loss: 4.8420 - acc: 0.4683 - val_loss: 4.5988 - val_acc: 0.5109\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 4.3006 - acc: 0.6056 - val_loss: 4.4389 - val_acc: 0.5217\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 4.0080 - acc: 0.6715 - val_loss: 4.2895 - val_acc: 0.5462\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.7652 - acc: 0.7282 - val_loss: 4.1632 - val_acc: 0.5580\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.5559 - acc: 0.7706 - val_loss: 4.0641 - val_acc: 0.5734\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.3311 - acc: 0.8227 - val_loss: 3.9832 - val_acc: 0.5716\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1569 - acc: 0.8537 - val_loss: 3.8841 - val_acc: 0.5625\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9550 - acc: 0.8906 - val_loss: 3.8336 - val_acc: 0.5571\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.7830 - acc: 0.9201 - val_loss: 3.7492 - val_acc: 0.5444\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.6353 - acc: 0.9362 - val_loss: 3.6546 - val_acc: 0.5707\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5000 - acc: 0.9505 - val_loss: 3.5674 - val_acc: 0.5525\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3724 - acc: 0.9540 - val_loss: 3.5073 - val_acc: 0.5652\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2237 - acc: 0.9810 - val_loss: 3.4607 - val_acc: 0.5697\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1195 - acc: 0.9760 - val_loss: 3.4378 - val_acc: 0.5426\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.0425 - acc: 0.9710 - val_loss: 3.4328 - val_acc: 0.5562\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 62s 7ms/step - loss: 3.6832 - acc: 0.4712 - val_loss: 3.4720 - val_acc: 0.5036\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1434 - acc: 0.6280 - val_loss: 3.3494 - val_acc: 0.5462\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.9135 - acc: 0.7099 - val_loss: 3.2991 - val_acc: 0.5543\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 2.7254 - acc: 0.7637 - val_loss: 3.3229 - val_acc: 0.5181\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 2.5613 - acc: 0.8233 - val_loss: 3.2494 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 2.4007 - acc: 0.8756 - val_loss: 3.2061 - val_acc: 0.5543\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.2785 - acc: 0.9114 - val_loss: 3.1984 - val_acc: 0.5553\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.1532 - acc: 0.9438 - val_loss: 3.2189 - val_acc: 0.5507\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.0468 - acc: 0.9634 - val_loss: 3.1758 - val_acc: 0.5525\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.9432 - acc: 0.9803 - val_loss: 3.1423 - val_acc: 0.5589\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.8637 - acc: 0.9889 - val_loss: 3.1610 - val_acc: 0.5543\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.7953 - acc: 0.9918 - val_loss: 3.1616 - val_acc: 0.5444\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.7386 - acc: 0.9937 - val_loss: 3.1509 - val_acc: 0.5543\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 1.7126 - acc: 0.9840 - val_loss: 3.1341 - val_acc: 0.5534\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.6663 - acc: 0.9831 - val_loss: 3.0969 - val_acc: 0.5598\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.6249 - acc: 0.9838 - val_loss: 3.1243 - val_acc: 0.5480\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.5560 - acc: 0.9909 - val_loss: 3.0685 - val_acc: 0.5534\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.4907 - acc: 0.9954 - val_loss: 3.0096 - val_acc: 0.5534\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 1.4312 - acc: 0.9965 - val_loss: 3.0131 - val_acc: 0.5525\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.4423 - acc: 0.9778 - val_loss: 3.2111 - val_acc: 0.5181\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.5933 - acc: 0.9081 - val_loss: 3.0549 - val_acc: 0.5272\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.4743 - acc: 0.9472 - val_loss: 2.9526 - val_acc: 0.5326\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.3333 - acc: 0.9896 - val_loss: 2.8630 - val_acc: 0.5607\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.2507 - acc: 0.9991 - val_loss: 2.7752 - val_acc: 0.5625\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.1988 - acc: 0.9995 - val_loss: 2.7296 - val_acc: 0.5688\n",
      "Epoch 26/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.1531 - acc: 0.9997 - val_loss: 2.7135 - val_acc: 0.5734\n",
      "Epoch 27/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.1097 - acc: 0.9998 - val_loss: 2.6755 - val_acc: 0.5679\n",
      "Epoch 28/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.0669 - acc: 0.9997 - val_loss: 2.6404 - val_acc: 0.5634\n",
      "Epoch 29/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.0241 - acc: 0.9998 - val_loss: 2.6145 - val_acc: 0.5707\n",
      "Epoch 30/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.9828 - acc: 0.9995 - val_loss: 2.5776 - val_acc: 0.5688\n",
      "Epoch 31/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.9422 - acc: 0.9995 - val_loss: 2.5351 - val_acc: 0.5806\n",
      "Epoch 32/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 0.9006 - acc: 0.9998 - val_loss: 2.4913 - val_acc: 0.5815\n",
      "Epoch 33/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.8610 - acc: 0.9998 - val_loss: 2.4799 - val_acc: 0.5670\n",
      "Epoch 34/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 0.8412 - acc: 0.9955 - val_loss: 3.1605 - val_acc: 0.4973\n",
      "Epoch 35/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 1.9842 - acc: 0.6386 - val_loss: 2.4332 - val_acc: 0.5082\n",
      "Epoch 36/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 1.3433 - acc: 0.8132 - val_loss: 2.3697 - val_acc: 0.5371\n",
      "Epoch 37/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.0389 - acc: 0.9395 - val_loss: 2.3642 - val_acc: 0.5480\n",
      "Epoch 38/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.8960 - acc: 0.9828 - val_loss: 2.3708 - val_acc: 0.5498\n",
      "Epoch 39/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.8313 - acc: 0.9934 - val_loss: 2.3354 - val_acc: 0.5553\n",
      "Epoch 40/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 0.7815 - acc: 0.9986 - val_loss: 2.3203 - val_acc: 0.5462\n",
      "Epoch 41/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.7517 - acc: 0.9981 - val_loss: 2.3003 - val_acc: 0.5688\n",
      "Epoch 42/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 0.7192 - acc: 0.9992 - val_loss: 2.2921 - val_acc: 0.5752\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 64s 7ms/step - loss: 3.3009 - acc: 0.4520 - val_loss: 3.0706 - val_acc: 0.5199\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.8647 - acc: 0.5830 - val_loss: 2.9699 - val_acc: 0.5408\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.6793 - acc: 0.6390 - val_loss: 2.9680 - val_acc: 0.5444\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.5393 - acc: 0.6915 - val_loss: 2.9186 - val_acc: 0.5444\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.4225 - acc: 0.7290 - val_loss: 2.9307 - val_acc: 0.5489\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 2.3056 - acc: 0.7759 - val_loss: 2.8676 - val_acc: 0.5571\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2092 - acc: 0.8096 - val_loss: 2.8634 - val_acc: 0.5580\n",
      "Epoch 8/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1166 - acc: 0.8455 - val_loss: 2.9007 - val_acc: 0.5607\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0286 - acc: 0.8736 - val_loss: 2.9084 - val_acc: 0.5534\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.9479 - acc: 0.8987 - val_loss: 2.9100 - val_acc: 0.5562\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8702 - acc: 0.9246 - val_loss: 2.9054 - val_acc: 0.5652\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 12s 1ms/step - loss: 1.8078 - acc: 0.9353 - val_loss: 2.8355 - val_acc: 0.5861\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.7393 - acc: 0.9588 - val_loss: 2.9162 - val_acc: 0.5462\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6927 - acc: 0.9633 - val_loss: 2.9119 - val_acc: 0.5580\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6397 - acc: 0.9749 - val_loss: 2.9272 - val_acc: 0.5471\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6025 - acc: 0.9766 - val_loss: 2.8899 - val_acc: 0.5598\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.5525 - acc: 0.9874 - val_loss: 2.8936 - val_acc: 0.5679\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 1.5180 - acc: 0.9881 - val_loss: 2.9478 - val_acc: 0.5625\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.4940 - acc: 0.9874 - val_loss: 2.9418 - val_acc: 0.5643\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4656 - acc: 0.9887 - val_loss: 3.0195 - val_acc: 0.5444\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4372 - acc: 0.9900 - val_loss: 2.8822 - val_acc: 0.5815\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4216 - acc: 0.9858 - val_loss: 2.9510 - val_acc: 0.5607\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8829/8829 [==============================] - 64s 7ms/step - loss: 3.5662 - acc: 0.4579 - val_loss: 3.2907 - val_acc: 0.5136\n",
      "Epoch 2/150\n",
      "8829/8829 [==============================] - 14s 2ms/step - loss: 3.1228 - acc: 0.5741 - val_loss: 3.2285 - val_acc: 0.5362\n",
      "Epoch 3/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.9344 - acc: 0.6317 - val_loss: 3.1868 - val_acc: 0.5408\n",
      "Epoch 4/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 2.7887 - acc: 0.6752 - val_loss: 3.1270 - val_acc: 0.5553\n",
      "Epoch 5/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.6553 - acc: 0.7204 - val_loss: 3.0731 - val_acc: 0.5534\n",
      "Epoch 6/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.5060 - acc: 0.7641 - val_loss: 3.0637 - val_acc: 0.5634\n",
      "Epoch 7/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.4015 - acc: 0.7970 - val_loss: 3.0200 - val_acc: 0.5688\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.2867 - acc: 0.8335 - val_loss: 3.0562 - val_acc: 0.5534\n",
      "Epoch 9/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.1791 - acc: 0.8632 - val_loss: 3.0010 - val_acc: 0.5679\n",
      "Epoch 10/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0904 - acc: 0.8829 - val_loss: 3.0114 - val_acc: 0.5562\n",
      "Epoch 11/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 2.0020 - acc: 0.8981 - val_loss: 2.9639 - val_acc: 0.5679\n",
      "Epoch 12/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8991 - acc: 0.9326 - val_loss: 2.9696 - val_acc: 0.5670\n",
      "Epoch 13/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.8283 - acc: 0.9438 - val_loss: 3.0462 - val_acc: 0.5480\n",
      "Epoch 14/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.7586 - acc: 0.9554 - val_loss: 2.9690 - val_acc: 0.5679\n",
      "Epoch 15/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6928 - acc: 0.9627 - val_loss: 2.8809 - val_acc: 0.5824\n",
      "Epoch 16/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.6284 - acc: 0.9736 - val_loss: 2.9416 - val_acc: 0.5661\n",
      "Epoch 17/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.5676 - acc: 0.9814 - val_loss: 2.9577 - val_acc: 0.5707\n",
      "Epoch 18/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.5535 - acc: 0.9701 - val_loss: 2.9469 - val_acc: 0.5661\n",
      "Epoch 19/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.4940 - acc: 0.9781 - val_loss: 2.8555 - val_acc: 0.5652\n",
      "Epoch 20/150\n",
      "8829/8829 [==============================] - 15s 2ms/step - loss: 1.4367 - acc: 0.9856 - val_loss: 2.9224 - val_acc: 0.5553\n",
      "Epoch 21/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.4134 - acc: 0.9790 - val_loss: 2.8863 - val_acc: 0.5679\n",
      "Epoch 22/150\n",
      "8829/8829 [==============================] - 13s 2ms/step - loss: 1.3984 - acc: 0.9732 - val_loss: 2.9449 - val_acc: 0.5697\n",
      "Epoch 23/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.3490 - acc: 0.9771 - val_loss: 2.8573 - val_acc: 0.5616\n",
      "Epoch 24/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.3225 - acc: 0.9750 - val_loss: 2.8852 - val_acc: 0.5571\n",
      "Epoch 25/150\n",
      "8829/8829 [==============================] - 13s 1ms/step - loss: 1.2694 - acc: 0.9838 - val_loss: 2.8393 - val_acc: 0.5688\n",
      "Train on 8829 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "8704/8829 [============================>.] - ETA: 0s - loss: nan - acc: 0.0694"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d9922953424f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m              num_iterations = 150, size_batch=trial.parameters[\"batch_size\"])\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e16d9a6f434a>\u001b[0m in \u001b[0;36msimple_NN\u001b[0;34m(study, trial, X_train, X_test, y_train, y_test, regularization, drop_likely, learning_rate, beta1, beta2, num_iterations, size_batch, activation)\u001b[0m\n\u001b[1;32m     37\u001b[0m     nn_history = model.fit(X_train, y_train, batch_size=size_batch, epochs=num_iterations, \n\u001b[1;32m     38\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                           callbacks=[es, study.keras_callback(trial, objective_name='val_acc')])\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = np.load(\"../../splitdata.npy\", allow_pickle=True)\n",
    "\n",
    "parameters = [sherpa.Continuous(name='lr', range=[0.0001, 0.1], scale='log'),\n",
    "              sherpa.Continuous(name='beta1', range=[0.85, 1.0], scale='log'),\n",
    "              sherpa.Continuous(name=\"regularization\", range=[0.0001, 1], scale='log'),\n",
    "              sherpa.Continuous(name='dropout', range=[0.0, 0.5]),\n",
    "              sherpa.Ordinal(name='batch_size', range=[16, 32, 64,128,256,512,1024, X_train.shape[0]]),\n",
    "              sherpa.Choice(name='activation', range=['relu', 'elu', 'prelu', 'tanh'])]\n",
    "\n",
    "alg =bayesian_optimization.GPyOpt()\n",
    "\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,dashboard_port=9998,disable_dashboard=False,\n",
    "                     lower_is_better=False)\n",
    "\n",
    "for trial in study:\n",
    "    simple_NN(study, trial, X_train, X_val, y_train, y_val, regularization =trial.parameters['regularization'],\n",
    "              drop_likely = trial.parameters['dropout'],\n",
    "              learning_rate = trial.parameters['lr'],\n",
    "              beta1 = trial.parameters['beta1'], beta2 = 0.999,\n",
    "             num_iterations = 150, size_batch=trial.parameters[\"batch_size\"])\n",
    "    study.finalize(trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_TESS, X_test_TESS, y_train_TESS, y_test_TESS = emotex_lib.x_y_split(data_TESS, fs_TESS, y_TESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TESS, fs_TESS, y_TESS = emotex_lib.data_extract_tess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TESS, X_test_TESS, y_train_TESS, y_test_TESS = emotex_lib.x_y_split(data_TESS, fs_TESS, y_TESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = simple_NN(X_train_TESS, X_test_TESS, y_train_TESS, y_test_TESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREMA DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CREMA, fs_CREMA, y_CREMA = emotex_lib.data_extract_CREMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CREMA, X_test_CREMA, y_train_CREMA, y_test_CREMA = emotex_lib.x_y_split(data_CREMA, fs_CREMA, y_CREMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = simple_NN(X_train_CREMA, X_test_CREMA, y_train_CREMA, y_test_CREMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, fs, x_size = emotex_lib.data_extraction_RAVDESS('../../RAVDESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',1380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = []\n",
    "for i in range(len(X_train)):\n",
    "    X_train_final.append([[x]for x in  X_train[i]])\n",
    "X_train = np.asarray(X_train_final)\n",
    "X_test_final = []\n",
    "for i in range(len(X_test)):\n",
    "    X_test_final.append([[x]for x in  X_test[i]])\n",
    "X_test = np.asarray(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "def simple_NN(X_train, X_test, y_train, y_test, regularization = 0.1,drop_likely = 0.1,\n",
    "              learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999,\n",
    "             num_iterations = 40, size_batch=256,\n",
    "             activation = 'tanh'):\n",
    "    target_class = y_train.shape[1]\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=X_train.shape[1],  activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(1024, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(512, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(target_class, activation='softmax'))\n",
    "    \n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_acc', mode='max',  patience=2, min_delta=0.01)\n",
    "    \n",
    "    opt = keras.optimizers.Adam(lr=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=10e-8)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    nn_history = model.fit(X_train, y_train, batch_size=size_batch, epochs=num_iterations, \n",
    "                         validation_data=(X_test, y_test),callbacks=[es])\n",
    "    return model, nn_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =np.load(\"RAVDESS_X_Y_train_test.npy\",  allow_pickle=True)\n",
    "model, nn_history = simple_NN(X_train, X_test, y_train, y_test, num_iterations=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =np.load(\"RAVDESS_X_Y_train_test.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_features , all_y = np.load('../../../most_of_the_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_NN(X_train, X_test, y_train, y_test, regularization = 0.1,drop_likely = 0.1,\n",
    "              learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999\n",
    "             num_iterations = 40, size_batch=X_train.shape[0],\n",
    "             activation = 'tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_iterations(best_reg):\n",
    "    iterations = np.arange(2, 200, 5)\n",
    "    validation_history = []\n",
    "    train_history = []\n",
    "    for one_reg in regularization:\n",
    "        model, nn_history = simple_NN(X_train, X_test, y_train, y_test, num_iterations=iterations,\n",
    "                                      regularization=best_reg)\n",
    "        validation_history.append(nn_history.history['val_acc'])\n",
    "        train_history.append(nn_history.history['acc'])\n",
    "    plt.plot(regularization, validation_history, label='validation')\n",
    "    plt.plot(regularization, train_history, label='training')\n",
    "    plt.show()\n",
    "    return iterations[np.argmex(validation_history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "def graph_regularization(num_iterations, ranges):\n",
    "    regularization = [10**c for c in -4.0 * np.arange(0.,1.0,ranges,dtype=float)]\n",
    "    validation_history = []\n",
    "    best_iteration = []\n",
    "    train_history = []\n",
    "    for one_reg in regularization:\n",
    "        \n",
    "        model, nn_history = simple_NN(X_train, X_test, y_train, y_test, num_iterations=num_iterations,\n",
    "                                      regularization=one_reg)\n",
    "        \n",
    "        validation_history.append(np.amax(nn_history.history['val_acc']))\n",
    "        train_history.append(np.amax(nn_history.history['acc']))\n",
    "        best_iteration.append(np.argmax(nn_history.history['val_acc']))\n",
    "                                  \n",
    "    print(train_history, validation_history, regularization)\n",
    "    plt.plot(regularization, validation_history, label='validation')\n",
    "    plt.plot(regularization, train_history, label='training')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    index = np.argmax(validation_history)\n",
    "    return regularization[index], best_iteration[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_regularization(65, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sherpa\n",
    "import sherpa.algorithms.bayesian_optimization as bayesian_optimization\n",
    "import time\n",
    "\n",
    "parameters = [sherpa.Continuous(name='lr', range=[0.0001, 0.1], scale='log'),\n",
    "              sherpa.Continuous(name='beta1', range=[0.8, 1.0], scale='log'),\n",
    "              sherpa.Continuous(name=\"regularization\", range=[0.0001, 3], scale='log'),\n",
    "              sherpa.Continuous(name='dropout', range=[0.0, 0.5]),\n",
    "              sherpa.Ordinal(name='batch_size', range=[16, 32, 64,128,256,512]),\n",
    "              sherpa.Choice(name='activation', range=['relu', 'elu', 'prelu', 'tanh'])]\n",
    "\n",
    "alg =bayesian_optimization.GPyOpt()\n",
    "\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,dashboard_port=9999,disable_dashboard=False,\n",
    "                     lower_is_better=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for trial in study:\n",
    "    simple_NN(study, trial, X_train, X_test, y_train, y_test, regularization =trial.parameters['regularization'],\n",
    "              drop_likely = trial.parameters['dropout'],\n",
    "              learning_rate = trial.parameters['lr'],\n",
    "              beta1 = trial.parameters['beta1'], beta2 = 0.999,\n",
    "             num_iterations = 150, size_batch=trial.parameters[\"batch_size\"])\n",
    "    study.finalize(trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "space  = [Integer(1, 5, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(1, n_features, name='max_features'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=True)\n",
    "\n",
    "for trial in study:\n",
    "    simple_NN(study, trial, X_train, X_test, y_train, y_test, regularization =trial.parameters['regularization'],\n",
    "              drop_likely = trial.parameters['dropout'],\n",
    "              learning_rate = trial.parameters['lr'],\n",
    "              beta1 = trial.parameters['beta1'], beta2 = 0.999,\n",
    "             num_iterations = 5, size_batch=trial.parameters[\"batch_size\"])\n",
    "    study.finalize(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "def simple_NN(study, trial, X_train, X_test, y_train, y_test, regularization = 0.1,drop_likely = 0.1,\n",
    "              learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999,\n",
    "             num_iterations = 40, size_batch=X_train.shape[0],\n",
    "             activation = 'tanh'):\n",
    "    target_class = y_train.shape[1]\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=X_train.shape[1], \n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(2048, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(drop_likely))\n",
    "    \n",
    "    model.add(Dense(1024, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(512, activation=activation,\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "\n",
    "    model.add(Dense(target_class, activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(lr=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=10e-8)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    nn_history = model.fit(X_train, y_train, batch_size=size_batch, epochs=num_iterations, \n",
    "                         validation_data=(X_test, y_test),\n",
    "                          callbacks=[study.keras_callback(trial, objective_name='val_acc')])\n",
    "    \n",
    "    \n",
    "    return model, nn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_train, X_test, y_train, y_test):\n",
    "    a = model.predict(X_train)\n",
    "    predictions = np.zeros_like(a)\n",
    "    predictions[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    print(predictions)\n",
    "    print(y_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    a = model.predict(X_test)\n",
    "    predictions = np.zeros_like(a)\n",
    "    predictions[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_cnn(X_train, X_test, y_train, y_test):\n",
    "    # Set the target class number\n",
    "    target_class = y_train.shape[1]\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1], 1))) #1\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Conv1D(256, 8, padding='same')) #2\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, 8, padding='same')) #3\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh')) \n",
    "    model.add(Conv1D(128, 8, padding='same')) #4\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Conv1D(128, 8, padding='same')) #5\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Conv1D(128, 8, padding='same')) #6\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(64, 8, padding='same')) #7\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Conv1D(64, 8, padding='same')) #8\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(target_class)) #9\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt,metrics=[keras.metrics.categorical_accuracy])\n",
    "    cnnhistory = model.fit(X_train, y_train, batch_size=128, epochs=40, \n",
    "                         validation_data=(X_test, y_test))\n",
    "    a = model.predict(X_train)\n",
    "    predictions = np.zeros_like(a)\n",
    "    predictions[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    print(predictions)\n",
    "    print(y_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    a = model.predict(X_test)\n",
    "    predictions = np.zeros_like(a)\n",
    "    predictions[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    print(classification_report(y_test,predictions))\n",
    "    return model, cnnhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " model, cnnhistory = complex_cnn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = complex_cnn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz = model.predict(X_train)\n",
    "xz[np.where(xz==np.max(xz))] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = complex_cnn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_NN(X_train, X_test, y_train, y_test):\n",
    "    target_class = y_train.shape[1]\n",
    "    regularization = 0.01\n",
    "    dropout= 0.25\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1024, input_dim=X_train.shape[1], \n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(4096, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2048, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(Dense(1024, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(512, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(256, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(128, activation='tanh',\n",
    "                   kernel_regularizer=regularizers.l2(regularization)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dense(target_class, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=X_train.shape[0], epochs=60, \n",
    "                         validation_data=(X_test, y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, cnnhistory = complex_cnn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DELETE\", (X,fs,x_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,fs,x_size) = np.load(\"DELETE.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =np.load(\"RAVDESS_X_Y_train_test.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"RAVDESS_X_Y_train_test\", (X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_extraction_RAVDESS(folder_location, number_examples):\n",
    "    nu_emotion = 8\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    directory = os.fsencode(folder_location)\n",
    "    for file_name in os.listdir(directory):\n",
    "        if  str(file_name) != \"b'.DS_Store'\":\n",
    "            emotion = str(file_name)[2:-1]\n",
    "            i = (emotion.split('-')[2])\n",
    "            if i == '01': # neutral \n",
    "                y[0][counter] = 1\n",
    "            elif i == '02': #calm\n",
    "                 y[1][counter] = 1\n",
    "            elif i == '03': #hahppy \n",
    "                 y[2][counter] = 1\n",
    "            elif i == '04': #sad\n",
    "                 y[3][counter] = 1\n",
    "            elif i == '05': #angry\n",
    "                 y[4][counter] = 1\n",
    "            elif i == '06': #fearful\n",
    "                 y[5][counter] = 1\n",
    "            elif i == '07': #disgust\n",
    "                 y[6][counter] = 1\n",
    "            elif i == '08': #surprised\n",
    "                 y[7][counter] = 1\n",
    "            else:\n",
    "                print(i)\n",
    "                break\n",
    "            counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize dataset and test set\n",
    "# dropout regularization\n",
    "# L2 regularization\n",
    "# early stopping\n",
    "#  torrent the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))\n",
    "seed = 20\n",
    "num_labels =15\n",
    "num_features = X_train.shape[1]\n",
    "# build model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=num_features, activation='softmax'))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    model.add(Dense(output_dim = num_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adadelta(), metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "def big_boy_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def complex_layers():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 5,padding='same', input_shape=( 11,13, 1))) #1\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #2\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #3\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #5\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #6\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10)) #7\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    return model\n",
    "def easy_NN():\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = X\n",
    "MFCC2 = []\n",
    "for one_sound in np_data:\n",
    "    one_sound = np.asarray(one_sound)\n",
    "    MFCC2.append(python_speech_features.base.mfcc(one_sound, samplerate=fs, \n",
    "                                 winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                 nfilt=26, nfft=1200).T)\n",
    "MFCC3 = []\n",
    "cached_variables = []\n",
    "for one_point in MFCC2:\n",
    "    cache_grad = (np.gradient(one_point, axis = 1))\n",
    "    cached_variables.append([np.mean(one_point, axis = 1), np.median(one_point, axis = 1),\n",
    "                             np.var(one_point, axis = 1), \n",
    "                       np.min(one_point, axis = 1), np.max(one_point, axis = 1), \n",
    "                             np.mean(cache_grad, axis = 1), np.var(cache_grad, axis = 1)])\n",
    "return cached_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(one_point, axis = 1).shape, np.median(one_point, axis = 1).shape,np.var(one_point, axis = 1).shape, np.min(one_point, axis = 1).shape, np.max(one_point, axis = 1).shape, np.mean(cache_grad, axis = 1).shape, np.var(cache_grad, axis = 1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(please.T, axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MFCC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MFCC2[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.gradient(MFCC2[0], axis = 1)), len(np.gradient(MFCC2[0], axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
