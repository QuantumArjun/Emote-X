{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import pysptk\n",
    "from  conch.analysis.formants import lpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDPASS_FREQ = [300, 3400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Process Sound Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    sos = butter(order, [low, high], btype='band', analog=False, output='sos')\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = sosfiltfilt(sos, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_silence_from(amplitudes, threshold):\n",
    "    silenced = []\n",
    "    for x in amplitudes:\n",
    "        if x >= threshold:\n",
    "            silenced.append(x)\n",
    "    return silenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_location):\n",
    "    BANDPASS_FREQ = [300, 3400]\n",
    "    fs, data = wavfile.read(file_location)\n",
    "    number_of_samples = data.shape[0]\n",
    "    meta_data = open(r\"LDC2002S28band-txt.txt\")\n",
    "    meta_data = pd.read_csv(\"LDC2002S28-txt.txt\", sep=\"A:\", header=None, engine='python')\n",
    "    meta_data.columns = [\"sound limits\",\"description\"]\n",
    "    \n",
    "    #dual channel to one channel\n",
    "    data = np.average(data, axis = 1)\n",
    "    #remove noise\n",
    "    data = butter_bandpass_filter(data, BANDPASS_FREQ[0], BANDPASS_FREQ[1], fs)\n",
    "    \n",
    "    # removee extra data pointts\n",
    "    meta_data = meta_data[meta_data.description != ' [MISC]']\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith(' (')]\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith(' Emotion category elation')]\n",
    "    meta_data = meta_data[~meta_data['description'].astype(str).str.startswith('  [MISC]')]\n",
    "\n",
    "    # description and time limits \n",
    "    voice_time_limits = meta_data[\"sound limits\"]\n",
    "    voice_time_limits = [i.split(\" \")[0:2] for i in voice_time_limits]\n",
    "    voice_time_limits = np.array(voice_time_limits)\n",
    "    voice_time_limits = voice_time_limits.astype(np.float)\n",
    "    description = meta_data[\"description\"]\n",
    "    description = [i.split(\",\")[0].strip() for i in description]\n",
    "\n",
    "    #divide the dataa set\n",
    "    divided_data = []\n",
    "    for i in voice_time_limits:\n",
    "        startingpoint = int(i[0]*fs)\n",
    "        endingpoint = int(i[1]*fs)\n",
    "        divided_data.append(data[startingpoint:endingpoint])\n",
    "    np_data = np.asarray(divided_data)\n",
    "    return np_data, description, len(divided_data), fs\n",
    "def data_extraction_RAVDESS(file_location):\n",
    "    divided_data = []\n",
    "    directory = os.fsencode(folder_location)\n",
    "    for file_name in os.listdir(directory):\n",
    "        if  str(file_name) != \"b'.DS_Store'\":\n",
    "            (sig, rate) = librosa.load(folder_location+'/'+str(file_name)[2:-1], sr=None)\n",
    "            data = butter_bandpass_filter(sig, BANDPASS_FREQ[0], BANDPASS_FREQ[1], rate)\n",
    "            data = normalize(data)\n",
    "            divided_data.append(data)\n",
    "    np_data = np.asarray(divided_data)\n",
    "    number_examples = np_data.shape[0]\n",
    "    return divided_data, number_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC_algorithm(np_data, fs):\n",
    "        # MFCC function taking the first thirteen coef\n",
    "    MFCC2 = []\n",
    "    for i in np_data:\n",
    "        i = np.asarray(i)\n",
    "        MFCC2.append(python_speech_features.base.mfcc(i, samplerate=fs, \n",
    "                                     winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                     nfilt=26, nfft=552))\n",
    "        \n",
    "    # gather information from the MFCC (feature extraction)\n",
    "    MFCC3 = []\n",
    "    cache = {}\n",
    "    for data_point in MFCC2:\n",
    "        for time_segment in data_point:\n",
    "            if (data_point[0] == time_segment).all():\n",
    "                for i in range(13):\n",
    "                    cache[i] = [time_segment[i]]\n",
    "            else:\n",
    "                for i in range(13):\n",
    "                    cache[i] = np.concatenate((cache[i], [time_segment[i]]))\n",
    "        cached_variables = []\n",
    "        cache_grad = []\n",
    "        for i in range(13):\n",
    "            cache_grad.append(np.gradient(cache[i]))\n",
    "            cached_variables.append([np.mean(cache[i]), np.median(cache[i]), np.var(cache[i]), \n",
    "                               np.min(cache[i]), np.max(cache[i]), \n",
    "                                     np.mean(cache_grad[i]), np.var(cache_grad[i])])\n",
    "        MFCC3.append(np.hstack(np.hstack(cached_variables)))\n",
    "    return MFCC3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch_vector(data, fs):\n",
    "    data = np.float32(data)\n",
    "    pitch = pysptk.sptk.rapt(data, fs, hopsize = 50)\n",
    "    silenced = remove_silence_from(pitch, np.mean(pitch))\n",
    "    return silenced\n",
    "\n",
    "def get_pitch_stats(np_array, fs):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        pitch_vector = get_pitch_vector(data, fs)\n",
    "        stats = get_stats(pitch_vector)\n",
    "        stats_matrix.append(stats)\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_vector(data, fs):\n",
    "    data = np.float32(data)\n",
    "    cent = librosa.feature.spectral_centroid(y=data, sr=fs)\n",
    "    return cent\n",
    "def get_spectral_stats(np_array, fs):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        spectral_vector = get_spectral_vector(data, fs)\n",
    "        stats = get_stats(spectral_vector)\n",
    "        stats_matrix.append(stats)\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lpc_vector(data):\n",
    "    vec = lpc.lpc_ref(data, 12)\n",
    "    return vec\n",
    "def get_lpc_stats(np_array):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        lpc_vector = get_lpc_vector(data)\n",
    "        stats_matrix.append(lpc_vector[1:])  #remove the first number, it's not useful\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms_vector(data):\n",
    "    temp_data = np.float32(data)\n",
    "    cent = librosa.feature.rms(y=temp_data)\n",
    "    return cent\n",
    "def get_rms_stats(np_array):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        rms_vector = get_rms_vector(data)\n",
    "        stats = get_stats(rms_vector)\n",
    "        stats_matrix.append(stats)\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_vector(data):\n",
    "    temp_data = np.float32(data)\n",
    "    cent = librosa.feature.zero_crossing_rate(y=temp_data)\n",
    "    return cent\n",
    "def get_zero_stats(np_array):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        zero_vector = get_zero_vector(data)\n",
    "        stats = get_stats(zero_vector)\n",
    "        stats_matrix.append(stats)\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sr_vector(data):\n",
    "    temp_data = np.float32(data)\n",
    "    cent = librosa.feature.spectral_rolloff(y=temp_data)\n",
    "    return cent\n",
    "def get_sr_stats(np_array):\n",
    "    stats_matrix = []\n",
    "    for data in np_array:\n",
    "        sr_vector = get_sr_vector(data)\n",
    "        stats = get_stats(sr_vector)\n",
    "        stats_matrix.append(stats)\n",
    "    return stats_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(pitch_vector):\n",
    "    mean = np.mean(pitch_vector)\n",
    "    median = np.median(pitch_vector)\n",
    "    low = np.min(pitch_vector)\n",
    "    high = np.max(pitch_vector)\n",
    "    variance = np.var(pitch_vector)\n",
    "    \n",
    "    #derivative\n",
    "    derivative = np.diff(pitch_vector)\n",
    "    d_mean = np.mean(derivative)\n",
    "    d_min = np.min(derivative)\n",
    "    d_max = np.max(derivative)\n",
    "    return [mean, median, low, high, variance, d_mean, d_min, d_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emotional extraction\n",
    "given an array of the emotions it converts the array to a number, if an emotion is not there it will print it out and break the loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_extraction(description, number_examples):\n",
    "    nu_emotion = 15\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    for i in description:\n",
    "        X0 = np.zeros((number_examples,1))\n",
    "        if i == 'neutral':\n",
    "            y[0][counter] = 1\n",
    "        elif i == 'disgust':\n",
    "             y[1][counter] = 1\n",
    "        elif i == 'panic':\n",
    "             y[2][counter] = 1\n",
    "        elif i == 'anxiety':\n",
    "             y[3][counter] = 1\n",
    "        elif i == 'hot anger':\n",
    "             y[4][counter] = 1\n",
    "        elif i == 'cold anger':\n",
    "             y[5][counter] = 1\n",
    "        elif i == 'despair':\n",
    "             y[6][counter] = 1\n",
    "        elif i == 'sadness':\n",
    "             y[7][counter] = 1\n",
    "        elif i == 'elation':\n",
    "             y[8][counter] = 1\n",
    "        elif i == 'happy':\n",
    "             y[9][counter] = 1\n",
    "        elif i == 'interest':\n",
    "             y[10][counter] = 1\n",
    "        elif i == 'boredom':\n",
    "             y[11][counter] = 1\n",
    "        elif i == 'shame':\n",
    "             y[12][counter] = 1\n",
    "        elif i == 'pride':\n",
    "             y[13][counter] = 1\n",
    "        elif i == 'contempt':\n",
    "             y[14][counter] = 1\n",
    "        else:\n",
    "            print(i)\n",
    "            break\n",
    "        counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y\n",
    "def emotion_extraction_RAVDESS(folder_location, number_examples):\n",
    "    nu_emotion = 8\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    directory = os.fsencode(folder_location)\n",
    "    for file_name in os.listdir(directory):\n",
    "        if  str(file_name) != \"b'.DS_Store'\":\n",
    "            emotion = str(file_name)[2:-1]\n",
    "            i = (emotion.split('-')[3])\n",
    "            if i == '01': # neutral \n",
    "                y[0][counter] = 1\n",
    "            elif i == '02': #calm\n",
    "                 y[1][counter] = 1\n",
    "            elif i == '03': #hahppy \n",
    "                 y[2][counter] = 1\n",
    "            elif i == '04': #sad\n",
    "                 y[3][counter] = 1\n",
    "            elif i == '05': #angry\n",
    "                 y[4][counter] = 1\n",
    "            elif i == '06': #fearful\n",
    "                 y[5][counter] = 1\n",
    "            elif i == '07': #disgust\n",
    "                 y[6][counter] = 1\n",
    "            elif i == '08': #surprised\n",
    "                 y[7][counter] = 1\n",
    "            else:\n",
    "                print(i)\n",
    "                break\n",
    "            counter +=1\n",
    "    y = np.transpose(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready Dataset and output\n",
    "Put all of the extracted features into X and the classifications into y and split into training and testing group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_split(filepath):\n",
    "    data, description, data_len, fs = extract_data(filepath)\n",
    "    x = MFCC_algorithm(data, fs)\n",
    "    x1 = get_pitch_stats(data, fs)\n",
    "    x2 = get_spectral_stats(data, fs)\n",
    "    x3 = get_lpc_stats(data)\n",
    "    x4 = get_rms_stats(data)\n",
    "    x5 = get_sr_stats(data)\n",
    "    x6 = get_zero_stats(data)\n",
    "    x = np.concatenate((x,x1,x2,x3,x4, x5, x6), axis=1)\n",
    "    y = emotion_extraction(description, data_len)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    num_labels = y_train.shape[1]\n",
    "    num_features = X_train.shape[1]\n",
    "    print(\"x train shape: \" +str(X_train.shape))\n",
    "    print(\"y train shape: \" +str(y_train.shape))\n",
    "    print(\"x test shape: \" +str(X_test.shape))\n",
    "    print(\"y test shape: \" +str(y_test.shape))\n",
    "    for i in range(num_labels):\n",
    "        print(\"y_train for emotion \"+str(i)+\": \"+ str(np.sum(y_train[:,i])))\n",
    "    for i in range(num_labels): \n",
    "        print(\"y_test for emotion \"+str(i)+\": \"+ str(np.sum(y_test[:,i])))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
