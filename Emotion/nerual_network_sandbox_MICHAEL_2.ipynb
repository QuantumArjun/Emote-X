{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import osascript\n",
    "from gtts import gTTS \n",
    "import os \n",
    "import pyaudio\n",
    "import wave\n",
    "import keyboard  # using module keyboard\n",
    "import soundfile as sf\n",
    "import math\n",
    "import pyloudnorm as pyln\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import librosa\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import python_speech_features\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.Pitch_vector import get_pitch_stats\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "import time\n",
    "import  ipynb.fs.full.concat_project2 as emotex_lib\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import keras as keras\n",
    "from  conch.analysis.formants import lpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3a3d670ec89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotex_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_extraction_RAVDESS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../RAVDESS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/loudness/Emote-X/Emotion/concat_project2.ipynb\u001b[0m in \u001b[0;36mdata_extraction_RAVDESS\u001b[0;34m(folder_location)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"            silenced.append(x)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;34m\"    return silenced\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m    ]\n\u001b[0m\u001b[1;32m    124\u001b[0m   },\n\u001b[1;32m    125\u001b[0m   {\n",
      "\u001b[0;32m~/Desktop/loudness/Emote-X/Emotion/concat_project2.ipynb\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(snd_data)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"# Constants\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m    ]\n\u001b[0;32m---> 66\u001b[0;31m   },\n\u001b[0m\u001b[1;32m     67\u001b[0m   {\n\u001b[1;32m     68\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/loudness/Emote-X/Emotion/concat_project2.ipynb\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"# Constants\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m    ]\n\u001b[0;32m---> 66\u001b[0;31m   },\n\u001b[0m\u001b[1;32m     67\u001b[0m   {\n\u001b[1;32m     68\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, fs, x_size = emotex_lib.data_extraction_RAVDESS('../../RAVDESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',1380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=10000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_cnn(X_train_test_splitain, X_test, y_train, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 5,padding='same', input_shape=(X_train[1],1))) #1\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #2\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #3\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Conv1D(128, 5,padding='same')) #4\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Conv1D(128, 5,padding='same')) #5\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #6\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10)) #7\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    cnnhistory=model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.14      0.20        69\n",
      "           1       0.71      0.35      0.47       150\n",
      "           2       0.28      0.15      0.19       149\n",
      "           3       0.64      0.05      0.09       138\n",
      "           4       0.58      0.40      0.47       149\n",
      "           5       0.20      0.64      0.31       150\n",
      "           6       0.47      0.25      0.33       147\n",
      "           7       0.37      0.48      0.42       152\n",
      "\n",
      "   micro avg       0.34      0.32      0.33      1104\n",
      "   macro avg       0.45      0.31      0.31      1104\n",
      "weighted avg       0.45      0.32      0.32      1104\n",
      " samples avg       0.25      0.32      0.27      1104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.26      0.32        23\n",
      "           1       0.45      0.26      0.33        34\n",
      "           2       0.35      0.17      0.23        35\n",
      "           3       0.25      0.02      0.04        46\n",
      "           4       0.20      0.11      0.15        35\n",
      "           5       0.19      0.68      0.29        34\n",
      "           6       0.19      0.11      0.14        37\n",
      "           7       0.31      0.44      0.36        32\n",
      "\n",
      "   micro avg       0.25      0.24      0.25       276\n",
      "   macro avg       0.29      0.26      0.23       276\n",
      "weighted avg       0.29      0.24      0.22       276\n",
      " samples avg       0.18      0.24      0.20       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DELETE\", (X,fs,x_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,fs,x_size) = np.load(\"DELETE.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = emotex_lib.emotion_extraction_RAVDESS('../../RAVDESS',x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =np.load(\"RAVDESS_X_Y_train_test.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = emotex_lib.x_y_split(X, fs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"RAVDESS_X_Y_train_test\", (X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_extraction_RAVDESS(folder_location, number_examples):\n",
    "    nu_emotion = 8\n",
    "    y = np.zeros(shape=(nu_emotion, number_examples))\n",
    "    counter = 0\n",
    "    directory = os.fsencode(folder_location)\n",
    "    for file_name in os.listdir(directory):\n",
    "        if  str(file_name) != \"b'.DS_Store'\":\n",
    "            emotion = str(file_name)[2:-1]\n",
    "            i = (emotion.split('-')[2])\n",
    "            if i == '01': # neutral \n",
    "                y[0][counter] = 1\n",
    "            elif i == '02': #calm\n",
    "                 y[1][counter] = 1\n",
    "            elif i == '03': #hahppy \n",
    "                 y[2][counter] = 1\n",
    "            elif i == '04': #sad\n",
    "                 y[3][counter] = 1\n",
    "            elif i == '05': #angry\n",
    "                 y[4][counter] = 1\n",
    "            elif i == '06': #fearful\n",
    "                 y[5][counter] = 1\n",
    "            elif i == '07': #disgust\n",
    "                 y[6][counter] = 1\n",
    "            elif i == '08': #surprised\n",
    "                 y[7][counter] = 1\n",
    "            else:\n",
    "                print(i)\n",
    "                break\n",
    "            counter +=1\n",
    "    y = np.transpose(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize dataset and test set\n",
    "# dropout regularization\n",
    "# L2 regularization\n",
    "# early stopping\n",
    "#  torrent the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03        69\n",
      "           1       0.87      0.32      0.47       150\n",
      "           2       1.00      0.02      0.04       149\n",
      "           3       0.81      0.16      0.27       138\n",
      "           4       0.50      0.03      0.06       149\n",
      "           5       0.91      0.07      0.12       150\n",
      "           6       0.80      0.05      0.10       147\n",
      "           7       0.78      0.05      0.09       152\n",
      "\n",
      "   micro avg       0.83      0.09      0.17      1104\n",
      "   macro avg       0.83      0.09      0.15      1104\n",
      "weighted avg       0.82      0.09      0.15      1104\n",
      " samples avg       0.09      0.09      0.09      1104\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.53      0.24      0.33        34\n",
      "           2       0.00      0.00      0.00        35\n",
      "           3       0.21      0.07      0.10        46\n",
      "           4       0.00      0.00      0.00        35\n",
      "           5       0.25      0.03      0.05        34\n",
      "           6       0.00      0.00      0.00        37\n",
      "           7       1.00      0.06      0.12        32\n",
      "\n",
      "   micro avg       0.31      0.05      0.09       276\n",
      "   macro avg       0.25      0.05      0.07       276\n",
      "weighted avg       0.25      0.05      0.08       276\n",
      " samples avg       0.04      0.05      0.05       276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "MLPalgorithm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPalgorithm(X_train, X_test, y_train, y_test):\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    mlp.fit(X_train,y_train)\n",
    "    predictions = mlp.predict(X_train)\n",
    "\n",
    "    print(classification_report(y_train,predictions))\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(classification_report(y_test,predictions))\n",
    "seed = 20\n",
    "num_labels =15\n",
    "num_features = X_train.shape[1]\n",
    "# build model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=num_features, activation='softmax'))\n",
    "    model.add(Dense(30, activation='softmax'))\n",
    "    model.add(Dense(output_dim = num_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adadelta(), metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "def big_boy_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def complex_layers():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 5,padding='same', input_shape=( 11,13, 1))) #1\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #2\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #3\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #5\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(128, 5,padding='same')) #6\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10)) #7\n",
    "    model.add(Activation('softmax'))\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "    return model\n",
    "def easy_NN():\n",
    "    mlp = MLPClassifier(max_iter=15000)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = X\n",
    "MFCC2 = []\n",
    "for one_sound in np_data:\n",
    "    one_sound = np.asarray(one_sound)\n",
    "    MFCC2.append(python_speech_features.base.mfcc(one_sound, samplerate=fs, \n",
    "                                 winlen=0.025, winstep=0.01, numcep=13, \n",
    "                                 nfilt=26, nfft=1200).T)\n",
    "MFCC3 = []\n",
    "cached_variables = []\n",
    "for one_point in MFCC2:\n",
    "    cache_grad = (np.gradient(one_point, axis = 1))\n",
    "    cached_variables.append([np.mean(one_point, axis = 1), np.median(one_point, axis = 1),\n",
    "                             np.var(one_point, axis = 1), \n",
    "                       np.min(one_point, axis = 1), np.max(one_point, axis = 1), \n",
    "                             np.mean(cache_grad, axis = 1), np.var(cache_grad, axis = 1)])\n",
    "return cached_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1423c0470>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot([1,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fcf17bcd7bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'one_point' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(one_point, axis = 1).shape, np.median(one_point, axis = 1).shape,np.var(one_point, axis = 1).shape, np.min(one_point, axis = 1).shape, np.max(one_point, axis = 1).shape, np.mean(cache_grad, axis = 1).shape, np.var(cache_grad, axis = 1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(please.T, axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MFCC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(MFCC2[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.gradient(MFCC2[0], axis = 1)), len(np.gradient(MFCC2[0], axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
